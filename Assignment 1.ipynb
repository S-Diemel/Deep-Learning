{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment 1 2AMM10 2023-2024\n",
    "\n",
    "## Group: [Fill in your group name]\n",
    "### Member 1: [Fill in your name]\n",
    "### Member 2: [Fill in your name]\n",
    "### Member 3: [Fill in your name]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc4f04c033b0e00"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from scipy.spatial.distance import cdist\n",
    "import os\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# function for loading the training data:\n",
    "\n",
    "def load_data(file):\n",
    "    \"\"\"\n",
    "    This function loads the data from the specified pickle file and returns a dictionary with the data\n",
    "    :param filename: the pickle file\n",
    "    :return: dict with data -- keys and values differ for the train data and test data for each task.\n",
    "     Please see the cells with example code below for explanations and examples of the data structure per data set.\n",
    "    \"\"\"\n",
    "    with open(file, 'rb') as f:\n",
    "        data_dict = pickle.load(f)\n",
    "    return data_dict"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d19b9de0e3461531",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data = load_data('train_data.pkl')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0da60a825f5080b",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example alphabet names: ['Alphabet_of_the_Magi', 'Anglo-Saxon_Futhorc', 'Arcadian', 'Armenian', 'Asomtavruli_(Georgian)']\n",
      "\n",
      "\n",
      "how to get an example image for a specific character:\n",
      "shape of image 2 of character character06 of alphabet Asomtavruli_(Georgian): torch.Size([1, 105, 105])\n"
     ]
    }
   ],
   "source": [
    "# the structure of the training data is a dict, where the keys are strings indicating the alphabet.\n",
    "# The values are again dicts, with the keys being the character and the values being a list of images of that character.\n",
    "\n",
    "# see the code below for examples of working with the train data\n",
    "\n",
    "alphabets = list(train_data.keys())\n",
    "\n",
    "\n",
    "print('example alphabet names:', alphabets[:5])\n",
    "print('\\n')\n",
    "print('how to get an example image for a specific character:')\n",
    "\n",
    "alphabet_id = 4\n",
    "alphabet = alphabets[alphabet_id]  # a dict\n",
    "characters_for_this_alphabet = list(train_data[alphabet].keys())\n",
    "character_id = 5\n",
    "character = characters_for_this_alphabet[character_id]\n",
    "image_id = 2\n",
    "\n",
    "print(f'shape of image {image_id} of character {character} of alphabet {alphabet}:', train_data[alphabet][character][image_id].shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "289b9d9817ddf745",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2991163aba746526",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# function for plotting some examples:\n",
    "\n",
    "def plot_example_data(data_dict):\n",
    "    \"\"\"\n",
    "    This function plots some examples of the data\n",
    "    :param data_dict: dict with as keys a string specifying the alphabet, and as values a dict with as keys the character of the alphabet, and as values a list om images of the alphabet\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    alphabets_to_plot = np.random.choice(list(data_dict.keys()), size=10, replace=False)\n",
    "    \n",
    "    for i, alphabet in enumerate(alphabets_to_plot):\n",
    "        characters = data_dict[alphabet]\n",
    "        character_to_plot = np.random.choice(list(characters.keys()), size=1)[0]\n",
    "        images = characters[character_to_plot]\n",
    "        im_idx = np.random.choice(len(images), size=1)[0]\n",
    "        axs[i//5, i%5].imshow(images[im_idx].permute(1, 2, 0))\n",
    "        axs[i//5, i%5].set_title(alphabet + '\\n' + character_to_plot, fontsize=8)\n",
    "        axs[i//5, i%5].axis('off')\n",
    "    # plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f68bfac0812b8988",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1080x432 with 10 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plot_example_data(train_data)\n",
    "# plt.savefig('example_data.png', dpi=600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "511e9fbc1b85e80f",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 1: character recognition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6449bef2185716"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"CNN Builder.\"\"\"\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "\n",
    "        self.front_layer = nn.Sequential(\n",
    "            # Conv Layer block 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Conv Layer block 2\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "            # Conv Layer block 3\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            Lambda(lambda x: x.view(x.size(0), -1)),\n",
    "\n",
    "            nn.Linear(256 * 13 * 13, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.last_layer = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward.\"\"\"\n",
    "        # conv layers\n",
    "        x = self.front_layer(x)\n",
    "        x = self.last_layer(x)\n",
    "        return x\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.forward(x)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f78ab6a6133991a4",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class EmbeddingNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"CNN Builder.\"\"\"\n",
    "        super(EmbeddingNet2, self).__init__()\n",
    "\n",
    "        self.convolutional_layers = nn.Sequential(\n",
    "            # Convolutional Block 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Convolutional Block 2\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Convolutional Block 3\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Convolutional Block 4\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            #nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Flatten\n",
    "            Lambda(lambda x: x.view(x.size(0), -1)),\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(13*13*512, 1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward.\"\"\"\n",
    "        # conv layers\n",
    "        x = self.convolutional_layers(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.forward(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import BatchSampler\n",
    "import numpy as np\n",
    "class BalancedBatchSampler(BatchSampler):\n",
    "    \"\"\"\n",
    "    Returns batches of size n_classes * n_samples\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, labels, n_classes, n_samples):\n",
    "        self.labels = labels\n",
    "        self.labels_set = list(set(self.labels))\n",
    "        self.label_to_indices = {label: np.where(  np.array(self.labels) == label)[0]\n",
    "                                 for label in self.labels_set}\n",
    "        for l in self.labels_set:\n",
    "            np.random.shuffle(self.label_to_indices[l])\n",
    "        self.used_label_indices_count = {label: 0 for label in self.labels_set}\n",
    "        self.count = 0\n",
    "        self.n_classes = n_classes\n",
    "        self.n_samples = n_samples\n",
    "        self.n_dataset = len(self.labels)\n",
    "        self.batch_size = self.n_samples * self.n_classes\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.count = 0\n",
    "        while self.count + self.batch_size <= self.n_dataset:\n",
    "            classes = np.random.choice(self.labels_set, self.n_classes, replace=False)\n",
    "            indices = []\n",
    "            for class_ in classes:\n",
    "                indices.extend(self.label_to_indices[class_][\n",
    "                               self.used_label_indices_count[class_]:self.used_label_indices_count[\n",
    "                                                                         class_] + self.n_samples])\n",
    "                self.used_label_indices_count[class_] += self.n_samples\n",
    "                if self.used_label_indices_count[class_] + self.n_samples > len(self.label_to_indices[class_]):\n",
    "                    np.random.shuffle(self.label_to_indices[class_])\n",
    "                    self.used_label_indices_count[class_] = 0\n",
    "            yield indices\n",
    "            self.count += self.n_classes * self.n_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_dataset // self.batch_size"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16b4aff5112f09b7",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Triplets loss\n",
    "    Takes a batch of embeddings and corresponding labels.\n",
    "    Triplets are generated using triplet_selector object that take embeddings and targets and return indices of\n",
    "    triplets\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin, triplet_selector):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.triplet_selector = triplet_selector\n",
    "\n",
    "    def forward(self, embeddings, target):\n",
    "\n",
    "        triplets = self.triplet_selector.get_triplets(embeddings, target)\n",
    "\n",
    "        if embeddings.is_cuda:\n",
    "            triplets = triplets.cuda()\n",
    "\n",
    "\n",
    "        anchor_idx= triplets[:, 0]\n",
    "        positive_idx= triplets[:, 1]\n",
    "        negative_idx= triplets[:, 2]\n",
    "\n",
    "\n",
    "        ap_distances = (embeddings[anchor_idx] - embeddings[positive_idx]).pow(2).sum(1)  # .pow(.5)\n",
    "        an_distances = (embeddings[anchor_idx] - embeddings[negative_idx]).pow(2).sum(1)  # .pow(.5)\n",
    "        losses = F.relu(ap_distances - an_distances + self.margin)\n",
    "\n",
    "        return losses.mean()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "948e55a5ea036e8a",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "char_dict = {f\"character{i:02d}\": i - 1 for i in range(1, 100)}\n",
    "train_loader_dict = {}\n",
    "# Iterate over the dictionary items (label: images_list)\n",
    "for alphabet in alphabets:\n",
    "    data_alphabet = train_data[alphabet]\n",
    "    image_label_list = []\n",
    "    targets = []\n",
    "    for label, images in data_alphabet.items():\n",
    "        # Append each image-label pair as a tuple to the list\n",
    "        for image in images:\n",
    "            targets.append(char_dict[label])\n",
    "            image_label_list.append((image, char_dict[label]))\n",
    "    #print(len(targets)/len(set(targets)))\n",
    "    train_batch_sampler = BalancedBatchSampler(targets, n_classes=len(set(targets)), n_samples=3)\n",
    "    triplets_train_loader = torch.utils.data.DataLoader(image_label_list, batch_sampler=train_batch_sampler)\n",
    "    train_loader_dict[alphabet] = triplets_train_loader\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Batch 0:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([ 8,  8,  8, 23, 23, 23, 19, 19, 19,  3,  3,  3, 15, 15, 15,  7,  7,  7,\n",
      "         6,  6,  6,  0,  0,  0,  5,  5,  5, 10, 10, 10, 16, 16, 16, 11, 11, 11,\n",
      "         1,  1,  1, 20, 20, 20, 17, 17, 17,  9,  9,  9, 22, 22, 22, 25, 25, 25,\n",
      "        21, 21, 21, 13, 13, 13, 12, 12, 12, 18, 18, 18, 14, 14, 14,  4,  4,  4,\n",
      "         2,  2,  2, 24, 24, 24])\n",
      "Batch 1:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([11, 11, 11,  7,  7,  7,  3,  3,  3, 13, 13, 13,  0,  0,  0, 24, 24, 24,\n",
      "         5,  5,  5, 25, 25, 25,  9,  9,  9, 10, 10, 10, 21, 21, 21, 15, 15, 15,\n",
      "         2,  2,  2, 18, 18, 18, 12, 12, 12,  6,  6,  6,  1,  1,  1, 20, 20, 20,\n",
      "         4,  4,  4, 17, 17, 17, 16, 16, 16, 19, 19, 19,  8,  8,  8, 22, 22, 22,\n",
      "        14, 14, 14, 23, 23, 23])\n",
      "Batch 2:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([ 1,  1,  1, 12, 12, 12, 15, 15, 15,  8,  8,  8, 18, 18, 18, 24, 24, 24,\n",
      "        10, 10, 10, 19, 19, 19,  7,  7,  7,  6,  6,  6, 16, 16, 16, 11, 11, 11,\n",
      "         4,  4,  4, 13, 13, 13, 17, 17, 17, 23, 23, 23,  0,  0,  0,  2,  2,  2,\n",
      "        20, 20, 20,  5,  5,  5, 21, 21, 21,  9,  9,  9,  3,  3,  3, 22, 22, 22,\n",
      "        25, 25, 25, 14, 14, 14])\n",
      "Batch 3:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([ 4,  4,  4, 15, 15, 15, 12, 12, 12, 16, 16, 16, 18, 18, 18, 22, 22, 22,\n",
      "         5,  5,  5, 10, 10, 10, 13, 13, 13,  9,  9,  9, 24, 24, 24, 20, 20, 20,\n",
      "         0,  0,  0,  2,  2,  2, 14, 14, 14,  6,  6,  6,  1,  1,  1, 25, 25, 25,\n",
      "         8,  8,  8, 23, 23, 23,  7,  7,  7, 21, 21, 21, 17, 17, 17, 19, 19, 19,\n",
      "        11, 11, 11,  3,  3,  3])\n",
      "Batch 4:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([17, 17, 17, 20, 20, 20, 15, 15, 15, 12, 12, 12,  2,  2,  2, 22, 22, 22,\n",
      "        14, 14, 14,  1,  1,  1,  3,  3,  3, 25, 25, 25, 18, 18, 18, 19, 19, 19,\n",
      "         8,  8,  8, 23, 23, 23, 21, 21, 21,  4,  4,  4, 10, 10, 10, 13, 13, 13,\n",
      "         0,  0,  0, 11, 11, 11,  6,  6,  6, 16, 16, 16,  9,  9,  9,  5,  5,  5,\n",
      "        24, 24, 24,  7,  7,  7])\n",
      "Batch 5:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([23, 23, 23, 21, 21, 21, 15, 15, 15, 20, 20, 20,  9,  9,  9,  5,  5,  5,\n",
      "         2,  2,  2, 22, 22, 22, 12, 12, 12,  3,  3,  3,  7,  7,  7, 14, 14, 14,\n",
      "        11, 11, 11, 25, 25, 25,  1,  1,  1,  4,  4,  4, 24, 24, 24, 10, 10, 10,\n",
      "        13, 13, 13,  0,  0,  0, 16, 16, 16, 18, 18, 18, 17, 17, 17,  6,  6,  6,\n",
      "        19, 19, 19,  8,  8,  8])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader_dict['Latin']))\n",
    "i=0\n",
    "for batch_idx, (inputs, targets) in enumerate(train_loader_dict['Latin']):\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(\"Inputs (features):\")\n",
    "    print(type(inputs))\n",
    "    print(len(targets))  # Print input data (features)\n",
    "    print(\"Targets (labels):\")\n",
    "    print(targets)\n",
    "    i+=1\n",
    "print(i)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n",
    "def pdist(vectors):\n",
    "    distance_matrix = -2 * vectors.mm(torch.t(vectors)) + vectors.pow(2).sum(dim=1).view(1, -1) + vectors.pow(2).sum(\n",
    "        dim=1).view(-1, 1)\n",
    "    return distance_matrix\n",
    "\n",
    "\n",
    "class Informative_Negative_TripletSelector():\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        super(Informative_Negative_TripletSelector, self).__init__()\n",
    "\n",
    "        self.margin = margin\n",
    "\n",
    "    # Our goal is to mining informative triplets.\n",
    "    def informative_negative(self, loss_values):\n",
    "\n",
    "        informative_negative = np.where(loss_values > 0)[0]\n",
    "        return np.random.choice(informative_negative) if len(informative_negative) > 0 else None\n",
    "\n",
    "    def get_triplets(self, embeddings, labels):\n",
    "\n",
    "        if torch.cuda.is_available() == False:\n",
    "            embeddings = embeddings.cpu()\n",
    "        distance_matrix = pdist(embeddings)\n",
    "        distance_matrix = distance_matrix.cpu()\n",
    "\n",
    "        labels = labels.cpu().data.numpy()\n",
    "        triplets = []\n",
    "\n",
    "        for label in set(labels):\n",
    "            label_mask = (labels == label)\n",
    "            label_indices = np.where(label_mask)[0]\n",
    "            if len(label_indices) < 2:\n",
    "                continue\n",
    "            negative_indices = np.where(np.logical_not(label_mask))[0]\n",
    "            anchor_positives = list(combinations(label_indices, 2))  # All anchor-positive pairs\n",
    "            anchor_positives = np.array(anchor_positives)\n",
    "\n",
    "            ap_distances = distance_matrix[anchor_positives[:, 0], anchor_positives[:, 1]]\n",
    "            for anchor_positive, ap_distance in zip(anchor_positives, ap_distances):\n",
    "                loss_values = ap_distance - distance_matrix[\n",
    "                    torch.LongTensor(np.array([anchor_positive[0]])), torch.LongTensor(negative_indices)] + self.margin\n",
    "                loss_values = loss_values.data.cpu().numpy()\n",
    "\n",
    "                hard_negative = self.informative_negative(loss_values)\n",
    "                if hard_negative is not None:\n",
    "                    hard_negative = negative_indices[hard_negative]\n",
    "                    triplets.append([anchor_positive[0], anchor_positive[1], hard_negative])\n",
    "\n",
    "        if len(triplets) == 0:\n",
    "            triplets.append([anchor_positive[0], anchor_positive[1], negative_indices[0]])\n",
    "\n",
    "        triplets = np.array(triplets)\n",
    "        #print(len(triplets))\n",
    "        return torch.LongTensor(triplets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module,\n",
    "                 device: torch.device,\n",
    "                 criterion: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 training_dict: torch.utils.data.Dataset,\n",
    "                 validation_DataLoader: torch.utils.data.Dataset ,\n",
    "                 epochs: int\n",
    "                 ):\n",
    "\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.training_dict= training_dict\n",
    "        self.validation_DataLoader = validation_DataLoader\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def run_trainer(self):\n",
    "\n",
    "\n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "\n",
    "            self.model.train()  # train mode\n",
    "            alphabets = self.training_dict.keys()\n",
    "            train_losses=[]\n",
    "            for alphabet in alphabets:\n",
    "                data_loader = self.training_dict[alphabet]\n",
    "                for batch in data_loader:\n",
    "                    #print('test')\n",
    "                    x,y=batch\n",
    "                    input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)\n",
    "                    self.optimizer.zero_grad()  # zerograd the parameters\n",
    "                    out = self.model(input)  # one forward pass\n",
    "                    loss = self.criterion(out, target)  # calculate loss\n",
    "\n",
    "                    loss_value = loss.item()\n",
    "                    train_losses.append(loss_value)\n",
    "\n",
    "                    loss.backward()  # one backward pass\n",
    "                    self.optimizer.step()\n",
    "                    input.cpu()\n",
    "                    target.cpu()# update the parameters\n",
    "                    del input\n",
    "                    del target\n",
    "                #print('\\n')\n",
    "                self.model.eval()  # evaluation mode\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # print the results\n",
    "            print(\n",
    "                f'EPOCH: {epoch+1:0>{len(str(self.epochs))}}/{self.epochs}',\n",
    "                end=' '\n",
    "            )\n",
    "            print(f'LOSS: {np.mean(train_losses):.4f}',end=' ')\n",
    "            #print(f'VAL-LOSS: {np.mean(valid_losses):.4f}',end='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "\n",
    "# model\n",
    "embedding_net = EmbeddingNet2()\n",
    "model = embedding_net.to(device)\n",
    "\n",
    "\n",
    "# margin value\n",
    "margin=1\n",
    "\n",
    "# criterion\n",
    "criterion = TripletLoss(margin,  Informative_Negative_TripletSelector(margin))\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(model=model,\n",
    "                  device=device,\n",
    "                  criterion=criterion,\n",
    "                  optimizer=optimizer,\n",
    "                  training_dict=train_loader_dict,\n",
    "                  validation_DataLoader=train_loader_dict,\n",
    "                  epochs=10)\n",
    "\n",
    "# start training\n",
    "trainer.run_trainer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "name = 'test1'\n",
    "state = {'net': model.state_dict(),'loss': 1.0}\n",
    "if not os.path.isdir('checkpoint'):\n",
    "    os.mkdir('checkpoint')\n",
    "torch.save(state, './checkpoint/%s.t7'%(name))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['annotated_images', 'annotated_images_labels', 'unseen_images', 'unseen_images_labels'])\n"
     ]
    }
   ],
   "source": [
    "# load the test data:\n",
    "\n",
    "data_dict_test = load_data('test_data_task1.pkl')\n",
    "# keys are 'annotated_images', 'annotated_images_labels', 'unseen_images', 'unseen_images_labels'.\n",
    "# These keys correspond to the annotated images with known labels for each test alphabet (the sets A);\n",
    "# labels of the images with known labels for each test alphabet;\n",
    "# to-be-labeled unseen images for each test alphabet (sets U);\n",
    "# and labels of the to-be-labeled unseen images for each alphabet, respectively.\n",
    "# For each alphabet, the labels of the unseen images should be predicted by the model.\n",
    "# The true labels of the unseen images can only be used to calculate evaluation metrics.\n",
    "print(data_dict_test.keys())\n",
    "\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f82021775a0a6fbf",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Atemayar_Qelisayer annotated images: torch.Size([26, 1, 105, 105])\n",
      "Number of Atemayar_Qelisayer annotated labels: 26\n",
      "Shape of Atemayar_Qelisayer unseen images: torch.Size([494, 1, 105, 105])\n",
      "Number of Atemayar_Qelisayer unseen labels: 494. Use the unseen labels only for evaluating your model!\n"
     ]
    }
   ],
   "source": [
    "# example: let's get some annotated images and their labels for an alphabet in the test data:\n",
    "\n",
    "alphabets_test = list(data_dict_test['annotated_images'].keys())\n",
    "alphabet_id = np.random.randint(0, len(alphabets_test))\n",
    "alphabet = alphabets_test[alphabet_id]\n",
    "\n",
    "alphabet_annotated = data_dict_test['annotated_images'][alphabet]  # a tensor of shape (num_images, 1, height, width)\n",
    "print(f'Shape of {alphabet} annotated images:', alphabet_annotated.shape)\n",
    "\n",
    "alphabet_annotated_labels = data_dict_test['annotated_images_labels'][alphabet]  # a list of length num_images\n",
    "print(f'Number of {alphabet} annotated labels:', len(alphabet_annotated_labels))  # equals num_images\n",
    "\n",
    "alphabet_unseen = data_dict_test['unseen_images'][alphabet]  # a tensor of shape (num_images, 1, height, width)\n",
    "print(f'Shape of {alphabet} unseen images:', alphabet_unseen.shape)\n",
    "\n",
    "alphabet_unseen_labels = data_dict_test['unseen_images_labels'][alphabet]  # a list of length num_images\n",
    "print(f'Number of {alphabet} unseen labels: {len(alphabet_unseen_labels)}. Use the unseen labels only for evaluating your model!')  # equals num_images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eedf16c955d94af7",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# evaluation of the model:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1966916fdd423fe",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1.t7 LOSS:\t 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_net(name,architecture, path = \"checkpoint/\"):\n",
    "    checkpoint = torch.load(path+name,map_location='cpu')\n",
    "    architecture.load_state_dict(checkpoint['net'])\n",
    "    architecture.eval()\n",
    "    print(name+' LOSS:\\t',checkpoint['loss'])\n",
    "    return architecture\n",
    "model = EmbeddingNet()\n",
    "model = load_net('test1.t7', model).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "char_dict = {f\"character{i:02d}\": i - 1 for i in range(1, 100)}\n",
    "annotated_loader_dict = {}\n",
    "annotated_images_dict = data_dict_test['annotated_images']\n",
    "annotated_targets_dict = data_dict_test['annotated_images_labels']\n",
    "# Iterate over the dictionary items (label: images_list)\n",
    "for alphabet in alphabets_test:\n",
    "    images = annotated_images_dict[alphabet]\n",
    "    targets = annotated_targets_dict[alphabet]\n",
    "    targets = [char_dict[key] for key in targets]\n",
    "    annotated_loader = torch.utils.data.DataLoader(list(zip(images, targets)), batch_size=200)\n",
    "    annotated_loader_dict[alphabet] = annotated_loader\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "char_dict = {f\"character{i:02d}\": i - 1 for i in range(1, 100)}\n",
    "test_loader_dict = {}\n",
    "test_images_dict = data_dict_test['unseen_images']\n",
    "test_targets_dict = data_dict_test['unseen_images_labels']\n",
    "# Iterate over the dictionary items (label: images_list)\n",
    "for alphabet in alphabets_test:\n",
    "    images = test_images_dict[alphabet]\n",
    "    targets = test_targets_dict[alphabet]\n",
    "    targets = [char_dict[key] for key in targets]\n",
    "    test_loader = torch.utils.data.DataLoader(list(zip(images, targets)), batch_size=200)\n",
    "    test_loader_dict[alphabet] = test_loader\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "200\n",
      "Targets (labels):\n",
      "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "         8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10])\n",
      "Batch 1:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "200\n",
      "Targets (labels):\n",
      "tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15,\n",
      "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17,\n",
      "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18,\n",
      "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19,\n",
      "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "        20, 21])\n",
      "Batch 2:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "94\n",
      "Targets (labels):\n",
      "tensor([21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
      "        22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n",
      "        24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "        25, 25, 25, 25])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#print(len(annotated_loader_dict['Atemayar_Qelisayer']))\n",
    "i=0\n",
    "for batch_idx, (inputs, targets) in enumerate(test_loader_dict['Atemayar_Qelisayer']):\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(\"Inputs (features):\")\n",
    "    print(type(inputs))\n",
    "    print(len(targets))  # Print input data (features)\n",
    "    print(\"Targets (labels):\")\n",
    "    print(targets)\n",
    "    i+=1\n",
    "print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_embeddings(dataloader, model):\n",
    "\n",
    "    cuda = torch.cuda.is_available()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        embeddings = np.zeros((len(dataloader.dataset), 10))\n",
    "        labels = np.zeros(len(dataloader.dataset))\n",
    "        k = 0\n",
    "        for images, target in dataloader:\n",
    "            if cuda:\n",
    "                images = images.cuda()\n",
    "            embeddings[k:k+len(images)] = model.get_embedding(images).data.cpu().numpy()\n",
    "            labels[k:k+len(images)] = target.numpy()\n",
    "            k += len(images)\n",
    "    return embeddings, labels\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e832c436112fef2",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 256, 380, 0.6736842105263158)\n",
      "('Atemayar_Qelisayer', 536, 874, 0.6132723112128147)\n",
      "('Atlantean', 763, 1368, 0.5577485380116959)\n",
      "('Aurek-Besh', 1136, 1862, 0.6100966702470462)\n",
      "('Avesta', 1400, 2356, 0.5942275042444821)\n",
      "('Ge_ez', 1646, 2850, 0.5775438596491228)\n",
      "('Glagolitic', 2010, 3705, 0.5425101214574899)\n",
      "('Gurmukhi', 2342, 4560, 0.5135964912280702)\n",
      "('Kannada', 2590, 5339, 0.4851095710807267)\n",
      "('Keble', 2944, 5833, 0.5047145551174352)\n",
      "('Malayalam', 3344, 6726, 0.4971751412429379)\n",
      "('Manipuri', 3618, 7486, 0.48330216403954046)\n",
      "('Mongolian', 3887, 8056, 0.48249751737835156)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 4429, 8911, 0.49702614745819773)\n",
      "('Oriya', 4650, 9785, 0.4752171691364333)\n",
      "('Sylheti', 4838, 10317, 0.4689347678588737)\n",
      "('Syriac_(Serto)', 5030, 10754, 0.46773293658173704)\n",
      "('Tengwar', 5248, 11229, 0.46736129664262177)\n",
      "('Tibetan', 5617, 12027, 0.46703251018541614)\n",
      "('ULOG', 5924, 12521, 0.4731251497484226)\n",
      "0.4731251497484226\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.4731251497484226"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_results(model, annotated_loader_dict, test_loader_dict, k):\n",
    "    correct=0\n",
    "    total_images = 0\n",
    "    for alphabet in annotated_loader_dict.keys():\n",
    "        annotated_embeddings, annotated_targets = extract_embeddings(annotated_loader_dict[alphabet], model)\n",
    "        test_embeddings, test_targets = extract_embeddings(test_loader_dict[alphabet], model)\n",
    "        distances=cdist(annotated_embeddings,test_embeddings)\n",
    "        all_image_distances=[]\n",
    "        for i in range(len(test_targets)):\n",
    "            image_distances= []\n",
    "            for j in range(len(distances)):\n",
    "                image_distances.append((distances[j][i], j))\n",
    "            all_image_distances.append(sorted(image_distances))\n",
    "\n",
    "        k_classification = []\n",
    "        for i in range(len(all_image_distances)):\n",
    "            k_classification.append([score[1] for score in all_image_distances[i]][:k])\n",
    "\n",
    "        for i in range(len(k_classification)):\n",
    "\n",
    "            if test_targets[i] in k_classification[i]:\n",
    "                correct+=1\n",
    "        total_images+=len(test_targets)\n",
    "        print((alphabet, correct, total_images, correct/total_images))\n",
    "\n",
    "    top_k_accuracy = correct/total_images\n",
    "    print(top_k_accuracy)\n",
    "    return top_k_accuracy\n",
    "get_results(model, annotated_loader_dict, test_loader_dict, 1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e87003112448465",
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 336, 380, 0.8842105263157894)\n",
      "('Atemayar_Qelisayer', 693, 874, 0.7929061784897025)\n",
      "('Atlantean', 980, 1368, 0.716374269005848)\n",
      "('Aurek-Besh', 1405, 1862, 0.7545649838882922)\n",
      "('Avesta', 1769, 2356, 0.7508488964346349)\n",
      "('Ge_ez', 2100, 2850, 0.7368421052631579)\n",
      "('Glagolitic', 2563, 3705, 0.6917678812415654)\n",
      "('Gurmukhi', 3054, 4560, 0.6697368421052632)\n",
      "('Kannada', 3438, 5339, 0.6439408128863083)\n",
      "('Keble', 3839, 5833, 0.6581518943939654)\n",
      "('Malayalam', 4381, 6726, 0.651352958667856)\n",
      "('Manipuri', 4772, 7486, 0.6374565856265028)\n",
      "('Mongolian', 5134, 8056, 0.6372889771598809)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 5820, 8911, 0.6531253506901582)\n",
      "('Oriya', 6163, 9785, 0.6298415942769545)\n",
      "('Sylheti', 6448, 10317, 0.624987884074828)\n",
      "('Syriac_(Serto)', 6698, 10754, 0.622838013762321)\n",
      "('Tengwar', 6995, 11229, 0.6229406002315433)\n",
      "('Tibetan', 7516, 12027, 0.6249272470275214)\n",
      "('ULOG', 7893, 12521, 0.6303809599872214)\n",
      "0.6303809599872214\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.6303809599872214"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results(model, annotated_loader_dict, test_loader_dict, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 360, 380, 0.9473684210526315)\n",
      "('Atemayar_Qelisayer', 785, 874, 0.8981693363844394)\n",
      "('Atlantean', 1150, 1368, 0.8406432748538012)\n",
      "('Aurek-Besh', 1593, 1862, 0.855531686358754)\n",
      "('Avesta', 2028, 2356, 0.8607809847198642)\n",
      "('Ge_ez', 2428, 2850, 0.8519298245614035)\n",
      "('Glagolitic', 3023, 3705, 0.8159244264507423)\n",
      "('Gurmukhi', 3687, 4560, 0.8085526315789474)\n",
      "('Kannada', 4188, 5339, 0.7844165574077543)\n",
      "('Keble', 4634, 5833, 0.7944453968798217)\n",
      "('Malayalam', 5322, 6726, 0.7912578055307761)\n",
      "('Manipuri', 5830, 7486, 0.7787870691958322)\n",
      "('Mongolian', 6292, 8056, 0.7810327706057597)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 7058, 8911, 0.7920547637751094)\n",
      "('Oriya', 7554, 9785, 0.7719979560551865)\n",
      "('Sylheti', 7951, 10317, 0.7706697683435108)\n",
      "('Syriac_(Serto)', 8284, 10754, 0.7703180212014135)\n",
      "('Tengwar', 8660, 11229, 0.7712173835604239)\n",
      "('Tibetan', 9335, 12027, 0.7761702835287271)\n",
      "('ULOG', 9757, 12521, 0.7792508585576232)\n",
      "0.7792508585576232\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7792508585576232"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results(model, annotated_loader_dict, test_loader_dict, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 373, 380, 0.9815789473684211)\n",
      "('Atemayar_Qelisayer', 849, 874, 0.971395881006865)\n",
      "('Atlantean', 1283, 1368, 0.9378654970760234)\n",
      "('Aurek-Besh', 1752, 1862, 0.9409237379162191)\n",
      "('Avesta', 2226, 2356, 0.9448217317487266)\n",
      "('Ge_ez', 2672, 2850, 0.9375438596491228)\n",
      "('Glagolitic', 3378, 3705, 0.9117408906882591)\n",
      "('Gurmukhi', 4154, 4560, 0.9109649122807018)\n",
      "('Kannada', 4779, 5339, 0.8951114440906537)\n",
      "('Keble', 5259, 5833, 0.9015943768215327)\n",
      "('Malayalam', 6059, 6726, 0.9008325899494499)\n",
      "('Manipuri', 6676, 7486, 0.8917980229762222)\n",
      "('Mongolian', 7214, 8056, 0.8954816285998014)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 8033, 8911, 0.9014700931433061)\n",
      "('Oriya', 8689, 9785, 0.8879918242207461)\n",
      "('Sylheti', 9162, 10317, 0.8880488514102937)\n",
      "('Syriac_(Serto)', 9556, 10754, 0.8885995908499164)\n",
      "('Tengwar', 9981, 11229, 0.8888592038471814)\n",
      "('Tibetan', 10734, 12027, 0.8924918932402095)\n",
      "('ULOG', 11194, 12521, 0.8940180496765434)\n",
      "0.8940180496765434\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.8940180496765434"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results(model, annotated_loader_dict, test_loader_dict, 8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 2: rotation problem"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f49a6fcc9bcd5994"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load the test data for task 2:\n",
    "# the structure of the test data of task 2 is exactly the same as for task 1,\n",
    "# but now the images are rotated by an unknown angle between 0 and 360 degrees.\n",
    "data_dict_test_task2 = load_data('test_data_task2.pkl')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "800d9fa43d711ae0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_dict_test_task2.keys()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfd690817a188882",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# solution and evaluation of task 2:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab7aa34500088f66",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "71298802fa5d6fb8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4e6e3e82ce917c0f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e701b2a68bd4d32a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 3: Domain knowledge injection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfdbe34799376c36"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load the test data for task 3:\n",
    "# the structure of the data of task 3 is exactly the same as for task 1, but now our the loaded dictionary contains some additional keys.\n",
    "# These additional keys will be explained in the cells below:\n",
    "\n",
    "data_dict_test_task3 = load_data('test_data_task3.pkl')\n",
    "print(data_dict_test_task3.keys())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa248dbece85da5c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# The keys 'annotated_images', 'annotated_images_labels', 'unseen_images', 'unseen_images_labels' are the same as for task 1, and the structure of the data is exactly the same. \n",
    "\n",
    "# The key 'unseen_images_preceding_types' maps to the type of the preceding character in the sequence where the unseen image was observed, for each alphabet.\n",
    "# The key 'character_to_type_mapping' maps to the mapping of each character to its type, for each alphabet.\n",
    "# The key 'type_following_probs' maps to the probabilities of each character type being followed by another character type, for each alphabet."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fb6a6237a187493",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# examples:\n",
    "\n",
    "alphabet = np.random.choice(list(data_dict_test_task3['unseen_images_preceding_types'].keys()))\n",
    "print(f'Alphabet: {alphabet}')\n",
    "\n",
    "\n",
    "preceding_character_types_alphabet = data_dict_test_task3[\"unseen_images_preceding_types\"][alphabet]  # a list\n",
    "print(f'Some character types that preceded unseen images from the {alphabet} alphabet: {np.random.choice(preceding_character_types_alphabet, size=5)}')\n",
    "print(f'There are {len(preceding_character_types_alphabet)} preceding character types in the {alphabet} alphabet, and {len(data_dict_test_task3[\"unseen_images\"][alphabet])} unseen images.')\n",
    "\n",
    "\n",
    "character_to_type_mapping_alphabet = data_dict_test_task3[\"character_to_type_mapping\"][alphabet]  \n",
    "# this is a dict, with as keys the characters and as values the types\n",
    "random_character = np.random.choice(list(character_to_type_mapping_alphabet.keys()))\n",
    "print(f'Type of {random_character} from the {alphabet} alphabet: {character_to_type_mapping_alphabet[random_character]}')\n",
    "\n",
    "\n",
    "\n",
    "type_following_probs_alphabet = data_dict_test_task3[\"type_following_probs\"][alphabet]  # a dict of dicts\n",
    "preceding_type = np.random.choice(list(type_following_probs_alphabet.keys()))\n",
    "following_type = np.random.choice(list(type_following_probs_alphabet[preceding_type].keys()))\n",
    "print(f'Probability of a character of type {following_type} following a character of type {preceding_type} in the {alphabet} alphabet: {type_following_probs_alphabet[preceding_type][following_type]}')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef9bcef5572f0a78",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cbaa137b41e610ce",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "700c29e735fd10c5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "eb7d09f31839b40",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "596ab2a615cb44e9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a2656ede1e4adbe8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "42d46e71207afe47"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment 1 2AMM10 2023-2024\n",
    "\n",
    "## Group: [Fill in your group name]\n",
    "### Member 1: [Fill in your name]\n",
    "### Member 2: [Fill in your name]\n",
    "### Member 3: [Fill in your name]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc4f04c033b0e00"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from scipy.spatial.distance import cdist\n",
    "import os\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# function for loading the training data:\n",
    "\n",
    "def load_data(file):\n",
    "    \"\"\"\n",
    "    This function loads the data from the specified pickle file and returns a dictionary with the data\n",
    "    :param filename: the pickle file\n",
    "    :return: dict with data -- keys and values differ for the train data and test data for each task.\n",
    "     Please see the cells with example code below for explanations and examples of the data structure per data set.\n",
    "    \"\"\"\n",
    "    with open(file, 'rb') as f:\n",
    "        data_dict = pickle.load(f)\n",
    "    return data_dict"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d19b9de0e3461531",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data = load_data('train_data.pkl')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0da60a825f5080b",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example alphabet names: ['Alphabet_of_the_Magi', 'Anglo-Saxon_Futhorc', 'Arcadian', 'Armenian', 'Asomtavruli_(Georgian)']\n",
      "\n",
      "\n",
      "how to get an example image for a specific character:\n",
      "shape of image 2 of character character06 of alphabet Asomtavruli_(Georgian): torch.Size([1, 105, 105])\n"
     ]
    }
   ],
   "source": [
    "# the structure of the training data is a dict, where the keys are strings indicating the alphabet.\n",
    "# The values are again dicts, with the keys being the character and the values being a list of images of that character.\n",
    "\n",
    "# see the code below for examples of working with the train data\n",
    "\n",
    "alphabets = list(train_data.keys())\n",
    "\n",
    "\n",
    "print('example alphabet names:', alphabets[:5])\n",
    "print('\\n')\n",
    "print('how to get an example image for a specific character:')\n",
    "\n",
    "alphabet_id = 4\n",
    "alphabet = alphabets[alphabet_id]  # a dict\n",
    "characters_for_this_alphabet = list(train_data[alphabet].keys())\n",
    "character_id = 5\n",
    "character = characters_for_this_alphabet[character_id]\n",
    "image_id = 2\n",
    "\n",
    "print(f'shape of image {image_id} of character {character} of alphabet {alphabet}:', train_data[alphabet][character][image_id].shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "289b9d9817ddf745",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2991163aba746526",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# function for plotting some examples:\n",
    "\n",
    "def plot_example_data(data_dict):\n",
    "    \"\"\"\n",
    "    This function plots some examples of the data\n",
    "    :param data_dict: dict with as keys a string specifying the alphabet, and as values a dict with as keys the character of the alphabet, and as values a list om images of the alphabet\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    alphabets_to_plot = np.random.choice(list(data_dict.keys()), size=10, replace=False)\n",
    "    \n",
    "    for i, alphabet in enumerate(alphabets_to_plot):\n",
    "        characters = data_dict[alphabet]\n",
    "        character_to_plot = np.random.choice(list(characters.keys()), size=1)[0]\n",
    "        images = characters[character_to_plot]\n",
    "        im_idx = np.random.choice(len(images), size=1)[0]\n",
    "        axs[i//5, i%5].imshow(images[im_idx].permute(1, 2, 0))\n",
    "        axs[i//5, i%5].set_title(alphabet + '\\n' + character_to_plot, fontsize=8)\n",
    "        axs[i//5, i%5].axis('off')\n",
    "    # plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f68bfac0812b8988",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1080x432 with 10 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plot_example_data(train_data)\n",
    "# plt.savefig('example_data.png', dpi=600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "511e9fbc1b85e80f",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 1: character recognition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6449bef2185716"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"CNN Builder.\"\"\"\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "\n",
    "        self.front_layer = nn.Sequential(\n",
    "            # Conv Layer block 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Conv Layer block 2\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "            # Conv Layer block 3\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            Lambda(lambda x: x.view(x.size(0), -1)),\n",
    "\n",
    "            nn.Linear(256 * 13 * 13, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.last_layer = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward.\"\"\"\n",
    "        # conv layers\n",
    "        x = self.front_layer(x)\n",
    "        x = self.last_layer(x)\n",
    "        return x\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.forward(x)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f78ab6a6133991a4",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "class EmbeddingNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"CNN Builder.\"\"\"\n",
    "        super(EmbeddingNet2, self).__init__()\n",
    "\n",
    "        self.convolutional_layers = nn.Sequential(\n",
    "            # Convolutional Block 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Convolutional Block 2\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Convolutional Block 3\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Convolutional Block 4\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            #nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Flatten\n",
    "            Lambda(lambda x: x.view(x.size(0), -1)),\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(13*13*512, 1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward.\"\"\"\n",
    "        # conv layers\n",
    "        x = self.convolutional_layers(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.forward(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import BatchSampler\n",
    "import numpy as np\n",
    "class BalancedBatchSampler(BatchSampler):\n",
    "    \"\"\"\n",
    "    Returns batches of size n_classes * n_samples\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, labels, n_classes, n_samples):\n",
    "        self.labels = labels\n",
    "        self.labels_set = list(set(self.labels))\n",
    "        self.label_to_indices = {label: np.where(  np.array(self.labels) == label)[0]\n",
    "                                 for label in self.labels_set}\n",
    "        for l in self.labels_set:\n",
    "            np.random.shuffle(self.label_to_indices[l])\n",
    "        self.used_label_indices_count = {label: 0 for label in self.labels_set}\n",
    "        self.count = 0\n",
    "        self.n_classes = n_classes\n",
    "        self.n_samples = n_samples\n",
    "        self.n_dataset = len(self.labels)\n",
    "        self.batch_size = self.n_samples * self.n_classes\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.count = 0\n",
    "        while self.count + self.batch_size <= self.n_dataset:\n",
    "            classes = np.random.choice(self.labels_set, self.n_classes, replace=False)\n",
    "            indices = []\n",
    "            for class_ in classes:\n",
    "                indices.extend(self.label_to_indices[class_][\n",
    "                               self.used_label_indices_count[class_]:self.used_label_indices_count[\n",
    "                                                                         class_] + self.n_samples])\n",
    "                self.used_label_indices_count[class_] += self.n_samples\n",
    "                if self.used_label_indices_count[class_] + self.n_samples > len(self.label_to_indices[class_]):\n",
    "                    np.random.shuffle(self.label_to_indices[class_])\n",
    "                    self.used_label_indices_count[class_] = 0\n",
    "            yield indices\n",
    "            self.count += self.n_classes * self.n_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_dataset // self.batch_size"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16b4aff5112f09b7",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Triplets loss\n",
    "    Takes a batch of embeddings and corresponding labels.\n",
    "    Triplets are generated using triplet_selector object that take embeddings and targets and return indices of\n",
    "    triplets\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin, triplet_selector):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.triplet_selector = triplet_selector\n",
    "\n",
    "    def forward(self, embeddings, target):\n",
    "\n",
    "        triplets = self.triplet_selector.get_triplets(embeddings, target)\n",
    "\n",
    "        if embeddings.is_cuda:\n",
    "            triplets = triplets.cuda()\n",
    "\n",
    "\n",
    "        anchor_idx= triplets[:, 0]\n",
    "        positive_idx= triplets[:, 1]\n",
    "        negative_idx= triplets[:, 2]\n",
    "\n",
    "\n",
    "        ap_distances = (embeddings[anchor_idx] - embeddings[positive_idx]).pow(2).sum(1)  # .pow(.5)\n",
    "        an_distances = (embeddings[anchor_idx] - embeddings[negative_idx]).pow(2).sum(1)  # .pow(.5)\n",
    "        losses = F.relu(ap_distances - an_distances + self.margin)\n",
    "\n",
    "        return losses.mean()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "948e55a5ea036e8a",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "char_dict = {f\"character{i:02d}\": i - 1 for i in range(1, 100)}\n",
    "train_loader_dict = {}\n",
    "# Iterate over the dictionary items (label: images_list)\n",
    "for alphabet in alphabets:\n",
    "    data_alphabet = train_data[alphabet]\n",
    "    image_label_list = []\n",
    "    targets = []\n",
    "    for label, images in data_alphabet.items():\n",
    "        # Append each image-label pair as a tuple to the list\n",
    "        for image in images:\n",
    "            targets.append(char_dict[label])\n",
    "            image_label_list.append((image, char_dict[label]))\n",
    "    #print(len(targets)/len(set(targets)))\n",
    "    train_batch_sampler = BalancedBatchSampler(targets, n_classes=len(set(targets)), n_samples=3)\n",
    "    triplets_train_loader = torch.utils.data.DataLoader(image_label_list, batch_sampler=train_batch_sampler)\n",
    "    train_loader_dict[alphabet] = triplets_train_loader\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Batch 0:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([15, 15, 15, 13, 13, 13, 10, 10, 10,  4,  4,  4, 18, 18, 18,  6,  6,  6,\n",
      "        23, 23, 23, 25, 25, 25, 11, 11, 11,  8,  8,  8, 16, 16, 16,  3,  3,  3,\n",
      "         0,  0,  0,  2,  2,  2,  5,  5,  5, 24, 24, 24, 19, 19, 19, 12, 12, 12,\n",
      "        20, 20, 20,  1,  1,  1,  9,  9,  9, 21, 21, 21,  7,  7,  7, 17, 17, 17,\n",
      "        14, 14, 14, 22, 22, 22])\n",
      "Batch 1:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([ 1,  1,  1,  4,  4,  4, 16, 16, 16,  0,  0,  0, 21, 21, 21, 18, 18, 18,\n",
      "        12, 12, 12,  9,  9,  9, 19, 19, 19, 25, 25, 25, 10, 10, 10, 20, 20, 20,\n",
      "         8,  8,  8, 24, 24, 24,  6,  6,  6,  5,  5,  5, 15, 15, 15, 23, 23, 23,\n",
      "         7,  7,  7, 17, 17, 17, 22, 22, 22, 13, 13, 13,  3,  3,  3, 14, 14, 14,\n",
      "        11, 11, 11,  2,  2,  2])\n",
      "Batch 2:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([ 6,  6,  6, 11, 11, 11,  0,  0,  0, 13, 13, 13, 17, 17, 17, 12, 12, 12,\n",
      "        18, 18, 18,  4,  4,  4, 25, 25, 25,  3,  3,  3, 21, 21, 21, 23, 23, 23,\n",
      "        16, 16, 16, 22, 22, 22,  7,  7,  7, 15, 15, 15,  2,  2,  2,  9,  9,  9,\n",
      "        19, 19, 19, 14, 14, 14, 20, 20, 20,  8,  8,  8, 24, 24, 24,  1,  1,  1,\n",
      "        10, 10, 10,  5,  5,  5])\n",
      "Batch 3:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([16, 16, 16, 13, 13, 13,  5,  5,  5,  3,  3,  3,  1,  1,  1, 22, 22, 22,\n",
      "        17, 17, 17,  7,  7,  7, 18, 18, 18, 23, 23, 23,  4,  4,  4,  2,  2,  2,\n",
      "         8,  8,  8, 25, 25, 25, 10, 10, 10,  9,  9,  9, 19, 19, 19, 24, 24, 24,\n",
      "        15, 15, 15, 21, 21, 21, 12, 12, 12, 14, 14, 14, 20, 20, 20,  6,  6,  6,\n",
      "         0,  0,  0, 11, 11, 11])\n",
      "Batch 4:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([ 7,  7,  7,  8,  8,  8, 20, 20, 20, 12, 12, 12,  5,  5,  5, 17, 17, 17,\n",
      "        22, 22, 22,  9,  9,  9,  2,  2,  2,  3,  3,  3,  6,  6,  6,  0,  0,  0,\n",
      "        15, 15, 15, 19, 19, 19,  4,  4,  4, 11, 11, 11, 14, 14, 14, 18, 18, 18,\n",
      "        21, 21, 21, 25, 25, 25, 23, 23, 23, 13, 13, 13, 10, 10, 10, 24, 24, 24,\n",
      "        16, 16, 16,  1,  1,  1])\n",
      "Batch 5:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([ 1,  1,  1,  2,  2,  2, 14, 14, 14,  8,  8,  8, 19, 19, 19, 12, 12, 12,\n",
      "        23, 23, 23,  7,  7,  7, 24, 24, 24, 20, 20, 20, 11, 11, 11, 17, 17, 17,\n",
      "        18, 18, 18,  5,  5,  5, 10, 10, 10,  6,  6,  6,  4,  4,  4, 16, 16, 16,\n",
      "        21, 21, 21,  3,  3,  3,  0,  0,  0, 25, 25, 25, 15, 15, 15, 22, 22, 22,\n",
      "         9,  9,  9, 13, 13, 13])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader_dict['Latin']))\n",
    "i=0\n",
    "for batch_idx, (inputs, targets) in enumerate(train_loader_dict['Latin']):\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(\"Inputs (features):\")\n",
    "    print(type(inputs))\n",
    "    print(len(targets))  # Print input data (features)\n",
    "    print(\"Targets (labels):\")\n",
    "    print(targets)\n",
    "    i+=1\n",
    "print(i)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "\n",
    "def pdist(vectors):\n",
    "    distance_matrix = -2 * vectors.mm(torch.t(vectors)) + vectors.pow(2).sum(dim=1).view(1, -1) + vectors.pow(2).sum(\n",
    "        dim=1).view(-1, 1)\n",
    "    return distance_matrix\n",
    "\n",
    "\n",
    "class Informative_Negative_TripletSelector():\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        super(Informative_Negative_TripletSelector, self).__init__()\n",
    "\n",
    "        self.margin = margin\n",
    "\n",
    "    # Our goal is to mining informative triplets.\n",
    "    def informative_negative(self, loss_values):\n",
    "\n",
    "        informative_negative = np.where(loss_values > 0)[0]\n",
    "        return np.random.choice(informative_negative) if len(informative_negative) > 0 else None\n",
    "\n",
    "    def get_triplets(self, embeddings, labels):\n",
    "\n",
    "        if torch.cuda.is_available() == False:\n",
    "            embeddings = embeddings.cpu()\n",
    "        distance_matrix = pdist(embeddings)\n",
    "        distance_matrix = distance_matrix.cpu()\n",
    "\n",
    "        labels = labels.cpu().data.numpy()\n",
    "        triplets = []\n",
    "\n",
    "        for label in set(labels):\n",
    "            label_mask = (labels == label)\n",
    "            label_indices = np.where(label_mask)[0]\n",
    "            if len(label_indices) < 2:\n",
    "                continue\n",
    "            negative_indices = np.where(np.logical_not(label_mask))[0]\n",
    "            anchor_positives = list(combinations(label_indices, 2))  # All anchor-positive pairs\n",
    "            anchor_positives = np.array(anchor_positives)\n",
    "\n",
    "            ap_distances = distance_matrix[anchor_positives[:, 0], anchor_positives[:, 1]]\n",
    "            for anchor_positive, ap_distance in zip(anchor_positives, ap_distances):\n",
    "                loss_values = ap_distance - distance_matrix[\n",
    "                    torch.LongTensor(np.array([anchor_positive[0]])), torch.LongTensor(negative_indices)] + self.margin\n",
    "                loss_values = loss_values.data.cpu().numpy()\n",
    "\n",
    "                hard_negative = self.informative_negative(loss_values)\n",
    "                if hard_negative is not None:\n",
    "                    hard_negative = negative_indices[hard_negative]\n",
    "                    triplets.append([anchor_positive[0], anchor_positive[1], hard_negative])\n",
    "\n",
    "        if len(triplets) == 0:\n",
    "            triplets.append([anchor_positive[0], anchor_positive[1], negative_indices[0]])\n",
    "\n",
    "        triplets = np.array(triplets)\n",
    "        #print(len(triplets))\n",
    "        return torch.LongTensor(triplets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module,\n",
    "                 device: torch.device,\n",
    "                 criterion: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 training_dict: torch.utils.data.Dataset,\n",
    "                 validation_DataLoader: torch.utils.data.Dataset ,\n",
    "                 epochs: int\n",
    "                 ):\n",
    "\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.training_dict= training_dict\n",
    "        self.validation_DataLoader = validation_DataLoader\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def run_trainer(self):\n",
    "\n",
    "\n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "\n",
    "            self.model.train()  # train mode\n",
    "            alphabets = self.training_dict.keys()\n",
    "            train_losses=[]\n",
    "            for alphabet in alphabets:\n",
    "                data_loader = self.training_dict[alphabet]\n",
    "                for batch in data_loader:\n",
    "                    #print('test')\n",
    "                    x,y=batch\n",
    "                    input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)\n",
    "                    self.optimizer.zero_grad()  # zerograd the parameters\n",
    "                    out = self.model(input)  # one forward pass\n",
    "                    loss = self.criterion(out, target)  # calculate loss\n",
    "\n",
    "                    loss_value = loss.item()\n",
    "                    train_losses.append(loss_value)\n",
    "\n",
    "                    loss.backward()  # one backward pass\n",
    "                    self.optimizer.step()\n",
    "                    input.cpu()\n",
    "                    target.cpu()# update the parameters\n",
    "                    del input\n",
    "                    del target\n",
    "                #print('\\n')\n",
    "                self.model.eval()  # evaluation mode\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # print the results\n",
    "            print(\n",
    "                f'EPOCH: {epoch+1:0>{len(str(self.epochs))}}/{self.epochs}',\n",
    "                end=' '\n",
    "            )\n",
    "            print(f'LOSS: {np.mean(train_losses):.4f}',end=' ')\n",
    "            #print(f'VAL-LOSS: {np.mean(valid_losses):.4f}',end='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 338.00 MiB (GPU 0; 4.00 GiB total capacity; 3.27 GiB already allocated; 0 bytes free; 3.39 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-31-7a5312bc8ea7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;31m# model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[0membedding_net\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mEmbeddingNet2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0membedding_net\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36mto\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    897\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_floating_point\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_complex\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_blocking\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    898\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 899\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconvert\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    900\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    901\u001B[0m     def register_backward_hook(\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    568\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    569\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 570\u001B[1;33m             \u001B[0mmodule\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    571\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    572\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    591\u001B[0m             \u001B[1;31m# `with torch.no_grad():`\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    592\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 593\u001B[1;33m                 \u001B[0mparam_applied\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    594\u001B[0m             \u001B[0mshould_use_set_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparam_applied\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    595\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mshould_use_set_data\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36mconvert\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m    895\u001B[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001B[0;32m    896\u001B[0m                             non_blocking, memory_format=convert_to_format)\n\u001B[1;32m--> 897\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_floating_point\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_complex\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_blocking\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    898\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    899\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconvert\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 338.00 MiB (GPU 0; 4.00 GiB total capacity; 3.27 GiB already allocated; 0 bytes free; 3.39 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "\n",
    "# model\n",
    "embedding_net = EmbeddingNet2()\n",
    "model = embedding_net.to(device)\n",
    "\n",
    "\n",
    "# margin value\n",
    "margin=1\n",
    "\n",
    "# criterion\n",
    "criterion = TripletLoss(margin,  Informative_Negative_TripletSelector(margin))\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(model=model,\n",
    "                  device=device,\n",
    "                  criterion=criterion,\n",
    "                  optimizer=optimizer,\n",
    "                  training_dict=train_loader_dict,\n",
    "                  validation_DataLoader=train_loader_dict,\n",
    "                  epochs=10)\n",
    "\n",
    "# start training\n",
    "trainer.run_trainer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "name = 'test1'\n",
    "state = {'net': model.state_dict(),'loss': 1.0}\n",
    "if not os.path.isdir('checkpoint'):\n",
    "    os.mkdir('checkpoint')\n",
    "torch.save(state, './checkpoint/%s.t7'%(name))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['annotated_images', 'annotated_images_labels', 'unseen_images', 'unseen_images_labels'])\n"
     ]
    }
   ],
   "source": [
    "# load the test data:\n",
    "\n",
    "data_dict_test = load_data('test_data_task1.pkl')\n",
    "# keys are 'annotated_images', 'annotated_images_labels', 'unseen_images', 'unseen_images_labels'.\n",
    "# These keys correspond to the annotated images with known labels for each test alphabet (the sets A);\n",
    "# labels of the images with known labels for each test alphabet;\n",
    "# to-be-labeled unseen images for each test alphabet (sets U);\n",
    "# and labels of the to-be-labeled unseen images for each alphabet, respectively.\n",
    "# For each alphabet, the labels of the unseen images should be predicted by the model.\n",
    "# The true labels of the unseen images can only be used to calculate evaluation metrics.\n",
    "print(data_dict_test.keys())\n",
    "\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f82021775a0a6fbf",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Atemayar_Qelisayer annotated images: torch.Size([26, 1, 105, 105])\n",
      "Number of Atemayar_Qelisayer annotated labels: 26\n",
      "Shape of Atemayar_Qelisayer unseen images: torch.Size([494, 1, 105, 105])\n",
      "Number of Atemayar_Qelisayer unseen labels: 494. Use the unseen labels only for evaluating your model!\n"
     ]
    }
   ],
   "source": [
    "# example: let's get some annotated images and their labels for an alphabet in the test data:\n",
    "\n",
    "alphabets_test = list(data_dict_test['annotated_images'].keys())\n",
    "alphabet_id = np.random.randint(0, len(alphabets_test))\n",
    "alphabet = alphabets_test[alphabet_id]\n",
    "\n",
    "alphabet_annotated = data_dict_test['annotated_images'][alphabet]  # a tensor of shape (num_images, 1, height, width)\n",
    "print(f'Shape of {alphabet} annotated images:', alphabet_annotated.shape)\n",
    "\n",
    "alphabet_annotated_labels = data_dict_test['annotated_images_labels'][alphabet]  # a list of length num_images\n",
    "print(f'Number of {alphabet} annotated labels:', len(alphabet_annotated_labels))  # equals num_images\n",
    "\n",
    "alphabet_unseen = data_dict_test['unseen_images'][alphabet]  # a tensor of shape (num_images, 1, height, width)\n",
    "print(f'Shape of {alphabet} unseen images:', alphabet_unseen.shape)\n",
    "\n",
    "alphabet_unseen_labels = data_dict_test['unseen_images_labels'][alphabet]  # a list of length num_images\n",
    "print(f'Number of {alphabet} unseen labels: {len(alphabet_unseen_labels)}. Use the unseen labels only for evaluating your model!')  # equals num_images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eedf16c955d94af7",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# evaluation of the model:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1966916fdd423fe",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1.t7 LOSS:\t 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_net(name,architecture, path = \"checkpoint/\"):\n",
    "    checkpoint = torch.load(path+name,map_location='cpu')\n",
    "    architecture.load_state_dict(checkpoint['net'])\n",
    "    architecture.eval()\n",
    "    print(name+' LOSS:\\t',checkpoint['loss'])\n",
    "    return architecture\n",
    "model = EmbeddingNet()\n",
    "model = load_net('test1.t7', model).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "char_dict = {f\"character{i:02d}\": i - 1 for i in range(1, 100)}\n",
    "annotated_loader_dict = {}\n",
    "annotated_images_dict = data_dict_test['annotated_images']\n",
    "annotated_targets_dict = data_dict_test['annotated_images_labels']\n",
    "# Iterate over the dictionary items (label: images_list)\n",
    "for alphabet in alphabets_test:\n",
    "    images = annotated_images_dict[alphabet]\n",
    "    targets = annotated_targets_dict[alphabet]\n",
    "    targets = [char_dict[key] for key in targets]\n",
    "    annotated_loader = torch.utils.data.DataLoader(list(zip(images, targets)), batch_size=200)\n",
    "    annotated_loader_dict[alphabet] = annotated_loader\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "char_dict = {f\"character{i:02d}\": i - 1 for i in range(1, 100)}\n",
    "test_loader_dict = {}\n",
    "test_images_dict = data_dict_test['unseen_images']\n",
    "test_targets_dict = data_dict_test['unseen_images_labels']\n",
    "# Iterate over the dictionary items (label: images_list)\n",
    "for alphabet in alphabets_test:\n",
    "    images = test_images_dict[alphabet]\n",
    "    targets = test_targets_dict[alphabet]\n",
    "    targets = [char_dict[key] for key in targets]\n",
    "    test_loader = torch.utils.data.DataLoader(list(zip(images, targets)), batch_size=200)\n",
    "    test_loader_dict[alphabet] = test_loader\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "200\n",
      "Targets (labels):\n",
      "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "         8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10])\n",
      "Batch 1:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "200\n",
      "Targets (labels):\n",
      "tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15,\n",
      "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17,\n",
      "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18,\n",
      "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19,\n",
      "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "        20, 21])\n",
      "Batch 2:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "94\n",
      "Targets (labels):\n",
      "tensor([21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
      "        22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n",
      "        24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "        25, 25, 25, 25])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#print(len(annotated_loader_dict['Atemayar_Qelisayer']))\n",
    "i=0\n",
    "for batch_idx, (inputs, targets) in enumerate(test_loader_dict['Atemayar_Qelisayer']):\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(\"Inputs (features):\")\n",
    "    print(type(inputs))\n",
    "    print(len(targets))  # Print input data (features)\n",
    "    print(\"Targets (labels):\")\n",
    "    print(targets)\n",
    "    i+=1\n",
    "print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_embeddings(dataloader, model):\n",
    "\n",
    "    cuda = torch.cuda.is_available()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        embeddings = np.zeros((len(dataloader.dataset), 10))\n",
    "        labels = np.zeros(len(dataloader.dataset))\n",
    "        k = 0\n",
    "        for images, target in dataloader:\n",
    "            if cuda:\n",
    "                images = images.cuda()\n",
    "            embeddings[k:k+len(images)] = model.get_embedding(images).data.cpu().numpy()\n",
    "            labels[k:k+len(images)] = target.numpy()\n",
    "            k += len(images)\n",
    "    return embeddings, labels\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e832c436112fef2",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 256, 380, 0.6736842105263158)\n",
      "('Atemayar_Qelisayer', 536, 874, 0.6132723112128147)\n",
      "('Atlantean', 763, 1368, 0.5577485380116959)\n",
      "('Aurek-Besh', 1136, 1862, 0.6100966702470462)\n",
      "('Avesta', 1400, 2356, 0.5942275042444821)\n",
      "('Ge_ez', 1646, 2850, 0.5775438596491228)\n",
      "('Glagolitic', 2010, 3705, 0.5425101214574899)\n",
      "('Gurmukhi', 2342, 4560, 0.5135964912280702)\n",
      "('Kannada', 2590, 5339, 0.4851095710807267)\n",
      "('Keble', 2944, 5833, 0.5047145551174352)\n",
      "('Malayalam', 3344, 6726, 0.4971751412429379)\n",
      "('Manipuri', 3618, 7486, 0.48330216403954046)\n",
      "('Mongolian', 3887, 8056, 0.48249751737835156)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 4429, 8911, 0.49702614745819773)\n",
      "('Oriya', 4650, 9785, 0.4752171691364333)\n",
      "('Sylheti', 4838, 10317, 0.4689347678588737)\n",
      "('Syriac_(Serto)', 5030, 10754, 0.46773293658173704)\n",
      "('Tengwar', 5248, 11229, 0.46736129664262177)\n",
      "('Tibetan', 5617, 12027, 0.46703251018541614)\n",
      "('ULOG', 5924, 12521, 0.4731251497484226)\n",
      "0.4731251497484226\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.4731251497484226"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_results(model, annotated_loader_dict, test_loader_dict, k):\n",
    "    correct=0\n",
    "    total_images = 0\n",
    "    for alphabet in annotated_loader_dict.keys():\n",
    "        annotated_embeddings, annotated_targets = extract_embeddings(annotated_loader_dict[alphabet], model)\n",
    "        test_embeddings, test_targets = extract_embeddings(test_loader_dict[alphabet], model)\n",
    "        distances=cdist(annotated_embeddings,test_embeddings)\n",
    "        all_image_distances=[]\n",
    "        for i in range(len(test_targets)):\n",
    "            image_distances= []\n",
    "            for j in range(len(distances)):\n",
    "                image_distances.append((distances[j][i], j))\n",
    "            all_image_distances.append(sorted(image_distances))\n",
    "\n",
    "        k_classification = []\n",
    "        for i in range(len(all_image_distances)):\n",
    "            k_classification.append([score[1] for score in all_image_distances[i]][:k])\n",
    "\n",
    "        for i in range(len(k_classification)):\n",
    "\n",
    "            if test_targets[i] in k_classification[i]:\n",
    "                correct+=1\n",
    "        total_images+=len(test_targets)\n",
    "        print((alphabet, correct, total_images, correct/total_images))\n",
    "\n",
    "    top_k_accuracy = correct/total_images\n",
    "    print(top_k_accuracy)\n",
    "    return top_k_accuracy\n",
    "get_results(model, annotated_loader_dict, test_loader_dict, 1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e87003112448465",
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 336, 380, 0.8842105263157894)\n",
      "('Atemayar_Qelisayer', 693, 874, 0.7929061784897025)\n",
      "('Atlantean', 980, 1368, 0.716374269005848)\n",
      "('Aurek-Besh', 1405, 1862, 0.7545649838882922)\n",
      "('Avesta', 1769, 2356, 0.7508488964346349)\n",
      "('Ge_ez', 2100, 2850, 0.7368421052631579)\n",
      "('Glagolitic', 2563, 3705, 0.6917678812415654)\n",
      "('Gurmukhi', 3054, 4560, 0.6697368421052632)\n",
      "('Kannada', 3438, 5339, 0.6439408128863083)\n",
      "('Keble', 3839, 5833, 0.6581518943939654)\n",
      "('Malayalam', 4381, 6726, 0.651352958667856)\n",
      "('Manipuri', 4772, 7486, 0.6374565856265028)\n",
      "('Mongolian', 5134, 8056, 0.6372889771598809)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 5820, 8911, 0.6531253506901582)\n",
      "('Oriya', 6163, 9785, 0.6298415942769545)\n",
      "('Sylheti', 6448, 10317, 0.624987884074828)\n",
      "('Syriac_(Serto)', 6698, 10754, 0.622838013762321)\n",
      "('Tengwar', 6995, 11229, 0.6229406002315433)\n",
      "('Tibetan', 7516, 12027, 0.6249272470275214)\n",
      "('ULOG', 7893, 12521, 0.6303809599872214)\n",
      "0.6303809599872214\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.6303809599872214"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results(model, annotated_loader_dict, test_loader_dict, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 360, 380, 0.9473684210526315)\n",
      "('Atemayar_Qelisayer', 785, 874, 0.8981693363844394)\n",
      "('Atlantean', 1150, 1368, 0.8406432748538012)\n",
      "('Aurek-Besh', 1593, 1862, 0.855531686358754)\n",
      "('Avesta', 2028, 2356, 0.8607809847198642)\n",
      "('Ge_ez', 2428, 2850, 0.8519298245614035)\n",
      "('Glagolitic', 3023, 3705, 0.8159244264507423)\n",
      "('Gurmukhi', 3687, 4560, 0.8085526315789474)\n",
      "('Kannada', 4188, 5339, 0.7844165574077543)\n",
      "('Keble', 4634, 5833, 0.7944453968798217)\n",
      "('Malayalam', 5322, 6726, 0.7912578055307761)\n",
      "('Manipuri', 5830, 7486, 0.7787870691958322)\n",
      "('Mongolian', 6292, 8056, 0.7810327706057597)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 7058, 8911, 0.7920547637751094)\n",
      "('Oriya', 7554, 9785, 0.7719979560551865)\n",
      "('Sylheti', 7951, 10317, 0.7706697683435108)\n",
      "('Syriac_(Serto)', 8284, 10754, 0.7703180212014135)\n",
      "('Tengwar', 8660, 11229, 0.7712173835604239)\n",
      "('Tibetan', 9335, 12027, 0.7761702835287271)\n",
      "('ULOG', 9757, 12521, 0.7792508585576232)\n",
      "0.7792508585576232\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7792508585576232"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results(model, annotated_loader_dict, test_loader_dict, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 373, 380, 0.9815789473684211)\n",
      "('Atemayar_Qelisayer', 849, 874, 0.971395881006865)\n",
      "('Atlantean', 1283, 1368, 0.9378654970760234)\n",
      "('Aurek-Besh', 1752, 1862, 0.9409237379162191)\n",
      "('Avesta', 2226, 2356, 0.9448217317487266)\n",
      "('Ge_ez', 2672, 2850, 0.9375438596491228)\n",
      "('Glagolitic', 3378, 3705, 0.9117408906882591)\n",
      "('Gurmukhi', 4154, 4560, 0.9109649122807018)\n",
      "('Kannada', 4779, 5339, 0.8951114440906537)\n",
      "('Keble', 5259, 5833, 0.9015943768215327)\n",
      "('Malayalam', 6059, 6726, 0.9008325899494499)\n",
      "('Manipuri', 6676, 7486, 0.8917980229762222)\n",
      "('Mongolian', 7214, 8056, 0.8954816285998014)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 8033, 8911, 0.9014700931433061)\n",
      "('Oriya', 8689, 9785, 0.8879918242207461)\n",
      "('Sylheti', 9162, 10317, 0.8880488514102937)\n",
      "('Syriac_(Serto)', 9556, 10754, 0.8885995908499164)\n",
      "('Tengwar', 9981, 11229, 0.8888592038471814)\n",
      "('Tibetan', 10734, 12027, 0.8924918932402095)\n",
      "('ULOG', 11194, 12521, 0.8940180496765434)\n",
      "0.8940180496765434\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.8940180496765434"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results(model, annotated_loader_dict, test_loader_dict, 8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 2: rotation problem"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f49a6fcc9bcd5994"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load the test data for task 2:\n",
    "# the structure of the test data of task 2 is exactly the same as for task 1,\n",
    "# but now the images are rotated by an unknown angle between 0 and 360 degrees.\n",
    "data_dict_test_task2 = load_data('test_data_task2.pkl')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "800d9fa43d711ae0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_dict_test_task2.keys()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfd690817a188882",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# solution and evaluation of task 2:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab7aa34500088f66",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "71298802fa5d6fb8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4e6e3e82ce917c0f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e701b2a68bd4d32a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 3: Domain knowledge injection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfdbe34799376c36"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load the test data for task 3:\n",
    "# the structure of the data of task 3 is exactly the same as for task 1, but now our the loaded dictionary contains some additional keys.\n",
    "# These additional keys will be explained in the cells below:\n",
    "\n",
    "data_dict_test_task3 = load_data('test_data_task3.pkl')\n",
    "print(data_dict_test_task3.keys())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa248dbece85da5c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# The keys 'annotated_images', 'annotated_images_labels', 'unseen_images', 'unseen_images_labels' are the same as for task 1, and the structure of the data is exactly the same. \n",
    "\n",
    "# The key 'unseen_images_preceding_types' maps to the type of the preceding character in the sequence where the unseen image was observed, for each alphabet.\n",
    "# The key 'character_to_type_mapping' maps to the mapping of each character to its type, for each alphabet.\n",
    "# The key 'type_following_probs' maps to the probabilities of each character type being followed by another character type, for each alphabet."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fb6a6237a187493",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# examples:\n",
    "\n",
    "alphabet = np.random.choice(list(data_dict_test_task3['unseen_images_preceding_types'].keys()))\n",
    "print(f'Alphabet: {alphabet}')\n",
    "\n",
    "\n",
    "preceding_character_types_alphabet = data_dict_test_task3[\"unseen_images_preceding_types\"][alphabet]  # a list\n",
    "print(f'Some character types that preceded unseen images from the {alphabet} alphabet: {np.random.choice(preceding_character_types_alphabet, size=5)}')\n",
    "print(f'There are {len(preceding_character_types_alphabet)} preceding character types in the {alphabet} alphabet, and {len(data_dict_test_task3[\"unseen_images\"][alphabet])} unseen images.')\n",
    "\n",
    "\n",
    "character_to_type_mapping_alphabet = data_dict_test_task3[\"character_to_type_mapping\"][alphabet]  \n",
    "# this is a dict, with as keys the characters and as values the types\n",
    "random_character = np.random.choice(list(character_to_type_mapping_alphabet.keys()))\n",
    "print(f'Type of {random_character} from the {alphabet} alphabet: {character_to_type_mapping_alphabet[random_character]}')\n",
    "\n",
    "\n",
    "\n",
    "type_following_probs_alphabet = data_dict_test_task3[\"type_following_probs\"][alphabet]  # a dict of dicts\n",
    "preceding_type = np.random.choice(list(type_following_probs_alphabet.keys()))\n",
    "following_type = np.random.choice(list(type_following_probs_alphabet[preceding_type].keys()))\n",
    "print(f'Probability of a character of type {following_type} following a character of type {preceding_type} in the {alphabet} alphabet: {type_following_probs_alphabet[preceding_type][following_type]}')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef9bcef5572f0a78",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cbaa137b41e610ce",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "700c29e735fd10c5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "eb7d09f31839b40",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "596ab2a615cb44e9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a2656ede1e4adbe8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "42d46e71207afe47"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
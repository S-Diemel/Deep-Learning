{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment 1 2AMM10 2023-2024\n",
    "\n",
    "## Group: [Fill in your group name]\n",
    "### Member 1: [Fill in your name]\n",
    "### Member 2: [Fill in your name]\n",
    "### Member 3: [Fill in your name]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc4f04c033b0e00"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from scipy.spatial.distance import cdist\n",
    "import os\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# function for loading the training data:\n",
    "\n",
    "def load_data(file):\n",
    "    \"\"\"\n",
    "    This function loads the data from the specified pickle file and returns a dictionary with the data\n",
    "    :param filename: the pickle file\n",
    "    :return: dict with data -- keys and values differ for the train data and test data for each task.\n",
    "     Please see the cells with example code below for explanations and examples of the data structure per data set.\n",
    "    \"\"\"\n",
    "    with open(file, 'rb') as f:\n",
    "        data_dict = pickle.load(f)\n",
    "    return data_dict"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d19b9de0e3461531",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data = load_data('train_data.pkl')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0da60a825f5080b",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example alphabet names: ['Alphabet_of_the_Magi', 'Anglo-Saxon_Futhorc', 'Arcadian', 'Armenian', 'Asomtavruli_(Georgian)']\n",
      "\n",
      "\n",
      "how to get an example image for a specific character:\n",
      "shape of image 2 of character character06 of alphabet Asomtavruli_(Georgian): torch.Size([1, 105, 105])\n"
     ]
    }
   ],
   "source": [
    "# the structure of the training data is a dict, where the keys are strings indicating the alphabet.\n",
    "# The values are again dicts, with the keys being the character and the values being a list of images of that character.\n",
    "\n",
    "# see the code below for examples of working with the train data\n",
    "\n",
    "alphabets = list(train_data.keys())\n",
    "\n",
    "\n",
    "print('example alphabet names:', alphabets[:5])\n",
    "print('\\n')\n",
    "print('how to get an example image for a specific character:')\n",
    "\n",
    "alphabet_id = 4\n",
    "alphabet = alphabets[alphabet_id]  # a dict\n",
    "characters_for_this_alphabet = list(train_data[alphabet].keys())\n",
    "character_id = 5\n",
    "character = characters_for_this_alphabet[character_id]\n",
    "image_id = 2\n",
    "\n",
    "print(f'shape of image {image_id} of character {character} of alphabet {alphabet}:', train_data[alphabet][character][image_id].shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "289b9d9817ddf745",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2991163aba746526",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# function for plotting some examples:\n",
    "\n",
    "def plot_example_data(data_dict):\n",
    "    \"\"\"\n",
    "    This function plots some examples of the data\n",
    "    :param data_dict: dict with as keys a string specifying the alphabet, and as values a dict with as keys the character of the alphabet, and as values a list om images of the alphabet\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    alphabets_to_plot = np.random.choice(list(data_dict.keys()), size=10, replace=False)\n",
    "    \n",
    "    for i, alphabet in enumerate(alphabets_to_plot):\n",
    "        characters = data_dict[alphabet]\n",
    "        character_to_plot = np.random.choice(list(characters.keys()), size=1)[0]\n",
    "        images = characters[character_to_plot]\n",
    "        im_idx = np.random.choice(len(images), size=1)[0]\n",
    "        axs[i//5, i%5].imshow(images[im_idx].permute(1, 2, 0))\n",
    "        axs[i//5, i%5].set_title(alphabet + '\\n' + character_to_plot, fontsize=8)\n",
    "        axs[i//5, i%5].axis('off')\n",
    "    # plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f68bfac0812b8988",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1080x432 with 10 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA14AAAFoCAYAAABHZCprAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABlPUlEQVR4nO3dd5xU1fnH8c8zs52lLL1LLyLFQlURxYKxG2MvqFgg9iTGmPzUJEZjN1HRKPZeY4+CChaaWACRLkUsNOlsYXfm/P64d2HZnVl2YWen7Pf9eu1rZ+89c+4zs2fu3Ofec88x5xwiIiIiIiISO4F4ByAiIiIiIpLqlHiJiIiIiIjEmBIvERERERGRGFPiJSIiIiIiEmNKvERERERERGJMiZeIiIiIiEiMJWTiZWaLzOx0//EkM0uLUm6kmY2qQn1VLdfBzA6rZqzjzOwzM2sTrS7/8TPVqbfM85yZHeD/3cLMSsxsWDXqaGlmf67utiWxmdkwM7u5zN9PmFmXCOWq1PYl9szsKDP71N+n3W1mQTO7z193nZm1icX/y8xyzOzhso/9GCab2Xk1uJ1hZnaT//i+GqjvHDObV67+myt7TpR67jWzYJR1I8zsmGrUFXVfbma/N7Op/vfBTZXU8Zn/u7LvtpvM7PDdjdXMrjCzAVUpK9VXlbZoZheUeRy1DYpI3ZJwiZeZ9QU+A46Lw+Y7ANVKvIDuzrmDnHM/1kBdkXwJnOQ/PgH4ujpPds6tdM79owbikBRkZgm3D0hFZtYU+DMwwjk3DFgDXOScuxzAOffPCPuQmnIm8Jb/+EbgYz+Gg4Clsdhg6evaQ8cAn5tZz92twMwCzrmrnHOhSOudc+85597Z7Qh3bKcBcKxzbrBz7iDgX3taZ3nVjPVpYExNxyDVsj3xqqwNitQG/2TBZjNr5P9d4WRt2RN/Zna1mf07DqGmvEQ86DoZGAvkmFlm6UL/DODzZvaBmT1apvzRZvau/2Nm1s/MPjaz6WZ2fZlyx5nZ+2b2hpll+GUfNLOPzOwdM8sDLgbOMbMPIwVmZv82s0/M7G0za+if8epjZm9HKF6+rr3M7FUz+9LM2vr13eCf9fzIzDpEeT/mA6UHHocDH/jPbW1mE/2zq2P9ZZlm9qaZvWdmL/gfot262iZJKdv/jHxkZi+aWbq/vHzbH+a3kzeBo8xslHlXYj41s/3M7Bgzu9y/OlJkZo3N7HwzOzWeLy7JHQM87Zzb6v99D3BSmasfZb8Ey/+/7jCz3mZ2hJnN9Ms/aWbNzWyg7bh6dX4l257kPx7inHsWwHk+MbN0M/vQ37e9at6VuA5+e9i+z4pUzo/lMTP7ANh+pa7M6/pTmf3xvv6ySWZ2l5nNMLMLIwVsZjlAEHiEHSeeAAaY2f/8Nt7YL1t+v9zB3ze+Aoz0t5dmZp39ON7wX0cHfx85qjqvN4oQ0NK8E4c459abWSsze9GPMc3MPoryWkf4MX5hZueWWXWhlfm+s50Pim729/0fmVkjM7vF/3uimbV2zq0HWpuZVRKz1BAz+5ffzj81s/ZmdjzQ2/+/HlGmDd5kZk/5/9dx8Y5b6pwVlNlPR2NmvwGGAFfFOqC6KBETr32dczOA9/ASjbLmOOcOB7aZ2SB/2Q/OuV8BPwJ9gAXAMOfcQOAIM8v2y612zh0FTMFL7o4FvnfOHQbcD1wKPIx3cDS8fFBm1h+o55wbCrwAXOqc+wvwjXPu2Aivo3xducBvgLuBX5tZH6CNf+b5t8CfKnlP5pvZQKAQKPKXrQWO8M+uNjCzrsCJwBTn3AhgfSX1SWo4x/9CnwSMAIYBb/ptehJwil+ufNsHyHDOHQ/MAI4HhuJdUb0BmAoMAgb49QzG2wlPifkrSl2tgJ9K/3DOFQIZUcqW/39NwXv/DwR+MrP6QAvn3Grgb3j/v4OAs8wsUp1NnHObK4mtBO9qzVBgHjuu1O+0z4pUzrzubCF/vzw3Qt3/cs4dApwF/L7M8mf8mKN1dRwBvAtMxmuHpcw5dzTwH+DiSPtlv1xz4DTn3GNlnvt74Eq897R5hG3u8vVGiRU/ob4SuMPMFprZic65n/FOINYHhuOfNIvgE/97YBBwSZnlkb7v8BPYTv6+fziwEa9tDHXOHQr87Bddh9fuJPb+5LfzvwKXOOfexDs2GOacm1Cu7Nf+/7W9+VcfRGrJG3gn9io7iXQw3n70HOdc2Mz6+if2ppnZ2bUTZmqL2L88Xsw749vbzN4DMoGF5YqUdrObCZSeHZ7j//4RaAR0BO7yz5h2Z8cXbNnn9ge2Aaeb2VF478PUXYTXGfjKf/wFcEgVX1apuX4j/tGPvQcwzD9ohh1flpG8jpfI3QLs7S9rAjzo77g7AK3xXvtsf/3MasYnyedpP/nHzJ4AjgaamNklQBbwPN5BWfm2v5IdbbkT0BeYWFqpc26dmTXBO9i/He+As51z7ocYv55U9jPeZxQAM8sCioH0CGXL/78eBu4ADHgWL0Fe5ZfpC7zpP24KNMPbF1ZHPeBh8+5TbQEs8n/K77MilWtSJt4v8ZL0ss4xs7OAMODKLJ/jnCs2s3CUmI4H2gOnAd3NrJ2/vOx7cwSwjMj75VkRunZ1BGY750JmNoeKqvJ6F0WJF+fc+8D7/mdnPN5++zW8/9dhQLR7gvY3sxvx2sLeZZZH+r4D6IZ/EsQ55wDM7HbgSTP7Ba9L61akNl1rZsPx/ofzdlG2tO39BDQENsQwLpGyQnjdzk+upMyJwJX+yUGAv+OdOPsR+MzMXnTOFcc0yhSXaFe8TgZGOedG+GfuWrFzjH3L/P7Of1z2y9yA0cBt/tmnxf6ySM9dADzln5E6CLge70Ao2pmA74D9/ccHlNl+NOXrKh/nQmC8v/1hQNkuJuXNwDuoebfMsjOB1/3nTvbrXAr09tf32UV8knreB27329QgvC67EPlzU3rAuxSYUaYdHuEvX4F3sPgRXpv6Jcaxp7r/AeeaWT3/76vxDswj2en/5V/ZaoX3pTkZ78pN6dXHr4Fj/P/dvlHuE1vnX3UBmOInQpjnYOAoYKG/z3yVHfvM8vusSOWWlol33wjbHoN3JfaiMvWWr3sn5nWRbeKcO8y/ej8a72Cg9D0p/f0d0ffLkRK6pXgn9oJArwjrq/J6o8WcbTsGWNqEt//Hf95pQGvn3JIoT78Wr/vP4ex8EB7pcwved1fZK2AGfOScOwdYjdebA6AxlZ/QkxrgJ9rDnHMHA/9H5M9PWeXbmUhtGoe3P47mJmC0mfXz/85zzi3zk62lRO4tINWQaInXMezcnWku3mXPUj3Nu2cq2zkX7QrVO8D9ZvYS3lWtUk3MbDxe95bX8M4Sd/D7yH+Ed7VgDnBgab/8svzujwVm9ile0vPQLl5L1Lr8+mYCK/2uYhOBaPdnlN6LcaFzbkuZxR8BvzOz1/HOzIJ3IHegmb0PtGTHl7/UDR/h3Tf0od+m9/OXl2/72znn1gDv+PexTASu81dNAbb6Z9Q3A9Nq5RWkKD95uhV4z8w+xruC8nCU4pH+Xz/jXa1ZhndVq3Q/eSPwlv+/eyFKfe/iJT/gdYU6xL/SPhnviud04Hjz7lXtUMnLqFDOOTcdyPT3y90iPOdz4BMq2b9FcBg7X7EvO9hSsd8jYgzwcDX3y3fiDXrxX7yu2LvaP1b1fQGvh8ZT5t3b9jFwL4BzbhNeF/H/VfLc/+J1ARrHzolXxO87/7tjud/95yO8qyZv+O/B0cDH5t2z/HPpFTGJibPMu7fxZeAA/39RdtTJz83sdf/khkhCcM5twDt5E23U083AGcBjZtYC2GDePbDpeN8Xq2sl0BRmybJfNm943s+cc9H6yQveTdzOuRIzexDvit6uulCKSJyY2af+mfJYbqMecI9z7uJYbifRldk3BvGSzoOccyW1sN3ngN/593zVCjO7ApjuJ8YiUseZNw3R4c65v/hjAiwAujnnFpcpMxJIc86N88vfBPwRbzCoIDDWOfdkrQaegpR4Rd/e/4DsMosucc4tiFK2Id4Zy7JOcM5tjNU2K6njfbybxBc752psjh4RqVlmdg+w0Tl3Uw3WeSU7jwL4X+dcjQ9tXpNqK2Yz64Z3Vake8KhzbuwunlJZXbey8/1sDzrnKvRuMG/+tHzn3FW7uy0REUkdSZN4iYiIiIjInjGz7nijw5Yq8EeMlRhT4iUiIiIiIhJjiTa4Rkz5A1nEZAh9M7tg16W2lz3OnxNhqpn9rszye8ybgDGhuwZJ7UqgdruvmX1jZssirPuXaaJu8SVymzWzI82bbHiamf0jFjFK8kmgNptmZk/7bfQ6f5narFSQQG22QvuMdpwrdSzxqi4zq877U6VG6tc5C2/CyyF4o2Y1NLP9gFz/RvsM8yYGFam2GLbbxXjDWP9Qbl0LvDmSRHZLLbfZic65g/wpF4aYWbNqbFsEiGmbPR6Y709zc5CZtURtVmpADNtspPZZ4Ti32gGnqJROvMwsYGbjzOxjf+AKgNvMbIaZXeiX+ZO/frqZ7esvm2TehJRPmVm/Muuv99fXM7NX/OWPm9nxePPDTDKzI8xsoP94spmdX75O59z3zrmQP9RvCd6cM4OA0hnuP6DiRKRSRyRwu93snIs0MetVwH0xflskgSVTmy2d/NO80Q1X4s27JXVMorZZdj4WmAgMUJsVSNw2G6l9RjnOFQDnXMr+4I2UdYv/OABMwpvkMxP4xF+e4//uAjzrP54EDPYfZ7PjXriJ/t9XAxeX1uv//qzMdt8HGuBNjvgBkFG2zjLljsabiwa8CZxH+I8PB26I9/unH7XbKO227HMa440U1wF4Jt7vnX7i85NMbdb/+2K8q2H3x/u90098fhK1zeLN79fDfzwKONd/rDZbx38Stc36ZSK2T8oc5+rH+4lJ39AE0g1/olHnXNjMAOY454rNrDT7PsfMzsLLxsuONPKl/7sjcJeZ5QDd8Wbt7gY8UFpvhO32xZugGaAp3oSnZevEzDoB1wLH+os24jVs/N8bqvlaJXUkbLuN4MrSOqVOS6Y2i3PuYTMbB7xmZvs6576u8iuVVJGobbb8scBivy61WUnUNhuxfUY4zhVSvKsh3gRxg2Cnvq3lh3EcAwwDLsLL5kuVNr7RwG3OuUPwdoBWhXq/Bo5xzg0D9nXO/Vi2TjOrDzwBXOh2dIOZCgz3Hx8OTKvWK5VUkpDtNoqOwK3Ak8BhZnbqrl+epKCkabNmlgnbDzC2AgVVeYGSchK1zZY9FjgUmKE2K76EbLOR2meU41wh9ROvN4FWZvYJ8HaUMp8DnwDnR1n/DnC/mb0EbPOXPQIcbWYf43WzAvjczF43s4OBG4G3zGwi8EKEOi/DO2B9zO8n29E59xVQaGafAiHn3OfVe6mSQhKy3ZpZOzP7ANjHzD4wsw7OuXOdcyOA84CPnHMvVf/lSgpImjYLnO/vdz8Fljjn5lf71UoqSMg2C7yF114/A6Y6535GbVY8idpmI7XPCse51XupqUvzeImIiIiIiMRYql/xEhERERERiTslXiIiIiIiIjGmxEtERERERCTGlHiJiIiIiIjEmBIvERERERGRGKt0AuUjAr/RkIeyRyaEX7Zdl6o5arOyp2q7zYLarew57Wsl2ajNSrKpiTarK14iIiIiIiIxpsRLREREREQkxpR4iYiIiIiIxJgSLxERERERkRhT4iUiIiIiIhJjSrxERERERERiTImXiIiIiIhIjCnxEhERERERiTElXiIiIiIiIjGmxEtERERERCTGlHiJiIiIiIjEmBIvERERERGRGFPiJSIiIiIiEmNKvERERERERGJMiZeIiIiIiEiMKfESERERERGJMSVeIiIiIiIiMabES0REREREJMaUeImIiIiIiMSYEi8REREREZEYU+IlIiIiIiISY2nxDkBEREQkkQV7dmXe5Xm1us2cFWm0vXVKrW5TRGJLiZeIiIhIeWYEeneHQIBVAxuy9MQHa3Xzf12zN9P+129HOMUhQt8uqNUYJMmUabMVVqn9JAQlXiIiIiLlBBs14uG3x9E2LTcu27+x2Vx4d+72v8fnp3NXtz4QDsUlHkl8lbVZtZ/EoHu8RERERMrYePYg9pu4lhbB7HiHst2QrM30+zJEn6+MhQ8NiHc4kqCC8Q5AKqUrXiIiIiK+jWcPYt2x+dzc/BsS6TA2N5DFbS1mApA5qIS3Lz+YVo98RbiwML6BiUiV6YqXiIiIiBnBvDwO//1kFg59Kt7RVOrm5t8w8do7CTRqGO9QRKQadMVLRERE6rxA7+48/PY4v3th4lzpEpHUocRLRERE6rQ1lw6m4a9/2uVAGj3GjSZrjcU8niHnfsXYNtNivh0RqV1KvESSWDAvj4KBXWq0zuzFawktXlqjdYqIJKqSw/anZMQGJvZ6I2qZ70u2cOfqQ+n01Mpa2T++33EQVx1SAsCNzT8hL5gT821Kcktr15aNA9qQbhVPDIzPT+eO5SMIuB/iEJmUpcRLJInlD+7CpHGP1Gid3Z4cTcc/KfESkdRn6Rn83yOPMyw7XGm521cNZ1H/IqB29o1drpnGPP/x+wvacHr99bWyXUleP/y6PbOuHQvUq7Du0v9dQNfLp9d+UFKBBtcQkZ28csY9NJvSKN5hiIjEVNEx/bng2wUMziqqtFyPcaNZckbrWopKRFKZrniJyE76ZGRxbev3+PXtVwPQeA40empqnKOSWPvh+iFsa+TiHUbCy11uNH9gSrzDkBpQXC/IqbkbgfSI67eEC+n99hV0mVAYl+7XwW6dWTSqOb0zpwKJM5+YJJ6frxlC/SNXxjsMqQIlXiJSQZ+MLBad/SAAg2aeQtpnHShZuhycDsxT1f+d97y6M1XBKd8dzuYH4h2F7Km0Vi0paBJ9kIyfS7bw7tYu9PjDPMKbN9deYGakddwLFwywdkhzfz+spEsqd9TZU7mj5dcR100uDJO2WR3cEoUSLxGp1OS+L7FsYj6X9/4VoU2b4h2OiMge2/pkFtN73U+0YeOP+OIS2pwyH8K1mHQBwUaNuH/iM7RNK022NKy97JmbTz6bjrM0QmaiUAocYz9dO4Qmk/NoMjkP69873uGIVFvQArRNy6TFeMeW3wyMdzgiInvMzJFu0ZMa54BwqPYCKiPLIN2ClcYnUmXhsHqrJJCku+JVeOwA8ptH3hk1e2MBoV/W1XJEUZix6YyBNDn8J57rOBGAbieNpl39/Un76Ms4ByepImt1AUO/OWmP69mn8c+VzhmTaek83v5T+rXsTeWz3IiIJK5AVhZrz9iXw5pGv2/13OVDcTMb1mJU1fdhQZDr5o2kWeGqeIcicRRs1JA1J+9N75yX4x2KVFHSJV5t/rRoeyJT3pHzzsOmJkbiZcEgt/794Z2GqF048kH67H0GbaZkES4sjGN0kircF3PIPmrP65l9ykA23juRhoHK7yVwaWCZmbiiykcBE0lVaYEwgSztw5NVoEljJv79HnIDWRHXbwwX8ONfutLuw8QdQGVLuJA/zT+HxscuJD7X5CRRuA5tmHHzgxHXhVyYTeFCqHymBKll6mpYyz494DGunPM1wQYN4h2KyHa5b3zNmYNOYXJh5Xvod66+nazxjWonKJEE9Nhe73HzvE9I69A+3qFIDXtpS0POPOBE0j+eFe9QKnXYX66m6Vmr4x2GJLjrVu3P2f1PIjx3UbxDkTKS5opXsFkz5t/Vjt+1eDreoeyS9e/N4qvS6J4+Ccp1zGoYyGbvjF/iEpdINK54GyU//sSYf19G118v5JXOH0Qs1zYtl7Y5G9BuPPXcdt8ZPHrSCib0fCvi+v5fnUr+lKa1HFXsXXPOa1zYsOrDMD+1qSP3PX0Ce62bE8OoJB4Kw+mUrEzcrnsLi7dy4sN/oMPklYQ2bIx3OJLgCkIZCd2e66qkSbxoVJ8Fwx+p9GbTdXvn0HxNx7jMt1HW5o71WHzoQ5RPukQSmnO0vHcK3zYawkNN5nFpox8jFmuduYEFBw0m7Yv56m6VQprfP4Ul7QdDz8jrf1mWR7f3N+K+/LZ2A4sRS88gNHBv5p/SCqqYeL26pQF3zjyCzrdOURevJJTWpjWbD2hLIJE7+4RC3LlmKM0zKo6m+OXG9rS7ZSohDZQgQFqnDqztndj3IkpFyZN4VcEXf3+QTuMvpOvI+CZeVRKIPn+ISDy1v2kKb7x+CJe++1zE9dc3XcD1Ly3g6BGnw+z5tRydxMuSk//DbYd05aPe9eIdSo0IdGjLWy8+Wq2R42675Sw6P6HJxJPV0gs6MHf0WCAj3qFEFdq0iTn7A0T6nKm3jOww99rmLD0+8v1dkrgS+LTP7nl92AN0+DwbS4/PjnXRE/tzzc2RD1hLtQpmc/TkZWw4Z3AtRSVSTfOXcOQp53H3uk7xjkRqUbf7VnDQ5ZdQ7CJfz7mw0UyOmrOJQN8ol8VS0L4zTufIU87jyFPOo+lbC+IdjsRIx3dH8dxZNTBSkUgC6PbUaL67sGO8w5AIUi7x6pORxehmk2r9ilKgXj1+uH4Iow+YxK9zK59kNt2CXJ63nPyTN/LLRUq+JPGECwuxKbP4eZu6MdQlJSt+oMHsNVHXNw3W45rGSwjlJO4Vg6ooGb4/Cy9uQYDKvyf2nXE6wbfzsCmzsCmzEme6Eqlx6avTU6YbraQ4M37+3RAG9l4ctUjOj0ZYPVISUkp1NSyVbmGCrVsS+mllrQ17HWjUkOlj7o46RG0k3wx8jsvaDmTRIzEMTESkGiwU5uttYfZJD5ETiJxgbWucQU6DBoQ2VX6SKREFWzRn0UlpLDn5QaKdeyxyxczbFqbF39NwX6hroYgkDgsG+feYh3aarqis2dsKCRbpPsBElXJXvAB6ZWTz4qcvsv60/eIdiohIUilZsowbehzEpSsOj1rm3f88wLx7utViVDXnxElzmHfS/ZWW+ff6HlzXY6iugIhIUvm+ZAvXDTyepuM+j3coEkVKJl4AuYEshl41jcX3Dor5tjaePQh71pFtyd39RkQEwBUVURKOPuhETiADCybnGdUGgQIyLT3q+i6TRvLm/x3u9ZbQ6HEikmwKCiGscVcTVcomXgB3tPyaffeP3ge2pmzqGODtbv8jaNV/O7vnrGTLbwYSqF8/BpGJiOyeqd905bZfukZdv1ebtRScOAAsOUZoDTZrxpZTB9E6fX3E9cUuxLnLh9LkvWxy/ju9lqMTEdm1tFYt2XTKATQO5sc7FNlNKZ14AQTMYWkxvJUtEMRV8i6GXJgiV0yRK464/vK85Uz+13+gY5sYBSgiUn3dLv2cV+4+POq+a2KvN/j3PfdhGUlwpT8QZOvAjky+9yGGRrgNN+TCrA0V8MtJ2TR6Svd0iUhi2nBwB6bc/RB9MiruyEIuTKFLjhNhdVlKDq5R1iMd3mbq/EbcN/xISpavqPH6W0yux9jWtxNtsuSur42m5z3ezOGDX5/PX5pqlBkRSQ5NX5rNSdPP4t7/PU639OSdv2vR4315beh9QGbE9ScsOgZ3fgYlq76v3cBERGrIgbNOpcmYbYQ21/yxrtSclL/i1TCQzRHZBcz7WzMKThhQY/WmddyLhWMHcGXLD+icHjnpAkjbHKBkyTJKlixjY0l2jW1fRCTWwlu34pb9QHGUy/pt00pY8K++MKB3LUdWPbkNC+iXGTnpAthUlEXJ0uW6p0tEEtaqK4aw7dzoU1psLsikZNn32o8luJRIvDaGC3hqU1M2hgsirg9agCVHPMaKoyG4d82MxLWtTR5LT3yY/TOjd7N5dUsDMjfosq+IpKamwXosPf5h1u8d/eRTovuwIMiPqxvFOwwRkUrlHfcjM/Z7KeK69/IzyV+TvL0S6pKUSLweWt+HZ3u05fGNPSstt/T4hzn9tY9qJaYiV8xjIw6j9e1TamV7IiJSfTdeO4ou53wd7zBERHbb7WPOodulGkI+GaRE4lXq3YuH0fHti2K+naW3DObohz6Juv4PK/fl6PMuJfTjzzGPRUQklsIFBVx5/m85cPbJUcuMue5VFj2ZePMmBurXp+20XJ7q+0S8QxER2S3BZs3oPCOLsV2fj3coUgNSKvGyyTNpPSHA/l+eSrGLPIdBt4xVrLxqCGltqzeKYLBnV1ZeNYSVVw3hgEPmc03jJRHLnb1sGG/+bxDpH3zpzQMjIpLMnCM48Su2/K8lR8w7LmKRkQ1Wc8UBH7HyyiEJMzVGoG9PVvy2N3e3nRDx/q6fS7awz7SzqLdCwzKLSOKyjHRubzWJnhk5FdYtLd5Cr6lnkblySxwik92RcqMa5r48nUZTWlM0vZh0qzgB6KCsILOuHcvQZRdTb916wvm7/tIN1K/Pz4c1Y9a1Y3dZduHDPenwhIYjFpHU0vJfUwh/2Q8i32LAVXnLGH3tvzj5rd8Q3ry5VmOL5KdD85hzxVgg8qBG32zLo80p8zXRqIgkLMvMxDWIfu/WpwUdaPvrbwnXYkyyZ1Lqild1vHbfPSweV7WBNuzN+nx03Z0xjkhERERExLPimv159P3HyQ1EmIBQklJKJl7hX9Zx8K3XcOOaXlHLNA3W4+/7v8HSF/oQyKl4+basRhkF5AUrL/N9yRb63jGGplNW71bMIiKJLn3RT/S7dQzj89Mjrk8jyIaxATaePaiWI6ue4XOP5/pbR+lql4gkNJcGrdIijxrb/6tTuf+fv6nliGRPpWbiVVhI8wem8NTUA3lgQ7uo5U6vv57PDnyQLSN6R7znK5CVxbYR/elUb22l2/ukEK5Y+mta3f8FoYXf7XH8IiKJKLRqNS3um8Lcosj3yAYtwOQ+r7Fu7/hOo+GG9GVzp+hJ1dJ5rWjyqLqEi0jiCh+8LwXti6Ou3zi7CXm6tSXppGTiVarbpZ/z3I2/qrRM82A9Pr3/P/x40l4V1lm71ox/9CFubv5NpXWM/ORCCg5ZhSveVmm5sKvkYMQ035eIJIdwlAmVE0Xf+2ez5JT/xDsMEZHddsxDE1l6zCPxDkNqWGJ/ewKtp9Xn/AXLufTd9yIOlrErDd6by4hjzuLzouhnDfbEkGsupeefqzZs/LzT9qL7Y6Mjrrvs1f+y/G+DazI0EZGY+ODkfen84qXxDmO3DB1zMT3/sSzeYUgty/64Bc9dcE+8wxDZJevfm/MXLGdUw/kR1xe7EIdecBFd7llcy5FJTUj4xOuovDmcXn89x9fbvSF/w5s342bO5ewXruCKn/pHLZf9q1UsuX0wS24bTLBFc4qO6c+83zUlQOQrUdMKQ3R69RLypv5IyY8/VSmW0OKlZK2NXN8xOYVsy9O4NCKS+EILvyNzXfSvj70PXMIPfxpSixF50lq2YMltgxneYG7UMvWWbKJk5apajEoSwbCmCyJOKxByYTq+N4pWU3W/nySGUGaQ0+uvjzqgRpgwOQvXEFqzppYjk5qQcsPJR+QcHf80lbfyBvDv42dELDK176vQ13s8bNJFLD/OWHr8w0TLTT/e2oOul0+nJEYhi4gksrStMKkgwLDsiieMXu/6Pk+1aMqzt7at1ZjCLZuw6JwHa3WbktxKCLH3zWspWbIs3qGIEGzWjC2tKp4gKLU+lM+nhU0hpBMFyapuJF7VNGHcQ/6VroS/ICgiEhet7pnKHS//igOmvqKhjkVEasD8u9qxYPhYIPKtNZcsP46NQzdAeEWtxiU1J2kTry3hQg77y9VkbA6TsTlEOl/s8jk9HtxMv7ljmHld5RMh7+peso7vjaLjC1RpmyIiKck5CEfvHj2i3nLem9ybdVe1xc2ofICi2nDv+g68csNR1P9uTrxDERGJyMxVegwadqZpMJJc0l7SKXZhmr23hHqvTid9fNUSoPCsebR560cOmn0y324r2I1thjhq3rG0nJBW5W2KiKQql1/A4bPPZlJBxa+S5sF6PNdxIktOyqXksP3jEN3OFue3oN6r0wlv3RrvUEREdhYIsuGcwfRqH32wtqt+PoCvZ3SpxaAkFpI28dpdJUuXU2/EEh5Ycyj54cqHfy+r2IX4vqSA4JnbaPD8tBhGKCISQ4EggaysiD+WVr1OEKH162n4q8X8dclxUcssHPkgK39buKdRi4ikrEBWJo/9/W7e7PpexPUbwwVMvbc/Xa7R8WeyS9quhntq2Ygc+l9yFd9eVnm3w1LHzj+B4JnbCK3WKDIikrzWXDKAp/94d8R1J750DZ2u1YScIiKJ4tttBVx7yKnkrfwKF+9gZI/VuStepUK/rKPd+E30eGQMG8OVdzvs+N4oNo1rS2jVau++hhg58+ApLHpgoCZTFpGYCWUavTKyI/6cduRnLH56351+Fj6+P8EGDSqts/DxVnQaf2HU9VfuPZGF4w4gkBW7QTjWnT+Yn27SYYmIJJfwwfuyeFw3Wgcj77+KXYDQytW4oqJajkxiIWGveAUbNKC4b2caB7+N2TbcF3PotLABfzv2QEY1+YyeGTkRy7V5J0i9V2vm8m7WOsfd6zpxed6iCjdQ3tz8G4YeNZ+7rA843TwpIrXr5ubfcPPwnQfC2Bgu4PhDriRj/TaCBcW4Lyvukxs8N41AySA4MnK9Fzf8iRFH3sulGb+Cwth0O1w7MMTSAc9HXPdOfhaTVnShDbH7PhER2R0bumaxaNiDQMVj0JlFRdy3ajhU49YYSWwJe8Ur/6DuTHjxcY7MKY7pdkKbNjFn/zCnzYx+trYmNXpqKh8cvBdrQ9Uf3ENEpLY1DGTz8X8eZsJLT3DoE5/HO5zd8ud/XUCbk5V0iUhyOfnjMfwwaAuuWIlXqkjYxKsypy89jNNOHU1o7S81Vmfba7fR79YxOy2bVhjiiFNH0uDD+TW2HRGRZHVho5kcNWcTgb49K6xrOH4eR5x2Pl8W1fIBQiBIsymNeOWo+2t3uyIie2jZi334vz89Ge8wpBYlZeL105aG2NRZuJKSGqsztPA7Wk1cR6cJF/Bd8RauX9WHM98eQ2DyLEIbNtbYdkREklXTYD2uabyEUE5GhXWhDRsJfDaT37x9OTeu6VVhfX0L8N0femEH7FOjMVnAGNXiE/bPrBjTlnAhXSaeT5O5ujdCRBLP/m1XcHy9/Ijr9p1xOo0nV9yvSXJLysQrVsJz5tP1vK94asNAXh5/IF2vmB7TwTRERFKKc3S9fDpPTT2wwqq8YA4LLnyQlYMrH6ijJq0Ll9Bt9HekffhlrW1TRKQmNPtnJk0e0SizqSZhB9eIp+kDcukcmqFhO0VEREREpEboilcErqioRrsxioiI54RRH7PwwQHxDkNEJG7SWrWkaHwHftf6/XiHUqOsf2+2TdiLtA7t4x1KwlLiJSJSh+T+FObsZcMo3o0pK74v2cIp3x1O2sbKR2XN/S6NMT8Oirjur82+5ZgDZlV725GktWrJplMOoHEw8j0SIiKJyOXmMKHXqxHvTa3qfjZRWFoaW389kC2nDmL5r+ozsdcb/HBCW7acOojC43SSrTx1NRQRqUNyX5rGugl5rJ1VQKu03Co/r9iFeHz9ADYfvBZYW2nZ1ndMYemEveHdyPMfBiyMpaXtcc+CDQd3YMrdDwEVJ2YOuTCFTpPRi0iCMYO0YNTVz2/ct0r72UQRqF+fl++5a6fvk1l/HAvA+Px07nqnD4Q1N20pXfESEZFd6vX0ZXx+TMcaqeuWlp/yhwVfE+zZtUbqi+TAWady9SFnENq8OWbbEBGpru9vGMwN77xAukVPviR1KfFKMD0y1rNw7P4R58kREakJ4fx8hj35B25e22OXZYtcMZ1fupT27xVR8sOPVd5GYOUvdHtyNO/lZ1ZYlxvIYnh2CJe++wceq64YwrZz10Vdv7kgk5Jl32tkWhFJKCX1HIOyIu/7Dv32BJ594ohajkhqkxKveAiFeGZTX5YWb6mwqn1aLkuPf5jNXWpvyGURqVtcUREd/m8qj047OGJiVOqHki08vKEL3W9eRHDSV9XaRsnKVXT801Q+3LT3HkYbWd5xPzJjv5cirnsvP5P8NfVisl0RkVhZPbENre6aEu8wqizYpDHFvfYiaOrWXVVKvOIgtGkTH+xTnxO+vijeoYhIHdbt4hn884pzo64/c945vN0rj9DaX2oxqj13+5hz6Hbp5/EOQ0Qkpf14Tg8mvPQEzYM60VVVGlxDRKQOy5m6mMNGjoq4rt7qfMIx3PbBz3zNs88Pp+2tVT/DG2zWjA7vbubyZs8DObELTuqETEtn8OvzeWXcYbT4d/JcaZDkVPB+R+7r/Fi8w6gVPSefQ9v70wiEv453KAlFiZeISB0WWr+e9PFfRFxXE0nXfycOZOvQTMa2qTjC4fVNFzCu9bBq1WcZ6dzeahK5gYpJ19LiLRz7xSW0X7klpgmjJJ9/TzyKH4d8zh0tKx4E/qXpfJ5qeWgcopK6ZkyHSYzIKaqwvNiFGPTVGeQtSJ7R/zaePYiCQRVvmSlVtDKHwMfTazGi5KCuhiIiEjOdfzeNyc/uF3W9S3cEGzWskW19WtCBtr/+lvDs+TVSn6SOrpdN553/Do53GCIRbQkX0fKijdR7NXkSlYOvmc7CoU/FO4yko8RLRETi5ptj/83p076FgIZWFhGR1KbES0REYqr1R+vofc8Y1ofyK6zLDWTRMm1jlerZcuogfnkkh0xLr+kQRURixvbtxcrXezIke0W8Q9ljaR3a8/PrPTkrr2L38VI9xo2m80vbajGq5KF7vEREJKbCs+fTbkUehZdHvvOqUTCfohH7kfP5kkpHUFzfPcDcfq8AujomdUuwaycKOjfZ/nfmmnzcl9/GMSKpjsJWOcwa8AiQW2Hd7G2F/Gvlkbji4toPbDeEG+Uye8BzQMWpSL4v2cKdqw+l01MrCS1eWvvBJQElXiIiUiui3TY+IDOdSeMe4aDLL6Heq7s/dH1YnTgkRS26qAWLzn5w+99DvzmJ7KPiGJDUmMsWnEH2UcmTpLhK5uy6fdVwFvUvApLn9dQ2fUuJiEjMhTZs4OKjL2TYnBN36/nZH7fguQvuibq+4xsX89IJQ3czOpHE1XpafV4/9e6dlr3Y82nOX7Cc8xcsZ/VlQ+IUmdSEF3s+zUlz1xBs1izeoezS0lsHc/nLr8Y7jKSmK14iIhJ7zhH6dgHr8ntGLbL2tHwK8wbTZNzUCuuGNV1Av8yKXVtCLkyX9y+m/bsQWrC4RkMWSQRH5c2hV0b2TstapeVyev31ADx60gqWtPdGbOz27+8p+eHHWo9Rolt/3mDWH1UQdX2rtFzOb7iM2284lmBBF7LWGK3vSMw55YrzQhyTUxhx3fC5x7NqQlvakJixJ4qUTrzSWrWEQICSH3+KdygiIgJs2ZDDl0Xb2D8zo8K6+Qc9zdCGJ8G4qtdXQoi9b15LyZJlNRekSBKZ0PMt8M9nHDztEupnZ2KhsD4TCaLwpA0sGvB8pWUyLZ0lv/4PAA9saMc7r/f3VmzYTGjNmliHWCVpHfciUC/6fWi/vNGWNvcp6dqVlE68tj6ZRaPMAkoOiXckIiIC0PX8r7jmmMv4+OGH4x2KSMr56L6xAHy9LcwNPQ7CFVWcrFcS228breDiScsA6Db+YrqdH//Ey9LSuHLCuwzPLkJ3Ke2ZlHz3gk2bUO+TZtzV9SX+sdfrNJmcR5PJeay5VJMniojElXNY2EVdfWe3l8j+uAXBvDwAAn160GRyHqfUn1NbEYoklIeuOoUen51TpbLpFiTdguyT7mg+KZMmk/NY+NCAGEcolWn1z3QOuvwSDrriEiYVVO2wu/T/+ODBz2w/ho3X/7LksP1p+kkuA7M2EbSK8a8ObWXQHy6lzVs/1HpsySjlrngF+vTgx0MbM7XTveQEvK4sz3WcCEC39j1I/FsXRURSW9bqAoZ+cxIv9nyaVmk7D688IDOdZzq/wUHnXEOrj9ZR0iDL34dXHIZ5WmGIqxecTuP8LbUUuUjty/zfDHLbDPa64eKdnBiQWflcdjmBDJ7a6xMAbmvwA6+cfzhNX5pNeOvWmMcr5UybTT3/4YUnnkebZhtokFnI293+t8unjsgpYoR/DAv+//KCwyuUa/7uEkpWrqqpiLfbNqI/3x8V5MMOk4DsiGUKnaPxW3Mp2bSpxrefilIu8Vp+QmPmjh4LVLx/QERE4s99MYfso+DjBe22DxBQVm4gi5nXjaVnozG0nhy9q9SdPx5Fg6O/oySWwUqd4IJgmZkJ2zWvybip2+99vOXjY3my8+sANAxEPhgu649NFnHVzXM5+ePfEF6ixCueupz9NQDhLh1ZPXErTQLZEa8iRfPHJov4482LKiwftuoisj/ceSJ659zutedAkECGl9hn/OFnvuv5dtSixS7EhnDKpRIxpXdLREQS0kejbif/Qoh0tUukJk0+807+fdQgZvRL/Mm5t524jTMzT4TsLO6c+Dw9M3LiHZJUU+i7ZZzf/2Rav7GFR9pN3uP6Hh97D/lu57b75+UnUnBI9a+C/fT7gbww5i4A9kozICtq2UFfnUGLURsIbVpd7e3UVUq8REQkLm677wwePWmFNypbBOW7IZbVZdJImryXTSPWxio8STFtP8qne9ZoZo/8N5m2c1e95sF6dMv6mRm0jVN0VRda710ltrQ0Trvv94QyoaB1iCUn/yfOkUmVOUfJylXMGjuYXm36bl886PjZPNr+s2pX1zG94r7ymnbvc/7T51dY3vXebbgvv8XSM1hwf18COTv3GTi8+9cVpi+IuM03L6bNBCO0amG1463LlHiJiEhcNL9/Cj9lD+GBVu34baMV1Xpu4/HZNHqq4nxfItHY5Jl0Wdaa4vNCFRKvZORKSmh1lzd8d/igfnByfOOR6st7cip5Zf7+pOFgbvvVjqtUB+QsYXh2aLfqHpoF3w1/vMLy3rPH0DK7H+HMIB+MuIfOEZK2ymwMF/DQ+j50faoImzJrt2Kry5R4iYhI3LS+YwrvvN6fiyctI90Sv5uXiEisdPrjVD76Y73tfz/5f5f44xbUnG+uHgtXl/5V/W7cb2xpx0e962Eo6dodCZl4LRw7gFuHvxzvMEQSUrBBA3p/vIkW6bEfQejsht8A9XZZTmRPhJf9wDGnXEDfB2ZzR8uvKy27sHgrY867nKbfLGD3zgOL1C1X/NSf+ZfvTWDFvHiHItXUcdwSjvzwPACa37mcZzpMim88746i+4MFwLdxjSOZJWTiVb/15ogjXYnUdda/N9+dkMvzze6u0mhWe05Jl8SeK96GTZ3FO68N4dvhrXi3+7tRy+aH00ib+i2hBB19TpJXr8yfWPF/p9Lx6R8oWfZ9vMOpMT8VNMSmziL67HmSqEp+Xon9vBKAWa8PodPenXdaX69hAd8MfC7mcYRcmF6Tz6PNe0Hcl0q69kRCJl4iEtnPB9ZnwQVjiTafhkgya3fzFNYtG8TsmwvplZ6x0zDLC4u3kh9OY3ZRmzhGKEkvFOKrbVnsl1FIbmDn0dr2z8xg7uixHDZ9FOkplHhJamh9+5QKywL79GDmWxVPQnVMD+/RydmQC/Nt8TbCzgAodGl0vnYjJcu+2e06xaPES0REEkbDZ6dz3f9+xV1fvr3TMNm/PfcygtPmAiTsXEuS+EpWruKWngMJvds86miaIskiPGc+1/UYWmH5qpc68nX/F3a73m+Lt3Fdv6MIFxRuX+aKdDKiJijxEhGRxOEcofUbueD6awhl2PbFTecsUPdCqRGuqIiScPRJazv+bT5TBg+h/V8rXmFIRD9eN4T9TpgT7zAkTiKdiGpybw4D9hodsfxvfj+ePzT+ji3hQg7+5zWkb6nYCTW4zdFg43Rw6qBa05R4iSSR3J/CnL1sGI/v9WFcRoC7e10npqzvBEBgcwHhWo9A6oRwiAbPTdtpkQbSkNryaPvP6NVnr3iHUWUFvQp4aq9PIq67ZW13vpzTiW6a765OCU78aqdh6ssaO2g403t1JL8kg1bPzts+L5zUDiVeCcoFgEAQwjrckB1yX5rGugl5fD+zgLZpmbW+/acfGkHz+0vPAuuLXESSUygcoNiFop7AMvMmKHYlJRHXJ4vX7z6Mbk9ovjvZoduln7M53kHUYUq8EtSDd/yL35xyMR1Omx3vUCTBhDZs4IphZ3lHBrWs5ZpvdJVLRJJe/fPyGXjiZXx1w4MR13/U/2Hem7MXz/fvSXizDlNFpGYkXeLV7ZNzaTi+HtksjXcoMdUnI4sWjbSzlwico2Tp8nhHISKStEpWrqLlp43o+vRoxp9+Bx3Td55ItnmwHifn/sCNd59E52dDBCd9FZ9AK2FpaSy+7QDO7RO5m6GIJJ7od5cmqOYvZ9P4sdS4bL55dS7v5UfvLtY0ewuBvj29LociIiJSY0LfLqDzn2ewvKRBxPW5gSyWHvMIK4ZnEuzWOWKZeLKMDN749T3c2GxuhXXFLsSzm5uQsUV9FEQSSdIlXqmk28Uz+OcV50Zd/1qXCTz99jjSmjetxahERESk1IILH6TTsz/EO4xqmVdczDN9u1LvlenxDkVEykipxGvtW9245dyn4hrDwv/0p89XVqWfTWcMImfqYg49fxQfFkS+qhWk9u/jERERqQtcSQn/uOA8ek8/s9Jy17b4cPt39w9/GlJL0UWXf9JA9p28hS7pke8YCTvDaShwkYSTdPd4/Xi4o0G7yDu9O3o+wpE5xbUckSeQk8PPo/oxctCkiJf9I+l6XF/yW/QEoH6gEEiPYYQiIiJSXuDjr8noMZihOSfxSe//RizTPi2XO1p+DcDMw9uy9pfBNH04Prc9bD5tECuPLuaWFrPRcYNIckm6xGvpCQ/HO4SIAnmN+Ozau8kNZFX5OYuGPQHDSv/SzlNERCQemv5nKoGpPfj+7S20CmZXOk/ihJ5vMemPAW5/7VDCGzbW3pDzZgQbNaL71d8ypf2ntbNNEalRKdXVUERERGR3hL9ZwKX7/Iq/rum3y7IHZ5Xw6FdvkH/sfrEPzJfWcS8emPkWD7ebVGvbFJGalZCJV+NHcun80qU1Vl+xC7H32DF0fHNrjdVZG65f1YfDbv094Q0b4x2KiIhIanOO0KZNfHjbgXSdNLLSokEL0Cotl5a//46fX+/J9y/3JtioYUzCWvhIf35+vScbxwbomJ5b6dU4gFO+O5wLb70KV5zckz+LpKKE7GqY+c4MOm/ox1UHH8CNzT8hL5izW/U8vLE1c/Nbsy2cRsfHl1Hy4081HOkOrqiIq38cTr20Irpmr+K3jVbscZ2fre5M87FTNGGtiIhILWnw/DRcYBBXdT8AgHMaT2H/zIyIZV/q9CF0gi3hQo486ioyN4a2r8uaPH+3J18O9Nubwpb1cAbjDnuM4dmhXT8JuGVtd+ZM7Mpecbr/TEQql5CJF4BNnsm8/eHdBe04q/4vu1XHuH+eQN6TU4ESIHZJF0Bo7S98P9B7POM3v+K3//rPHtcZdhrRUEREpLY1fHYa8571Hp//+nnMHvB8peVzA1lMueehnZYdecp52JRZu7X9n25yzBrwSLWfN+mSQew1VUmXSKJK2MSr1LPHH8pffp/H0mOqvgOaty2fq0+5mKYLv6Vq54hqVoP35nL0iNN3Wa7gzkIm7fP6TssmF4a5+eSzIRym4aZ81FFAREQkftpdvpkDRozmi78+WK3nXfPUC2wI5TCvsDXTB+TiiooqLf/LhYP5/bUvADAk+zMgt8rbemhDG944/WACC+ajQeRFElfCJ16hBYtp984AOhVeUuXnBPMDdJ45g1BtjTRUTnjzZpg9f5fltrw8mE4Ldn5daZsDdJw1DZxTF0MREZE4K1nxA80/y6bTa5fwzrH30DOjarc/jMgpAopYnfMDz97yOyxUeS+W5n1WcXr99f5fVU+6jl80gsUTOtFu9pQqP0dE4iPhEy+A7Nc/p+vr1XtOMpzxafLIVJrEOwgRERGpVGjeIrpeBg8OOoRjG80kK1DM0CrOHtM8WI/FZzy064JV9GXRNn4J1dv+9/LXOtHuX0q6RJJBUiReIiIiIvG2YECYBfQh2LUjgz96cZcjDMbCFddeTu6rX2z/u6XTPV0iyUKJl4iIiEhVhL07x92Knzjs8jE4g58PNL47veauaEXS9/MzqP90AwAaTV5GSTged7CLyJ5S4iUiIiJSDeH8fHJemw5A+y0HMLTXSdvXtc3dwHMdJ+7xNmZvK+SyBWcAEJiQR71Xve6EGnRLJHkp8RIRERHZTRnvfwHv7/h77YH92PhiAQDpBMkJRJ4DLJqNYe+596w8kuyjlgKQzdKaCVZE4kqJl4iIiEgNCUyfw5kHnAjAois7sfC8qg9D/0PJFi4efi62eSuuuDhGEYpIvCjxEhEREakhrqSEkpWrAOjwdit6bR5T5ecGSqDNsi9wxdtiFZ6IxJESLxEREZEYsMkzaTu5es9JhulwRGT3BOIdgIiIiIiISKpT4iUiIiIiIhJjSrxERERERERiTImXiIiIiIhIjCnxEhERERERiTElXiIiIiIiIjGmxEtERERERCTGlHiJiIiIiIjEmBIvERERERGRGFPiJSIiIiIiEmNKvERERERERGJMiZeIiIiIiEiMKfESERERERGJMSVeIiIiIiIiMabES0REREREJMbMORfvGERERERERFKarniJiIiIiIjEmBIvERERERGRGFPiJSIiIiIiEmNKvERERERERGJMiZeIiIiIiEiMKfESERERERGJMSVeIiIiIiIiMabES0REREREJMaUeImIiIiIiMSYEq8yzGyYmS03s0lmNtnMelbhOSPM7Bgz62Bmz/jLPot9tFKXlGubk8ysYbn1jczs5HjFJztE2o/4j9OqUcdn5f42M3vHzD4xs2AV6+hnZvtVsv73Zrav/3i4H+MnZvZfM2tS1VirEMck//dIM9u/BupbZGanl62/Ou+t/5x+ZnZhJevvq2Z9T5hZlwjL25vZh36MU8ysXZTn32Rmh/tt5+ZKtlPhu6WqsZpZppk9VpWy4jGzQ8zsI///96GZHbib9ZxoZo39xzeZ2eE1G2ndtqvPTYTy5fevHczsMP9xSzP7s//4gl3UM9LMIh5H+/vsp/3HQTP7p5l97H8n/LGqse6KH/sT/uNq7bei1HewmW00s4wy9T+zG/VcZ2ZtoqyrdP8b5TkRj6vN7Cwzm2Zmn5rZw7t6frR9tb9upJmN2t1YzewEMzt1V+WUeFX0tHNuGPAH4NLShdE+XM6595xz79RSbFK3Pe2cG+b/bCy3rhFQpcQrWluWGhVxP7IHWgGbnXNDnXOhKj6nHxAx8fLbwIHOua/NrBlwA3Ccc24o8EcgowZi3olz7gnn3Jd7UoeZ9QU+A47bgzoCzrmZzrlHo5Vxzl2+u/WXcwVwi98WDgPW1FC921U1VudcEbDOzLrWdAypyMyaAn8FTvT/fycC+WXWV2c/eiLQuAbDk5rVAe/ziXNupXPuH/7yShMvYCTRj6OHA5/7jy/G238f4pw7EJi+R9FGUUP7rZOBl/Di3y3+PvafzrkfI63f1f63mq4EDnLOHYz33VWjqhnrW8DpuyqkA7DoGgCb/DNdtwNP+Znvx2Y23cyuh8gZcikz62Jm4/3n/KU2g5fUVfbsnt/+RuLt2I/w22t/23H1dZiZ3eQ/nuUvv9bMzvfLfmFmR/rrnzCzB/0zcjeb2f1m9mXpWb9Iz5FdagBsKv3DvCvkpe/huf6ylmb2P3/5rWXKmpn927yrO7cDh5rZODNraGZvm3d16t9+2QrL8NrEH8zs2Qhx9QUW+49/hZcobgZwzi10zv1cSRt5yMw+M7Mb/WWRyvU3s6/M7CUgz19WelWntZlN9OsY668b5r8Hb/ntLzfK+3kyMBbIMbPMMsvv8c96XuzX19evZ5qZnV0m9vuB98p9hm7237f7bMeZ47JnR3f5eiuRDwwzswbOuULnXKH/GdvHr+sqM/t1pCea2Uv+d8d4M2vgL25kZi/7n8v+5WLtYTuuiF9p3vfPVP+9vt5//kfsQdJax/wKeMY5twnAObfZP1FRlf3o9jZjZu2BEcCzZvYHv+5zzewDMxvnP6fCfkGqz8y+MbPn/P9RP9u5J9L270L/77L714uBc8y7qtnBzJ4xs+OB3v7/5Qgrc8XFXzYA7+TWh2Z2ToRwjsP7vIG337qrdIVzbpJfT4XPePnXUEm5v5nZp8CfysRVui/YZbus5G3sBvwN72RBqY5m9qa/P+3o1/dHfx/7kd/Gyx9jPOHvg5r4+6B3zewN//9Qdv9bpddbiXrAQPOSvfXmXdmfUOY9+dDM0ss/ySIcz/uOM7P3/VgzysU62n8PJppZdzP7bZm/93POhYFi21WPEeecfvwfYBiwHPgE+BnoDUwCBvvrswHzH0/0/x4JjMI7Y/KMv+4z//eLQDv/8fNA23i/Rv0k50+ZtjkJWArc7C8f6f+UbX9lHw8DbvIf/wLU8x/n+L8bAuP9x08AJ/mPFwD7ApnA5GjP0U+l/6vy+5G0Mu9hWpn39V/Akf7jgP/7M3/5GRH+p38AzvEfjwMGRlk2EhgVJcZTgd/6j68DjolQZldtZHol5d4C2gO5wC/+spuAw/GupqX5y54Buvrv2Rv+sj8DJ0SJ+03/9yWlMfvv7YFAEJji1/+m/56l451dTvdjL30/hwE3411JfNdfdhrwROn7X83X+wTQJUK89fEOuBYAL+MdJBzEjs/v+0BWmfdmWJl1pdsZBVzkP17nv6dtgLfLxfpfoEdpOwIuBEb6f5d+b/UAHo73ZyQZfsp+LoAz8T6Td1K9/ej0Msu6lPkcXO0/Ho/XW6HCfkE/1fpflX6eV/mfpwOBe4j+XVh+/1r2c1f2OZ+V2UbZx5NKf+PvyyLE9G6ZdvJplDKRPuM7vYZI5fD2W++VaZtPlI2xqu0yQjz7AX/1H7/u70c6APP8tjkQeAhoCbzvlzsIeNB/XPaz8QTQBe8q1On+sv/573XZ93uXr7f8+18u5v5+rN8Bl/jLxvnb7o6/v2PnfXoXoh/PP+Iv+yPe1atheG2rOV4iHfTXB/A+v9n+36V1/RMYUll71RWvip52XnebfsAt/rLS7jEdgXfN7GOgJ94/ojLdgafNu8ehJ96XpcjuKu2+NrLMMotQzkVZv8A5t9V/fJTfLt8Eyt53Msf//TMwx3ndk9wuniMVRdqPAOxvZh8AHwJ7+8u64SUMOO+MWemyXsALEeruDHzlP/4C70sk0rKq+hloHWH5rtpIQSXlGjnnvnfObQEWlqu3CfCK/5yDymy7tN4f8Q5Gd2Jev/zeZvYe3hfi8WVWf+28LpjL8fbLec65Zc65YrwTFaX76vJdHfcqs92Z5bdZjdcbkfOukvzOOdfd3/Y5wGRgkJl1AH52zhVGeK1B4A4z+wS4jB3v0WLn3BbndeFpWO5pTZ1z8/3thvESvT7mXfEcUVmcEtH2z4Vz7jngbKAp1duPFhBZ6fqf8P6PkfYLUn2L/c9T6T4k2ndhZfvXSplZpO/cXSk0s6xy9VT2Gd/+GqKU2wuY7ZeP1H17d9vlycBwfx/bHRjiL//GOVeCt4/sgpeMlW6/7PdN2c9GqY5lys6MsM2qvN6onHMznHMn4p3gvMC83hLP4n1HnI530SOSaMfzX5eJtUu58l/53zOl+9gbgQfNu7dsV/nAdkq8otuM100IoPRgaDRwm3PuELxuOrv6AC7AO6MyDNgfmBGDOKXu2Yh3xgu8nQ1AMd4Z/9L1Lcuthx3tGLzuCUcDJ5Rb7qI8ruw5El3Z/QjAtXhn8Q4HNvjLFgCDYKf7RhbifWHcEaHO7/D2JwAH+H9HWla2TZS3CO/LE7wzs2ebWX0/hi5m1oqqtRGilNtoZm3NrB7eFa2yzgRe9/eLk9mxH412kFTqZLwreCOcc4cCrcq8X339L+y9gNXABvO6DKUDnfxlULHdLmfHgW6fCNus6uuNyMw6lzlQW4N3RdPh3ftxB9EP/PrhnTkeCjzAjveji5nVM7PWlOnCWlq/mXXztxsAip1z1wDn43UdAu+9mF9ZzLLdu3jdz0oT3NIBXKq7H4WKn8XybT3SfkGqr/z7Gu27sPz+Ndq+cqf6zOveXLaequ5jXwN+V6ai0pNykT7j5V9DpHLLy8Sxb4RtV7VdlneAc+4g59wI4CT/B2Aff//aF++7ZZn/GHZ830Dk/eHSMrFG2sdW5fVGZf49q865fHYklB8DB/s/H0d5arTj+b5lfn9XpvwSYN/S7xz/90zn3Ei8K58j/XId8b7To6rWSFB1xDlmdhDepc+bgd+XWfcOcL+ZzQW2VaGuPwOP+R/WYuDXwJYajlfqntlAazN7F+/SPsBKoLGZvYLXX/17/wzqYn9deW/jdYX7nKp/0e/Oc+qqaPuR/wJv4J1N2+Av+yfwpHn3gU4Brgdwzj1qZn8ybwSsF8vU/QjwnJldBMx2zk0zs/kRlq0BnjCzfVzFm65n4XV5wjm3xsz+DrztJwnr8LqpVfX/Hanc3/HOti4Evi9X/iO8e2ZPrKTOSI4Byo7aNRfvixXgN8C9wOPOuW1mdgPwHN5B0QPOueJIJ6qddy/bTPPulZiLt5/elep8Dg7HOwubj5eEn+Uvfxbvy/qMKM9bgJdkvQeswDsbjP/4MbwzsWPKPed64BEzc3jtbKWZXQbk4HXpBG8Agagjf8kO/ufiJuANMwsDJXif1b+VKVbVtvA+MNbMXo6yPtJ+QfaQc26DmUX8Liy3f30IuNXMXmTnARo+N7PX8boLP4HXRfF/Zda/A7xuZuOcc6+W2/w7eJ+3b/E+c//wr66k4e0bHyDyZ7y8CvsCf7/1pb/fmhXhOdX+rjaz7pQZ/Mc5N9/MBuHtc1fjdedrBpzlnFvp39c0Be9Y+LxKqh4HvGpm5wMhvH1shXuuKnu9uwj9HjPL8x+/4veywMxm43UDjXZyLNrxfBMzGw8U4n2vDIbt+4NXgSlmVoA3aNb15t3zlgmc7ydjmc65X6hEaZ9EERGpQ8zs98CHzrmvd1k4hZlZmnOuxMxOAzo5527d5ZP2fJt7A2Occ5fFeltltpkB/Mc5d35tbVOkrvJPYj3lnIs08EadUXqFyDkXNrN3gItdlNEOa3i7twMvO+dqraeZmZ0AZDnnXqy0nBIvEZHU5XeVeqPc4hNcxSkJEkZtxmxmt+Gd1QwBpzrndmvId/+M8X/KLCpwzh0dodzBeKNUnuecK3//m4gkGf+kzegyi6Y65/4UrXwiqK2YzRuV8B28QY8+cM79eQ/qupId3R8B/uuc+1eEcn8DujvnTtvdbcWSEi8REREREZEY0+AaIiIiIiIiMVanEi/zJpSLyYAi5k8yW8Wy+5o3adyyCOv+Zf6EfyKQUO02zcyeNm8Cxuv8ZSNtx6St682fAFHqtgRvsy39+D42s8diEaMknwRqs8eZNynrVDP7nb9sHzObYmafmtnjFmmkGKlzEqjNVtjP+sv/aN5E4ZNsxwi0dZ7eiEpUs6FUqZH6dS7GGz76h3LrWuANRSmy22LYbo8H5jvnDgIOMrOWzrkn/GHBD8cb4jbSCEsilarNNos3nP1j/jDCITPrW1k9IpHEsM3OwptMdghwvH+/4wLn3BDnXOkongdUK1gRanc/a2YDgFzn3OHOuWGVjC5Y56R04mVmATMb55/ZLB0C9DYzm2FmF/pl/uSvn25m+/rLJvkjojxlZv3KrL/eX1/PzF7xlz9uZsfjTew5ycyOMLOB/uPJ5g2huVOd/qSa5SeZA7iKnYdLljooUdst3smCCX48E4EBZcIeCnzidNNonZRkbXYhOyYfro+G766TErXN+hOPh/x9aQkQ9icCL1WEN8y21DGJ2maJvJ89Fmhq3rDzN9TWe5QUnHMp+4M3+skt/uMA3rwp++KNuf+JvzzH/90FeNZ/PAkY7D/OZscgJBP9v6/GGxITvAkxAT4rs9338SZNNeADvNFcttdZplzZ5zTGm++gA/BMvN87/cTvJ1HbLd5cJD38x6OAc8s8937g0Hi/d/pRm91VmwWaA98A8/AOdOP+/ulHbZaKxwdHAw+X+ft4YA7enF/p8X7/9KM2u4v97H/KxPoCsF+8379E+Un1CZS74U1IivPmEACY47zJNEsve55jZmfhzbhd9mz9l/7vjsBdZpYDdMf70u6GN/kdLvLl0754E+QBNMWbdK5snZFcWVqn1HmJ2m434u188X8vhu3zlRyE14albkqmNvs74G/OuZfN7D4zG+qc+2T3XrYksURts5hZJ+BavKsG+HW9CbxpZvf5y/+7G69ZkluittlI+9mNwMf+solAT+Crar7elJTSXQ3xZsAeBDv1bS3fFWoMMAy4CC+bL1Xa+EYDtznvfoDFfpld1fs1cIzz7n3Z1+2YLK6yPq4dgVuBJ4HDzOzUXb88SVGJ2m6nAsP9x4cCpRMT9ge+cs6FqvMiJaUkU5s1YJ2/7Bd2dDuUuiUh26yZ1QeeAC50/i0JZpZZ5vmbgIJqvVJJFQnZZom8n50C9PGX9QOWVvlVprhUT7zeBFqZ2SfA21HKfA58ApwfZf07wP1m9hKwzV/2CHC0mX2M1z0Q4HMze928yTFvBN4ys4l4l1h3YmbtzOwDYB/zRnzp4Jw71zk3AjgP+Mg591L1X66kiIRst8BbeG32M7zJFn/2l58EvFb1lycpKJna7FjgBr/OPnjdaKTuSdQ2exneidjH/PtoOgIj/PtvPgZaAOOr9UolVSRqm420n30b2NuvM+Ccm1KtV5rCNIGyiIiIiIhIjKX6FS8REREREZG4U+IlIiIiIiISY0q8REREREREYkyJl4iIiIiISIxVOo/XEYHfaOQN2SMTwi/brkvVHLVZ2VO13WZB7Vb2nPa1kmzUZiXZ1ESb1RUvERERERGRGFPiJSIiIiIiEmNKvERERERERGJMiZeIiIiIiEiMKfESERERERGJMSVeySwQJNilI4F69eIdiYiIiIiIVEKJVxJLa9GMpyY+wy+n9Il3KCIiIiIiUgklXklq3fmDaf36ZvIC2VDrsw6JiIiIiEh1VDqBsiSmLb8ZyKYRW3mk3WSUO4uIiIiIJL7US7wCQQIZ6RUWhwsL4xBMDTMjkJnJ6Te9x+V5y+MdjYiIiIiIVFHKJV4//X4gL4y5a6dlhS7IDYeeQsmy7+MUVc1wg/pw5/MP0S09AwjGOxwREREREamilEq8vrtjMMMP+ZpeGdk7LQ+5MMvuqk9h/r7bl3W/dSuhuQtrO8Rqs/QMFtzfl0BOCU0ab6nw2kREREREJPGlROIVqFePkn278tfjX+Ks+r9UWB+0AN8OfnanZYc9PYr0ubUVYTmBIG7QPrjArkfFCGcG+WDEPXROz62FwEREREREJBZSIvEq2bcrE156It5hVFmwYQMefeEBWqVVNZlS0iUiIiIiksySMvHaespATr5pwva/m6a9Xe06Lr7vVX4qzttp2ROLB9LqxHl7HF9l1p83mHOufZfmwZyYbkdERERERBJH0iVe684fzKYRW7mm8ZI9quf0+uuB9Tsta7v3L9z0l7Po8NACQmsrdlmsCUV55o9IqGHgRURERETqiqQ7+u86aj4LDn4qJnWfmruRuWPG4lo3i0n9IiIiIiJSNyVd4iUiIiIiIpJsUjLxWlq8hQNuGM0fVu6768IiIiIiIiIxlnT3eFXmip/681NBQ1ZubUDTJ7/ki9PaQ8uv4x1Wlb20pSEvreoPwF/bvaU5u0Sk1gVycth0TG+wXU93UVb2mm0EJ34Vo6hERESSX0olXvOu6kVw2hxy2QBAWiAc34Cq6boJp9Ptyi9xJSX8Y/KveK7jxHiHJCJ1jLVpyaR7x5JuwWo979Qlw9k0LKW+UnabKymJdwgiIpKAUupb8p9PP8zmcNb2v/tmbAGSZ9j2ScfdxeMHDWDKvrrSJSLJ5ZEOb/P1gnrxDiPuvi9uzPP9exLevDneoYiISIJJqcRr/8wMoOxVrsRLulp8vpUuz1/KzNPuJTeQtdO69mm5DK63iCn0iVN0kip++sMQtnSMfNZ979t+pmT5ilqOSFJdw0A2w7KTq5dBTbtxTS9efGMoHbapy6WIiFSUUolXMrAps+g2L4/Nvykht5KhTb5Z3YpPWsHQrOhlRMqztDRsn24MP/1z7m31RcQygz+7lEZ59aEkTHjO/FqOUCQ1vZefyVNTD6TbDVNx8Q5GREQSkhKvBNX6pLlcc+Fovvj7g/EORZJIoGN7/vvOk2RaetQyU+98CICZRUVc12MorqiotsITSVm3jzmHbuM/j3cYIiKSwJJuOPl1V7Wl2xOjY1L3Hes6c9jIUbD4+5jUXxVDsjbT78sQfb4yrvjDy3GLQ5JXIPk+1iJJ6738TA4bOYqszxfFOxQREUlwSXfFy834hoa9B9d4vZf8MJgPP+5H5/FTieddCrmBLG5rMTOOEYhIXWabt9J36nmYVa/DXM/mq3il8wcxiiox/WV1b56dNphu4z8nFO9gREQk4SVd4lWT8sPbWBveBsCMx/rR+aGptbNhF2Z5STYNA9vICWTUzjZFygmYI9g4j9CatRr+WrYrWbmKdqesqvbzVp08kO/vfb3mA4qjVsHsqMPq/1CyhVdfP5huN02p5ahERCRZ1enEa/AX59Hm3B8BaJ4/o9ZuiA5t2Mjf+h3Kqmdb8uX+L9XSVkV21icji3HTX+Gk639Pw2emxTscSXI5r3/BpR/8Kt5h1JyAccyUJfy2UcURQItcMRcddxF7zf9SA2mIiEiVJWXi1WzyGvrcOYZ3r7qdtmm5u1VH5xcupd2EEKFNm2o4uqoJbdpE/Ye60/mIS/nu1Id2q47vS7Zw3D3X0mbKKnVzkWrb3n4+V/uRGhCO3/40Vopd9EmkA5sLKNHANCIiUg1JmXiFFiym9bIVXHHiSbSvtz5quYuafEqvjJ0nI14b2srNqw+hy0v5MG12rEOtVOY7M+i8oR9XHXwAAEc0nMMxOYVVeu4nhXD3il/T6v4vCBVvi2WYkqLWhdJpNfZLQjp4FBEREYm5pEy8AFxREVuHrmFeJWUum3A6E3u9sdOyt7d2ZN7+JUB8k65SNnkm8/b3Hr9z2/kcc07Vho8f+cmFdB35ZQwjExERERGRmpK0iVdV5Fzk6HvCGL649j6OvPBSsn7ajBWVAIvjHVpEXe/+jqOfPb1KZXv+8jMaDkF21z7TzqL9X4pxRQvjHYpIwrH+vRn5zNscW+9nQLPYi4hIzUjpxKtk2fe0nlSP7p1+S48ZCwn9si7eIVUqtGo1rFpdpbLxHPJeklvXSSNp/L9sQnNraRRPkSQTygxyev31KOkSEZGalNKJF0B41jy6XokGD5A6wUpCjC+ox5DMdeQFcyKW6Xifw6Yq6RLZHetD+Xxa2BRC+lYREZHqCcQ7ABGpOSVLl/Pvbr24fEUKDestkkAuWX4cD3TvScnyisPMi4iIVEaJl0iqCYcIO4t3FCIpKewMwrraJSIi1afES0REREREJMaUeImIiIiIiMSYEi8REREREZEYU+IlIiIiIiISY0q8REREREREYkyJl4iIiIiISIyl/ATKIiIiIiKpJtizK4e//GW8w9ilt685jPTxX8Q7jISgxEtEREREJMm4zHSuabwk3mHs0v1nDaN5s0E0fHZavEOJO3U1FBERERGRmFhyxGNknLsq3mEkBCVeIiIiIiIiMabES0REREREJMaUeImIiIiISEz8ZXVvfvy2RbzDSAgaXENEREREJMUUueJ4hwDAx38bQpfXNLAGKPESEREREUkp16/qw6xfd4p3GADk/jSLcLyDSBBKvGrRij8PoaBNSZXLN5yXRov7psQwIhERERFJNZtKsilZsizeYUg5SrxiLK1Na8LNGgFw3ukT+GOTRVV+7sn7HEHBJz0Jf7MQwqEYRSgiIpLagj274jLTK65wDvftIlxJ1U+KiojsLiVeMTb3/9qy9PiHd+u5r3WZwNq3t3Je/5MpWan5D0RERHbHka/M4Kq8ZRWW54e38Zuhp+rKgIjUCiVesRIIEvywBY+3H7dH1QSxGgpIREREygqavmNFpPZoOPkYsYBxbfv3GJa9Z7cTZloayy7ojB2wTw1FJnXd0hNzKD7ygHiHISIiIlKnKPGKAUtLI5CXR7rteZ/xnEAG3142lhVHNqiByCSVWWYmwbw8gnl5ZAajt71F5zzIsjNdLUYmIiIiIupqGANbTtifl++5i+bBnHiHInXI0hv2Y9I5dwDQNJgNBOMbkIiIiIhsp8QrBlzQaJWWG+8wpA5Z+Eh/Lhr4UZXaXbcnR9Pxg221EJWIiIiIlFLiJZICbh36CqfXX1+lsh3ezMemzopxRCIiIiJSlu7xEkl2GpVLREREJOHpipdIEgsduh+jHvovx9dbBWRELdfl+Uvp+uQGAAIL5qOhNURERERqlxIvkSS1/rzBrD+qwO9iGDnpKnLF9Hh3DB3GlxCePb92AxQRERGR7ZR4iSQbM9I67kXGGatY1Oe1qMXWhrbyUUFrel6/jNCaNbUYoIiIiIiUp8RLJMkEGzXi/onP0DG98hEMT557NtlHfw9hJV0iIiIi8abBNUSSyObTBtHifyW0TcuutFz3R0eT9beGEA7VUmQiIiIiUhld8RJJEvknDWTl0cVMaf8p0SZHXhvayslzz2av9wqwyTNrNT4RERERiU6JVxLYGC7AwvGOQuIpkJXFwTdM5ZYWs6OWKXLFfFTQ2u9eqCtdIiIiIolEiVeC2xgu4PQR59NuyUyUe9VNgX16cOfbj9MlPQ1Ij1qux7tj6Hn9Mt3TJSIiIpKAlHgluLBzBNaupyQ/P96hSLykBeiVUfk9XV2ev5QO40s0eqGIiIhIglLiFQMZm0Lc9ktXLs/7lpxA9EltI8kPb+O+9b22/72xJBtXUlLTIUqSSOvUgbW9G0Zd/3PJFh7fsD/dHlpNaNGSWoxMpG5qm7OBbw/qR3D6XFzxtniHIyIiSUSJVwxkvDeDiR80ZOCCLIZlV6+D4GeF9fiob4Ny9+j8UrMBStKYe21zlh7/YNT1/1g1nEX9iwAlXSK14d5WX1D04lROPvg3lCxZFu9wREQkiSjxihFXUsI/Tz+LW9KrN2J/YFsIwnNiFJUkjUCQZp/V55ZW9wPRr5r+ucWHPD+nT5WqfPWHfuSOUIImIiIiEg9KvGLIzfgGq+5zYhKJJBsLGKNafML+mZV3VW2Vlss1jauWTPXNXs7l/3dJxHW5Kxx5T0ytdpwiqSh95UY6jb+Q14c9QJ+MrHiHIyIiKUKJl0gdMTw7xNzRYyOuO//7g1k9ofX2v11JCaFVq2srNJGEElq8lK4jl/LRtz3ok7Es3uGIiEiKUOIlIoxr9zEF03cMFPDkpq68uXeTOEYkIiIiklqUeIkIQQuQazu6VJ2QO4/XPjiTsPM6y24pyqTpqT8Q1rQGIiIiIrtFiZeIVNA2LZcP935z+99rQ1s55pTfk1a4812IDRZsJDxrXm2HJyJSIwIE+PnIVmSvaxmzbQS3hcl+YwY43cUtUtcp8RJJUIUunSK3pUbqSiNI0Ko3wmZZTYP1mP7PisPad/rvJXS7Mk1zzYlIUkq3IF/dEH3Kjpowe1shf/zwCFxBQY3V6cKu3LQzIpIMlHiJJCBXUsJ9w4/kvmCwRupbdkc9vh38bI3UVdak4+7i8YMGMGXfbB0EiIhE0Cs9gz/N+pSw2/2TX+Vd8sXZdDhtdo3VJyK1Q4mXSIIqWb6ixupq+NIgui0aHXHdlce/zW8b7d622qflMrjeIqZQtbnERETqmqAFGJoFEK6xOls02lxjdYlI7UnpxCutUwfCDXIir1y4TAMFSJ1R/8Vp1H8x8rp72h1O/f3f2v53/6zv6ZkR5XMTQb1AEbZvD2zh94Q362BAREREJJKUTrzy/+OY2Ou5iOsOGzmK9PFf1HJEIomn81lf8yxtt/9940Mns/T4h6v8/AOzArz31rMcdPkl1Ht1eixCFBEREUl6NdfhOEGsvWQwfb4y+nxljO36fNRyJ90zge/uGlSLkYkkh573rOOwkaM4bOQo7lu/V7zDEREREUkJKXHFK61lC344vTNtnl9MQXPjjpZf+2uid5e6PG85D3VQtyiR8kILFpO+wHv8fVFjYHmVnvfj4Y624YHk/FdXvUQksfx74lE80qpmRokFqJ9dxLR+r1Ra5tBvT2D1plyyMoqZtt/zpNueDZb0c8kWjvjiEpwDN7Mh7Vi6R/WJSO1L+sQrkJNDfr/2zLp2LIfNuZBQpubJENkTgawsLDsbgMzA2l2WD7kwP4by+fiYuzmh9Shy/hvrCEVEqqfrZTV7QijYtRPFk0KVJlPpNzSi7dRZpLVqycKp26gf2LORXyds7UKbU+ZrBFmRJJb0idf8+/ZmxpH3AvV44fF/k2kBIDvOUYkkrwW392XyiXcB0DSYDVR+lvbTwjRuH3A8FJfQsuT7Ghy3S0Qk+ZX8vJI/9Dlqj+txzkFYPXVEkllSJl4lw/dnzeXeiIR/6f42TYP1AGju/xaR3RAIsujxvlx9wHu0SsvdvviSHwYz5eV9+eSKO8kL7tx9d/jc49n4fBua/DK1tqMVEYkbt3INA269nAtGv8Plebvujh3atKkWohKRRJeUidemvTKYPeDReIchkjKCzZqRP6ADrw29n36ZmTutW7E1j4ZLQoTwuvF+X7KFu9cMA2DVB21p8+iU2g5XRCSuwps30/z+KUw9o1OVEi8REUjSxMtZvCMQSS0bD+3M5HsfAjIrrHu3+7twH4B3Rfn2VcNZ1L8IgDYo6RIRERGpiqRLvFa+3pOxfR4gBUfCF6lVwRbNOXHSHBoECmidPrNKz+kxbjSdnloJGk1LREREpFqSJvEKNmnMomu78/eeL3BgVs0kXad2+Zrn/nEIHf/2Fa6oqEbqFEkGJcP3Z9FJaZzX4B0yLb3Ssnes68yDEw8HoPOEQkKLlXSJiIiIVFfSJF40bsTcs+/f43kwyrqx2VwuPudzLnj5Yuy7FYQ3a7QgSX1pe7XjuxEZLDn5QaDypAvgiQWD6Hq55uYSERER2RN1vr9eq7Rc3nznaVae1zveoYjUimHvzGXBmQ/EOwwRERGROiV5rnjFULoFNWCH1BnpFiJoVTvn0uv+MbT9QFeCRURERPZUUiRedsA+rDi0AQGUHYnsrmDTJqw5vhtdMx+PuD7kwpyw6Bg2FWVtX9b+3Q2EZ86trRBFRJLed8VbOH/+OeSu20oo3sGISEJJisTru1Prs+jssUTqGZkf3kaYMLmBrIpPFBEALD2Dor4dmHHzgxHXh1yY1aF83PkZZC/dMXhGuLYCFBFJQvklGWwMFwDQMJBNfngbj64bQvZRS5V0iUgFSZF4VWbfJ66k5fQQH//n4XiHIpKwFtzflw9G3APkRlx//vfD+OWkbEpWfV+7gYmIJLFtJ27jzMwTITuLOyc+z4nP/I7O9y4Efol3aCKSgJI+8UrLNzLWb4t3GCIJLZBTQuf0yEkXeGdtS1auqsWIRESSX2j9egAsLY3T7vs9e03ZSmitki4RiazOj2ooUte9uqUBM1e0jXcYIiJJy5WU0OquKdjUWfEOReoQK9jGLWu7szq0Nd6hSBUp8RKp42675Sw6nzkz3mGIiIhINYQWLObjPtncseageIciVZT0XQ1FREREROqqOSO70/XsQXxy+h2cdcGVpOWXENxSBMyPd2hSTtInXvUPWs3ido3jHYaIiIiISK0Lz55Puw8OYEjDq+nx2TeECws1KnGCSvrEa1q/V6BfvKMQEREREYmP9PFf0G28poFJdLrHS0REREREJMbqfOK1NrSV/f86mtbvayhtERERERGJjaRIvHKXGxetODAmdec7R4vnvyW08LuY1C8iIiIiIpIUiVfzB6bw49ktKHaheIciIiIiIiJSbUmReImIiIiIiCSz5BnVcO16ej11GTee/BJn1f9lj6vr9MEFpP2USWAbdCj6qgYCFBERERERiSxpEq/Q+vV0/NNU3hnah7PqT6z281/d0oCt4Yztf3d+OEzgs6kAuBqLUkREREREpKKkSbz2RJEr5rERh1GyZNn2ZQFmxi0eERERERGpW5Iu8Vp3VVsOyxtVvSeFHRk/zolNQCIiIiIiIruQdImXm/EN6bvzvBqPRERE6qIAAZac05p2ExpiU2bFOxwREUkSGtVQRESkGtItyLxLxrLs2Jx4hyIiIklEiZeIiIiIiEiMKfESERGJ4Pl/Hk3v6WfGOwwREUkRSrxEREQiaPT0VEJfNYp3GCIikiKUeImIiIiIiMSYEi8REREREZEYU+IlIiIiIiISY0q8REREREREYkyJl4iIiIiISIwp8RIREREREYkxJV4iIiIiIiIxpsRLpA7bGC7AQvGOQkRERCT1pcU7ABGJj2+3FXDtIaeSt/IrXLyDEREREUlxuuIlUge0eSWdTq9dsv3v878/mDPu+x0lK37CFRXFMTIRERGRukFXvETqgOw3PqfbD7247ZCuAEyeuA8d75oS56hERERE6g4lXiJ1hPvyWz7qXQ+AjkyNczQiIiIidYu6GoqIiIiIiMSYEi8REREREZEYU+IlIiISRbDIGwG0vG+3FZBWYHGISEREkpUSLxERkSha3zmdaw89nS3hwu3Lilwxfzj6XNr9Y3ocIxMRkWSjwTVERESiCYcI/bSS4ddfjfNPVVoYGi+fBWHNPi4iIlWnxEtERKQSrqiIRk/tPBJoOE6xiIhI8lJXQxERERERkRhT4iUiIiIiIhJjSrxERERERERiTImXiIiIiIhIjCnxEhERERERiTElXiIiIiIiIjGmxEtERERERCTGlHiJiIiIiIjEmDnn4h2DiIiIiIhIStMVLxERERERkRhT4iUiIiIiIhJjSrxERERERERiTImXiIiIiIhIjCnxEhERERERiTElXiIiIiIiIjH2/1PxFay6AGNxAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plot_example_data(train_data)\n",
    "# plt.savefig('example_data.png', dpi=600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "511e9fbc1b85e80f",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 1: character recognition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6449bef2185716"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"CNN Builder.\"\"\"\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "\n",
    "        self.front_layer = nn.Sequential(\n",
    "            # Conv Layer block 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Conv Layer block 2\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "            # Conv Layer block 3\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            Lambda(lambda x: x.view(x.size(0), -1)),\n",
    "\n",
    "            nn.Linear(256 * 13 * 13, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.last_layer = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward.\"\"\"\n",
    "        # conv layers\n",
    "        x = self.front_layer(x)\n",
    "        x = self.last_layer(x)\n",
    "        return x\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.forward(x)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f78ab6a6133991a4",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class EmbeddingNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"CNN Builder.\"\"\"\n",
    "        super(EmbeddingNet2, self).__init__()\n",
    "\n",
    "        self.convolutional_layers = nn.Sequential(\n",
    "            # Convolutional Block 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Convolutional Block 2\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Convolutional Block 3\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Convolutional Block 4\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            #nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Flatten\n",
    "            Lambda(lambda x: x.view(x.size(0), -1)),\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(13*13*512, 1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward.\"\"\"\n",
    "        # conv layers\n",
    "        x = self.convolutional_layers(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.forward(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import BatchSampler\n",
    "import numpy as np\n",
    "class BalancedBatchSampler(BatchSampler):\n",
    "    \"\"\"\n",
    "    Returns batches of size n_classes * n_samples\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, labels, n_classes, n_samples):\n",
    "        self.labels = labels\n",
    "        self.labels_set = list(set(self.labels))\n",
    "        self.label_to_indices = {label: np.where(  np.array(self.labels) == label)[0]\n",
    "                                 for label in self.labels_set}\n",
    "        for l in self.labels_set:\n",
    "            np.random.shuffle(self.label_to_indices[l])\n",
    "        self.used_label_indices_count = {label: 0 for label in self.labels_set}\n",
    "        self.count = 0\n",
    "        self.n_classes = n_classes\n",
    "        self.n_samples = n_samples\n",
    "        self.n_dataset = len(self.labels)\n",
    "        self.batch_size = self.n_samples * self.n_classes\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.count = 0\n",
    "        while self.count + self.batch_size <= self.n_dataset:\n",
    "            classes = np.random.choice(self.labels_set, self.n_classes, replace=False)\n",
    "            indices = []\n",
    "            for class_ in classes:\n",
    "                indices.extend(self.label_to_indices[class_][\n",
    "                               self.used_label_indices_count[class_]:self.used_label_indices_count[\n",
    "                                                                         class_] + self.n_samples])\n",
    "                self.used_label_indices_count[class_] += self.n_samples\n",
    "                if self.used_label_indices_count[class_] + self.n_samples > len(self.label_to_indices[class_]):\n",
    "                    np.random.shuffle(self.label_to_indices[class_])\n",
    "                    self.used_label_indices_count[class_] = 0\n",
    "            yield indices\n",
    "            self.count += self.n_classes * self.n_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_dataset // self.batch_size"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16b4aff5112f09b7",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Triplets loss\n",
    "    Takes a batch of embeddings and corresponding labels.\n",
    "    Triplets are generated using triplet_selector object that take embeddings and targets and return indices of\n",
    "    triplets\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin, triplet_selector):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.triplet_selector = triplet_selector\n",
    "\n",
    "    def forward(self, embeddings, target):\n",
    "\n",
    "        triplets = self.triplet_selector.get_triplets(embeddings, target)\n",
    "\n",
    "        if embeddings.is_cuda:\n",
    "            triplets = triplets.cuda()\n",
    "\n",
    "\n",
    "        anchor_idx= triplets[:, 0]\n",
    "        positive_idx= triplets[:, 1]\n",
    "        negative_idx= triplets[:, 2]\n",
    "\n",
    "\n",
    "        ap_distances = (embeddings[anchor_idx] - embeddings[positive_idx]).pow(2).sum(1)  # .pow(.5)\n",
    "        an_distances = (embeddings[anchor_idx] - embeddings[negative_idx]).pow(2).sum(1)  # .pow(.5)\n",
    "        losses = F.relu(ap_distances - an_distances + self.margin)\n",
    "        print(losses)\n",
    "        return losses.mean()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "948e55a5ea036e8a",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "char_dict = {f\"character{i:02d}\": i - 1 for i in range(1, 100)}\n",
    "train_loader_dict = {}\n",
    "# Iterate over the dictionary items (label: images_list)\n",
    "for alphabet in alphabets:\n",
    "    data_alphabet = train_data[alphabet]\n",
    "    image_label_list = []\n",
    "    targets = []\n",
    "    for label, images in data_alphabet.items():\n",
    "        # Append each image-label pair as a tuple to the list\n",
    "        for image in images:\n",
    "            targets.append(char_dict[label])\n",
    "            image_label_list.append((image, char_dict[label]))\n",
    "    #print(len(targets)/len(set(targets)))\n",
    "    train_batch_sampler = BalancedBatchSampler(targets, n_classes=len(set(targets)), n_samples=3)\n",
    "    triplets_train_loader = torch.utils.data.DataLoader(image_label_list, batch_sampler=train_batch_sampler)\n",
    "    train_loader_dict[alphabet] = triplets_train_loader\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Batch 0:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([ 9,  9,  9,  2,  2,  2, 10, 10, 10, 12, 12, 12, 16, 16, 16, 22, 22, 22,\n",
      "         6,  6,  6, 15, 15, 15,  5,  5,  5, 23, 23, 23,  8,  8,  8, 13, 13, 13,\n",
      "        11, 11, 11, 21, 21, 21, 17, 17, 17,  7,  7,  7, 20, 20, 20, 14, 14, 14,\n",
      "         3,  3,  3,  1,  1,  1, 24, 24, 24, 19, 19, 19, 18, 18, 18,  0,  0,  0,\n",
      "        25, 25, 25,  4,  4,  4])\n",
      "Batch 1:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([ 5,  5,  5, 16, 16, 16,  1,  1,  1, 20, 20, 20, 25, 25, 25,  8,  8,  8,\n",
      "         0,  0,  0, 17, 17, 17, 19, 19, 19,  3,  3,  3, 21, 21, 21,  4,  4,  4,\n",
      "        11, 11, 11,  9,  9,  9, 24, 24, 24, 10, 10, 10, 18, 18, 18,  7,  7,  7,\n",
      "        22, 22, 22, 12, 12, 12, 23, 23, 23, 13, 13, 13, 15, 15, 15,  6,  6,  6,\n",
      "        14, 14, 14,  2,  2,  2])\n",
      "Batch 2:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([12, 12, 12, 25, 25, 25,  0,  0,  0,  4,  4,  4,  6,  6,  6,  8,  8,  8,\n",
      "        22, 22, 22,  9,  9,  9,  5,  5,  5, 19, 19, 19, 17, 17, 17, 20, 20, 20,\n",
      "        18, 18, 18,  2,  2,  2,  7,  7,  7, 16, 16, 16, 11, 11, 11, 10, 10, 10,\n",
      "         3,  3,  3, 15, 15, 15, 24, 24, 24, 23, 23, 23, 21, 21, 21,  1,  1,  1,\n",
      "        14, 14, 14, 13, 13, 13])\n",
      "Batch 3:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([24, 24, 24,  7,  7,  7, 11, 11, 11, 19, 19, 19, 21, 21, 21, 22, 22, 22,\n",
      "         8,  8,  8,  1,  1,  1,  5,  5,  5, 18, 18, 18, 20, 20, 20,  2,  2,  2,\n",
      "         0,  0,  0, 10, 10, 10, 14, 14, 14, 25, 25, 25, 15, 15, 15, 23, 23, 23,\n",
      "         9,  9,  9,  3,  3,  3,  4,  4,  4, 12, 12, 12, 13, 13, 13,  6,  6,  6,\n",
      "        17, 17, 17, 16, 16, 16])\n",
      "Batch 4:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([17, 17, 17,  2,  2,  2, 18, 18, 18, 10, 10, 10, 13, 13, 13,  7,  7,  7,\n",
      "        22, 22, 22, 23, 23, 23,  1,  1,  1, 24, 24, 24, 15, 15, 15,  3,  3,  3,\n",
      "         8,  8,  8,  5,  5,  5,  0,  0,  0, 14, 14, 14, 12, 12, 12,  9,  9,  9,\n",
      "        25, 25, 25, 19, 19, 19, 21, 21, 21, 20, 20, 20, 16, 16, 16,  6,  6,  6,\n",
      "        11, 11, 11,  4,  4,  4])\n",
      "Batch 5:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([12, 12, 12, 23, 23, 23, 22, 22, 22,  5,  5,  5,  9,  9,  9, 13, 13, 13,\n",
      "        20, 20, 20,  7,  7,  7, 15, 15, 15,  2,  2,  2,  1,  1,  1, 19, 19, 19,\n",
      "         6,  6,  6, 10, 10, 10,  0,  0,  0,  4,  4,  4, 24, 24, 24, 14, 14, 14,\n",
      "        16, 16, 16,  3,  3,  3, 17, 17, 17,  8,  8,  8, 21, 21, 21, 25, 25, 25,\n",
      "        18, 18, 18, 11, 11, 11])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader_dict['Latin']))\n",
    "i=0\n",
    "for batch_idx, (inputs, targets) in enumerate(train_loader_dict['Latin']):\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(\"Inputs (features):\")\n",
    "    print(type(inputs))\n",
    "    print(len(targets))  # Print input data (features)\n",
    "    print(\"Targets (labels):\")\n",
    "    print(targets)\n",
    "    i+=1\n",
    "print(i)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "\n",
    "def pdist(vectors):\n",
    "    distance_matrix = -2 * vectors.mm(torch.t(vectors)) + vectors.pow(2).sum(dim=1).view(1, -1) + vectors.pow(2).sum(\n",
    "        dim=1).view(-1, 1)\n",
    "    return distance_matrix\n",
    "\n",
    "\n",
    "class Informative_Negative_TripletSelector():\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        super(Informative_Negative_TripletSelector, self).__init__()\n",
    "\n",
    "        self.margin = margin\n",
    "\n",
    "    # Our goal is to mining informative triplets.\n",
    "    def informative_negative(self, loss_values):\n",
    "\n",
    "        informative_negative = np.where(loss_values > 0)[0]\n",
    "        return np.random.choice(informative_negative) if len(informative_negative) > 0 else None\n",
    "\n",
    "    def get_triplets(self, embeddings, labels):\n",
    "\n",
    "        if torch.cuda.is_available() == False:\n",
    "            embeddings = embeddings.cpu()\n",
    "        distance_matrix = pdist(embeddings)\n",
    "        distance_matrix = distance_matrix.cpu()\n",
    "\n",
    "        labels = labels.cpu().data.numpy()\n",
    "        triplets = []\n",
    "\n",
    "        for label in set(labels):\n",
    "            label_mask = (labels == label)\n",
    "            label_indices = np.where(label_mask)[0]\n",
    "            if len(label_indices) < 2:\n",
    "                continue\n",
    "            negative_indices = np.where(np.logical_not(label_mask))[0]\n",
    "            anchor_positives = list(combinations(label_indices, 2))  # All anchor-positive pairs\n",
    "            anchor_positives = np.array(anchor_positives)\n",
    "\n",
    "            ap_distances = distance_matrix[anchor_positives[:, 0], anchor_positives[:, 1]]\n",
    "            for anchor_positive, ap_distance in zip(anchor_positives, ap_distances):\n",
    "                loss_values = ap_distance - distance_matrix[\n",
    "                    torch.LongTensor(np.array([anchor_positive[0]])), torch.LongTensor(negative_indices)] + self.margin\n",
    "                loss_values = loss_values.data.cpu().numpy()\n",
    "\n",
    "                hard_negative = self.informative_negative(loss_values)\n",
    "                if hard_negative is not None:\n",
    "                    hard_negative = negative_indices[hard_negative]\n",
    "                    triplets.append([anchor_positive[0], anchor_positive[1], hard_negative])\n",
    "\n",
    "        if len(triplets) == 0:\n",
    "            triplets.append([anchor_positive[0], anchor_positive[1], negative_indices[0]])\n",
    "\n",
    "        triplets = np.array(triplets)\n",
    "        #print(len(triplets))\n",
    "        return torch.LongTensor(triplets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module,\n",
    "                 device: torch.device,\n",
    "                 criterion: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 training_dict: torch.utils.data.Dataset,\n",
    "                 validation_DataLoader: torch.utils.data.Dataset ,\n",
    "                 epochs: int\n",
    "                 ):\n",
    "\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.training_dict= training_dict\n",
    "        self.validation_DataLoader = validation_DataLoader\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def run_trainer(self):\n",
    "\n",
    "\n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "\n",
    "            self.model.train()  # train mode\n",
    "            alphabets = self.training_dict.keys()\n",
    "            train_losses=[]\n",
    "            for alphabet in alphabets:\n",
    "                data_loader = self.training_dict[alphabet]\n",
    "                for batch in data_loader:\n",
    "                    #print('test')\n",
    "                    x,y=batch\n",
    "                    input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)\n",
    "                    self.optimizer.zero_grad()  # zerograd the parameters\n",
    "                    out = self.model(input)  # one forward pass\n",
    "                    loss = self.criterion(out, target)  # calculate loss\n",
    "\n",
    "                    loss_value = loss.item()\n",
    "                    train_losses.append(loss_value)\n",
    "\n",
    "                    loss.backward()  # one backward pass\n",
    "                    self.optimizer.step()\n",
    "                    loss.cpu()\n",
    "                    input.cpu()\n",
    "                    target.cpu()\n",
    "                    del loss#update the parameters\n",
    "                    del input\n",
    "                    del target\n",
    "                #print('\\n')\n",
    "                self.model.eval()  # evaluation mode\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # print the results\n",
    "            print(\n",
    "                f'EPOCH: {epoch+1:0>{len(str(self.epochs))}}/{self.epochs}',\n",
    "                end=' '\n",
    "            )\n",
    "            print(f'LOSS: {np.mean(train_losses):.4f}',end=' ')\n",
    "            #print(f'VAL-LOSS: {np.mean(valid_losses):.4f}',end='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0015, 1.0000, 0.9996, 0.9982, 1.0001, 0.9974, 0.9976, 0.9947, 0.9992,\n",
      "        0.9953, 0.9980, 0.9987, 1.0020, 0.9991, 0.9993, 0.9846, 0.9983, 1.0077,\n",
      "        0.9993, 0.9983, 0.9828, 1.0066, 0.9872, 1.0049, 0.9980, 0.9987, 0.9895,\n",
      "        0.9942, 1.0007, 0.9989, 0.9952, 0.9933, 1.0061, 0.9939, 1.0026, 1.0049,\n",
      "        0.9987, 0.9950, 0.9971, 1.0000, 1.0046, 0.9988, 0.9986, 0.9971, 1.0059,\n",
      "        0.9993, 1.0028, 1.0047, 0.9982, 0.9999, 0.9991, 1.0022, 0.9987, 0.9997,\n",
      "        0.9905, 0.9882, 0.9968, 0.9932, 1.0004, 1.0111], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0059, 0.9959, 0.9924, 0.9919, 0.9886, 1.0002, 0.9984, 1.0072, 1.0047,\n",
      "        0.9949, 0.9938, 0.9906, 0.9980, 0.9983, 1.0001, 1.0042, 0.9998, 1.0009,\n",
      "        0.9970, 0.9999, 1.0013, 1.0035, 1.0012, 0.9962, 0.9961, 1.0071, 1.0019,\n",
      "        0.9942, 1.0032, 0.9998, 1.0039, 1.0019, 0.9975, 1.0015, 0.9999, 0.9969,\n",
      "        0.9985, 1.0071, 0.9955, 0.9974, 0.9985, 1.0052, 0.9981, 0.9955, 0.9957,\n",
      "        0.9963, 1.0077, 1.0021, 1.0047, 0.9895, 0.9951, 0.9956, 0.9929, 1.0055,\n",
      "        1.0061, 0.9932, 1.0023, 0.9972, 0.9982, 0.9963], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9946, 0.9958, 1.0029, 0.9926, 1.0054, 0.9939, 0.9939, 0.9913, 0.9959,\n",
      "        0.9933, 1.0006, 0.9874, 0.9929, 0.9968, 1.0012, 0.9983, 1.0055, 0.9966,\n",
      "        0.9956, 0.9998, 0.9997, 0.9944, 0.9921, 1.0006, 0.9878, 0.9839, 0.9957,\n",
      "        0.9986, 0.9929, 0.9942, 0.9891, 1.0063, 0.9990, 1.0071, 0.9981, 0.9908,\n",
      "        0.9896, 1.0024, 0.9970, 0.9985, 1.0002, 0.9995, 0.9969, 0.9945, 0.9949,\n",
      "        0.9983, 0.9964, 0.9942, 0.9861, 0.9930, 1.0081, 1.0035, 0.9972, 1.0000,\n",
      "        0.9944, 0.9906, 0.9911, 1.0101, 0.9927, 1.0027], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9976, 1.0013, 0.9934, 0.9984, 0.9866, 0.9920, 1.0016, 0.9969, 0.9988,\n",
      "        0.9945, 1.0012, 0.9943, 0.9941, 1.0035, 1.0047, 0.9938, 0.9981, 0.9949,\n",
      "        0.9915, 0.9959, 0.9986, 0.9989, 0.9930, 1.0038, 1.0041, 0.9997, 0.9939,\n",
      "        1.0023, 0.9834, 0.9901, 0.9975, 0.9976, 1.0041, 1.0015, 1.0039, 1.0068,\n",
      "        0.9904, 0.9979, 1.0027, 0.9910, 1.0001, 1.0011, 0.9995, 1.0143, 1.0167,\n",
      "        0.9967, 1.0065, 1.0006, 0.9956, 0.9941, 0.9926, 1.0001, 1.0046, 1.0019,\n",
      "        1.0001, 0.9923, 0.9810, 1.0084, 1.0005, 0.9954], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9903, 0.9844, 0.9924, 0.9996, 0.9834, 0.9949, 1.0001, 0.9859, 0.9928,\n",
      "        0.9946, 0.9949, 0.9847, 0.9983, 0.9952, 1.0002, 0.9925, 1.0048, 0.9968,\n",
      "        0.9978, 0.9923, 0.9916, 0.9994, 0.9937, 0.9948, 0.9956, 0.9784, 0.9981,\n",
      "        0.9946, 0.9986, 1.0023, 0.9985, 0.9949, 1.0075, 1.0081, 0.9939, 0.9977,\n",
      "        0.9974, 0.9980, 0.9993, 0.9835, 1.0030, 1.0006, 1.0004, 0.9845, 1.0005,\n",
      "        1.0017, 0.9828, 1.0018, 0.9725, 0.9927, 0.9894, 0.9993, 0.9942, 0.9957,\n",
      "        0.9916, 1.0033, 1.0052, 0.9922, 1.0027, 1.0073], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9932, 0.9792, 0.9796, 0.9909, 0.9987, 0.9697, 1.0065, 0.9957, 0.9979,\n",
      "        0.9811, 0.9788, 0.9754, 0.9776, 0.9645, 0.9885, 0.9749, 0.9965, 1.0045,\n",
      "        0.9453, 0.9915, 0.9868, 1.0028, 0.9791, 1.0073, 0.9786, 0.9741, 0.9804,\n",
      "        0.9836, 0.9991, 0.9673, 0.9844, 1.0012, 0.9808, 1.0067, 0.9661, 0.9921,\n",
      "        0.9937, 0.9954, 0.9903, 0.9970, 0.9948, 0.9843, 0.9954, 0.9781, 0.9647,\n",
      "        0.9954, 1.0028, 0.9871, 0.9821, 0.9891, 1.0049, 1.0026, 0.9962, 0.9955,\n",
      "        0.9999, 0.9818, 0.9821, 1.0239, 0.9878, 0.9523], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [02:25<21:50, 145.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 01/10 LOSS: 0.9999 tensor([0.8453, 0.2469, 0.2466, 0.9871, 0.9050, 0.6907, 0.7383, 1.0121, 0.9613,\n",
      "        0.6252, 0.1395, 0.7112, 0.9801, 0.9169, 0.7978, 0.7348, 0.9455, 0.3014,\n",
      "        0.4665, 0.2454, 0.4434, 0.7680, 0.8137, 0.3917, 1.0433, 0.7673, 0.5461,\n",
      "        0.3669, 0.5956, 0.9599, 0.9874, 0.7031, 0.9276, 0.8850, 1.0151, 0.9371,\n",
      "        0.9228, 0.5815, 1.0863, 0.9178, 0.4139, 0.0085, 0.7151, 1.0272, 1.0448,\n",
      "        0.9562, 0.8061, 0.9579, 0.0438, 0.7142, 0.9726, 1.0404, 1.0512, 0.9410,\n",
      "        0.1612, 0.0848, 0.9306, 1.0179, 0.9130, 0.9859], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0545, 0.3057, 0.6504, 0.8610, 0.3896, 0.7807, 0.0471, 0.9439, 0.7938,\n",
      "        0.2676, 0.5388, 0.2099, 0.2707, 0.6849, 0.6699, 0.5847, 0.8969, 0.5813,\n",
      "        1.0040, 0.2947, 0.3351, 0.9055, 0.1981, 0.8130, 0.1258, 0.7229, 0.3923,\n",
      "        0.7579, 0.6992, 1.2015, 0.3290, 1.1377, 1.0282, 0.4242, 1.6370, 1.4495,\n",
      "        0.9280, 0.9022, 0.9305, 0.9265, 0.9240, 0.7725, 0.6634, 0.2204, 0.1550,\n",
      "        0.3327, 0.6817, 0.2568, 1.1288, 1.0463, 0.8146, 1.5284, 0.8181, 1.3152,\n",
      "        0.8309, 1.2314, 0.9088, 1.0088, 1.0925, 0.8470], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.4733, 1.1307, 0.0354, 0.7476, 0.0030, 0.7116, 1.1964, 0.8893, 0.7230,\n",
      "        0.5211, 0.0101, 0.0268, 0.2967, 0.7574, 0.9504, 1.1894, 0.1835, 0.2921,\n",
      "        0.4402, 0.6365, 1.0662, 0.7550, 0.4935, 1.3386, 0.0979, 0.9250, 0.2688,\n",
      "        0.8609, 0.6629, 0.3433, 0.7641, 0.5602, 0.5320, 1.8947, 0.5312, 1.1757,\n",
      "        1.4753, 0.7847, 0.2367, 1.5565, 1.5033, 0.2259, 0.6650, 1.2651, 0.5759,\n",
      "        0.4923, 2.4330, 0.9602, 0.3167, 1.0706, 0.9790, 0.6739, 0.4071, 1.0246,\n",
      "        0.4428, 0.5631, 0.8081, 0.7691, 1.2019, 0.6585], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([3.5690e-01, 1.1262e-01, 1.1351e+00, 6.4302e-01, 1.1881e+00, 8.7659e-01,\n",
      "        3.2671e-01, 1.6392e-01, 7.1418e-01, 5.0714e-01, 2.5494e-01, 1.5507e+00,\n",
      "        4.0026e-01, 1.3105e+00, 2.0710e-01, 1.2701e+00, 1.5149e+00, 9.7812e-01,\n",
      "        2.0297e-01, 2.7890e+00, 5.6363e-01, 4.8562e-01, 3.7689e+00, 2.4670e+00,\n",
      "        6.6548e-01, 7.8176e-01, 7.1935e-03, 8.2829e-01, 1.1900e+00, 2.7955e-01,\n",
      "        1.9923e+00, 4.9786e+00, 9.3388e+00, 2.1139e+00, 1.4224e+00, 1.2836e+00,\n",
      "        3.9881e-02, 5.1977e-01, 2.5517e+00, 3.4913e-01, 4.2318e+00, 8.9072e-01,\n",
      "        2.1403e+00, 1.3424e+00, 1.9309e+00, 6.7444e-01, 3.2183e+00, 5.8239e-01,\n",
      "        4.7184e-01, 8.5216e-01, 7.7432e-01, 3.4356e-01, 5.0061e-01, 5.6621e+00,\n",
      "        3.6871e-03, 1.9633e+00, 8.7162e-01, 3.3720e-01, 4.0501e-01],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([ 0.3059, 11.8523,  7.5206,  0.1587,  0.3262,  0.6688,  2.1500,  3.6498,\n",
      "         0.6638,  0.1468,  0.1054,  0.2226,  0.1525,  1.4864,  0.4361,  2.1235,\n",
      "         1.0518,  1.2492,  1.4959,  0.6073,  1.6438,  0.1380,  3.2220,  0.3601,\n",
      "         0.5799,  0.8484,  1.0974,  1.2665,  4.6602,  0.7521,  1.7580,  0.9833,\n",
      "         0.8456,  1.2998,  0.6031,  0.1031,  1.1125,  0.7622,  0.1754,  3.2079,\n",
      "         0.3473,  1.8273,  0.2055, 10.4033,  8.4842,  0.1278,  0.4897,  0.7711,\n",
      "         0.8982,  0.4390,  0.1077,  0.4259,  3.7591,  0.6771,  1.4509,  0.3706,\n",
      "         0.0468,  0.8098], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([3.5958, 4.8084, 0.3047, 0.7125, 0.3319, 0.1056, 2.6544, 3.0958, 0.9376,\n",
      "        0.1748, 0.1000, 0.6984, 0.8404, 0.7727, 0.3610, 0.1561, 1.1324, 0.7075,\n",
      "        0.8423, 1.8361, 0.8631, 2.1056, 0.1157, 3.3973, 0.9137, 0.2225, 0.2852,\n",
      "        0.0406, 0.5402, 0.4322, 1.8490, 1.9211, 0.2813, 0.2678, 1.3583, 0.1429,\n",
      "        0.8622, 0.4272, 1.8591, 0.8929, 1.3957, 0.1634, 0.3168, 0.7718, 0.7581,\n",
      "        2.1748, 0.8306, 0.2467, 0.5702, 3.7580, 0.6571, 1.9363, 0.7693, 0.2309,\n",
      "        0.1836, 1.5291, 1.9514], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9998, 0.9994, 0.9989, 0.9994, 1.0000, 0.9998, 0.9989, 0.9982, 0.9993,\n",
      "        0.9971, 1.0000, 0.9999, 1.0000, 1.0000, 1.0002, 1.0000, 1.0005, 0.9995,\n",
      "        0.9998, 0.9996, 0.9996, 0.9989, 0.9989, 0.9998, 0.9998, 0.9997, 0.9997,\n",
      "        0.9987, 1.0005, 1.0000, 0.9980, 0.9983, 0.9998, 0.9999, 0.9989, 1.0002,\n",
      "        0.9998, 0.9996, 1.0000, 0.9991, 0.9985, 0.9997, 0.9999, 0.9991, 0.9987,\n",
      "        0.9989, 0.9997, 0.9999, 0.9988, 1.0000, 0.9995, 0.9995, 0.9981, 0.9977,\n",
      "        1.0004, 0.9992, 0.9981, 0.9972, 0.9991, 0.9989, 0.9999, 0.9995, 0.9998,\n",
      "        0.9984, 0.9983, 0.9984, 1.0000, 0.9996, 0.9986, 1.0002, 0.9997, 0.9972,\n",
      "        0.9997, 0.9985, 0.9992, 0.9992, 0.9999, 0.9994, 0.9992, 0.9998, 0.9994,\n",
      "        0.9992, 0.9996, 0.9993, 0.9989, 0.9992, 1.0002], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9973, 0.9990, 0.9999, 0.9976, 1.0005, 0.9980, 0.9992, 0.9979, 0.9980,\n",
      "        0.9978, 0.9980, 1.0001, 1.0001, 0.9993, 0.9978, 0.9995, 1.0004, 0.9992,\n",
      "        1.0008, 0.9966, 0.9978, 0.9976, 0.9987, 0.9992, 0.9987, 0.9992, 0.9982,\n",
      "        0.9982, 0.9995, 0.9998, 0.9975, 0.9974, 0.9961, 0.9993, 0.9989, 0.9967,\n",
      "        0.9999, 0.9985, 1.0004, 1.0000, 0.9997, 0.9976, 1.0003, 0.9985, 0.9993,\n",
      "        0.9990, 0.9999, 0.9992, 0.9988, 0.9987, 0.9950, 0.9995, 0.9986, 0.9987,\n",
      "        0.9987, 0.9997, 1.0006, 0.9972, 0.9954, 0.9989, 1.0025, 0.9994, 0.9979,\n",
      "        1.0005, 1.0003, 0.9996, 0.9972, 0.9973, 0.9983, 0.9967, 0.9997, 0.9932,\n",
      "        0.9939, 0.9964, 0.9991, 0.9985, 0.9988, 0.9997, 0.9988, 0.9990, 0.9977,\n",
      "        0.9979, 0.9964, 0.9994, 0.9966, 0.9989, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9988, 1.0000, 0.9987, 1.0000, 1.0011, 1.0007, 1.0004, 0.9999, 1.0001,\n",
      "        0.9992, 0.9981, 0.9987, 0.9995, 1.0000, 0.9986, 0.9994, 0.9963, 0.9961,\n",
      "        0.9938, 0.9956, 0.9989, 0.9881, 0.9960, 1.0001, 0.9971, 0.9969, 0.9998,\n",
      "        0.9997, 0.9997, 0.9955, 0.9966, 0.9971, 0.9975, 0.9984, 0.9922, 0.9975,\n",
      "        1.0000, 0.9980, 0.9949, 0.9996, 0.9981, 0.9992, 0.9961, 1.0004, 0.9942,\n",
      "        0.9997, 0.9994, 1.0009, 0.9983, 0.9986, 0.9985, 0.9985, 0.9998, 0.9977,\n",
      "        0.9979, 0.9934, 0.9932, 0.9967, 0.9940, 0.9984, 0.9999, 0.9957, 0.9958,\n",
      "        0.9923, 1.0003, 0.9999, 0.9987, 0.9989, 0.9972, 0.9953, 0.9942, 0.9911,\n",
      "        0.9994, 0.9924, 0.9989, 0.9978, 0.9945, 1.0000, 0.9967, 0.9971, 0.9969,\n",
      "        0.9991, 0.9959, 1.0015, 0.9996, 0.9974, 0.9960], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9960, 1.0036, 0.9973, 0.9861, 1.0022, 0.9986, 0.9880, 0.9995, 0.9969,\n",
      "        1.0008, 0.9982, 0.9966, 1.0000, 0.9948, 0.9994, 0.9872, 0.9926, 0.9937,\n",
      "        0.9999, 1.0023, 0.9959, 0.9957, 0.9961, 0.9995, 0.9901, 0.9958, 0.9798,\n",
      "        1.0000, 0.9899, 0.9910, 0.9959, 0.9995, 0.9892, 0.9834, 0.9983, 0.9907,\n",
      "        0.9998, 0.9906, 0.9944, 0.9984, 0.9887, 0.9789, 0.9971, 0.9955, 0.9970,\n",
      "        0.9998, 0.9938, 0.9998, 0.9919, 0.9986, 0.9989, 0.9988, 0.9987, 0.9979,\n",
      "        0.9995, 0.9889, 1.0002, 0.9973, 0.9993, 0.9928, 0.9936, 1.0005, 1.0021,\n",
      "        0.9993, 0.9968, 0.9953, 0.9953, 0.9934, 0.9999, 0.9912, 0.9963, 0.9907,\n",
      "        1.0049, 0.9990, 0.9985, 0.9981, 0.9984, 0.9983, 1.0030, 0.9975, 0.9997,\n",
      "        0.9979, 0.9899, 0.9919, 0.9827, 0.9941, 0.9889], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9971, 0.9982, 0.9833, 0.9756, 0.9819, 0.9907, 0.9988, 0.9981, 0.9941,\n",
      "        0.9933, 0.9898, 1.0000, 0.9970, 0.9979, 0.9991, 0.9979, 0.9786, 0.9984,\n",
      "        0.9954, 0.9962, 1.0000, 0.9800, 0.9982, 0.9964, 0.9880, 0.9970, 0.9928,\n",
      "        0.9985, 0.9799, 0.9978, 0.9817, 0.9753, 0.9874, 0.9698, 0.9968, 0.9834,\n",
      "        0.9864, 1.0001, 0.9820, 1.0000, 0.9753, 0.9936, 0.9977, 0.9886, 0.9919,\n",
      "        1.0024, 1.0097, 1.0042, 0.9971, 0.9984, 0.9940, 0.9844, 0.9926, 0.9996,\n",
      "        1.0003, 0.9774, 1.0026, 1.0051, 1.0056, 0.9864, 1.0037, 0.9999, 0.9890,\n",
      "        0.9984, 0.9989, 0.9886, 0.9906, 0.9768, 0.9991, 0.9751, 0.9814, 0.9803,\n",
      "        0.9909, 0.9865, 0.9889, 0.9828, 0.9836, 0.9981, 0.9995, 0.9978, 1.0012,\n",
      "        0.9927, 0.9956, 0.9820, 0.9889, 1.0017, 0.9894], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9908, 0.9941, 0.9959, 0.9676, 0.9580, 0.9696, 1.0052, 1.0112, 0.9764,\n",
      "        0.9914, 0.9520, 0.9478, 1.0137, 0.9908, 1.0056, 0.9912, 0.9804, 0.9929,\n",
      "        0.9933, 0.9941, 0.9989, 0.9784, 1.0077, 0.9785, 0.9995, 0.9966, 0.9879,\n",
      "        0.9947, 0.9626, 0.9652, 0.9854, 0.9736, 0.9599, 0.9986, 0.9874, 1.0034,\n",
      "        1.0201, 1.0136, 0.9845, 1.0071, 0.9660, 1.0055, 0.9676, 0.9577, 0.9516,\n",
      "        0.9754, 0.9937, 1.0119, 0.9759, 0.9970, 0.9845, 0.9758, 0.9818, 0.9897,\n",
      "        0.9943, 1.0000, 0.9728, 0.9652, 1.0189, 0.9967, 0.9649, 0.9698, 1.0018,\n",
      "        1.0008, 0.9976, 1.0029, 0.9960, 0.9840, 0.9841, 0.9908, 0.9803, 0.9995,\n",
      "        0.9876, 0.9935, 1.0004, 0.9709, 1.0110, 1.0088, 0.9595, 0.9866, 0.9738,\n",
      "        0.9825, 0.9759, 0.9794, 0.9789, 0.9662, 0.9388], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9949, 0.9983, 0.9134, 1.0121, 0.9660, 0.9827, 0.9869, 0.9817, 0.9835,\n",
      "        1.0192, 1.0406, 0.9976, 0.9910, 0.9776, 1.0096, 0.9817, 0.9835, 0.9881,\n",
      "        1.0138, 0.9706, 0.9578, 0.9797, 1.0144, 0.9837, 0.9376, 0.9986, 0.9884,\n",
      "        1.0047, 1.0044, 0.9758, 0.9979, 1.0283, 1.0015, 1.0190, 0.9774, 0.9975,\n",
      "        1.0066, 1.0081, 0.9952, 0.9800, 1.0009, 0.9785, 0.9189, 0.9464, 1.0041,\n",
      "        0.9991, 0.9992, 0.9886, 0.9767, 0.9888, 0.9949, 0.9837, 0.9556, 0.9991,\n",
      "        0.9888, 1.0031, 0.9945, 0.9907, 1.0046, 0.9941, 0.9936, 1.0013, 0.9986,\n",
      "        0.9717, 0.9923, 0.9878, 1.0142, 0.9958, 1.0074, 0.9593, 0.9984, 1.0202,\n",
      "        0.9971, 0.9919, 0.9970, 0.9811, 0.9989, 0.9933], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0546, 1.0014, 0.9481, 1.0554, 0.9735, 0.9541, 0.9795, 0.9615, 1.0044,\n",
      "        1.0104, 0.9948, 0.9190, 0.9999, 1.0075, 1.0143, 0.9898, 0.9864, 1.0230,\n",
      "        1.0246, 0.9913, 1.0306, 1.0073, 0.9768, 0.9558, 0.9808, 0.9579, 1.0227,\n",
      "        0.9783, 0.9997, 0.9787, 0.9988, 1.0142, 1.0029, 0.9648, 1.0002, 0.9846,\n",
      "        0.8460, 1.0832, 0.9933, 0.9771, 0.9622, 0.9914, 1.0191, 0.9537, 1.0336,\n",
      "        1.0825, 0.9484, 1.0138, 0.9979, 0.9554, 1.0142, 0.9428, 0.9940, 0.9823,\n",
      "        1.0062, 1.0264, 0.9870, 0.9867, 0.9954, 1.0251, 0.9879, 0.9861, 0.9584,\n",
      "        0.9777, 0.9918, 1.0018, 0.9641, 0.9850, 0.9657, 0.9879, 1.0055, 0.9657,\n",
      "        1.0223, 1.0207, 0.9992, 1.0190, 0.9911, 0.9553], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9179, 0.8996, 0.6415, 0.9906, 0.9677, 0.9854, 0.9610, 0.9641, 0.8953,\n",
      "        1.2098, 1.0990, 1.0745, 1.0128, 0.9930, 0.9892, 0.8768, 1.0337, 0.9477,\n",
      "        0.9777, 0.9552, 0.9707, 0.8727, 0.8524, 0.9663, 0.9710, 0.9729, 0.9971,\n",
      "        0.9425, 1.0151, 1.0030, 0.9641, 0.9497, 1.0093, 0.9954, 1.0451, 1.0513,\n",
      "        0.9634, 0.9580, 1.0643, 0.9020, 1.0020, 0.9245, 0.9386, 0.8830, 0.8995,\n",
      "        1.0081, 0.9969, 0.9896, 0.9928, 0.9814, 1.0142, 1.0394, 0.9746, 0.9954,\n",
      "        1.0047, 1.0274, 0.9961, 0.9824, 0.9418, 0.9575, 1.0011, 1.0080, 0.9367,\n",
      "        0.9609, 0.9544, 0.8888, 1.0087, 0.9533, 1.0104, 0.8575, 0.9669, 0.8800,\n",
      "        0.9855, 0.9700, 0.9037, 0.9961, 0.9772, 0.9779], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9078, 0.9936, 0.9745, 0.8337, 0.9307, 1.1116, 0.9348, 0.4782, 1.0144,\n",
      "        0.4392, 1.0255, 0.4787, 1.0115, 1.0191, 0.9180, 1.1103, 0.8147, 0.4359,\n",
      "        0.8921, 0.8581, 0.9249, 0.9671, 0.4846, 1.0532, 0.5534, 1.2561, 0.9506,\n",
      "        1.3990, 1.1332, 1.7430, 1.1869, 0.8188, 1.0566, 0.9111, 0.9891, 0.9767,\n",
      "        1.1368, 1.0724, 0.9836, 0.9867, 1.0184, 0.9835, 0.9851, 0.8892, 1.0165,\n",
      "        0.9813, 0.9920, 0.9703, 0.9392, 0.9036, 0.9417, 0.8763, 0.8626, 1.1649,\n",
      "        1.0900, 1.0417, 0.7472, 0.9769, 1.0430, 0.9581, 0.8651, 0.8653, 0.9567,\n",
      "        1.1615, 1.0604, 0.9906, 1.0248, 0.9739, 0.9675, 0.8897, 0.9032, 0.9214,\n",
      "        1.0181, 0.7976, 0.8099, 0.9518, 0.9254, 0.4796], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9710, 1.2000, 0.9324, 0.8741, 0.1979, 0.8834, 1.3483, 0.7732, 1.6178,\n",
      "        0.4025, 0.3514, 1.0985, 0.7897, 1.0564, 0.6803, 0.9490, 0.8157, 1.1440,\n",
      "        1.0347, 1.2819, 1.2885, 0.3894, 0.2076, 0.6076, 1.4487, 0.5007, 1.5348,\n",
      "        0.6078, 0.3940, 0.9086, 1.0696, 0.8096, 0.9734, 0.7246, 0.3085, 1.3181,\n",
      "        0.7248, 0.5816, 0.9978, 0.3427, 0.9424, 1.1441, 1.6105, 1.0059, 0.1721,\n",
      "        1.0153, 0.6779, 1.2678, 1.0171, 0.7791, 0.7708, 0.8481, 0.9250, 1.2954,\n",
      "        0.8728, 1.2086, 0.3051, 1.1118, 0.3443, 0.3069, 0.6968, 0.8129, 0.9148,\n",
      "        1.7190, 1.5773, 0.8200, 0.7473, 0.5593, 0.8840, 0.9247, 0.9024, 1.1355,\n",
      "        0.9525, 1.0394, 0.8492, 0.9290, 0.9356, 0.8110], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.9333, 2.4420, 0.2174, 0.7617, 0.4191, 0.6421, 0.2784, 1.0694, 0.6755,\n",
      "        1.0419, 1.4195, 4.0609, 0.7212, 1.1259, 0.2789, 0.5784, 0.5703, 1.8813,\n",
      "        2.7051, 0.3675, 0.6611, 1.0663, 1.1103, 0.8571, 0.0444, 0.1855, 0.8968,\n",
      "        1.7138, 1.0212, 1.8621, 3.0490, 3.7608, 0.5102, 1.0760, 1.0328, 0.8777,\n",
      "        0.9578, 1.3529, 0.2724, 1.0254, 1.4036, 0.8444, 0.9450, 1.5589, 0.0128,\n",
      "        0.4364, 0.6095, 0.4440, 0.9486, 0.6857, 0.9455, 0.9296, 1.5179, 0.9501,\n",
      "        1.4893, 0.5546, 1.0529, 2.3991, 1.9320, 0.7820, 0.7594, 0.8453, 1.0685,\n",
      "        1.4118, 0.4988, 0.1659, 0.2840, 1.1712, 0.7876, 0.5842, 0.9405, 0.9711,\n",
      "        0.5884, 1.0214, 2.1454, 0.4934, 1.5316, 0.7265], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0276, 1.8474, 1.3761, 2.2919, 4.1205, 0.0132, 0.3975, 0.0925, 0.9969,\n",
      "        2.7644, 1.0223, 1.6994, 2.4951, 0.2180, 0.5795, 3.6370, 1.2038, 0.5743,\n",
      "        1.9232, 1.2918, 0.2892, 1.0323, 6.1111, 1.4744, 0.7833, 4.2868, 2.1711,\n",
      "        0.0778, 1.9771, 0.5748, 0.9169, 1.6758, 0.6365, 0.6105, 0.3788, 0.0428,\n",
      "        1.5107, 1.7705, 0.8962, 2.2481, 1.5628, 1.4901, 0.6143, 2.7267, 1.4217,\n",
      "        1.7072, 0.5158, 1.3187, 1.7028, 1.7204, 1.0143, 2.2666, 1.9989, 1.2542,\n",
      "        0.2048, 0.2088, 0.8994, 1.6378, 1.2158, 0.8686, 0.9313, 1.7503, 0.2292,\n",
      "        1.2624, 2.0196, 1.1413, 1.7016, 0.1113, 1.6913, 6.1117, 1.1005, 1.0024,\n",
      "        2.5929, 1.9932, 1.0211, 2.3463, 0.4566, 0.4257, 0.6417, 1.3739, 0.3367,\n",
      "        0.0986, 1.1079, 0.9623, 2.1218, 0.4453, 0.5920, 0.5512, 0.2532, 0.1608,\n",
      "        0.7844, 0.8246, 0.9090, 1.5073, 0.8052, 1.4322, 0.0130, 1.6987, 0.0572,\n",
      "        0.0481, 0.9471, 0.2746, 4.2953, 0.0221, 3.3722, 0.9497, 0.5813, 2.5808,\n",
      "        1.7597, 1.3681, 0.6536, 0.7738, 0.0164, 3.4920, 0.8502, 0.8879, 0.1606,\n",
      "        0.5933, 0.8832, 1.2940, 0.8350, 0.8134, 1.1607], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.3661, 1.6920, 0.8333, 0.2558, 0.3982, 0.0956, 0.6023, 0.6683, 0.4475,\n",
      "        0.9205, 0.3045, 1.5655, 0.2991, 0.9834, 0.4027, 0.5779, 0.4717, 0.2954,\n",
      "        0.4536, 1.1121, 0.5631, 0.2388, 0.0083, 0.3564, 0.1363, 0.8069, 1.3099,\n",
      "        0.4611, 1.3083, 0.2983, 0.7765, 1.2291, 2.7954, 0.9959, 1.0711, 1.1611,\n",
      "        0.6919, 1.1610, 0.6200, 1.7336, 0.1377, 0.8276, 2.0516, 0.0599, 2.3131,\n",
      "        0.7721, 1.2534, 1.6219, 0.8780, 0.5698, 0.4069, 2.5236, 0.9309, 1.5936,\n",
      "        0.8667, 0.1855, 0.0157, 1.5616, 0.8524, 0.6874, 0.7822, 0.5017, 0.9424,\n",
      "        1.7703, 1.3363, 0.4823, 1.5760, 0.5733, 0.8137, 2.2145, 0.7976, 0.3292,\n",
      "        0.6189, 0.7703, 1.1610, 2.5390, 0.7134, 4.1317, 1.1064, 0.5942, 0.5407,\n",
      "        1.0564, 0.9998, 0.9354, 0.5225, 0.8846, 1.3981, 1.2103, 0.2949, 0.8996,\n",
      "        0.4895, 0.4069, 1.0484, 0.3531, 3.8075, 3.7806, 2.5441, 1.3282, 2.0971,\n",
      "        1.1702, 0.9494, 1.2662, 2.7721, 0.5047, 0.8689, 1.3255, 3.4826, 5.1348,\n",
      "        1.7092, 0.8811, 1.1170, 1.4891, 0.0531, 0.2614, 0.6592, 1.2870, 1.0366,\n",
      "        0.9616, 0.6913, 1.1401, 0.6142, 0.6563, 0.9781], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0538, 1.6999, 0.5206, 0.0959, 0.0375, 0.2414, 0.8657, 0.4145, 1.0028,\n",
      "        1.4459, 0.1554, 1.7937, 1.3968, 1.0168, 0.2988, 1.3460, 1.2686, 0.9652,\n",
      "        1.1637, 1.7749, 0.0421, 1.5068, 0.6999, 0.5986, 0.7775, 2.1903, 2.5375,\n",
      "        1.0755, 0.8732, 0.0291, 0.0718, 1.5495, 1.0649, 3.1197, 0.3471, 0.8872,\n",
      "        0.1567, 0.0689, 1.3778, 0.6055, 0.3424, 0.7632, 0.0918, 1.1852, 1.6940,\n",
      "        0.5211, 1.7014, 1.9784, 0.4904, 0.6826, 1.3231, 1.1096, 3.5855, 3.9852,\n",
      "        1.1588, 0.5390, 1.8403, 1.1179, 1.1155, 1.6264, 0.8554, 1.5694, 0.0767,\n",
      "        0.0087, 0.5224, 1.2519, 0.1010, 0.3042, 0.8301, 1.2368, 4.1126, 2.3815,\n",
      "        1.2925, 1.1415, 0.0401, 0.1876, 1.3525, 0.7251, 0.1372, 0.7798, 0.0124,\n",
      "        0.4527, 1.1112, 0.4861, 0.4350, 0.5047, 0.3160, 0.8452, 1.0534, 0.8989,\n",
      "        1.1416, 0.4841, 0.6662, 0.7773, 1.7116, 0.5234, 1.2065, 1.0716, 0.8833,\n",
      "        1.1606, 0.0785, 0.2218, 0.2953, 0.7419, 0.8770, 1.6732, 0.6036, 0.7287,\n",
      "        1.0800, 1.0287, 1.3378, 0.4999, 0.2454, 1.1206, 0.2328, 1.2444, 0.2033,\n",
      "        0.1299, 0.1466, 0.1419, 1.1543, 1.1308, 1.0659], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.2252, 1.1636, 1.2282, 0.2424, 0.9153, 0.7904, 0.0915, 0.6184, 0.2278,\n",
      "        0.9352, 0.1805, 1.4035, 1.2685, 0.3405, 1.2810, 0.7335, 0.9162, 0.2614,\n",
      "        0.9004, 1.4384, 0.4269, 0.9760, 0.7967, 0.3682, 0.7102, 1.2927, 2.1460,\n",
      "        0.3263, 0.5205, 0.4312, 0.8704, 0.4674, 0.6289, 0.3193, 1.2683, 0.4489,\n",
      "        0.5878, 0.6577, 1.6614, 1.8707, 1.1141, 0.8671, 0.7859, 0.7340, 0.7104,\n",
      "        0.0265, 0.8525, 1.7236, 0.7148, 1.0975, 0.8169, 0.5489, 0.8226, 1.1386,\n",
      "        1.3313, 0.1249, 1.0121, 1.9772, 0.9757, 2.7157, 0.6719, 0.6091, 1.1241,\n",
      "        1.0033, 0.8820, 0.7847, 1.0218, 1.8738, 0.0839, 1.3125, 0.5159, 0.0250,\n",
      "        1.7943, 1.3938, 1.3479, 1.7326, 1.1946, 0.6897, 1.3717, 0.0617, 0.7529,\n",
      "        0.7563, 0.5137, 0.6726, 0.7067, 1.0562, 0.0681, 0.6712, 0.0566, 0.7926,\n",
      "        0.4681, 1.6148, 2.2285, 0.3324, 0.3696, 1.7505, 0.9589, 0.9042, 0.3793,\n",
      "        0.6748, 0.6946, 1.0190, 0.8470, 1.1438, 0.5557, 0.7590, 1.1133, 0.9251,\n",
      "        0.9975, 0.7096, 0.1789, 0.4993, 0.8532, 0.8990, 1.5862, 0.4827, 1.5458,\n",
      "        0.6445, 1.1673, 0.5336, 0.9156, 0.7160, 0.2005], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.4550, 0.0563, 0.1933, 0.7151, 0.1026, 1.5132, 0.6239, 0.5946, 0.8668,\n",
      "        2.7276, 1.8555, 3.6448, 0.7073, 1.3439, 0.9602, 1.2101, 3.4603, 2.9020,\n",
      "        0.6948, 0.9910, 0.3849, 0.3104, 0.1223, 0.3435, 0.6299, 0.9145, 2.2580,\n",
      "        0.6043, 0.4987, 0.7939, 2.7959, 1.1529, 1.0155, 0.2879, 0.8054, 0.1973,\n",
      "        0.2906, 0.4552, 0.2788, 0.8289, 1.1989, 1.7099, 0.2470, 1.1078, 0.3343,\n",
      "        0.5560, 0.5663, 0.0052, 1.7479, 0.5515, 0.3126, 2.9747, 1.3392, 0.3432,\n",
      "        0.6652, 1.0967, 2.0185, 0.1571, 0.6099, 1.3652, 0.5876, 0.0728, 1.1411,\n",
      "        1.3921, 0.1895, 0.6485, 2.4480, 1.4798, 0.0402, 1.2795, 0.7489, 1.6800,\n",
      "        1.4654, 1.4326, 1.0820, 2.2048, 0.8036, 0.2981, 1.0031, 1.2254, 0.3444,\n",
      "        1.1591, 1.1746, 1.2624, 0.0187, 0.6953, 0.2224, 1.3448, 0.5190, 0.4475,\n",
      "        0.7186, 0.2953, 0.6488, 0.7334, 0.2359, 1.4520, 0.4371, 0.9850, 0.9813,\n",
      "        0.9318, 0.9084, 1.2417, 0.5417, 0.1621, 0.9821, 0.5537, 1.0766, 1.0562,\n",
      "        0.9519, 0.7799, 0.6863, 0.1637, 0.8075, 0.3504, 0.3794, 1.2762, 0.8254,\n",
      "        0.1788, 1.1361, 0.1731, 0.6578, 0.1300, 1.0428], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9877, 0.4600, 0.4476, 3.9275, 0.7180, 2.6970, 2.2100, 0.4903, 1.3370,\n",
      "        1.1808, 0.3831, 0.5663, 2.3571, 0.6578, 2.8372, 0.1264, 0.6997, 0.0404,\n",
      "        2.2164, 1.7158, 0.1309, 0.8561, 1.1746, 1.4951, 0.6199, 0.2530, 0.3881,\n",
      "        0.5809, 2.0768, 0.0535, 0.2569, 0.9906, 0.3755, 1.5786, 1.2302, 2.8752,\n",
      "        0.2566, 0.7228, 1.7278, 3.7868, 1.5577, 2.5698, 2.0623, 0.5182, 1.0136,\n",
      "        0.6881, 1.2703, 0.8131, 1.2578, 0.5515, 0.4020, 1.2606, 1.7499, 0.4275,\n",
      "        0.8198, 0.6471, 0.2007, 3.7864, 0.6934, 4.5403, 0.5128, 1.7373, 0.8489,\n",
      "        0.2589, 1.6485, 0.7934, 0.5697, 0.1721, 1.3269, 0.5862, 0.0760, 0.6074,\n",
      "        1.2866, 1.0765, 0.2244, 1.4856, 0.3205, 0.4873, 0.8941, 0.8809, 0.8607,\n",
      "        2.8417, 2.4184, 0.2936, 2.0965, 0.5237, 3.1597, 0.6372, 2.1390, 4.3478,\n",
      "        0.3819, 0.9553, 0.9134, 1.1121, 0.8357, 0.1261, 0.9079, 0.3766, 2.7743,\n",
      "        1.4527, 1.0771, 1.6264, 0.2050, 0.1646, 0.3941, 0.8935, 0.6284, 0.0782,\n",
      "        1.0435, 0.1264, 2.2849, 0.3129, 0.8510, 0.6911, 0.6708, 1.1798, 1.0907,\n",
      "        0.9273, 1.0102, 0.4430, 0.0241, 1.0095, 0.7984], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.6045, 0.8421, 1.6172, 0.6137, 1.0969, 0.5092, 1.3348, 0.1741, 0.1883,\n",
      "        0.1460, 0.1478, 0.5325, 0.6860, 0.6971, 0.8146, 0.0738, 0.6091, 1.2437,\n",
      "        0.5626, 0.0386, 0.8230, 0.3914, 0.3494, 0.7594, 0.6213, 0.1440, 0.5417,\n",
      "        1.1635, 1.8395, 1.1210, 4.6658, 0.9876, 1.1562, 0.9905, 0.8636, 1.5934,\n",
      "        1.3954, 0.6265, 2.4953, 0.8197, 0.3036, 0.6578, 8.4750, 1.3079, 1.0127,\n",
      "        0.5568, 0.1334, 0.4206, 0.1162, 0.7540, 1.3545, 0.1947, 0.2804, 1.4148,\n",
      "        0.4763, 0.6395, 0.2244, 3.3157, 2.4249, 2.1200, 0.9828, 0.8387, 0.8597,\n",
      "        0.9303, 1.1250, 3.8310, 0.0210, 0.3693, 1.6473, 0.1671, 2.6197, 0.7032,\n",
      "        1.0297, 0.3697, 0.4584, 0.7868, 1.5484, 2.5909, 1.1449, 0.9180, 0.2836,\n",
      "        2.6005, 0.0241, 1.6612, 0.0608, 0.8838, 1.3338, 0.5875, 0.2456, 0.4205,\n",
      "        1.7001, 1.1781, 0.8142, 0.0486, 0.4280, 1.1728, 0.8944, 1.8051, 0.8206,\n",
      "        1.1091, 0.8895, 1.5833, 0.8676, 1.7429, 0.9629, 0.9774, 1.0357, 0.0819,\n",
      "        0.0384, 0.8296, 2.1717, 0.6915, 1.3228, 0.6161, 1.8970, 3.9815, 0.1119,\n",
      "        3.5516], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9321, 3.7951, 2.5969, 0.7711, 0.7558, 1.5681, 1.1314, 0.2914, 0.9990,\n",
      "        1.1335, 1.2150, 0.9196, 2.1337, 1.0620, 3.8735, 0.6080, 4.9610, 2.0588,\n",
      "        0.9297, 1.5154, 1.7762, 0.8380, 0.0725, 0.6578, 0.4520, 0.0270, 0.8917,\n",
      "        0.1747, 0.2633, 1.2870, 0.1544, 0.9527, 1.1919, 1.1097, 2.2671, 0.2878,\n",
      "        0.3905, 1.5599, 0.9538, 0.0277, 0.1865, 0.8789, 1.6258, 0.0187, 1.0241,\n",
      "        0.4589, 0.8214, 0.4727, 0.9575, 0.8838, 0.4450, 0.8035, 0.7412, 0.0684,\n",
      "        0.5787, 0.8492, 1.2530, 3.4388, 0.7912, 1.9491, 0.6616, 0.0409, 1.0629,\n",
      "        0.1922, 1.4668, 0.6476, 1.2518, 1.8271, 0.8757, 1.0111, 0.0259, 0.4339,\n",
      "        1.3843, 1.1341, 1.0489, 0.0825, 0.2010, 0.8557, 2.7410, 0.0495, 0.5086,\n",
      "        0.3052, 0.1729, 0.1717, 0.3082, 0.3862, 1.2314, 2.2996, 0.5497, 0.6075,\n",
      "        0.0738, 1.1784, 0.7364, 1.2510, 1.1083, 0.5351, 1.7051, 0.0313, 0.1079,\n",
      "        1.1212, 1.4899, 0.3265, 0.7848, 0.0673, 1.6911, 1.1262, 1.9567, 1.1208,\n",
      "        0.1381, 0.7036, 0.1887, 1.4095, 0.5057, 0.8924, 0.4544, 0.2255, 1.4197,\n",
      "        0.2937, 2.9179, 0.1010], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.7961, 0.1162, 1.6083, 0.9018, 1.1871, 0.1111, 1.0222, 0.4623, 0.4892,\n",
      "        0.3299, 1.8041, 0.6366, 1.0792, 2.1884, 0.5624, 0.9834, 0.2118, 0.2986,\n",
      "        1.9823, 0.3718, 3.9102, 2.1677, 0.5645, 3.2205, 1.0106, 1.7937, 0.1864,\n",
      "        1.0954, 0.9986, 0.3147, 0.2430, 0.6231, 1.0715, 0.2824, 0.1146, 0.3442,\n",
      "        0.6102, 1.0028, 0.6245, 0.5404, 1.1207, 0.8688, 0.2781, 0.0095, 0.9132,\n",
      "        0.3587, 0.5896, 0.8884, 0.9081, 0.7611, 0.1430, 1.5412, 0.4195, 0.0989,\n",
      "        0.3906, 1.2459, 0.8875, 0.3555, 0.3821, 1.2879, 5.1900, 1.0235, 0.7097,\n",
      "        0.9428, 0.2327, 1.6735, 2.2041, 0.3882, 0.5622, 2.0405, 0.2672, 0.3798,\n",
      "        0.3559, 1.2791, 0.1875, 0.1577, 0.5006, 4.9777, 2.7177, 0.1561, 1.6252,\n",
      "        0.7514, 0.5157, 0.4598, 2.1175, 0.8188, 0.8211, 0.2756, 0.9173, 0.1433,\n",
      "        0.2347, 0.4727, 1.1139, 0.0491, 1.9027, 0.8626, 0.0168, 0.5845, 0.8933,\n",
      "        0.6242, 0.0635, 1.1172, 1.3936, 0.1981, 1.3257, 3.0796, 0.9275, 0.8213,\n",
      "        0.7456, 0.1204, 0.8438, 0.0616, 2.6149, 0.6821, 3.3459, 0.1521, 0.2616],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([8.8690e-01, 3.9967e-01, 3.3731e-01, 3.6710e-01, 3.3265e-01, 1.1565e+00,\n",
      "        2.7275e-01, 8.1808e-01, 8.4563e-01, 1.5364e+00, 8.3885e-01, 9.3894e-01,\n",
      "        2.9063e+00, 1.5846e+00, 8.2683e-01, 7.6737e-01, 8.8637e-02, 3.7142e-01,\n",
      "        1.8780e+00, 9.6806e-01, 1.1726e+00, 1.5787e+00, 8.8284e-01, 6.8503e-02,\n",
      "        3.5679e-01, 5.4387e-01, 5.4150e-01, 7.0824e-01, 9.9285e-01, 3.9404e-01,\n",
      "        8.6838e-01, 2.8458e-01, 1.4454e-01, 8.8692e-01, 6.9407e-01, 3.9004e-01,\n",
      "        3.4587e-01, 8.8364e-01, 1.2640e+00, 6.0549e-02, 5.1846e-01, 1.6423e-01,\n",
      "        3.3861e+00, 1.2466e+00, 8.1839e-01, 3.2802e-01, 1.0015e+00, 9.3841e-01,\n",
      "        1.1986e+00, 1.6486e+00, 7.1728e-01, 1.3913e+00, 1.5942e-01, 5.0119e-02,\n",
      "        1.8532e+00, 3.3526e-01, 1.3435e-01, 3.2937e+00, 1.2631e+00, 2.3223e+00,\n",
      "        9.0355e-01, 1.3500e-02, 5.3546e-01, 4.6807e-01, 7.6567e-01, 2.5072e+00,\n",
      "        2.4131e-01, 2.0880e-02, 1.0047e+00, 3.1427e-01, 1.7941e+00, 2.6071e+00,\n",
      "        9.4893e-01, 6.5066e-01, 1.0691e+00, 7.0568e-01, 1.9940e-01, 7.3086e-01,\n",
      "        2.0850e+00, 1.0976e+00, 3.2032e-01, 5.0496e-01, 2.1488e-01, 7.3031e-01,\n",
      "        2.4461e+00, 2.5824e-02, 3.3847e-01, 2.5868e-03, 1.4572e-01, 7.6796e-01,\n",
      "        1.9141e+00, 6.3404e-01, 1.0065e+00, 7.1203e-01, 4.7116e+00, 3.2969e+00,\n",
      "        7.9928e-01, 1.1317e+00, 2.2686e+00, 1.9125e+00, 1.3667e+00, 4.6315e-01,\n",
      "        1.9767e+00, 5.4477e-01, 3.0202e-01, 1.3335e-01, 7.6815e-01, 7.5779e-01,\n",
      "        2.0101e-01, 1.8750e+00, 1.7709e+00, 3.2124e-01, 7.5586e-01, 2.5270e+00,\n",
      "        4.8653e-01, 1.1892e+00, 1.4702e+00, 6.1875e-01, 2.0806e-01],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([ 0.0207,  1.9712,  0.5907,  2.9832,  0.1370,  0.9390,  2.1504,  3.0155,\n",
      "         0.2293,  4.1327,  0.4666,  4.4838,  4.9553,  6.2247,  1.3728,  1.1013,\n",
      "         1.1220,  0.1949,  0.6771,  1.7952,  0.0767,  1.8883,  1.4535,  0.4793,\n",
      "         0.2796,  1.0409,  0.2579,  2.2159,  3.1094,  0.0738,  1.4239,  0.6602,\n",
      "         0.8607,  4.2327,  2.9691,  2.5176,  6.8695,  0.3341,  1.1244,  0.5519,\n",
      "         0.5451,  0.4182,  1.3034,  1.2291,  0.3911,  0.5214,  0.5417,  0.2234,\n",
      "         0.2871,  1.0240,  1.1969,  2.0324,  0.0643,  1.8112, 13.5104,  0.5412,\n",
      "         0.3840,  0.9138,  0.9819,  0.4400,  0.3483,  1.1045,  0.8789,  0.4358,\n",
      "         0.4635,  1.1459,  1.0652,  0.9783,  2.0422,  1.0207,  7.2949,  0.6052,\n",
      "         2.9220,  0.2046,  0.9241,  4.8392,  1.2166,  0.3791,  1.7392,  0.3669,\n",
      "         0.3022,  0.1104,  3.7496,  1.6910,  2.9769,  0.0143,  0.2276,  2.2311,\n",
      "         1.0051,  8.6563,  0.7272,  0.9928,  0.0914,  0.7515,  0.1747,  0.1413,\n",
      "         1.2185,  1.1345,  1.1124,  0.3189,  0.8511,  0.3564,  4.7258,  1.0236,\n",
      "         0.3222,  0.4741,  2.3058,  2.9172,  0.3279,  1.3973,  0.3760,  0.0159,\n",
      "         0.5627,  0.9275,  0.6939,  0.1636,  0.7956,  0.5905], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.8666, 0.6043, 0.7477, 3.9645, 4.6824, 0.5669, 0.2788, 0.4946, 0.7164,\n",
      "        0.5967, 0.8388, 1.3717, 2.1327, 1.6712, 1.2942, 1.1923, 0.3698, 0.1396,\n",
      "        0.4668, 0.5916, 1.8841, 0.8223, 1.6750, 0.2697, 1.0002, 0.5114, 2.5548,\n",
      "        2.5647, 0.9069, 2.8572, 1.5203, 0.5174, 1.0247, 0.9794, 0.9662, 2.3619,\n",
      "        0.6969, 0.3195, 0.8801, 1.2450, 1.0729, 0.4685, 0.4304, 2.3010, 1.1030,\n",
      "        0.1883, 0.2747, 0.2605, 1.4999, 0.2224, 1.8378, 0.0804, 0.1097, 0.0224,\n",
      "        0.5711, 0.0204, 0.4010, 0.8772, 0.6679, 0.4769, 0.8428, 0.3385, 0.6871,\n",
      "        0.8902, 0.1448, 0.1610, 0.1587, 0.3974, 0.0567, 1.6325, 0.6393, 2.8122,\n",
      "        0.8483, 0.2448, 1.2647, 1.4421, 0.2389, 0.0543, 1.2096, 0.1488, 0.5312,\n",
      "        0.2679, 0.1861, 0.3279, 1.0393, 1.1655, 0.4267, 1.8057, 1.1195, 0.0820,\n",
      "        0.6519, 0.1324, 2.8217, 1.9868, 0.5398, 1.9424, 2.7484, 0.1600, 0.0430,\n",
      "        0.4616, 0.8081, 0.5742, 0.6481, 0.0104, 0.9944, 0.6424, 0.4803, 0.3143,\n",
      "        0.3946, 0.4628, 1.8994, 0.5892, 3.0205, 0.3883, 0.5657, 0.8335, 1.7534,\n",
      "        0.5520], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([ 0.3653,  1.3909,  0.7075,  0.8582,  1.6216,  1.9150,  2.0617,  1.0156,\n",
      "         0.0274,  0.2487,  2.2338,  1.2168,  1.0647,  0.1540,  1.8554,  0.3571,\n",
      "         2.2504,  2.9105,  1.7294,  0.8958,  1.2490,  3.1888,  2.7527,  0.9967,\n",
      "         4.9132,  0.9494,  2.5738,  0.5042,  2.5376,  0.4298,  0.2461,  0.0312,\n",
      "         0.2207,  3.0022,  0.8871,  1.5247, 10.2598,  0.5099,  0.9722,  0.2651,\n",
      "         0.0215,  0.6758,  0.8525,  0.8278,  1.2112,  1.5618,  1.3887,  0.8839,\n",
      "         0.8009,  1.3154,  1.0120,  0.6533,  0.9566,  1.0102,  0.7990,  2.2680,\n",
      "         1.4519,  0.7271,  3.1057,  3.9796,  0.2063,  0.3190,  0.5054,  1.0613,\n",
      "         0.8775,  1.4338,  6.0428,  2.7130,  0.8521,  0.8055,  9.9172,  3.8121],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0122, 1.1432, 0.8142, 0.9441, 0.7099, 0.8504, 0.8249, 0.8678, 0.6589,\n",
      "        1.2758, 0.9694, 1.0107, 0.3959, 0.8807, 0.4383, 0.9508, 0.0433, 0.4677,\n",
      "        0.7968, 1.2779, 1.0557, 0.3224, 1.0119, 0.7120, 1.0438, 1.0091, 0.9645,\n",
      "        0.8500, 0.9513, 0.9038, 0.7803, 1.0238, 0.9196, 0.9710, 0.9587, 0.9886,\n",
      "        1.1059, 0.8347, 1.0132, 0.4304, 0.0490, 0.3544, 1.0591, 1.2732, 1.1183,\n",
      "        1.1244, 0.8761, 0.7134, 1.0167, 0.7426, 0.9203, 1.0955, 0.5849, 0.8396,\n",
      "        1.0048, 1.0400, 0.9671, 0.9221, 0.7289, 0.7970, 0.9056, 0.7051, 1.0090,\n",
      "        1.0150, 1.0245, 1.0148, 0.9784, 0.8814, 0.9686, 0.1499, 0.9898, 1.0129],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9896, 1.0049, 0.9897, 1.0073, 0.9976, 1.0056, 1.0080, 0.9924, 1.0209,\n",
      "        0.9831, 0.9800, 0.9963, 0.9292, 0.9761, 0.8553, 0.8455, 0.9888, 0.9930,\n",
      "        0.9808, 0.9756, 0.9301, 1.0107, 0.9658, 0.9807, 0.9497, 1.0002, 0.9844,\n",
      "        0.9867, 0.9861, 0.9836, 1.0166, 0.9907, 0.9998, 1.0255, 1.0143, 0.9684,\n",
      "        0.9293, 0.9967, 1.0027, 0.8558, 0.9068, 0.7896, 0.9858, 0.9705, 1.0196,\n",
      "        1.0277, 1.0027, 0.9608, 1.0116, 0.9538, 1.0174, 0.9796, 1.0240, 0.9226,\n",
      "        0.9750, 0.8651, 1.0117, 1.0840, 0.9783, 0.9648, 0.9990, 1.0080, 0.9609,\n",
      "        0.9555, 0.9252, 0.9793, 0.9887, 0.9740, 1.0379, 1.0117, 0.9272, 0.8485],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9991, 0.9971, 0.9947, 1.0154, 0.9808, 1.0051, 1.0012, 1.0024, 1.0014,\n",
      "        0.9940, 0.9926, 1.0013, 0.9764, 0.9838, 0.9954, 0.9838, 0.9744, 0.9930,\n",
      "        0.9968, 0.9973, 0.9923, 0.9970, 1.0040, 1.0040, 1.0000, 0.9945, 1.0027,\n",
      "        1.0017, 0.9876, 0.9978, 1.0001, 1.0019, 1.0025, 0.9772, 1.0087, 1.0029,\n",
      "        0.9879, 0.9955, 0.9979, 0.9581, 0.9887, 0.9971, 0.9966, 0.9999, 1.0003,\n",
      "        0.9963, 0.9999, 1.0014, 0.9977, 0.9912, 0.9821, 0.9951, 1.0015, 0.9982,\n",
      "        1.0043, 0.9825, 0.9869, 1.0010, 0.9994, 0.9950, 0.9967, 1.0052, 0.9872,\n",
      "        1.0045, 1.0027, 0.9630, 0.9933, 1.0013, 0.9980, 0.9890, 0.9964, 0.9825],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0011, 0.9993, 0.9995, 0.9976, 0.9993, 0.9994, 0.9999, 0.9996, 0.9989,\n",
      "        1.0007, 1.0000, 1.0042, 1.0000, 0.9964, 0.9977, 1.0002, 0.9949, 0.9936,\n",
      "        0.9946, 0.9989, 0.9975, 1.0063, 1.0014, 1.0120, 1.0009, 0.9998, 0.9907,\n",
      "        1.0069, 1.0001, 0.9988, 1.0034, 0.9984, 1.0010, 1.0011, 1.0009, 0.9974,\n",
      "        1.0014, 1.0069, 1.0054, 0.9852, 0.9851, 0.9847, 0.9933, 1.0004, 0.9957,\n",
      "        1.0001, 1.0128, 1.0159, 1.0002, 0.9982, 1.0016, 0.9887, 0.9944, 0.9967,\n",
      "        0.9972, 0.9911, 0.9979, 0.9891, 1.0019, 0.9968, 0.9949, 1.0000, 1.0003,\n",
      "        1.0019, 0.9989, 0.9787, 1.0013, 0.9967, 0.9968, 0.9929, 0.9980, 0.9973],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9921, 0.9993, 0.9996, 0.9945, 1.0005, 0.9999, 1.0000, 0.9987, 1.0030,\n",
      "        0.9997, 0.9974, 0.9998, 0.9959, 0.9995, 1.0025, 1.0027, 0.9999, 0.9982,\n",
      "        0.9991, 0.9975, 0.9958, 0.9985, 0.9984, 0.9925, 0.9999, 1.0035, 1.0000,\n",
      "        0.9976, 1.0020, 0.9888, 0.9939, 0.9850, 0.9924, 0.9996, 1.0010, 1.0000,\n",
      "        0.9991, 0.9996, 0.9993, 0.9998, 0.9928, 0.9944, 0.9965, 1.0015, 0.9977,\n",
      "        0.9964, 1.0032, 1.0007, 0.9995, 1.0014, 1.0054, 1.0002, 0.9989, 1.0001,\n",
      "        1.0004, 1.0022, 1.0001, 0.9990, 0.9997, 1.0006, 0.9944, 0.9935, 1.0009,\n",
      "        1.0017, 0.9991, 0.9978, 1.0026, 1.0012, 1.0005, 0.9973, 1.0012, 0.9976],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9992, 0.9978, 1.0005, 0.9981, 0.9991, 0.9981, 1.0010, 0.9998, 1.0000,\n",
      "        0.9999, 1.0001, 0.9994, 0.9999, 1.0002, 1.0001, 1.0002, 0.9997, 0.9981,\n",
      "        1.0002, 0.9995, 0.9997, 0.9969, 0.9991, 0.9998, 0.9989, 0.9994, 0.9907,\n",
      "        0.9994, 0.9993, 0.9986, 0.9995, 1.0004, 0.9996, 0.9996, 0.9997, 1.0001,\n",
      "        1.0005, 1.0009, 0.9987, 1.0006, 0.9988, 1.0007, 0.9994, 0.9995, 0.9995,\n",
      "        1.0006, 1.0010, 1.0040, 0.9997, 0.9991, 0.9989, 0.9984, 0.9978, 1.0004,\n",
      "        0.9997, 0.9974, 0.9979, 0.9970, 0.9996, 1.0002, 0.9976, 0.9990, 1.0003,\n",
      "        1.0000, 0.9998, 0.9999, 0.9998, 0.9987, 0.9997, 1.0003, 1.0000, 1.0004,\n",
      "        0.9972, 0.9974, 1.0002, 1.0011, 1.0005, 0.9995, 1.0000, 0.9992, 1.0004,\n",
      "        1.0004, 0.9995, 1.0005, 1.0004, 1.0003, 0.9992, 0.9992, 1.0001, 0.9993,\n",
      "        0.9999, 0.9995, 1.0001, 0.9995, 0.9991, 0.9996, 0.9990, 1.0007, 1.0003,\n",
      "        0.9988, 1.0000, 0.9987, 1.0002, 1.0000, 0.9989, 0.9989, 1.0000, 1.0000,\n",
      "        0.9998, 0.9994, 0.9996, 0.9982, 0.9990, 0.9983, 0.9997, 0.9994, 0.9996,\n",
      "        1.0027, 0.9979, 0.9998, 0.9999, 1.0003, 0.9998, 0.9998, 0.9995, 1.0003,\n",
      "        0.9999, 0.9992, 0.9997, 0.9926, 0.9988, 0.9997, 0.9995, 0.9991, 1.0001,\n",
      "        0.9971, 0.9999, 0.9991], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9994, 0.9998, 0.9998, 0.9968, 0.9975, 0.9998, 1.0010, 0.9983, 1.0000,\n",
      "        1.0005, 0.9977, 1.0000, 0.9991, 0.9976, 0.9997, 0.9981, 0.9989, 0.9978,\n",
      "        0.9992, 0.9989, 0.9991, 0.9974, 0.9994, 0.9988, 0.9989, 0.9977, 0.9995,\n",
      "        0.9992, 0.9993, 0.9998, 1.0008, 1.0022, 0.9994, 1.0000, 0.9991, 1.0000,\n",
      "        0.9997, 0.9998, 1.0000, 0.9998, 0.9997, 0.9995, 1.0003, 1.0008, 1.0001,\n",
      "        1.0000, 0.9998, 0.9998, 0.9998, 0.9993, 0.9990, 0.9997, 1.0004, 0.9995,\n",
      "        1.0004, 0.9996, 1.0000, 0.9985, 0.9995, 1.0001, 0.9998, 0.9992, 1.0003,\n",
      "        0.9996, 0.9998, 1.0000, 1.0001, 0.9993, 1.0001, 0.9994, 0.9998, 1.0005,\n",
      "        0.9984, 0.9969, 0.9990, 0.9997, 1.0003, 1.0000, 1.0001, 1.0001, 1.0002,\n",
      "        1.0008, 1.0002, 0.9978, 0.9994, 0.9997, 0.9997, 0.9984, 0.9991, 0.9999,\n",
      "        1.0009, 0.9997, 1.0003, 1.0010, 1.0005, 0.9997, 0.9999, 1.0002, 1.0002,\n",
      "        0.9995, 1.0002, 1.0003, 1.0002, 1.0000, 1.0005, 0.9998, 0.9998, 1.0003,\n",
      "        1.0007, 1.0002, 0.9994, 0.9997, 1.0010, 1.0009, 0.9993, 0.9998, 0.9998,\n",
      "        0.9996, 0.9984, 1.0001, 1.0003, 0.9996, 0.9998, 0.9995, 0.9998, 0.9987,\n",
      "        0.9990, 0.9994, 1.0000, 0.9999, 1.0002, 0.9998, 0.9995, 0.9998, 0.9997,\n",
      "        0.9989, 0.9988, 0.9994], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9991, 0.9989, 0.9989, 0.9984, 0.9988, 0.9990, 0.9999, 0.9995, 0.9998,\n",
      "        0.9993, 1.0004, 1.0011, 0.9997, 1.0002, 0.9999, 1.0008, 1.0008, 0.9986,\n",
      "        1.0002, 0.9994, 1.0001, 1.0002, 0.9994, 0.9992, 0.9995, 0.9999, 0.9993,\n",
      "        1.0011, 1.0008, 0.9979, 0.9982, 0.9984, 0.9986, 0.9992, 0.9986, 0.9999,\n",
      "        1.0004, 0.9998, 1.0001, 1.0003, 1.0005, 0.9996, 0.9996, 0.9996, 0.9995,\n",
      "        1.0000, 0.9994, 1.0006, 0.9995, 0.9990, 1.0000, 0.9991, 0.9995, 0.9984,\n",
      "        0.9999, 0.9987, 0.9992, 1.0011, 1.0003, 0.9982, 1.0003, 0.9989, 1.0001,\n",
      "        0.9994, 0.9992, 1.0003, 0.9995, 0.9995, 0.9999, 1.0006, 0.9995, 0.9990,\n",
      "        0.9998, 0.9996, 0.9976, 0.9999, 1.0001, 0.9999, 0.9996, 1.0003, 0.9999,\n",
      "        1.0003, 0.9997, 0.9997, 0.9977, 0.9993, 0.9991, 1.0000, 0.9991, 1.0005,\n",
      "        0.9996, 0.9995, 0.9991, 0.9990, 0.9999, 0.9993, 0.9991, 0.9993, 0.9984,\n",
      "        0.9992, 0.9995, 0.9996, 1.0002, 0.9998, 0.9995, 0.9993, 1.0002, 1.0012,\n",
      "        1.0003, 0.9997, 0.9995, 0.9994, 1.0004, 0.9990, 0.9998, 0.9997, 1.0000,\n",
      "        0.9993, 0.9995, 0.9999, 0.9996, 0.9995, 0.9988, 1.0001, 0.9996, 0.9994,\n",
      "        0.9992, 1.0001, 0.9999, 0.9999, 1.0000, 0.9992, 1.0005, 1.0002, 1.0000,\n",
      "        0.9989, 0.9989, 0.9965], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9997, 0.9994, 0.9995, 0.9997, 0.9995, 1.0000, 0.9999, 0.9999, 0.9988,\n",
      "        1.0005, 0.9998, 1.0007, 0.9998, 0.9999, 0.9997, 1.0001, 0.9993, 0.9998,\n",
      "        0.9999, 1.0001, 0.9986, 0.9989, 0.9993, 1.0004, 0.9992, 0.9998, 0.9993,\n",
      "        0.9998, 1.0003, 1.0000, 1.0012, 0.9993, 0.9994, 1.0009, 0.9985, 1.0003,\n",
      "        1.0000, 0.9999, 0.9999, 1.0001, 1.0004, 0.9998, 0.9987, 0.9995, 0.9991,\n",
      "        1.0001, 0.9994, 1.0000, 1.0003, 0.9988, 0.9986, 0.9991, 0.9994, 0.9998,\n",
      "        0.9996, 0.9997, 0.9992, 0.9984, 1.0002, 0.9994, 0.9999, 0.9994, 0.9995,\n",
      "        0.9992, 1.0001, 1.0005, 0.9986, 0.9998, 1.0000, 0.9999, 1.0001, 0.9995,\n",
      "        0.9995, 0.9998, 0.9994, 1.0005, 0.9998, 0.9996, 0.9993, 0.9995, 1.0002,\n",
      "        0.9999, 0.9995, 0.9988, 1.0001, 0.9997, 0.9999, 0.9997, 1.0003, 1.0001,\n",
      "        0.9997, 1.0002, 1.0001, 1.0006, 1.0000, 1.0001, 0.9998, 0.9999, 0.9998,\n",
      "        1.0001, 0.9999, 1.0001, 1.0000, 1.0000, 0.9999, 1.0009, 1.0001, 0.9998,\n",
      "        0.9990, 1.0002, 1.0009, 1.0000, 0.9995, 0.9999, 0.9998, 0.9996, 1.0000,\n",
      "        0.9996, 0.9999, 0.9998, 1.0000, 1.0000, 0.9994, 1.0004, 0.9997, 0.9998,\n",
      "        0.9997, 1.0000, 0.9996, 1.0002, 1.0000, 1.0002, 0.9998, 0.9999, 1.0001,\n",
      "        0.9994, 0.9993, 0.9999], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9997, 0.9998, 0.9997, 0.9989, 0.9999, 1.0010, 0.9996, 1.0000, 0.9997,\n",
      "        1.0000, 0.9994, 1.0000, 0.9992, 0.9994, 0.9998, 0.9998, 1.0005, 1.0004,\n",
      "        0.9995, 0.9998, 0.9995, 1.0000, 1.0002, 0.9996, 0.9997, 0.9999, 0.9998,\n",
      "        1.0001, 0.9999, 0.9994, 0.9990, 0.9993, 0.9998, 1.0000, 1.0002, 1.0003,\n",
      "        0.9999, 1.0001, 1.0001, 0.9999, 0.9998, 0.9999, 0.9994, 0.9980, 0.9999,\n",
      "        0.9998, 0.9995, 1.0001, 0.9998, 0.9998, 0.9998, 0.9997, 0.9988, 1.0003,\n",
      "        0.9992, 0.9997, 0.9995, 0.9989, 0.9998, 1.0001, 0.9996, 1.0008, 1.0002,\n",
      "        0.9999, 0.9992, 1.0002, 1.0000, 0.9995, 1.0000, 0.9999, 0.9997, 0.9999,\n",
      "        0.9998, 0.9992, 0.9991, 1.0003, 0.9995, 0.9997, 1.0002, 1.0000, 0.9994,\n",
      "        0.9994, 0.9998, 0.9997, 0.9995, 0.9999, 0.9998, 0.9998, 1.0000, 1.0001,\n",
      "        0.9997, 1.0001, 1.0002, 0.9995, 0.9997, 1.0002, 1.0000, 1.0002, 1.0000,\n",
      "        1.0000, 1.0005, 1.0002, 0.9999, 1.0000, 0.9997, 0.9994, 1.0000, 0.9993,\n",
      "        1.0001, 1.0001, 0.9995, 1.0002, 0.9990, 1.0000, 1.0002, 0.9999, 0.9996,\n",
      "        1.0003, 1.0000, 1.0003, 0.9999, 0.9996, 0.9996, 1.0003, 0.9999, 1.0001,\n",
      "        0.9996, 0.9998, 0.9995, 1.0008, 0.9996, 0.9999, 0.9991, 0.9998, 0.9998,\n",
      "        0.9986, 0.9988, 0.9994], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 0.9995, 0.9995, 1.0003, 1.0006, 0.9991, 1.0000, 0.9999, 0.9997,\n",
      "        0.9998, 0.9998, 1.0001, 0.9998, 0.9998, 0.9997, 0.9993, 0.9995, 0.9994,\n",
      "        0.9999, 0.9999, 0.9999, 0.9997, 1.0000, 1.0005, 0.9996, 0.9986, 0.9996,\n",
      "        1.0002, 1.0005, 0.9999, 0.9993, 0.9996, 0.9994, 0.9999, 0.9996, 0.9996,\n",
      "        1.0001, 0.9998, 0.9993, 1.0001, 0.9997, 1.0004, 1.0001, 0.9997, 1.0002,\n",
      "        1.0004, 1.0000, 1.0004, 0.9992, 0.9988, 0.9991, 1.0002, 0.9999, 0.9998,\n",
      "        0.9984, 0.9982, 0.9996, 0.9997, 0.9999, 0.9995, 0.9999, 0.9998, 0.9993,\n",
      "        0.9996, 1.0000, 0.9996, 1.0001, 1.0004, 1.0003, 1.0000, 0.9996, 1.0000,\n",
      "        0.9993, 0.9998, 0.9997, 0.9990, 0.9998, 0.9990, 1.0001, 0.9984, 0.9995,\n",
      "        0.9998, 0.9992, 1.0005, 0.9997, 1.0005, 1.0002, 0.9990, 0.9988, 1.0000,\n",
      "        0.9999, 0.9998, 0.9998, 0.9999, 0.9998, 1.0005, 0.9999, 0.9994, 0.9995,\n",
      "        0.9998, 0.9998, 1.0000, 0.9999, 0.9994, 1.0002, 1.0002, 0.9988, 0.9999,\n",
      "        0.9997, 0.9995, 1.0000, 0.9994, 1.0006, 1.0003, 0.9998, 1.0000, 1.0001,\n",
      "        1.0001, 1.0000, 0.9994, 0.9997, 0.9999, 1.0004, 0.9997, 0.9995, 0.9993,\n",
      "        0.9990, 0.9997, 0.9995, 0.9998, 0.9999, 0.9997, 0.9998, 0.9996, 0.9998,\n",
      "        1.0000, 0.9999, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9992, 0.9997, 0.9976, 0.9976, 0.9995, 0.9976, 0.9998, 0.9993, 0.9993,\n",
      "        0.9995, 0.9997, 0.9980, 1.0001, 0.9995, 0.9994, 1.0000, 0.9998, 0.9992,\n",
      "        1.0000, 0.9998, 0.9999, 1.0000, 0.9997, 0.9989, 1.0001, 1.0003, 1.0003,\n",
      "        0.9986, 1.0000, 0.9996, 0.9992, 0.9998, 0.9957, 0.9970, 0.9979, 0.9994,\n",
      "        0.9993, 0.9998, 0.9996, 0.9989, 0.9998, 0.9977], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9992, 0.9983, 0.9983, 1.0000, 0.9991, 0.9975, 0.9985, 0.9993, 0.9987,\n",
      "        0.9975, 0.9985, 0.9986, 0.9996, 0.9995, 0.9994, 0.9986, 1.0000, 0.9999,\n",
      "        1.0001, 0.9985, 0.9997, 0.9988, 0.9998, 0.9989, 1.0002, 1.0001, 1.0001,\n",
      "        0.9982, 0.9999, 0.9999, 0.9988, 0.9996, 0.9991, 0.9980, 0.9974, 0.9996,\n",
      "        0.9989, 1.0004, 1.0001, 0.9990, 1.0002, 0.9995], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9966, 0.9997, 0.9984, 0.9973, 0.9965, 0.9983, 0.9986, 0.9995, 0.9991,\n",
      "        0.9989, 0.9999, 0.9991, 0.9978, 0.9982, 0.9989, 0.9995, 0.9970, 1.0001,\n",
      "        0.9999, 0.9998, 1.0001, 0.9997, 0.9993, 0.9989, 0.9977, 0.9981, 0.9999,\n",
      "        1.0000, 0.9992, 0.9990, 0.9999, 1.0002, 0.9993, 0.9996, 0.9985, 0.9960,\n",
      "        0.9996, 1.0000, 0.9987, 0.9981, 1.0001, 0.9989], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0014, 0.9997, 1.0017, 0.9991, 0.9980, 0.9966, 0.9985, 0.9993, 0.9991,\n",
      "        0.9998, 0.9988, 0.9975, 0.9992, 0.9993, 0.9996, 0.9986, 1.0000, 1.0007,\n",
      "        0.9993, 0.9997, 0.9996, 0.9985, 0.9997, 0.9990, 0.9979, 0.9986, 0.9990,\n",
      "        0.9988, 1.0000, 0.9992, 0.9987, 0.9998, 1.0001, 0.9964, 0.9981, 0.9973,\n",
      "        1.0000, 1.0000, 0.9999, 0.9995, 0.9985, 0.9999], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9973, 0.9973, 0.9979, 0.9983, 0.9985, 0.9995, 0.9960, 0.9973, 1.0002,\n",
      "        0.9983, 0.9971, 0.9987, 0.9984, 0.9984, 0.9989, 0.9997, 0.9993, 0.9987,\n",
      "        0.9984, 0.9992, 0.9991, 0.9990, 0.9992, 0.9986, 1.0000, 0.9984, 1.0000,\n",
      "        0.9996, 0.9999, 0.9992, 0.9960, 0.9998, 0.9998, 0.9971, 0.9979, 0.9982,\n",
      "        1.0000, 0.9989, 0.9993, 0.9991, 1.0016, 1.0001], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9989, 0.9990, 1.0001, 0.9961, 0.9976, 0.9979, 0.9973, 0.9998, 1.0003,\n",
      "        0.9995, 0.9988, 0.9995, 1.0001, 0.9994, 0.9999, 1.0000, 1.0000, 0.9998,\n",
      "        0.9997, 0.9996, 0.9978, 0.9986, 0.9986, 0.9992, 0.9996, 0.9994, 1.0001,\n",
      "        0.9999, 0.9992, 1.0000, 1.0002, 0.9977, 0.9987, 1.0002, 1.0002, 1.0007,\n",
      "        0.9991, 1.0001, 0.9978, 0.9991, 0.9999, 0.9984], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9997, 0.9999, 0.9996, 1.0000, 1.0001, 1.0003, 0.9999, 0.9989, 0.9996,\n",
      "        0.9999, 1.0000, 0.9982, 0.9999, 1.0001, 0.9993, 0.9994, 0.9978, 0.9995,\n",
      "        0.9979, 1.0001, 1.0000, 0.9997, 1.0003, 0.9963, 0.9994, 1.0000, 1.0001,\n",
      "        0.9994, 1.0004, 1.0002, 1.0006, 1.0001, 1.0007, 0.9994, 0.9998, 1.0003,\n",
      "        0.9994, 0.9991, 0.9979, 0.9994, 0.9997, 0.9997, 0.9997, 1.0001, 0.9998,\n",
      "        0.9998, 0.9993, 0.9994, 0.9998, 0.9971, 1.0003, 1.0001, 0.9998, 1.0005,\n",
      "        0.9998, 1.0005, 0.9990, 1.0002, 1.0006, 0.9997, 1.0001, 0.9999, 0.9997,\n",
      "        0.9999, 0.9995, 0.9997, 0.9987, 0.9967, 0.9995, 1.0000, 0.9984, 0.9997,\n",
      "        1.0000, 1.0002, 1.0001, 0.9998, 0.9999, 0.9999], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9995, 0.9999, 0.9992, 1.0003, 1.0003, 0.9997, 0.9999, 0.9988, 0.9973,\n",
      "        0.9997, 0.9993, 0.9997, 0.9993, 0.9996, 0.9997, 0.9993, 1.0002, 0.9990,\n",
      "        0.9998, 0.9990, 0.9995, 1.0000, 0.9994, 1.0000, 0.9998, 0.9999, 0.9996,\n",
      "        1.0016, 1.0001, 0.9981, 0.9998, 1.0001, 1.0001, 1.0002, 1.0000, 0.9999,\n",
      "        1.0003, 1.0001, 0.9999, 0.9975, 0.9996, 1.0002, 1.0000, 1.0004, 1.0008,\n",
      "        0.9979, 0.9994, 0.9995, 1.0001, 0.9996, 0.9985, 0.9996, 0.9999, 0.9991,\n",
      "        1.0008, 0.9992, 0.9998, 0.9985, 0.9998, 0.9993, 1.0003, 0.9989, 1.0000,\n",
      "        0.9993, 0.9999, 0.9991, 1.0003, 1.0003, 0.9982, 0.9999, 1.0003, 1.0002,\n",
      "        0.9995, 1.0006, 1.0002, 1.0005, 0.9997, 0.9996], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9995, 0.9994, 0.9992, 0.9973, 0.9989, 0.9993, 0.9992, 0.9998, 0.9999,\n",
      "        0.9998, 0.9996, 0.9995, 1.0000, 0.9975, 1.0001, 0.9997, 1.0011, 1.0004,\n",
      "        0.9991, 0.9987, 0.9976, 0.9995, 1.0001, 0.9989, 0.9999, 0.9994, 1.0009,\n",
      "        0.9999, 0.9990, 0.9997, 0.9998, 0.9999, 0.9993, 1.0003, 1.0003, 0.9978,\n",
      "        0.9990, 0.9995, 0.9985, 0.9991, 1.0003, 0.9996, 0.9990, 0.9963, 0.9958,\n",
      "        0.9989, 0.9992, 1.0000, 0.9999, 0.9999, 0.9989, 1.0005, 0.9995, 1.0004,\n",
      "        0.9994, 1.0000, 0.9981, 1.0014, 0.9993, 0.9982, 0.9998, 0.9996, 1.0003,\n",
      "        1.0000, 1.0003, 1.0007, 0.9989, 0.9992, 0.9993, 0.9999, 1.0002, 0.9999,\n",
      "        1.0010, 0.9990, 0.9996, 1.0001, 0.9998, 0.9992], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9994, 0.9998, 1.0001, 0.9990, 1.0009, 0.9995, 0.9996, 0.9986, 0.9995,\n",
      "        0.9993, 0.9998, 0.9987, 1.0012, 1.0006, 0.9997, 1.0005, 1.0009, 0.9975,\n",
      "        1.0006, 0.9996, 1.0000, 0.9994, 0.9999, 0.9996, 0.9996, 1.0003, 0.9996,\n",
      "        1.0001, 1.0002, 1.0000, 0.9997, 1.0000, 0.9990, 1.0013, 1.0001, 1.0004,\n",
      "        1.0000, 0.9996, 0.9988, 1.0008, 1.0001, 1.0002, 0.9999, 1.0002, 1.0004,\n",
      "        1.0003, 0.9999, 1.0003, 1.0001, 1.0001, 0.9988, 1.0002, 0.9999, 0.9997,\n",
      "        0.9999, 0.9991, 1.0005, 1.0005, 0.9978, 0.9992, 0.9996, 0.9996, 0.9990,\n",
      "        0.9998, 0.9994, 1.0001, 0.9983, 1.0009, 1.0001, 0.9999, 0.9993, 0.9997,\n",
      "        0.9980, 1.0004, 0.9993, 0.9999, 0.9997, 0.9995], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9998, 0.9990, 0.9995, 0.9995, 0.9981, 1.0005, 0.9991, 0.9997, 1.0000,\n",
      "        0.9998, 0.9968, 0.9996, 1.0003, 0.9970, 1.0002, 0.9997, 1.0012, 1.0010,\n",
      "        1.0008, 0.9996, 0.9997, 0.9980, 1.0003, 0.9988, 1.0002, 0.9984, 1.0001,\n",
      "        1.0013, 0.9989, 1.0003, 0.9992, 0.9995, 0.9997, 0.9993, 0.9997, 1.0013,\n",
      "        0.9996, 0.9994, 1.0000, 0.9999, 1.0000, 0.9983, 0.9996, 0.9994, 0.9979,\n",
      "        0.9999, 1.0003, 0.9999, 1.0005, 1.0005, 0.9995, 0.9998, 1.0001, 0.9999,\n",
      "        0.9997, 0.9992, 0.9997, 1.0000, 0.9997, 0.9998, 0.9991, 1.0007, 1.0013,\n",
      "        0.9984, 0.9998, 0.9996, 0.9950, 0.9985, 0.9995, 0.9961, 0.9995, 1.0000,\n",
      "        0.9998, 0.9995, 1.0000, 0.9998, 0.9954, 1.0002], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9999, 0.9998, 1.0000, 0.9995, 1.0005, 1.0003, 0.9996, 1.0005, 1.0001,\n",
      "        1.0014, 0.9980, 0.9997, 1.0001, 0.9974, 0.9995, 1.0003, 1.0003, 0.9994,\n",
      "        0.9972, 0.9977, 0.9981, 0.9981, 1.0009, 0.9999, 0.9977, 1.0001, 1.0004,\n",
      "        0.9998, 1.0004, 0.9993, 0.9995, 0.9995, 0.9992, 0.9994, 0.9997, 0.9998,\n",
      "        0.9999, 1.0006, 0.9987, 0.9994, 0.9980, 1.0006, 1.0000, 0.9989, 1.0000,\n",
      "        0.9997, 1.0006, 0.9997, 0.9980, 1.0000, 0.9997, 0.9997, 0.9967, 0.9992,\n",
      "        1.0003, 0.9995, 0.9996, 1.0007, 1.0005, 0.9999, 0.9984, 0.9998, 0.9997,\n",
      "        0.9998, 1.0000, 0.9973, 1.0001, 1.0001, 1.0010, 1.0004, 1.0005, 0.9993,\n",
      "        0.9986, 0.9956, 1.0000, 0.9999, 1.0003, 1.0006], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9983, 0.9998, 0.9998, 0.9999, 0.9987, 0.9996, 1.0002, 1.0011, 0.9987,\n",
      "        0.9995, 1.0001, 1.0002, 0.9995, 0.9985, 0.9999, 0.9998, 0.9999, 0.9992,\n",
      "        1.0014, 1.0002, 1.0002, 1.0001, 0.9999, 0.9991, 0.9984, 0.9975, 0.9993,\n",
      "        0.9994, 0.9996, 0.9999, 0.9980, 0.9992, 0.9993, 1.0000, 0.9999, 0.9998,\n",
      "        0.9998, 0.9997, 0.9993, 1.0000, 0.9999, 0.9992, 0.9994, 0.9977, 1.0000,\n",
      "        0.9993, 1.0002, 0.9990, 0.9994, 0.9993, 0.9984, 0.9979, 0.9994, 0.9999,\n",
      "        0.9990, 0.9986, 0.9995, 1.0001, 0.9997, 0.9987, 0.9987, 0.9982, 0.9990,\n",
      "        1.0000, 0.9997, 0.9999, 0.9985, 0.9998, 0.9999, 0.9998, 1.0000, 1.0000,\n",
      "        0.9996, 0.9997, 1.0000, 0.9991, 0.9991, 0.9997, 0.9993, 1.0002, 0.9994,\n",
      "        0.9997, 0.9997, 0.9995, 1.0001, 1.0000, 1.0003, 0.9970, 0.9992, 0.9994,\n",
      "        1.0003, 0.9996, 0.9998, 0.9993, 0.9997, 0.9999, 0.9995, 0.9993, 1.0003,\n",
      "        0.9994, 0.9991, 1.0007], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0012, 0.9999, 1.0002, 1.0000, 1.0001, 1.0000, 1.0008, 0.9994, 0.9984,\n",
      "        0.9993, 0.9996, 1.0001, 0.9992, 0.9998, 0.9996, 0.9996, 0.9982, 1.0000,\n",
      "        1.0001, 0.9991, 0.9998, 1.0001, 1.0007, 0.9999, 0.9993, 0.9969, 0.9995,\n",
      "        0.9993, 0.9993, 1.0002, 0.9995, 0.9992, 0.9972, 0.9997, 0.9989, 1.0000,\n",
      "        0.9990, 0.9994, 0.9981, 1.0000, 0.9981, 1.0000, 1.0000, 1.0003, 0.9998,\n",
      "        1.0011, 1.0027, 1.0001, 0.9998, 0.9997, 0.9995, 0.9993, 1.0011, 1.0003,\n",
      "        0.9967, 0.9997, 0.9990, 1.0001, 0.9996, 0.9991, 1.0007, 1.0010, 0.9999,\n",
      "        0.9997, 1.0008, 1.0001, 1.0005, 1.0002, 0.9992, 1.0004, 0.9996, 0.9993,\n",
      "        0.9999, 0.9994, 0.9999, 1.0000, 1.0001, 0.9993, 0.9993, 1.0000, 0.9998,\n",
      "        0.9980, 0.9995, 1.0003, 1.0003, 1.0008, 0.9998, 1.0004, 1.0001, 0.9999,\n",
      "        0.9999, 0.9998, 0.9999, 1.0003, 0.9985, 0.9998, 0.9988, 0.9990, 0.9999,\n",
      "        0.9994, 1.0007, 1.0001], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9999, 1.0002, 0.9977, 0.9993, 1.0000, 0.9998, 0.9996, 1.0004, 0.9986,\n",
      "        0.9999, 0.9988, 0.9996, 0.9997, 1.0001, 0.9991, 1.0004, 0.9995, 0.9997,\n",
      "        0.9999, 0.9993, 0.9996, 0.9994, 1.0001, 1.0002, 0.9983, 0.9995, 0.9999,\n",
      "        0.9997, 0.9996, 0.9998, 0.9973, 0.9980, 0.9982, 1.0003, 0.9999, 1.0002,\n",
      "        0.9998, 0.9989, 1.0000, 0.9996, 0.9984, 0.9998, 0.9996, 0.9998, 1.0000,\n",
      "        1.0001, 0.9997, 0.9996, 1.0006, 1.0000, 0.9990, 0.9996, 1.0000, 1.0000,\n",
      "        0.9995, 0.9993, 0.9998, 0.9995, 1.0009, 0.9990, 1.0004, 0.9990, 1.0004,\n",
      "        1.0001, 0.9997, 0.9998, 0.9998, 1.0000, 1.0010, 0.9998, 1.0001, 0.9991,\n",
      "        0.9990, 1.0004, 1.0003, 0.9995, 0.9999, 0.9999, 1.0003, 0.9998, 1.0000,\n",
      "        1.0012, 1.0004, 1.0002, 0.9995, 0.9996, 0.9994, 0.9995, 1.0008, 1.0007,\n",
      "        0.9991, 1.0006, 1.0003, 0.9997, 1.0001, 1.0003, 0.9996, 0.9983, 0.9985,\n",
      "        0.9996, 0.9980, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9989, 0.9989, 0.9999, 0.9980, 0.9996, 1.0000, 0.9984, 0.9995, 0.9994,\n",
      "        0.9965, 1.0000, 1.0002, 0.9999, 0.9997, 0.9998, 1.0005, 1.0000, 1.0008,\n",
      "        1.0000, 1.0015, 1.0015, 0.9975, 1.0000, 0.9996, 0.9984, 0.9995, 0.9985,\n",
      "        1.0004, 1.0000, 0.9996, 0.9977, 0.9952, 0.9991, 0.9999, 0.9994, 1.0000,\n",
      "        0.9990, 0.9989, 1.0003, 0.9991, 0.9987, 0.9986, 1.0011, 0.9999, 0.9992,\n",
      "        1.0003, 0.9962, 0.9994, 0.9995, 0.9983, 0.9997, 0.9993, 1.0002, 1.0001,\n",
      "        0.9990, 1.0006, 1.0000, 1.0002, 0.9998, 1.0008, 1.0010, 1.0021, 1.0016,\n",
      "        0.9999, 0.9976, 0.9997, 0.9996, 1.0010, 0.9994, 0.9996, 1.0000, 1.0002,\n",
      "        1.0010, 0.9999, 1.0004, 1.0005, 1.0000, 0.9996, 1.0002, 1.0004, 1.0002,\n",
      "        0.9988, 0.9995, 1.0007, 1.0004, 1.0001, 1.0003, 0.9983, 1.0000, 0.9995,\n",
      "        0.9993, 0.9991, 0.9995, 0.9996, 1.0000, 1.0001, 0.9994, 0.9994, 0.9992,\n",
      "        1.0003, 1.0007, 0.9994], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9991, 1.0004, 1.0002, 0.9987, 1.0007, 0.9989, 0.9997, 1.0016, 1.0006,\n",
      "        0.9987, 0.9962, 0.9991, 0.9995, 0.9998, 0.9994, 0.9993, 0.9995, 1.0003,\n",
      "        0.9988, 0.9983, 0.9997, 0.9999, 0.9997, 0.9994, 1.0000, 0.9989, 0.9988,\n",
      "        0.9996, 0.9989, 0.9999, 0.9999, 0.9989, 0.9963, 1.0000, 0.9988, 1.0000,\n",
      "        1.0004, 0.9997, 0.9998, 0.9995, 0.9997, 0.9999, 1.0000, 1.0007, 1.0000,\n",
      "        0.9991, 1.0005, 0.9989, 1.0000, 0.9997, 0.9986, 0.9999, 1.0005, 1.0014,\n",
      "        0.9964, 0.9999, 0.9989, 0.9993, 0.9985, 0.9986, 1.0052, 0.9996, 0.9974,\n",
      "        0.9999, 0.9986, 0.9999, 0.9994, 0.9995, 0.9996, 1.0002, 1.0001, 1.0007,\n",
      "        0.9992, 0.9984, 0.9983, 0.9998, 0.9993, 1.0001, 0.9993, 0.9994, 1.0001,\n",
      "        0.9999, 1.0000, 1.0008, 0.9993, 0.9991, 0.9998, 1.0011, 0.9991, 0.9987,\n",
      "        1.0000, 0.9999, 0.9998, 1.0002, 1.0001, 1.0003, 1.0000, 0.9999, 0.9997,\n",
      "        0.9988, 1.0005, 1.0004], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9975, 1.0004, 1.0002, 0.9997, 0.9981, 0.9998, 1.0004, 0.9994, 0.9979,\n",
      "        0.9999, 1.0000, 1.0002, 0.9986, 0.9998, 0.9988, 1.0004, 0.9990, 0.9995,\n",
      "        0.9998, 1.0008, 1.0010, 1.0001, 1.0005, 1.0001, 0.9991, 0.9992, 1.0005,\n",
      "        0.9993, 0.9986, 1.0000, 0.9990, 0.9989, 0.9986, 0.9990, 1.0003, 0.9996,\n",
      "        1.0000, 0.9975, 0.9999, 0.9998, 0.9984, 0.9991, 0.9996, 0.9995, 0.9988,\n",
      "        1.0031, 0.9995, 1.0034, 1.0001, 0.9996, 1.0003, 0.9995, 1.0000, 0.9997,\n",
      "        1.0002, 0.9997, 0.9998, 1.0000, 0.9996, 1.0005, 0.9988, 0.9995, 0.9993,\n",
      "        0.9995, 0.9999, 1.0000, 0.9994, 0.9990, 0.9990, 1.0002, 0.9997, 0.9974,\n",
      "        1.0001, 0.9996, 0.9993, 0.9980, 1.0004, 1.0005, 0.9996, 0.9998, 0.9999,\n",
      "        1.0003, 0.9998, 0.9984, 1.0005, 0.9991, 0.9993, 0.9995, 1.0000, 0.9994,\n",
      "        0.9987, 1.0003, 1.0007, 1.0002, 0.9996, 0.9993, 0.9982, 1.0002, 0.9998,\n",
      "        0.9998, 0.9995, 0.9990], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9996, 0.9995, 0.9994, 0.9998, 0.9998, 0.9994, 0.9995, 0.9981, 0.9977,\n",
      "        0.9986, 0.9971, 0.9955, 0.9999, 0.9997, 0.9990, 0.9976, 0.9994, 0.9994,\n",
      "        1.0002, 0.9995, 1.0001, 0.9998, 0.9997, 0.9988, 0.9995, 0.9977, 0.9995,\n",
      "        0.9990, 0.9994, 1.0011, 0.9986, 0.9993, 0.9992, 0.9996, 1.0000, 1.0002,\n",
      "        0.9980, 0.9999, 0.9993, 0.9999, 1.0003, 1.0002, 0.9987, 0.9998, 0.9999,\n",
      "        0.9998, 0.9995, 0.9987, 0.9999, 1.0003, 0.9983, 0.9990, 0.9980, 0.9994,\n",
      "        0.9990, 0.9999, 0.9992, 0.9999, 0.9998, 0.9993, 0.9986, 0.9996, 0.9994,\n",
      "        0.9981, 0.9953, 0.9986, 0.9996, 0.9994, 1.0005, 0.9998, 0.9983, 0.9996,\n",
      "        0.9990, 0.9990, 0.9996, 1.0046, 1.0002, 0.9996, 1.0003, 1.0005, 1.0008,\n",
      "        0.9993, 0.9998, 0.9995, 0.9991, 0.9998, 0.9996, 0.9996, 0.9967, 0.9980,\n",
      "        1.0000, 0.9985, 1.0002, 1.0002, 1.0000, 1.0003, 0.9993, 0.9982, 0.9998],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0003, 1.0000, 0.9999, 1.0006, 1.0003, 0.9997, 1.0005, 1.0000, 1.0000,\n",
      "        0.9999, 0.9976, 1.0001, 0.9998, 0.9963, 0.9999, 0.9999, 0.9977, 1.0001,\n",
      "        0.9987, 1.0000, 0.9996, 1.0015, 0.9975, 0.9978, 0.9998, 1.0007, 0.9998,\n",
      "        1.0005, 1.0004, 1.0020, 0.9987, 0.9994, 0.9995, 0.9997, 1.0011, 1.0007,\n",
      "        0.9995, 0.9999, 1.0000, 1.0027, 0.9970, 1.0033, 0.9998, 0.9993, 0.9995,\n",
      "        0.9987, 0.9999, 1.0004, 0.9997, 0.9979, 0.9987, 0.9995, 0.9945, 0.9989,\n",
      "        0.9997, 0.9997, 0.9987, 0.9995, 0.9986, 0.9991, 0.9999, 1.0004, 1.0001,\n",
      "        0.9959, 0.9985, 1.0012, 1.0001, 0.9998, 0.9998, 0.9985, 0.9986, 0.9996,\n",
      "        0.9997, 1.0002, 0.9990, 0.9998, 1.0001, 0.9998, 0.9996, 0.9979, 0.9991,\n",
      "        0.9990, 0.9989, 0.9981, 0.9973, 0.9964, 0.9984, 0.9978, 1.0007, 0.9977,\n",
      "        1.0001, 0.9998, 0.9999, 0.9972, 0.9994, 1.0002, 0.9993, 1.0003, 0.9998],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9996, 1.0009, 0.9997, 0.9999, 0.9981, 0.9994, 1.0002, 0.9984, 1.0013,\n",
      "        0.9983, 0.9979, 0.9993, 1.0023, 1.0000, 0.9993, 0.9990, 1.0001, 0.9990,\n",
      "        0.9973, 0.9995, 0.9996, 0.9997, 0.9997, 0.9992, 0.9988, 0.9999, 0.9991,\n",
      "        0.9981, 1.0002, 0.9998, 1.0000, 0.9973, 0.9973, 1.0003, 1.0019, 1.0007,\n",
      "        0.9999, 0.9991, 1.0002, 0.9990, 0.9998, 0.9994, 1.0008, 0.9995, 0.9996,\n",
      "        0.9997, 0.9988, 0.9995, 1.0002, 0.9999, 0.9997, 0.9988, 0.9969, 0.9981,\n",
      "        0.9992, 0.9957, 0.9998, 1.0002, 0.9967, 0.9995, 0.9999, 0.9994, 0.9981,\n",
      "        0.9983, 0.9974, 0.9984, 0.9994, 0.9993, 0.9983, 0.9963, 0.9991, 0.9982,\n",
      "        1.0002, 1.0010, 0.9999, 0.9988, 0.9991, 1.0002, 0.9983, 1.0002, 1.0006,\n",
      "        0.9965, 0.9982, 1.0003, 0.9972, 0.9994, 0.9987, 0.9985, 0.9988, 0.9996,\n",
      "        1.0002, 0.9996, 0.9987, 0.9998, 0.9998, 0.9992, 0.9979, 0.9995, 0.9991],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9995, 0.9999, 1.0021, 0.9988, 0.9994, 1.0000, 1.0001, 1.0004, 1.0001,\n",
      "        0.9943, 0.9996, 0.9967, 0.9990, 0.9995, 0.9999, 0.9997, 0.9982, 0.9982,\n",
      "        1.0001, 1.0002, 0.9998, 0.9997, 0.9992, 0.9994, 1.0000, 0.9994, 0.9998,\n",
      "        0.9974, 0.9990, 0.9989, 0.9993, 0.9971, 1.0000, 0.9995, 1.0002, 1.0015,\n",
      "        0.9997, 0.9986, 0.9972, 0.9933, 0.9985, 0.9987, 0.9988, 0.9995, 1.0001,\n",
      "        0.9995, 0.9999, 1.0007, 1.0000, 0.9994, 0.9977, 0.9996, 0.9979, 0.9963,\n",
      "        0.9994, 0.9991, 0.9989, 0.9967, 0.9997, 1.0000, 0.9979, 0.9996, 0.9962,\n",
      "        1.0007, 1.0004, 0.9986, 0.9998, 0.9999, 1.0007, 1.0000, 0.9998, 1.0005,\n",
      "        0.9998, 0.9978, 0.9983, 1.0002, 0.9998, 0.9993, 0.9998, 0.9992, 0.9999,\n",
      "        0.9935, 0.9954, 0.9986, 0.9997, 0.9995, 0.9995, 0.9978, 0.9965, 0.9990,\n",
      "        0.9999, 0.9998, 1.0000, 0.9999, 0.9987, 0.9999, 0.9998, 1.0002, 0.9993],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9996, 0.9992, 1.0007, 0.9995, 1.0000, 0.9988, 0.9993, 0.9997, 0.9993,\n",
      "        0.9980, 0.9968, 0.9969, 0.9982, 0.9990, 0.9993, 1.0009, 1.0012, 0.9997,\n",
      "        1.0008, 0.9972, 0.9979, 0.9965, 0.9993, 1.0013, 1.0002, 0.9988, 1.0002,\n",
      "        0.9997, 0.9980, 0.9993, 1.0013, 0.9996, 1.0012, 1.0003, 0.9999, 0.9964,\n",
      "        1.0004, 1.0016, 1.0002, 1.0003, 0.9966, 1.0003, 1.0001, 0.9999, 0.9984,\n",
      "        0.9980, 0.9974, 0.9999, 0.9978, 0.9975, 0.9982, 0.9996, 0.9974, 0.9977,\n",
      "        0.9996, 0.9989, 1.0002, 0.9992, 0.9954, 0.9977, 0.9979, 0.9988, 0.9990,\n",
      "        0.9976, 1.0007, 0.9970, 0.9997, 0.9969, 0.9998, 0.9984, 0.9990, 0.9991,\n",
      "        0.9999, 0.9992, 0.9980, 0.9991, 1.0000, 0.9980, 0.9993, 0.9959, 0.9991,\n",
      "        0.9982, 0.9965, 0.9979, 0.9945, 0.9987, 0.9981, 0.9984, 0.9983, 0.9999,\n",
      "        0.9967, 0.9986, 0.9997, 0.9998, 0.9998, 0.9997, 1.0000, 0.9993, 0.9995],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9986, 1.0011, 1.0001, 0.9999, 0.9975, 0.9986, 0.9996, 1.0004, 0.9999,\n",
      "        0.9974, 0.9960, 0.9982, 0.9949, 0.9999, 0.9980, 0.9987, 1.0000, 0.9992,\n",
      "        0.9984, 0.9946, 0.9990, 0.9998, 0.9977, 0.9986, 0.9974, 0.9990, 1.0001,\n",
      "        0.9974, 0.9992, 0.9976, 0.9990, 0.9996, 0.9997, 0.9995, 0.9994, 0.9993,\n",
      "        0.9960, 0.9980, 1.0001, 0.9894, 0.9961, 0.9898, 0.9993, 1.0003, 0.9988,\n",
      "        1.0004, 0.9988, 1.0000, 0.9973, 0.9993, 0.9988, 0.9992, 1.0000, 0.9984,\n",
      "        0.9966, 0.9984, 0.9985, 1.0007, 0.9994, 0.9998, 1.0017, 1.0000, 0.9992,\n",
      "        0.9955, 0.9960, 0.9985, 1.0012, 0.9992, 0.9981, 1.0002, 0.9992, 0.9986,\n",
      "        1.0010, 0.9997, 0.9974, 0.9956, 1.0001, 1.0011, 0.9984, 0.9966, 0.9959,\n",
      "        0.9964, 0.9964, 0.9984, 0.9980, 0.9975, 0.9995, 0.9987, 0.9946, 1.0002,\n",
      "        0.9978, 1.0004, 0.9992, 1.0012, 0.9999, 0.9965, 0.9993, 0.9960, 0.9999],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9992, 1.0000, 0.9998, 0.9973, 0.9990, 0.9987, 0.9997, 0.9994, 0.9990,\n",
      "        0.9998, 0.9993, 0.9994, 0.9999, 0.9996, 0.9987, 0.9992, 1.0008, 1.0002,\n",
      "        1.0000, 0.9995, 0.9993, 0.9974, 1.0017, 0.9980, 0.9963, 0.9985, 0.9941,\n",
      "        1.0001, 1.0002, 0.9977, 1.0013, 1.0006, 0.9991, 0.9984, 0.9982, 0.9968,\n",
      "        0.9995, 1.0010, 1.0001, 0.9981, 0.9977, 0.9980, 0.9997, 0.9995, 1.0022,\n",
      "        0.9996, 0.9988, 0.9996, 1.0016, 1.0005, 0.9986, 0.9973, 0.9993, 0.9954,\n",
      "        0.9975, 0.9996, 0.9981, 0.9993, 1.0004, 0.9989, 1.0024, 1.0030, 0.9975,\n",
      "        0.9989, 1.0001, 0.9992], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9991, 0.9982, 0.9975, 0.9949, 0.9999, 0.9940, 1.0035, 0.9995, 0.9988,\n",
      "        0.9993, 0.9996, 0.9976, 0.9989, 0.9998, 0.9989, 0.9992, 0.9991, 0.9975,\n",
      "        0.9985, 0.9996, 1.0003, 0.9994, 0.9995, 0.9961, 0.9997, 1.0002, 0.9979,\n",
      "        0.9983, 0.9990, 0.9998, 0.9975, 1.0022, 0.9979, 0.9979, 0.9986, 0.9999,\n",
      "        1.0000, 0.9968, 0.9984, 0.9982, 0.9993, 0.9996, 0.9973, 0.9985, 0.9996,\n",
      "        0.9992, 0.9992, 0.9987, 1.0008, 1.0014, 1.0037, 0.9988, 0.9972, 0.9972,\n",
      "        0.9992, 0.9980, 0.9974, 0.9990, 0.9990, 0.9985, 0.9977, 0.9947, 0.9986,\n",
      "        1.0001, 0.9933, 0.9970], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0006, 0.9999, 1.0006, 1.0005, 1.0007, 0.9992, 1.0010, 0.9984, 1.0017,\n",
      "        0.9980, 0.9997, 1.0019, 0.9984, 0.9994, 0.9996, 1.0000, 0.9988, 0.9996,\n",
      "        0.9999, 0.9964, 0.9983, 0.9947, 0.9963, 0.9987, 1.0000, 0.9992, 1.0002,\n",
      "        0.9978, 0.9981, 0.9995, 0.9992, 0.9972, 0.9996, 0.9998, 0.9982, 0.9951,\n",
      "        0.9992, 0.9994, 0.9989, 1.0007, 0.9986, 0.9987, 0.9999, 0.9966, 0.9987,\n",
      "        1.0000, 0.9997, 0.9975, 1.0001, 0.9994, 0.9946, 0.9986, 0.9942, 0.9969,\n",
      "        0.9969, 0.9975, 0.9980, 0.9986, 0.9952, 1.0000, 0.9996, 0.9975, 0.9997,\n",
      "        0.9983, 0.9985, 0.9997], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9995, 0.9980, 0.9991, 1.0030, 1.0001, 1.0002, 0.9985, 0.9983, 0.9998,\n",
      "        0.9986, 1.0001, 1.0024, 0.9995, 1.0012, 0.9993, 0.9997, 1.0007, 0.9999,\n",
      "        0.9985, 0.9990, 0.9995, 1.0007, 0.9948, 0.9918, 0.9981, 0.9999, 0.9902,\n",
      "        1.0000, 0.9991, 0.9981, 1.0000, 0.9996, 0.9988, 0.9922, 0.9956, 0.9940,\n",
      "        1.0008, 0.9995, 0.9997, 0.9972, 0.9994, 0.9992, 0.9995, 0.9981, 0.9995,\n",
      "        0.9985, 0.9994, 1.0003, 0.9950, 0.9996, 0.9980, 0.9985, 0.9984, 0.9973,\n",
      "        0.9910, 0.9960, 0.9989, 0.9995, 1.0002, 0.9961, 0.9968, 0.9994, 0.9952,\n",
      "        0.9993, 0.9989, 0.9974], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9991, 0.9998, 0.9990, 1.0000, 1.0004, 1.0013, 0.9999, 0.9986, 1.0000,\n",
      "        1.0033, 0.9988, 1.0000, 0.9999, 0.9997, 0.9998, 0.9997, 0.9982, 1.0017,\n",
      "        0.9992, 0.9997, 0.9988, 0.9962, 0.9970, 0.9992, 1.0006, 0.9994, 0.9939,\n",
      "        0.9991, 0.9978, 0.9936, 0.9998, 0.9990, 0.9979, 0.9997, 1.0002, 0.9987,\n",
      "        0.9988, 1.0000, 0.9999, 0.9994, 0.9984, 1.0026, 0.9985, 0.9994, 0.9963,\n",
      "        0.9977, 0.9973, 0.9997, 0.9971, 1.0015, 1.0026, 0.9982, 0.9976, 0.9994,\n",
      "        1.0009, 0.9987, 0.9989, 0.9990, 0.9987, 0.9966, 0.9976, 0.9981, 0.9989,\n",
      "        1.0002, 0.9994, 0.9992], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9989, 1.0008, 0.9986, 0.9996, 0.9985, 0.9990, 0.9981, 1.0001, 0.9984,\n",
      "        0.9992, 0.9939, 0.9975, 0.9956, 1.0001, 0.9985, 0.9988, 1.0001, 1.0001,\n",
      "        0.9980, 0.9989, 0.9999, 0.9997, 0.9984, 0.9972, 1.0000, 0.9943, 1.0005,\n",
      "        0.9897, 1.0014, 0.9971, 0.9992, 0.9999, 1.0005, 0.9999, 0.9992, 0.9986,\n",
      "        1.0006, 0.9996, 0.9970, 1.0009, 0.9996, 0.9951, 0.9984, 0.9984, 0.9974,\n",
      "        0.9993, 0.9991, 0.9959, 0.9994, 1.0003, 0.9998, 0.9988, 0.9986, 0.9963,\n",
      "        0.9973, 1.0009, 0.9989, 0.9999, 0.9989, 0.9975, 0.9990, 0.9995, 1.0000,\n",
      "        0.9986, 0.9994, 0.9948], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0013, 1.0002, 0.9980, 0.9997, 0.9942, 0.9999, 1.0019, 0.9977, 0.9999,\n",
      "        1.0000, 0.9966, 0.9998, 0.9999, 1.0003, 1.0013, 0.9990, 1.0001, 0.9970,\n",
      "        0.9957, 0.9977, 0.9984, 0.9978, 0.9996, 1.0000, 0.9983, 0.9982, 1.0002,\n",
      "        0.9973, 0.9981, 0.9990, 0.9987, 0.9958, 0.9953, 1.0003, 1.0010, 0.9986,\n",
      "        0.9987, 0.9971, 0.9993, 1.0005, 0.9996, 0.9984, 0.9922, 0.9976, 0.9987,\n",
      "        0.9999, 0.9996, 0.9999, 1.0010, 0.9974, 1.0002, 0.9997, 1.0023, 0.9955,\n",
      "        0.9994, 0.9922, 1.0003, 0.9989, 0.9974, 0.9817, 0.9945, 0.9894, 0.9939,\n",
      "        1.0009, 0.9922, 0.9999, 0.9900, 0.9969, 0.9955, 0.9990, 1.0019, 1.0007,\n",
      "        0.9994, 0.9981, 0.9985, 0.9998, 0.9993, 1.0042], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0017, 0.9957, 1.0001, 0.9986, 1.0000, 0.9984, 1.0065, 0.9991, 1.0030,\n",
      "        0.9987, 1.0015, 0.9947, 1.0008, 0.9995, 1.0009, 0.9968, 0.9980, 0.9992,\n",
      "        0.9922, 0.9897, 1.0002, 0.9999, 1.0004, 0.9964, 0.9983, 0.9991, 0.9918,\n",
      "        0.9978, 0.9991, 1.0001, 0.9976, 0.9998, 0.9996, 0.9974, 1.0009, 0.9991,\n",
      "        0.9997, 0.9998, 0.9962, 0.9975, 0.9990, 0.9964, 0.9995, 1.0001, 1.0034,\n",
      "        1.0025, 0.9990, 1.0032, 0.9986, 1.0036, 0.9992, 1.0003, 1.0015, 0.9978,\n",
      "        0.9976, 0.9991, 0.9985, 0.9950, 0.9943, 0.9916, 1.0034, 1.0004, 0.9999,\n",
      "        1.0000, 0.9994, 0.9959, 0.9938, 0.9823, 0.9946, 1.0005, 0.9979, 1.0007,\n",
      "        0.9981, 0.9996, 0.9991, 0.9992, 0.9972, 0.9982], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9998, 1.0011, 1.0018, 0.9898, 0.9952, 0.9981, 0.9990, 0.9993, 0.9961,\n",
      "        0.9995, 0.9961, 0.9977, 1.0071, 1.0001, 0.9980, 0.9965, 1.0021, 1.0011,\n",
      "        0.9876, 0.9993, 1.0000, 1.0004, 0.9993, 0.9979, 0.9977, 1.0000, 0.9999,\n",
      "        1.0007, 0.9993, 0.9975, 1.0022, 0.9987, 0.9994, 0.9995, 1.0004, 0.9993,\n",
      "        1.0001, 1.0032, 1.0005, 1.0012, 1.0001, 1.0023, 0.9971, 1.0000, 1.0016,\n",
      "        0.9994, 0.9986, 0.9928, 1.0002, 0.9988, 0.9987, 0.9995, 1.0016, 0.9920,\n",
      "        1.0004, 0.9976, 0.9990, 0.9913, 0.9930, 0.9975, 0.9991, 0.9991, 0.9993,\n",
      "        0.9970, 0.9957, 0.9948, 1.0015, 0.9993, 0.9984, 0.9978, 0.9974, 0.9985,\n",
      "        0.9997, 1.0010, 0.9991, 1.0026, 0.9957, 0.9986], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9968, 0.9951, 0.9974, 0.9966, 0.9979, 0.9970, 0.9973, 0.9989, 0.9979,\n",
      "        1.0001, 0.9733, 0.9996, 1.0008, 0.9980, 1.0016, 0.9990, 0.9989, 0.9964,\n",
      "        0.9961, 0.9999, 0.9968, 0.9955, 0.9976, 0.9953, 0.9971, 1.0009, 0.9968,\n",
      "        0.9986, 0.9973, 0.9996, 1.0005, 1.0011, 1.0017, 1.0031, 1.0023, 1.0020,\n",
      "        0.9988, 1.0033, 1.0029, 1.0016, 0.9995, 1.0000, 1.0015, 0.9952, 0.9986,\n",
      "        0.9978, 1.0268, 1.0208, 1.0025, 1.0022, 0.9986, 1.0050, 1.0020, 0.9987,\n",
      "        1.0037, 0.9993, 0.9972, 0.9906, 0.9993, 0.9950, 1.0026, 0.9958, 1.0006,\n",
      "        0.9969, 0.9982, 1.0009, 0.9930, 0.9930, 0.9960, 0.9995, 0.9994, 0.9979,\n",
      "        1.0020, 0.9967, 0.9904, 1.0013, 0.9986, 0.9988], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9976, 0.9999, 0.9975, 1.0015, 0.9911, 0.9996, 1.0001, 0.9977, 0.9973,\n",
      "        1.0004, 0.9903, 0.9989, 1.0004, 1.0002, 1.0008, 1.0011, 0.9966, 0.9997,\n",
      "        0.9997, 1.0010, 1.0004, 0.9965, 0.9990, 0.9999, 1.0009, 0.9949, 0.9963,\n",
      "        0.9992, 0.9977, 0.9987, 1.0027, 0.9997, 1.0020, 1.0007, 0.9951, 1.0000,\n",
      "        1.0009, 0.9996, 0.9951, 1.0014, 1.0013, 0.9998, 0.9998, 0.9920, 1.0014,\n",
      "        0.9982, 0.9988, 0.9953, 0.9952, 1.0005, 0.9983, 1.0003, 0.9952, 1.0005,\n",
      "        1.0021, 0.9989, 0.9982, 0.9946, 0.9963, 0.9882, 0.9991, 1.0057, 0.9996,\n",
      "        1.0000, 0.9988, 0.9968, 1.0004, 0.9890, 0.9994, 0.9998, 0.9980, 0.9955,\n",
      "        0.9986, 0.9997, 0.9993, 1.0000, 0.9985, 0.9996], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9989, 1.0000, 0.9990, 0.9997, 1.0002, 0.9946, 0.9993, 0.9951, 0.9978,\n",
      "        0.9989, 0.9991, 0.9993, 0.9973, 1.0010, 1.0035, 0.9975, 0.9985, 1.0009,\n",
      "        0.9966, 0.9980, 1.0001, 1.0009, 0.9976, 0.9988, 1.0028, 1.0053, 0.9979,\n",
      "        0.9978, 0.9985, 0.9992, 0.9999, 1.0067, 0.9998, 0.9931, 1.0012, 0.9978,\n",
      "        0.9987, 1.0008, 0.9968, 0.9976, 1.0016, 1.0002, 1.0000, 0.9965, 1.0020,\n",
      "        0.9990, 0.9995, 0.9987, 0.9964, 0.9967, 1.0001, 0.9975, 0.9948, 1.0002,\n",
      "        0.9986, 1.0001, 0.9991, 0.9990, 0.9913, 0.9995, 0.9981, 0.9939, 0.9962,\n",
      "        0.9998, 0.9986, 0.9976, 1.0015, 1.0034, 0.9977, 0.9993, 0.9987, 1.0001,\n",
      "        1.0018, 0.9999, 1.0011, 0.9989, 0.9956, 1.0006], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9988, 0.9999, 0.9990, 0.9985, 0.9989, 0.9974, 1.0003, 0.9992, 0.9998,\n",
      "        0.9998, 0.9993, 0.9994, 0.9978, 0.9999, 0.9947, 0.9893, 1.0000, 1.0007,\n",
      "        1.0005, 0.9997, 1.0001, 0.9985, 0.9994, 0.9972, 0.9990, 1.0002, 0.9974,\n",
      "        1.0013, 1.0003, 0.9913, 0.9937, 0.9994, 0.9997, 0.9991, 0.9990, 0.9956,\n",
      "        0.9997, 1.0003, 0.9993, 1.0006, 0.9985, 0.9990, 0.9989, 1.0004, 1.0012,\n",
      "        0.9994, 0.9999, 0.9995, 0.9984, 0.9999, 1.0005, 0.9989, 0.9954, 1.0001,\n",
      "        1.0024, 1.0002, 1.0035, 0.9999, 0.9990, 1.0031, 1.0001, 1.0001, 0.9993,\n",
      "        0.9999, 1.0002, 1.0009, 0.9941, 0.9969, 0.9980, 0.9993, 1.0000, 0.9925,\n",
      "        0.9991, 1.0002, 0.9991, 0.9989, 0.9992, 0.9981, 0.9995, 0.9969, 0.9991,\n",
      "        1.0000, 0.9986, 0.9971, 0.9998, 1.0001, 1.0003, 0.9999, 0.9993, 0.9998,\n",
      "        0.9993, 0.9989, 0.9998, 1.0000, 0.9998, 0.9999, 1.0000, 0.9999, 1.0000,\n",
      "        1.0004, 0.9985, 1.0023, 0.9994, 0.9997, 1.0000, 0.9958, 0.9986, 0.9974,\n",
      "        0.9990, 0.9998, 0.9972, 1.0000, 1.0002, 0.9991, 1.0026, 1.0027, 0.9909,\n",
      "        1.0002, 1.0000, 0.9991, 0.9987, 1.0007, 1.0005, 1.0005, 1.0003, 1.0001,\n",
      "        0.9992, 0.9995, 0.9993], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9994, 0.9989, 1.0012, 0.9974, 0.9998, 0.9943, 0.9986, 1.0002, 0.9967,\n",
      "        1.0012, 0.9996, 0.9997, 0.9907, 0.9957, 0.9965, 1.0002, 0.9999, 0.9943,\n",
      "        0.9992, 1.0016, 0.9983, 0.9994, 0.9990, 0.9976, 0.9956, 0.9960, 0.9995,\n",
      "        0.9977, 0.9986, 0.9904, 0.9946, 1.0019, 0.9979, 1.0007, 0.9937, 1.0011,\n",
      "        0.9980, 0.9959, 1.0006, 1.0002, 0.9990, 1.0001, 0.9967, 0.9986, 0.9917,\n",
      "        1.0011, 0.9986, 0.9991, 1.0004, 0.9975, 0.9976, 0.9997, 0.9995, 0.9998,\n",
      "        0.9969, 1.0003, 0.9995, 0.9994, 0.9999, 1.0005, 0.9995, 1.0008, 1.0019,\n",
      "        1.0037, 1.0001, 1.0000, 0.9964, 0.9904, 0.9937, 0.9990, 1.0005, 1.0011,\n",
      "        0.9993, 0.9997, 0.9997, 0.9998, 1.0000, 1.0002, 0.9991, 0.9999, 0.9988,\n",
      "        1.0006, 0.9999, 0.9995, 1.0003, 0.9970, 0.9997, 0.9948, 0.9987, 0.9980,\n",
      "        0.9938, 1.0010, 1.0011, 0.9989, 0.9969, 1.0000, 0.9998, 0.9998, 0.9999,\n",
      "        0.9976, 0.9942, 0.9990, 0.9967, 0.9974, 1.0000, 0.9993, 0.9990, 0.9983,\n",
      "        1.0001, 0.9994, 0.9950, 1.0010, 0.9998, 0.9960, 1.0007, 0.9996, 1.0006,\n",
      "        0.9969, 0.9930, 1.0020, 1.0012, 0.9944, 0.9972, 1.0014, 1.0024, 0.9992,\n",
      "        0.9958, 0.9998, 1.0001], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9995, 0.9999, 1.0010, 1.0003, 0.9991, 1.0007, 1.0002, 0.9997, 1.0000,\n",
      "        0.9969, 0.9978, 1.0002, 0.9966, 1.0012, 1.0001, 0.9959, 0.9984, 0.9933,\n",
      "        0.9990, 0.9999, 0.9999, 1.0005, 0.9995, 1.0028, 0.9984, 0.9994, 0.9992,\n",
      "        0.9923, 0.9973, 0.9986, 0.9982, 0.9991, 0.9992, 1.0007, 0.9997, 0.9978,\n",
      "        1.0010, 1.0031, 0.9948, 0.9981, 0.9937, 0.9998, 0.9932, 0.9985, 1.0002,\n",
      "        1.0009, 1.0015, 0.9995, 0.9987, 0.9970, 1.0019, 1.0006, 1.0000, 0.9997,\n",
      "        0.9991, 0.9984, 1.0030, 1.0000, 0.9913, 0.9996, 1.0004, 1.0011, 0.9971,\n",
      "        1.0004, 1.0006, 1.0032, 0.9971, 0.9930, 0.9923, 0.9999, 0.9956, 0.9966,\n",
      "        0.9971, 1.0020, 0.9988, 1.0007, 0.9982, 0.9964, 0.9937, 0.9997, 0.9975,\n",
      "        0.9976, 0.9989, 0.9991, 0.9988, 0.9988, 0.9939, 1.0000, 1.0003, 0.9971,\n",
      "        0.9991, 0.9972, 0.9974, 0.9988, 0.9983, 0.9996, 1.0005, 1.0004, 0.9996,\n",
      "        0.9990, 1.0013, 1.0009, 0.9999, 1.0001, 0.9978, 0.9989, 0.9952, 0.9997,\n",
      "        0.9998, 0.9934, 0.9996, 0.9997, 0.9966, 0.9988, 0.9997, 1.0036, 1.0019,\n",
      "        1.0003, 1.0001, 1.0002, 1.0002, 1.0000, 0.9977, 0.9971, 0.9982, 1.0002,\n",
      "        1.0004, 0.9995, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9998, 1.0000, 0.9997, 0.9986, 0.9982, 0.9992, 0.9980, 0.9953, 0.9994,\n",
      "        0.9984, 0.9989, 0.9996, 0.9989, 0.9970, 0.9973, 1.0018, 0.9990, 0.9982,\n",
      "        1.0002, 1.0028, 1.0000, 1.0006, 1.0002, 0.9958, 0.9902, 0.9911, 0.9999,\n",
      "        0.9995, 0.9903, 0.9978, 0.9982, 1.0000, 0.9977, 0.9996, 0.9931, 0.9928,\n",
      "        1.0008, 0.9942, 1.0008, 0.9980, 0.9996, 0.9990, 0.9969, 0.9998, 0.9996,\n",
      "        1.0018, 0.9994, 0.9983, 0.9982, 0.9954, 0.9987, 0.9939, 0.9996, 0.9988,\n",
      "        1.0001, 0.9990, 0.9998, 1.0002, 0.9992, 0.9993, 0.9995, 0.9941, 0.9999,\n",
      "        0.9968, 0.9986, 0.9994, 0.9933, 0.9940, 0.9971, 0.9978, 0.9965, 0.9976,\n",
      "        1.0003, 0.9999, 1.0001, 0.9998, 0.9991, 0.9997, 1.0003, 1.0055, 1.0017,\n",
      "        1.0007, 0.9995, 0.9985, 1.0012, 0.9976, 0.9985, 0.9996, 0.9994, 0.9994,\n",
      "        0.9987, 0.9994, 0.9998, 1.0002, 0.9914, 0.9994, 0.9994, 0.9945, 0.9962,\n",
      "        0.9992, 0.9998, 0.9979, 1.0023, 0.9919, 1.0014, 0.9971, 0.9878, 1.0004,\n",
      "        0.9921, 0.9994, 0.9960, 1.0001, 0.9992, 1.0012, 0.9982, 0.9952, 1.0003,\n",
      "        0.9986, 1.0002, 1.0004, 1.0043, 0.9922, 0.9987, 1.0003, 0.9982, 0.9942,\n",
      "        0.9975, 0.9997, 0.9998], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9942, 0.9973, 0.9945, 1.0015, 0.9999, 0.9937, 1.0000, 1.0000, 0.9971,\n",
      "        0.9934, 0.9995, 1.0005, 0.9940, 0.9970, 0.9997, 0.9990, 0.9986, 0.9999,\n",
      "        1.0002, 1.0003, 1.0005, 1.0012, 1.0006, 0.9962, 0.9974, 0.9959, 0.9983,\n",
      "        0.9965, 0.9850, 1.0001, 0.9994, 1.0031, 1.0015, 0.9963, 0.9994, 0.9908,\n",
      "        0.9975, 0.9992, 0.9985, 1.0005, 0.9989, 0.9953, 1.0014, 1.0008, 0.9991,\n",
      "        0.9995, 1.0022, 1.0000, 0.9996, 0.9999, 1.0000, 0.9946, 0.9983, 1.0001,\n",
      "        0.9977, 1.0004, 0.9959, 1.0032, 1.0016, 1.0004, 0.9970, 0.9948, 0.9977,\n",
      "        0.9968, 1.0014, 1.0021, 0.9968, 0.9964, 0.9967, 0.9955, 0.9897, 0.9972,\n",
      "        1.0005, 0.9971, 0.9992, 0.9973, 1.0039, 0.9982, 1.0024, 1.0043, 0.9947,\n",
      "        1.0003, 0.9963, 1.0007, 1.0002, 0.9997, 0.9985, 1.0001, 0.9926, 0.9949,\n",
      "        1.0004, 1.0029, 1.0022, 0.9972, 0.9949, 0.9996, 0.9998, 0.9992, 0.9947,\n",
      "        0.9981, 0.9997, 0.9913, 0.9989, 0.9999, 0.9994, 0.9961, 0.9998, 0.9981,\n",
      "        1.0010, 0.9949, 0.9996, 0.9961, 0.9985, 0.9994, 0.9981, 1.0011, 0.9987,\n",
      "        1.0003, 0.9897, 0.9942, 0.9982, 1.0003, 0.9943, 0.9951, 0.9916, 0.9931,\n",
      "        0.9987, 0.9988, 1.0020], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0038, 0.9985, 1.0018, 0.9998, 1.0003, 0.9973, 0.9966, 0.9991, 0.9981,\n",
      "        0.9992, 1.0011, 0.9998, 0.9911, 0.9911, 0.9854, 0.9997, 0.9998, 0.9937,\n",
      "        0.9999, 0.9994, 1.0009, 1.0025, 0.9999, 1.0023, 0.9985, 0.9965, 1.0022,\n",
      "        0.9921, 0.9951, 0.9808, 0.9952, 0.9984, 0.9995, 1.0001, 0.9988, 0.9971,\n",
      "        0.9980, 0.9924, 0.9994, 1.0061, 0.9968, 0.9997, 0.9970, 0.9960, 1.0005,\n",
      "        1.0001, 0.9994, 0.9999, 0.9979, 0.9967, 0.9965, 0.9984, 0.9842, 0.9995,\n",
      "        0.9976, 0.9991, 0.9906, 0.9989, 0.9977, 0.9973, 0.9997, 0.9998, 0.9988,\n",
      "        0.9999, 1.0007, 0.9996, 0.9996, 0.9976, 0.9938, 0.9922, 0.9911, 0.9896,\n",
      "        0.9974, 0.9967, 1.0011, 0.9994, 0.9992, 0.9954, 1.0023, 0.9946, 0.9997,\n",
      "        0.9967, 0.9768, 0.9941, 0.9993, 0.9989, 0.9993, 0.9972, 0.9935, 0.9990,\n",
      "        0.9996, 1.0000, 0.9991, 0.9994, 0.9955, 0.9994, 0.9991, 1.0015, 1.0027,\n",
      "        0.9994, 0.9990, 0.9990, 0.9965, 1.0002, 0.9999, 0.9955, 0.9994, 0.9984,\n",
      "        0.9924, 1.0029, 1.0015, 0.9996, 1.0009, 0.9984, 1.0000, 0.9989, 1.0013,\n",
      "        0.9963, 1.0019, 1.0001, 1.0008, 0.9999, 0.9991, 1.0007, 0.9987, 0.9916,\n",
      "        0.9933, 1.0001, 0.9956], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9958, 0.9945, 0.9967, 0.9980, 0.9958, 0.9944, 0.9991, 0.9987, 0.9977,\n",
      "        1.0001, 1.0019, 0.9994, 1.0013, 0.9967, 0.9957, 0.9983, 0.9996, 0.9996,\n",
      "        1.0012, 0.9888, 0.9978, 0.9952, 0.9981, 0.9900, 0.9943, 0.9811, 0.9946,\n",
      "        1.0013, 1.0001, 0.9974, 0.9999, 0.9922, 1.0025, 1.0029, 1.0021, 0.9999,\n",
      "        0.9957, 0.9993, 0.9948, 0.9969, 0.9815, 0.9980, 0.9982, 0.9907, 0.9943,\n",
      "        0.9990, 1.0005, 1.0029, 0.9898, 0.9987, 0.9991, 1.0012, 1.0093, 0.9987,\n",
      "        0.9992, 1.0017, 0.9950, 0.9962, 1.0001, 1.0013, 0.9977, 0.9873, 1.0011,\n",
      "        0.9987, 0.9980, 0.9945, 0.9841, 0.9893, 0.9866, 0.9983, 0.9938, 0.9886],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9889, 0.9968, 0.9843, 1.0041, 0.9981, 0.9901, 0.9989, 0.9931, 0.9988,\n",
      "        0.9928, 1.0076, 0.9998, 0.9912, 0.9976, 0.9991, 0.9959, 0.9971, 1.0031,\n",
      "        0.9957, 1.0019, 0.9933, 1.0006, 0.9892, 0.9943, 0.9703, 0.9924, 0.9703,\n",
      "        1.0005, 1.0038, 1.0011, 1.0003, 0.9663, 0.9976, 1.0015, 0.9976, 1.0005,\n",
      "        1.0044, 0.9945, 0.9862, 0.9970, 0.9974, 0.9950, 0.9998, 1.0009, 0.9995,\n",
      "        1.0003, 1.0004, 0.9935, 0.9871, 0.9974, 0.9982, 0.9942, 0.9976, 0.9959,\n",
      "        0.9999, 1.0004, 0.9906, 1.0014, 0.9987, 1.0014, 0.9956, 0.9933, 0.9960,\n",
      "        1.0011, 1.0010, 0.9942, 1.0009, 0.9986, 0.9815, 0.9926, 0.9750, 1.0006],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9859, 0.9880, 0.9971, 1.0018, 0.9870, 0.9997, 0.9949, 0.9997, 0.9966,\n",
      "        1.0013, 0.9887, 0.9967, 1.0006, 1.0021, 1.0046, 0.9815, 0.9814, 0.9911,\n",
      "        1.0013, 1.0029, 1.0049, 1.0030, 1.0001, 0.9995, 0.9928, 0.9799, 0.9967,\n",
      "        0.9991, 1.0014, 0.9991, 0.9890, 0.9994, 0.9998, 0.9983, 1.0011, 0.9943,\n",
      "        0.9980, 1.0006, 0.9958, 1.0042, 1.0027, 0.9949, 0.9997, 0.9980, 0.9967,\n",
      "        0.9946, 0.9782, 0.9945, 0.9923, 1.0000, 0.9908, 0.9901, 1.0027, 0.9910,\n",
      "        0.9966, 0.9969, 1.0017, 0.9909, 1.0009, 0.9939, 1.0018, 0.9910, 1.0050,\n",
      "        1.0019, 1.0060, 1.0065, 0.9989, 0.9966, 0.9872, 0.9994, 1.0087, 0.9744],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9766, 0.9977, 0.9785, 0.9936, 0.9950, 0.9956, 1.0053, 1.0005, 0.9933,\n",
      "        0.9985, 1.0006, 0.9988, 0.9953, 0.9967, 0.9959, 1.0049, 1.0004, 0.9863,\n",
      "        0.9983, 0.9937, 1.0001, 0.9959, 0.9927, 0.9968, 0.9788, 0.9788, 0.9940,\n",
      "        0.9984, 1.0023, 0.9959, 0.9700, 1.0052, 1.0008, 0.9951, 1.0019, 0.9988,\n",
      "        1.0023, 1.0033, 0.9957, 1.0000, 0.9971, 0.9972, 0.9918, 1.0013, 0.9744,\n",
      "        0.9987, 0.9992, 1.0002, 0.9895, 1.0113, 1.0098, 0.9993, 0.9855, 0.9984,\n",
      "        1.0012, 0.9818, 0.9942, 1.0015, 1.0037, 0.9750, 0.9974, 0.9997, 0.9632,\n",
      "        1.0007, 0.9947, 0.9997, 1.0041, 1.0052, 0.9737, 0.9900, 0.9993, 1.0005],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0120, 0.9995, 1.0124, 0.9971, 1.0017, 0.9755, 1.0057, 0.9935, 0.9992,\n",
      "        0.9891, 0.9950, 0.9933, 0.9989, 0.9989, 0.9996, 0.9934, 0.9979, 1.0002,\n",
      "        0.9901, 0.9988, 0.9803, 0.9894, 0.9896, 0.9932, 0.9858, 0.9988, 0.9756,\n",
      "        0.9935, 0.9997, 0.9965, 0.9849, 0.9972, 0.9974, 0.9999, 0.9873, 1.0053,\n",
      "        0.9981, 0.9958, 0.9996, 0.9996, 0.9981, 0.9989, 1.0075, 0.9975, 1.0197,\n",
      "        0.9865, 1.0017, 0.9944, 0.9951, 1.0008, 0.9985, 0.9940, 0.9965, 0.9954,\n",
      "        0.9886, 1.0054, 1.0006, 0.9878, 0.9978, 0.9985, 0.9858, 1.0037, 0.9827,\n",
      "        0.9981, 1.0004, 0.9909, 0.9836, 0.9961, 1.0051, 1.0038, 1.0030, 1.0015],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9849, 0.9984, 0.9986, 0.9962, 1.0001, 0.9944, 0.9988, 1.0097, 0.9935,\n",
      "        0.9998, 1.0011, 0.9973, 1.0002, 0.9975, 0.9955, 1.0004, 0.9991, 0.9926,\n",
      "        0.9992, 0.9997, 0.9699, 1.0098, 0.9978, 0.9924, 0.9815, 0.9835, 0.9945,\n",
      "        0.9966, 1.0001, 0.9997, 0.9782, 0.9709, 0.9939, 0.9877, 1.0045, 0.9991,\n",
      "        1.0061, 0.9935, 1.0048, 0.9825, 0.9978, 0.9898, 0.9978, 0.9951, 0.9953,\n",
      "        0.9996, 1.0008, 1.0000, 0.9967, 0.9905, 1.0005, 1.0016, 1.0030, 1.0034,\n",
      "        0.9983, 1.0011, 0.9906, 1.0002, 1.0005, 0.9963, 1.0086, 0.9816, 0.9990,\n",
      "        1.0003, 0.9985, 1.0007, 0.9961, 0.9745, 1.0036, 1.0071, 0.9933, 0.9905],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9457, 1.0065, 0.9998, 0.9775, 0.9559, 0.9987, 0.9806, 1.0066, 1.0107,\n",
      "        1.0000, 0.9959, 1.0027, 0.9838, 1.0022, 1.0049, 0.9852, 0.9941, 1.0026,\n",
      "        1.0005, 0.9985, 0.9970, 1.0053, 0.9723, 0.9984, 0.9966, 0.9654, 0.9858,\n",
      "        1.0036, 0.9938, 0.9777, 0.9646, 0.9886, 1.0003, 0.9624, 0.9942, 0.9767,\n",
      "        1.0015, 0.9494, 0.9927, 0.9857, 0.9657, 0.8594, 0.9968, 0.9974, 1.0010,\n",
      "        0.9846, 1.0043, 0.9977, 1.0001, 0.9963, 0.9906, 0.9985, 0.9989, 0.9773,\n",
      "        0.9809, 0.9977, 0.9849, 0.9935, 1.0042, 0.9974, 1.0106, 0.9965, 1.0003,\n",
      "        0.9981, 1.0036, 1.0001, 0.9898, 0.9907, 0.9901, 1.0012, 0.9871, 0.9909,\n",
      "        0.9781, 0.9942, 0.9859, 0.9960, 1.0067, 0.9964, 0.9826, 0.9782, 0.9896,\n",
      "        0.9790, 0.9694, 1.0111, 0.9907, 0.9928, 0.9824, 0.9931, 0.9941, 0.9875,\n",
      "        0.9975, 0.9991, 1.0015, 0.9746, 0.9873, 0.9918, 0.9958, 0.9830, 1.0082,\n",
      "        1.0003, 0.9936, 1.0023, 0.9995, 1.0081, 0.9867, 0.9928, 1.0031, 0.9991,\n",
      "        0.9869, 0.9918, 0.9951, 0.9958, 0.9965, 0.9643, 0.9983, 0.9946, 0.9991,\n",
      "        0.9987, 0.9977, 1.0006, 0.9894, 0.9928, 0.9926, 0.9815, 0.9986, 0.9977,\n",
      "        0.9969, 0.9827, 0.9995, 0.9888, 1.0086, 0.9899, 0.9967, 1.0051, 1.0013,\n",
      "        1.0002, 0.9957, 0.9899, 0.9983, 0.9915, 0.9991, 1.0087, 1.0271, 0.9588],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9945, 1.0069, 1.0074, 0.9787, 1.0021, 0.9869, 0.9915, 0.9837, 0.9921,\n",
      "        0.9795, 1.0041, 0.9768, 0.9403, 0.9905, 0.9849, 0.9548, 0.9720, 0.9816,\n",
      "        1.0063, 0.9953, 1.0067, 0.9988, 0.9969, 0.9990, 0.9797, 0.9963, 0.9792,\n",
      "        0.9986, 1.0009, 0.9763, 1.0015, 0.9831, 0.9757, 1.0085, 0.9915, 1.0155,\n",
      "        0.9776, 0.9805, 1.0051, 0.9813, 0.9680, 0.9630, 0.9965, 0.9907, 1.0005,\n",
      "        0.9970, 0.9880, 0.9997, 0.9966, 0.9927, 0.9688, 1.0015, 0.9994, 1.0061,\n",
      "        0.9868, 1.0015, 1.0046, 1.0011, 0.9974, 0.9961, 0.9806, 1.0012, 0.9962,\n",
      "        1.0028, 1.0082, 0.9978, 0.9917, 0.9949, 0.9843, 1.0045, 1.0045, 0.9965,\n",
      "        0.9680, 0.9574, 0.9258, 0.9725, 0.9773, 0.9715, 1.0027, 0.9372, 0.9654,\n",
      "        1.0083, 0.9964, 0.9924, 0.9793, 0.9780, 1.0023, 0.9951, 1.0066, 0.9799,\n",
      "        0.9965, 0.9839, 0.9998, 0.9749, 0.9495, 0.9857, 0.9775, 0.9881, 0.9956,\n",
      "        0.9906, 0.9971, 0.9964, 1.0016, 0.9898, 1.0063, 0.9911, 0.9914, 1.0023,\n",
      "        0.9826, 0.9885, 0.9872, 1.0012, 1.0008, 0.9896, 1.0022, 1.0068, 0.9979,\n",
      "        0.9940, 0.9981, 0.9931, 0.9835, 1.0042, 1.0021, 0.9973, 0.9981, 1.0000,\n",
      "        0.9964, 1.0173, 0.9892, 0.9971, 1.0051, 0.9998, 0.9969, 0.9962, 0.9780,\n",
      "        0.9988, 1.0015, 0.9927, 0.9996, 0.9855, 0.9950, 0.9978, 0.9970, 0.9910],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9632, 1.0136, 1.0104, 1.0004, 0.9928, 0.9968, 1.0008, 0.9736, 0.9813,\n",
      "        0.9892, 0.9834, 0.9800, 0.9822, 1.0044, 1.0062, 0.9877, 0.9975, 0.9970,\n",
      "        0.9876, 0.9917, 0.9953, 1.0086, 0.9964, 0.9773, 0.9823, 0.9855, 0.9757,\n",
      "        1.0082, 0.9883, 1.0000, 0.9112, 0.9524, 0.9861, 0.9952, 0.9559, 0.9835,\n",
      "        0.9891, 0.9913, 0.9651, 0.9485, 0.9281, 1.0006, 0.9796, 1.0002, 0.9875,\n",
      "        1.0095, 1.0057, 0.9987, 0.9943, 0.9849, 0.9910, 0.9966, 0.9858, 0.9878,\n",
      "        0.9659, 0.9959, 0.9668, 0.9863, 0.9917, 0.9990, 0.9975, 1.0087, 0.9978,\n",
      "        0.9913, 1.0004, 0.9900, 0.9985, 0.9998, 0.9950, 1.0031, 1.0089, 0.9805,\n",
      "        0.9996, 0.9911, 0.9807, 0.9824, 0.9851, 0.9983, 1.0001, 0.9917, 0.9761,\n",
      "        0.9479, 1.0062, 1.0055, 0.9836, 1.0031, 1.0096, 0.9961, 1.0160, 0.9875,\n",
      "        0.9948, 0.9972, 1.0007, 0.9714, 0.9666, 0.9838, 0.9950, 0.9731, 0.9938,\n",
      "        1.0012, 1.0066, 0.9979, 0.9843, 1.0070, 1.0060, 0.9942, 0.9877, 0.9780,\n",
      "        1.0000, 0.9990, 0.9939, 1.0091, 1.0017, 0.9795, 0.9760, 1.0002, 0.9957,\n",
      "        1.0018, 1.0008, 0.9992, 0.9927, 0.9919, 0.9859, 1.0006, 0.9965, 0.9728,\n",
      "        0.9916, 0.9811, 0.9921, 0.9968, 0.9727, 1.0186, 1.0040, 1.0114, 1.0030,\n",
      "        0.9939, 0.9964, 0.9400, 0.9887, 0.9993, 0.9863, 0.9871, 0.9778, 0.9924],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9944, 0.9953, 0.9938, 1.0037, 1.0187, 0.9872, 0.9967, 0.9981, 1.0004,\n",
      "        0.9672, 1.0031, 0.9963, 0.9934, 1.0025, 1.0007, 0.9703, 0.9647, 0.9745,\n",
      "        0.9976, 0.9997, 0.9845, 1.0070, 0.9905, 0.9877, 0.9925, 0.9973, 0.9595,\n",
      "        1.0137, 1.0078, 0.9316, 0.9566, 0.8864, 0.9959, 0.9872, 0.9937, 0.9883,\n",
      "        0.9690, 0.8651, 0.9325, 0.9556, 1.0027, 0.9510, 0.9645, 0.9768, 0.9707,\n",
      "        0.9979, 0.9994, 1.0009, 0.9857, 0.9963, 0.9929, 0.9995, 1.0089, 1.0016,\n",
      "        0.9570, 0.9775, 1.0029, 0.9915, 0.9872, 0.9939, 0.9689, 1.0256, 1.0012,\n",
      "        0.9905, 0.9950, 1.0047, 0.9811, 1.0025, 0.9965, 0.9940, 0.9753, 1.0024,\n",
      "        0.9833, 1.0102, 0.9850, 1.0023, 0.9979, 0.9744, 0.9926, 0.9887, 0.9934,\n",
      "        1.0447, 1.0007, 0.9627, 0.9991, 0.9940, 0.9837, 0.9971, 0.9967, 0.9942,\n",
      "        0.9751, 0.9765, 0.9911, 0.9971, 1.0012, 0.9913, 1.0053, 0.9413, 0.9910,\n",
      "        0.9537, 0.9890, 1.0033, 0.9521, 1.0025, 0.9929, 0.9858, 0.9975, 0.9995,\n",
      "        1.0079, 0.9993, 1.0113, 0.9716, 1.0006, 1.0046, 0.9946, 0.9941, 0.9734,\n",
      "        0.9963, 0.9184, 0.9997, 0.9721, 0.9642, 0.9544, 0.9943, 1.0018, 0.9955,\n",
      "        0.9980, 0.9716, 0.9988, 0.9977, 1.0122, 0.9609, 1.0109, 0.9798, 0.9966,\n",
      "        0.9545, 0.9989, 1.0051, 0.9955, 0.9961, 0.9960, 0.9749, 0.9633, 0.9885],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9631, 0.9957, 0.9960, 0.9639, 0.9361, 0.9518, 0.9954, 0.9904, 1.0012,\n",
      "        1.0102, 0.9682, 0.9896, 0.9936, 0.9654, 0.9962, 0.9999, 1.0019, 0.9908,\n",
      "        0.9887, 0.9790, 1.0037, 0.9970, 0.9759, 0.9967, 0.9866, 0.9870, 0.9587,\n",
      "        0.9683, 0.9722, 0.9936, 1.0633, 1.0019, 1.0432, 0.9552, 1.0029, 1.0017,\n",
      "        0.9847, 0.9521, 0.8727, 0.9984, 0.9892, 0.9118, 0.9961, 1.0031, 0.9931,\n",
      "        0.9909, 0.9948, 1.0023, 0.9762, 1.0139, 0.9776, 0.9959, 1.0113, 1.0043,\n",
      "        0.9933, 0.9979, 1.0005, 1.0046, 1.0048, 1.0044, 1.0046, 0.9724, 0.9875,\n",
      "        1.0048, 1.0047, 0.9874, 1.0105, 0.9865, 1.0169, 0.9961, 1.0008, 0.9914,\n",
      "        0.9948, 0.9933, 0.9911, 0.9876, 0.9977, 0.9274, 0.9726, 0.9389, 0.9451,\n",
      "        0.9340, 0.9742, 0.9806, 0.9683, 0.9660, 0.9753, 0.9850, 0.9883, 1.0010,\n",
      "        1.0144, 0.9961, 0.9866, 0.9835, 0.9143, 1.0003, 0.9836, 1.0056, 0.9943,\n",
      "        0.9860, 0.9971, 0.9844, 1.0032, 0.9955, 0.9963, 0.9992, 0.9763, 1.0073,\n",
      "        0.9982, 0.9667, 0.9656, 0.9920, 0.9611, 0.9735, 1.0073, 1.0206, 0.9706,\n",
      "        0.9587, 1.0006, 1.0045, 0.9970, 1.0054, 0.9899, 0.9943, 0.9986, 0.9956,\n",
      "        0.9920, 0.9993, 0.9996, 0.9927, 0.9912, 1.0015, 0.9903, 1.0054, 0.9935,\n",
      "        1.0250, 0.9994, 1.0169, 1.0022, 0.9972, 1.0014, 0.9954, 1.0213, 1.0153],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9832, 1.0032, 0.9998, 0.9452, 0.9589, 0.9674, 0.9550, 0.9947, 0.9994,\n",
      "        0.9739, 0.9269, 1.0119, 0.9571, 1.0324, 0.9967, 0.9529, 0.9794, 0.9879,\n",
      "        0.9463, 1.0016, 0.9586, 0.9859, 1.0059, 0.9732, 1.0006, 0.9829, 0.9651,\n",
      "        0.9927, 0.9799, 0.9934, 0.8750, 1.0076, 0.9993, 0.9823, 1.0464, 1.0015,\n",
      "        1.0025, 1.0036, 0.9665, 0.9818, 0.9424, 0.9294, 0.9851, 0.9656, 0.9946,\n",
      "        0.9916, 0.9820, 0.9728, 0.9703, 0.9636, 0.9728, 0.9750, 1.0031, 1.0265,\n",
      "        0.9598, 0.9466, 0.9628, 1.0082, 1.0003, 1.0075, 0.9948, 0.9601, 0.9792,\n",
      "        0.9839, 1.0388, 1.0484, 0.9929, 0.9805, 0.9978, 1.0050, 0.9833, 1.0050,\n",
      "        1.0186, 1.0040, 0.9959, 1.0387, 0.9590, 1.0031, 1.0010, 0.9891, 0.9396,\n",
      "        0.9874, 0.9742, 1.0112, 1.0009, 0.9223, 1.0188, 0.9954, 1.0070, 0.9803,\n",
      "        0.9858, 0.9720, 0.9980, 0.9953, 0.9916, 0.8341, 0.9937, 0.9761, 0.9963,\n",
      "        0.8815, 0.9738, 0.9917, 0.9984, 0.9947, 0.9884, 0.9952, 0.9811, 0.9943,\n",
      "        0.9644, 0.9926, 1.0275, 0.9976, 1.0098, 0.9718, 0.9947, 0.9759, 1.0116,\n",
      "        0.9968, 0.9907, 0.9720, 1.0048, 0.9553, 0.9976, 0.9881, 0.9721, 1.0035,\n",
      "        0.9883, 0.9744, 0.9698, 0.9827, 0.9712, 0.9802, 1.0047, 0.9856, 0.9805,\n",
      "        1.0297, 1.0126, 0.9734, 0.9936, 0.9460, 0.9924, 0.8094, 0.8918, 0.9840],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0371, 0.9672, 0.9922, 0.9814, 1.0036, 0.9903, 1.0007, 1.0142, 1.0085,\n",
      "        0.9872, 0.9794, 1.0036, 1.0211, 1.0230, 0.9868, 0.9812, 0.9777, 0.8476,\n",
      "        1.0004, 1.0189, 1.0468, 0.9506, 0.9687, 0.9751, 0.9779, 0.9736, 0.9864,\n",
      "        0.9724, 0.9731, 0.9858, 0.9961, 0.9974, 0.9785, 0.9859, 0.9927, 0.9504,\n",
      "        0.9426, 1.0053, 1.0065, 0.9621, 0.8273, 0.9586, 0.9856, 0.9832, 0.9941,\n",
      "        0.9650, 0.9854, 0.9307, 0.9788, 0.9256, 0.9873, 0.9648, 0.9828, 0.9514,\n",
      "        0.9443, 0.9902, 0.9926, 0.9572, 0.9257, 0.9931, 0.8107, 0.9633, 0.8660,\n",
      "        1.0002, 1.0053, 1.0055], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9802, 0.9430, 0.9588, 1.0091, 1.0176, 0.9964, 1.0590, 0.9568, 1.0424,\n",
      "        0.9866, 0.9997, 0.9788, 0.9933, 0.7899, 1.0077, 0.9915, 1.0331, 1.0180,\n",
      "        0.9810, 0.9749, 0.9832, 1.0148, 0.9675, 1.0066, 0.9488, 0.9515, 0.9409,\n",
      "        0.9778, 0.9305, 0.8158, 0.9373, 0.9929, 0.9785, 1.0216, 0.9944, 1.0076,\n",
      "        0.9944, 0.9574, 1.0059, 0.9078, 0.7128, 1.0154, 1.0198, 0.9789, 0.9704,\n",
      "        0.9881, 1.0169, 1.0272, 0.9703, 1.0059, 0.9781, 0.9739, 1.0382, 1.0667,\n",
      "        0.8732, 1.0848, 0.9996, 1.0004, 0.8707, 0.9606, 0.8463, 0.9102, 0.5969,\n",
      "        0.9966, 0.9727, 0.9681], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0235, 0.9986, 0.7982, 0.9652, 0.9970, 0.9439, 0.8411, 1.0939, 1.0405,\n",
      "        0.9762, 0.9978, 1.0466, 0.9783, 0.9975, 0.9466, 0.9825, 0.8568, 0.7951,\n",
      "        0.8354, 0.9417, 0.9741, 0.9253, 0.9788, 1.0016, 0.7394, 0.9984, 0.8258,\n",
      "        0.9117, 1.0215, 1.0195, 0.9803, 1.0020, 1.0115, 1.0102, 0.8199, 0.8609,\n",
      "        0.9803, 0.9613, 1.0219, 1.1152, 0.8834, 1.0034, 0.9716, 0.9287, 0.9373,\n",
      "        0.9219, 1.0608, 1.0285, 0.9417, 0.9898, 1.0122, 0.8940, 0.9574, 0.9837,\n",
      "        0.8577, 0.9134, 0.9683, 0.9891, 0.9623, 0.9593, 0.7949, 0.7397, 0.6540,\n",
      "        0.9862, 1.0283, 1.0133], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9872, 0.9990, 1.0015, 0.9467, 0.9052, 0.7513, 0.9993, 1.0130, 1.0118,\n",
      "        1.0623, 0.9892, 1.0245, 1.0096, 1.0632, 1.0037, 0.7790, 0.5490, 0.7430,\n",
      "        0.8987, 0.9382, 1.0149, 0.7576, 0.8974, 0.9815, 0.9738, 0.9825, 1.0164,\n",
      "        1.0030, 0.9602, 1.0444, 1.0161, 0.9909, 1.0011, 0.9895, 0.9826, 0.9594,\n",
      "        1.0247, 0.9659, 0.9045, 0.9719, 0.8582, 0.8164, 0.9670, 1.0145, 0.9348,\n",
      "        1.0023, 1.0063, 1.0708, 0.8789, 0.8365, 0.9766, 0.9090, 0.7616, 0.9369,\n",
      "        0.9030, 1.0268, 1.0361, 0.9194, 1.0176, 0.9873, 1.0656, 0.7196, 1.1122,\n",
      "        0.9508, 0.9827, 0.9600], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0389, 0.9226, 1.0604, 0.9434, 1.0948, 0.4344, 1.0095, 1.1029, 0.7565,\n",
      "        0.8516, 0.7366, 0.9127, 0.7015, 0.6036, 1.0150, 0.8798, 1.0263, 0.0347,\n",
      "        0.8950, 0.7782, 0.9268, 0.9913, 0.8679, 0.9770, 0.7128, 0.8741, 0.9134,\n",
      "        0.7186, 0.2319, 0.6493, 0.9949, 0.9946, 0.9908, 0.5604, 0.2775, 0.8854,\n",
      "        0.9616, 0.9267, 0.8089, 0.4527, 1.0779, 0.6578, 0.4271, 1.0721, 1.2115,\n",
      "        0.5978, 1.1690, 0.4710, 0.8038, 0.6021, 0.9607, 1.1014, 0.6869, 0.8436,\n",
      "        0.9026, 0.2923, 1.0123, 1.0060, 0.5737, 0.7992, 0.9757, 0.5020, 0.0711,\n",
      "        1.0049, 1.0103, 1.0190], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9976, 0.9157, 0.1342, 0.0940, 0.8470, 0.2537, 0.8218, 0.6664, 0.8741,\n",
      "        1.2358, 0.2517, 0.9772, 0.5043, 1.1954, 0.9365, 0.6928, 0.3678, 0.5834,\n",
      "        1.3583, 0.9260, 1.0684, 0.9372, 0.9736, 0.4810, 1.0017, 0.9671, 1.1311,\n",
      "        0.7571, 0.9545, 0.7936, 0.5056, 1.0040, 0.7317, 0.5788, 0.6771, 1.0206,\n",
      "        1.3464, 0.2765, 1.1597, 1.0341, 0.9275, 0.7176, 1.1215, 0.8880, 1.4069,\n",
      "        0.0577, 0.9736, 0.5247, 0.5748, 1.0314, 1.2551, 0.5476, 0.8440, 0.3155,\n",
      "        0.8390, 0.9548, 0.6929, 0.2758, 0.9404, 0.6683, 0.5547, 0.6855, 0.8923,\n",
      "        0.9553, 0.7765, 0.6280], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.1399, 0.7366, 1.0168, 0.9074, 0.8384, 1.0838, 1.0965, 0.9165, 0.9298,\n",
      "        1.2143, 1.1481, 1.0319, 0.5455, 0.6899, 0.4350, 0.8236, 0.1636, 0.1459,\n",
      "        0.1304, 0.1943, 0.0234, 0.5451, 0.9805, 2.3976, 0.3988, 0.9949, 0.8745,\n",
      "        0.5140, 0.6999, 1.1260, 1.2476, 0.8453, 0.8986, 0.9310, 0.7674, 0.8537,\n",
      "        0.6908, 2.2101, 1.4740, 0.6763, 0.3741, 0.2373, 0.4961, 0.8209, 0.5073,\n",
      "        0.2679, 0.8500, 0.8306], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([5.9035e-01, 3.4433e-01, 3.7329e-01, 5.6552e-01, 7.6846e-01, 1.3010e+00,\n",
      "        3.3255e-01, 1.0803e+00, 5.4065e-01, 6.1185e-01, 5.3467e-01, 1.3932e+00,\n",
      "        3.9676e-02, 4.0773e-01, 9.3576e-01, 2.6721e+00, 8.5904e-01, 1.0429e+00,\n",
      "        1.5081e+00, 6.4939e-01, 2.0015e-03, 1.2682e-01, 5.6094e-01, 3.0106e-01,\n",
      "        2.4656e+00, 3.1632e+00, 5.7988e-01, 2.3771e+00, 1.3026e+00, 5.8596e-01,\n",
      "        4.4188e-02, 1.4947e-01, 3.0312e+00, 3.6390e-02, 2.9218e-01, 2.8964e-01,\n",
      "        3.7484e-01, 3.3789e-01, 8.0760e-01, 3.1663e-01, 5.3018e-01, 3.7190e-01,\n",
      "        2.4830e-01, 6.3168e+00, 9.5040e-01, 4.0215e+00, 1.8157e+00, 2.9487e+00],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([9.8462e+00, 3.6420e+00, 3.9923e-01, 3.0604e+00, 2.9545e+00, 4.7078e-01,\n",
      "        3.0385e+00, 1.5811e+00, 1.1794e+00, 2.9635e-01, 2.9316e-01, 3.0808e-02,\n",
      "        8.7457e-01, 5.9106e-01, 5.7709e-01, 3.7641e+00, 4.8488e+00, 1.8142e+01,\n",
      "        5.2242e+00, 2.2934e+01, 1.3023e+00, 1.4399e+00, 5.6311e+00, 9.5554e-01,\n",
      "        1.7229e-01, 1.6011e+00, 2.4087e-03, 2.3421e+00, 6.0250e-01, 9.7337e-01,\n",
      "        7.1862e-01, 3.6730e+00, 4.9549e+00, 5.8478e-01, 1.7739e+00, 9.6271e-01,\n",
      "        2.1754e+00, 1.7112e+00, 1.2332e+00, 2.3354e+00, 1.4844e+00, 2.5970e+00,\n",
      "        6.0308e+00, 1.7565e+01, 4.8302e-01, 2.7810e-01, 1.9210e+00],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.2631, 0.1371, 1.7503, 0.6327, 0.2472, 0.4949, 0.7964, 0.7762, 1.2104,\n",
      "        0.9056, 1.0583, 0.7566, 0.3757, 0.4513, 0.1352, 0.2600, 0.3384, 0.8180,\n",
      "        1.0521, 0.2573, 0.3168, 0.1140, 0.6829, 0.1273, 1.0736, 0.9678, 0.7187,\n",
      "        0.1392, 0.7260, 0.5843, 1.1540, 1.0996, 1.0656, 0.3603, 0.3584, 0.5240,\n",
      "        0.6191, 0.7845, 1.6907, 0.5846, 0.3953, 0.7839, 0.0643, 0.6481, 1.4915,\n",
      "        1.8352, 0.7711], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.8526, 0.3339, 0.7894, 1.0435, 0.4389, 0.9374, 0.8928, 0.9023, 0.8039,\n",
      "        0.8949, 0.8603, 0.9437, 0.6345, 0.5048, 0.8211, 0.7510, 0.7492, 0.7024,\n",
      "        0.4199, 0.7847, 0.2981, 0.1935, 0.3787, 1.0320, 0.7048, 0.9869, 0.8038,\n",
      "        0.8362, 0.8960, 0.8094, 1.0066, 0.1006, 0.4202, 0.8417, 0.6868, 0.4514,\n",
      "        0.5891, 0.6492, 0.3286, 1.0987, 1.0355, 0.8929, 0.7140, 1.0115, 0.9089,\n",
      "        0.9867, 0.9472, 0.8585], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0034, 0.9209, 0.3938, 0.4922, 0.7357, 1.0247, 0.8690, 0.9735, 0.9435,\n",
      "        0.7694, 0.9995, 0.9944, 0.9933, 0.9758, 0.8281, 0.6120, 0.9148, 0.7087,\n",
      "        0.9632, 1.0023, 0.8873, 0.9911, 0.9403, 1.0482, 0.8346, 1.0278, 0.9838,\n",
      "        0.9878, 0.9667, 0.9459, 0.9946, 0.8223, 0.9993, 0.4278, 0.2718, 0.9520,\n",
      "        0.8382, 0.6194, 0.9632, 0.0674, 0.7366, 0.0358, 0.0541, 0.9942, 0.0730,\n",
      "        0.8853, 1.0449, 1.0201], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.1021, 0.9766, 0.4919, 0.9816, 0.6826, 0.7403, 0.9861, 1.1651, 0.9583,\n",
      "        0.9889, 0.9508, 1.0238, 0.9744, 1.0819, 0.9970, 0.7560, 1.0330, 1.0312,\n",
      "        0.8806, 0.7640, 0.8476, 0.4320, 0.7638, 0.5167, 0.9808, 0.5971, 0.7097,\n",
      "        1.0287, 0.2233, 0.6339, 0.2525, 0.9902, 0.5689, 0.7978, 0.2098, 0.8088,\n",
      "        0.0276, 0.9805, 0.7773, 0.5937, 0.9377, 1.0971, 0.9383, 0.9804, 0.8459,\n",
      "        1.0077, 1.0271, 0.7322, 0.9825, 0.5750, 0.9784, 0.6498, 0.6745, 0.9559,\n",
      "        0.6417, 0.9976, 0.9668, 0.7484, 0.7130, 0.8700, 0.9139, 1.0159, 0.9749,\n",
      "        0.8415, 0.8409, 0.9685, 1.3736, 0.7843, 1.2666, 0.3394, 0.4417, 0.8685,\n",
      "        1.0147, 0.9944, 0.9205, 0.3541, 0.8361, 0.9911, 1.0761, 0.9455, 1.0412,\n",
      "        0.9098, 1.0626, 1.0412, 0.9525, 0.8246, 0.0129, 0.9784, 0.5721, 0.8582,\n",
      "        0.8477, 0.9263, 0.8259, 0.9712, 0.9891, 0.9569, 0.7782, 0.9831, 0.9255,\n",
      "        1.4929, 1.5890, 0.6970, 0.9614, 1.0576, 0.9005, 1.0692, 1.0701, 0.5824,\n",
      "        0.1168, 0.4210, 0.7151, 1.1229, 0.9408, 0.6408, 0.8691, 0.8410, 0.9091,\n",
      "        0.7452, 0.9905, 1.0274, 1.1831, 1.0488, 0.9240, 0.7504, 1.2475, 1.3743,\n",
      "        0.6800, 0.7548, 0.9692, 0.9248, 0.8728, 0.8762, 0.7493, 0.5477, 0.9987,\n",
      "        0.8452, 1.0000, 0.5914, 0.8151, 0.6604, 0.8544, 1.6860, 0.8245, 1.5370,\n",
      "        1.0049, 0.4294, 0.2930, 0.5412, 0.8493, 1.0221, 0.7794, 0.9434, 0.9415,\n",
      "        0.9808, 0.9612, 0.9679], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.1518, 0.1457, 0.7753, 0.6871, 0.4084, 0.2247, 0.3989, 0.8545, 1.4086,\n",
      "        1.0348, 0.8661, 0.9567, 1.1361, 1.1689, 1.0113, 1.1658, 1.1963, 0.6786,\n",
      "        1.0991, 0.6503, 0.5266, 0.3490, 0.2017, 0.3474, 0.9420, 0.9883, 0.9453,\n",
      "        0.1872, 0.5365, 0.3691, 0.9939, 0.7525, 0.0676, 0.7600, 0.7413, 0.7305,\n",
      "        0.8933, 0.6167, 1.0071, 0.6477, 1.2633, 1.1738, 1.0899, 0.9988, 1.0549,\n",
      "        0.9554, 1.0389, 1.0310, 1.2990, 1.1101, 0.0196, 0.4869, 0.8909, 0.7170,\n",
      "        0.6127, 1.3864, 1.3132, 0.9535, 0.7010, 0.7928, 0.8983, 0.4782, 1.1052,\n",
      "        0.6983, 1.1140, 0.6843, 1.0227, 0.9077, 1.0053, 0.8268, 0.7584, 0.9224,\n",
      "        0.1512, 1.0276, 0.7377, 1.2464, 1.0346, 0.4226, 0.9773, 0.9724, 0.9629,\n",
      "        1.0501, 0.9354, 1.1065, 0.3903, 0.4010, 0.8204, 0.4372, 0.7240, 0.9092,\n",
      "        0.8149, 0.9525, 0.6825, 1.0801, 0.6395, 1.1181, 1.2354, 1.2788, 0.8470,\n",
      "        1.1642, 0.3212, 0.9920, 1.1255, 0.5181, 0.8862, 0.9923, 0.9770, 1.0105,\n",
      "        0.3855, 1.0975, 1.0119, 0.9482, 0.8244, 1.0019, 0.9941, 1.0860, 0.8854,\n",
      "        0.9899, 0.9862, 0.6054, 1.0146, 0.7292, 1.1421, 0.7315, 0.8654, 0.7135,\n",
      "        0.9716, 0.8848, 0.7507, 1.0529, 0.8517, 1.3089, 0.9315, 0.9579, 1.0025,\n",
      "        0.3741, 1.0216, 1.3155, 1.5242, 1.4843, 0.3657, 1.3705, 1.1237, 1.0168,\n",
      "        0.8882, 0.9313, 0.8045, 1.0193, 0.2987, 0.9888, 0.8454, 0.9179, 0.4404,\n",
      "        0.8053, 1.0546, 0.9651], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9426, 0.9361, 0.9297, 0.7838, 0.2770, 0.8422, 1.4522, 0.8799, 1.1840,\n",
      "        1.0977, 0.5605, 1.0133, 1.0490, 1.1667, 0.2432, 1.0977, 0.6881, 1.0191,\n",
      "        1.1738, 1.2483, 0.9325, 0.5855, 0.3840, 0.2141, 1.3647, 0.0732, 1.0897,\n",
      "        0.0749, 0.3235, 0.0863, 1.7607, 1.6834, 0.3740, 0.1802, 0.3465, 1.0672,\n",
      "        1.5028, 1.6314, 0.8525, 0.0324, 0.5064, 0.7960, 0.7014, 0.9220, 0.1697,\n",
      "        1.3823, 0.9511, 1.0445, 0.9681, 0.9870, 0.1195, 0.5483, 0.8373, 1.1447,\n",
      "        0.8002, 0.8600, 0.5976, 0.6546, 0.2363, 0.2970, 1.5311, 1.2909, 0.1508,\n",
      "        0.3367, 1.7777, 1.6398, 0.0822, 0.7923, 0.7971, 0.8072, 0.9595, 0.9092,\n",
      "        0.9069, 0.8775, 0.8654, 0.9934, 1.1184, 0.2919, 0.9338, 0.8863, 0.7111,\n",
      "        1.0996, 0.5503, 1.0706, 0.6442, 1.5848, 1.7355, 0.4851, 0.9924, 0.9246,\n",
      "        1.0380, 0.9454, 0.5721, 0.7212, 1.0444, 1.2563, 0.3609, 0.1222, 0.8148,\n",
      "        0.4822, 0.6848, 0.5990, 0.8090, 1.4043, 0.1468, 1.0930, 1.0012, 1.0049,\n",
      "        1.5114, 1.7362, 0.8963, 0.3146, 1.0056, 0.8641, 1.1506, 0.9204, 0.9580,\n",
      "        1.2088, 1.2404, 0.9356, 0.9437, 1.1423, 0.2063, 0.9155, 0.9554, 0.8205,\n",
      "        1.0948, 0.7598, 0.9230, 0.6574, 1.4250, 0.9941, 1.1282, 0.8602, 0.9690,\n",
      "        0.9120, 0.9446, 0.2833, 0.9969, 1.3622, 0.8748, 0.9983, 0.7586, 0.7727,\n",
      "        0.5765, 0.6529, 2.4163, 1.0032, 0.9061, 0.9764, 0.9182, 0.8535, 1.0129,\n",
      "        1.2196, 1.1284, 0.1189], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.3923, 0.6800, 1.2953, 1.2944, 1.6128, 0.3301, 1.0163, 0.7239, 1.0217,\n",
      "        0.5468, 2.8899, 1.4376, 1.6402, 0.9506, 1.0533, 1.1492, 0.9359, 1.0244,\n",
      "        2.5911, 0.8377, 1.9854, 0.3417, 0.6781, 0.3936, 1.1784, 1.4428, 0.6553,\n",
      "        0.7936, 1.6892, 2.4214, 0.6939, 1.0956, 0.4037, 0.5023, 0.6811, 0.1712,\n",
      "        0.2813, 0.3114, 0.3823, 0.9804, 0.8677, 0.3071, 0.6013, 3.4456, 3.7511,\n",
      "        0.9517, 1.6757, 0.2607, 0.3907, 1.1048, 1.0904, 0.8814, 0.0096, 0.8892,\n",
      "        0.7494, 0.3540, 0.9634, 1.1171, 2.8352, 1.1101, 1.4057, 1.7532, 0.6847,\n",
      "        0.3554, 0.0737, 0.3633, 0.7580, 0.9738, 1.0405, 0.6219, 1.0416, 1.0329,\n",
      "        0.8051, 0.9934, 0.7183, 1.1728, 0.6834, 1.0101, 0.9736, 1.1016, 1.0078,\n",
      "        0.2475, 1.5954, 0.7666, 0.7054, 1.2083, 1.1515, 0.9280, 0.8910, 0.3689,\n",
      "        0.0572, 0.1647, 0.1069, 0.9854, 0.3392, 0.9839, 0.5796, 0.2109, 0.8460,\n",
      "        1.5784, 0.3718, 1.0293, 1.2650, 0.6261, 1.2406, 0.9026, 1.1230, 1.3173,\n",
      "        0.3380, 1.2143, 1.0024, 0.8937, 0.7950, 1.0601, 1.1581, 0.8949, 0.1612,\n",
      "        0.9441, 1.1721, 0.8224, 0.8814, 0.7170, 0.9889, 0.9751, 1.0801, 0.8256,\n",
      "        0.9052, 1.6024, 1.1683, 1.7373, 1.4684, 0.9471, 1.3799, 0.7404, 1.4418,\n",
      "        1.5415, 0.6762, 0.5099, 1.4062, 1.4000, 0.8595, 1.3275, 1.3738, 0.5167,\n",
      "        0.4873, 0.1934, 1.0452, 0.3259, 1.2426, 0.6944, 1.2675, 1.0230, 0.3238,\n",
      "        1.4445, 0.5212, 0.2193], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.7676, 0.5412, 1.0214, 1.0124, 2.2540, 0.9660, 0.1823, 0.6858, 1.8628,\n",
      "        0.0406, 0.2749, 0.7250, 0.2869, 2.4385, 2.1054, 1.0532, 1.5094, 1.4494,\n",
      "        1.7942, 1.3762, 0.9133, 0.6082, 0.5831, 0.8647, 0.1548, 1.3848, 1.1458,\n",
      "        1.1747, 1.2783, 0.1601, 1.6072, 0.7527, 1.0608, 0.7734, 0.8526, 0.7920,\n",
      "        1.6348, 1.3200, 0.1768, 0.2582, 1.0992, 0.2617, 0.2786, 2.3075, 6.2008,\n",
      "        2.3335, 0.3030, 0.5001, 1.4045, 0.4933, 1.2922, 0.2121, 0.4753, 0.7584,\n",
      "        1.2366, 0.5976, 3.6354, 0.1435, 0.5578, 0.1791, 0.4644, 0.7273, 0.5388,\n",
      "        0.8770, 2.3378, 2.1884, 0.1824, 0.0506, 0.7247, 0.7770, 1.7688, 0.2481,\n",
      "        1.5746, 0.9192, 2.3389, 0.7769, 0.9493, 0.9327, 1.9234, 0.8040, 1.6751,\n",
      "        0.5627, 1.2837, 0.2713, 0.9654, 1.3909, 2.3119, 0.3230, 0.7405, 1.0564,\n",
      "        0.6422, 0.2346, 1.6795, 0.9217, 0.7946, 0.6748, 7.0565, 0.9589, 1.9730,\n",
      "        0.3197, 0.0176, 1.3122, 0.8863, 0.8765, 1.0428, 0.9137, 0.2556, 2.5391,\n",
      "        0.7108, 1.0034, 1.0233, 1.1090, 1.0836, 0.1494, 1.7532, 0.0700, 1.1656,\n",
      "        1.2745, 1.0774, 1.8409, 1.3353, 1.0928, 1.3236, 0.6049, 0.2769, 2.2429,\n",
      "        1.4306, 0.1038, 1.4625, 1.9894, 0.8962, 1.1913, 1.7309, 2.9932, 0.4874,\n",
      "        2.4246, 1.1084, 1.8716, 0.3069, 0.9286, 0.7345, 1.2531, 8.0570, 4.9663,\n",
      "        1.9979, 1.1234, 1.9248, 0.8902, 0.6933, 0.2947, 1.7597, 0.1713, 1.1685,\n",
      "        0.7079, 1.4671, 0.4684], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0617e+00, 1.0532e+00, 7.3641e-01, 1.9095e-01, 6.4077e-01, 6.7970e-01,\n",
      "        5.1972e-01, 7.0036e-01, 5.2309e-01, 2.6476e+00, 1.9577e+00, 7.4708e-01,\n",
      "        7.6215e-01, 1.8626e+00, 1.7660e+00, 2.2671e+00, 8.7907e-01, 9.5979e-01,\n",
      "        1.5446e+00, 5.4057e+00, 1.9463e+00, 9.5213e-01, 3.2685e+00, 4.3011e-02,\n",
      "        4.2090e-02, 1.5665e-01, 5.9082e-01, 1.7396e-01, 9.5717e-01, 1.3868e-01,\n",
      "        1.2986e+00, 2.1240e+00, 6.0462e+00, 2.1024e-01, 4.4125e-01, 1.0689e+00,\n",
      "        9.4469e-01, 1.1618e+00, 9.2011e-01, 1.5992e+00, 9.3827e-01, 1.1466e+00,\n",
      "        4.9966e-01, 1.7882e-01, 1.1464e+00, 2.6928e+00, 1.3875e+00, 6.0935e-01,\n",
      "        5.3188e-01, 1.0605e+00, 7.8173e-01, 5.7928e-01, 7.2533e-01, 6.0084e-01,\n",
      "        9.7154e-01, 8.6774e-01, 4.9271e-01, 5.6243e-01, 3.8626e-01, 6.5657e-02,\n",
      "        5.1338e+00, 5.9926e-01, 3.3755e+00, 1.4533e+00, 2.0895e+00, 1.0981e+00,\n",
      "        5.9663e-01, 1.4866e+00, 5.0372e-01, 7.4948e-01, 2.1985e+00, 1.7289e+00,\n",
      "        2.1324e+00, 6.4018e-02, 9.9853e-01, 1.4859e+00, 9.9101e-01, 1.0425e-01,\n",
      "        9.8903e-01, 6.7925e-01, 1.6078e-01, 9.1563e-01, 3.1528e+00, 7.1583e-02,\n",
      "        9.3661e+00, 4.9132e+00, 7.7464e-01, 1.5851e-03, 9.1835e-01, 6.5192e-01,\n",
      "        1.0591e-01, 2.9080e-01, 4.7233e-01, 3.3616e+00, 5.9224e+00, 8.6247e-01,\n",
      "        7.8911e-02, 4.1013e-01, 5.5433e-01, 1.6570e+00, 1.8870e+00, 1.0806e+00,\n",
      "        2.1122e-01, 8.2894e-01, 1.0128e+00, 1.0629e+00, 1.6780e+00, 2.6985e+00,\n",
      "        7.8029e-01, 1.6124e+00, 1.6315e+00, 1.2238e+00, 1.1470e+00, 1.0335e+00,\n",
      "        1.1185e+00, 4.3864e-01, 1.2297e+00, 1.3324e+00, 1.5876e+00, 7.6887e-01,\n",
      "        1.4264e+00, 1.6253e+00, 1.0818e+00, 9.0475e-01, 3.0308e+00, 1.0729e+00,\n",
      "        3.2914e+00, 2.7484e-02, 3.2121e+00, 1.5355e+00, 4.9537e-01, 1.0107e+00,\n",
      "        4.7509e+00, 3.0969e+00, 9.2015e+00, 3.5582e-01, 1.1165e+00, 1.1933e+00,\n",
      "        5.2076e-01, 5.9305e-01, 6.6825e-01, 2.0125e+00, 4.3056e-01, 3.0185e-02,\n",
      "        2.2143e-01, 1.4944e+00, 1.0570e+00, 8.4603e-01, 5.4269e-01, 5.9113e-01,\n",
      "        7.6834e-01, 1.0608e+00, 1.0889e+00, 1.5991e+00, 1.0642e+00, 1.9070e+00],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.3242, 1.3999, 0.7400, 0.3804, 0.3961, 0.8060, 1.2981, 0.9009, 0.5861,\n",
      "        3.2012, 1.0100, 5.2726, 0.9405, 2.7574, 0.6752, 1.5201, 0.4772, 0.8870,\n",
      "        1.2415, 0.5948, 1.6434, 0.5078, 0.7596, 0.0128, 0.7011, 1.1803, 2.3810,\n",
      "        0.9728, 0.9482, 0.8557, 1.6367, 0.4180, 0.9524, 0.9608, 1.8909, 1.1308,\n",
      "        1.4047, 0.4272, 1.1787, 0.9097, 0.9903, 1.0843, 1.5141, 0.8142, 0.6140,\n",
      "        0.6283, 1.1657, 2.9083, 1.5561, 0.2723, 0.7079, 1.8176, 0.6524, 1.0722,\n",
      "        1.3483, 2.4291, 2.4826, 0.4858, 1.4567, 1.9526, 0.4827, 0.7091, 0.8268,\n",
      "        1.8154, 0.2243, 0.7457, 0.5467, 0.9363, 0.9553, 0.0149, 0.0328, 1.8513,\n",
      "        2.4650, 0.2501, 1.2385, 0.8698, 0.9780, 0.1135, 2.8828, 0.8920, 0.4495,\n",
      "        0.3253, 1.8853, 1.5993, 0.2311, 0.6542, 1.0459, 1.6137, 0.9446, 1.2326,\n",
      "        1.3604, 1.3871, 0.7525, 0.9076, 1.3362, 2.7802, 2.7251, 0.4340, 1.9659,\n",
      "        1.3807, 0.8978, 0.1538, 1.9753, 1.0997, 0.5647, 0.2327, 1.2271, 1.1031,\n",
      "        2.4762, 1.1698, 4.0367, 1.4123, 0.1714, 0.5562, 0.1980, 0.5685, 1.1117,\n",
      "        0.5743, 0.5215, 0.4995, 1.2460, 0.9114, 1.2500, 1.0019, 0.9912, 0.1588,\n",
      "        0.9939, 0.7538, 0.7669, 0.4874, 1.3627, 0.3332, 1.1932, 1.0375, 0.9923,\n",
      "        0.8734, 0.7744, 2.8353, 2.2502, 0.0677], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.2665, 0.7895, 1.8722, 1.2254, 1.3723, 0.6535, 0.1130, 1.2076, 0.6151,\n",
      "        0.8802, 3.3254, 4.4891, 1.0519, 0.5222, 1.5785, 0.9093, 2.2523, 1.0708,\n",
      "        1.4097, 1.0215, 0.5425, 1.4141, 0.8667, 1.0935, 0.7128, 0.3272, 0.9565,\n",
      "        1.0010, 0.9002, 0.1179, 1.3616, 0.9746, 1.2481, 1.0234, 0.6651, 0.4890,\n",
      "        1.1489, 0.8188, 1.5474, 0.8676, 0.8782, 0.7133, 1.7100, 5.8690, 0.7320,\n",
      "        1.0887, 0.8901, 0.6815, 1.1203, 0.8801, 1.2734, 0.9510, 0.2966, 1.1820,\n",
      "        0.7137, 1.1218, 2.8728, 1.3577, 0.6390, 1.3881, 1.5102, 1.5741, 0.9827,\n",
      "        0.2172, 0.9602, 1.3569, 0.8549, 0.7988, 0.5727, 0.1971, 0.0885, 0.0641,\n",
      "        1.0030, 1.5245, 2.3270, 0.1806, 1.2029, 1.0861, 0.9174, 1.0301, 0.2668,\n",
      "        2.2863, 0.8059, 1.4578, 3.8218, 1.5451, 0.6739, 3.5023, 0.8062, 1.9815,\n",
      "        1.2310, 0.8752, 1.5589, 0.1650, 1.1613, 1.0307, 2.3472, 0.7235, 0.1341,\n",
      "        1.1971, 1.5158, 0.8897, 0.7349, 0.2174, 0.8892, 1.2448, 2.8676, 0.5007,\n",
      "        1.6866, 0.0598, 1.8125, 0.8982, 1.5587, 1.5171, 0.9059, 0.4273, 1.4595,\n",
      "        1.9883, 0.8306, 0.8384, 0.9722, 0.6178, 0.3379, 0.8163, 1.1038, 0.7047,\n",
      "        0.8774, 1.1264, 1.6276, 1.1319, 0.5151, 0.9243, 2.5405, 1.3809, 1.0311,\n",
      "        0.5571, 1.1779, 1.1804, 0.7108, 0.4304, 0.9592], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.7787, 1.7137, 0.6688, 1.3313, 1.0922, 0.8387, 0.6921, 0.8841, 0.9061,\n",
      "        1.0256, 1.0056, 0.8443, 1.0200, 0.9455, 1.2990, 0.3409, 1.0021, 1.0944,\n",
      "        0.8058, 0.0630, 1.3014, 0.7713, 0.5119, 0.9027, 0.4437, 0.9975, 0.9893,\n",
      "        0.2755, 0.5384, 0.8943, 0.5619, 0.8667, 0.8118, 0.5462, 1.0697, 1.2384,\n",
      "        0.6620, 0.6051, 0.9928, 0.8585, 0.9365, 0.9403, 0.8039, 1.1747, 0.7258,\n",
      "        0.8782, 0.9412, 1.2034, 1.1458, 0.9897, 1.3598, 1.3542, 0.8880, 2.1583,\n",
      "        1.2035, 1.4422, 1.1254, 0.5711, 0.4739, 0.5886, 0.8441, 0.4185, 0.6635,\n",
      "        0.5261, 1.0399, 0.7693, 0.7719, 0.9685, 1.1256, 0.2597, 0.3705, 0.2489,\n",
      "        1.2279, 0.2801, 1.0277, 0.6865, 0.6030, 1.1211, 0.9869, 0.7606, 1.4470,\n",
      "        1.7752, 1.2326, 0.4317, 0.2878, 1.1459, 1.5245, 1.9518, 1.0221, 1.5587,\n",
      "        1.2507, 0.6781, 0.6717, 1.0067, 1.7209, 0.8538, 1.0330, 1.1369, 0.1956,\n",
      "        1.6617, 0.9431, 0.1981, 0.8697, 0.2425, 0.9840, 1.6342, 0.5013, 1.0872,\n",
      "        1.3644, 1.3578, 1.0797, 0.7268, 0.4792, 0.5990, 0.3524, 1.1061, 1.4016,\n",
      "        0.8951, 1.5801, 0.9980, 0.4557, 0.8157, 0.8565, 0.5622, 0.8613, 0.8256,\n",
      "        0.5021, 1.0279, 0.6974, 0.2030, 0.0135, 0.4735, 2.2059, 1.2691, 1.1873,\n",
      "        1.0224, 1.5659, 1.0266, 0.8622, 0.0969, 1.1437], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.6607, 0.8840, 1.3581, 1.3916, 1.0093, 1.0120, 0.0915, 0.9161, 0.2144,\n",
      "        1.0107, 0.7156, 0.6200, 0.6002, 0.4311, 1.4389, 0.1081, 0.5615, 0.6523,\n",
      "        1.0204, 0.6003, 0.1503, 0.6521, 0.9074, 0.1434, 0.3596, 0.8912, 0.8118,\n",
      "        0.6655, 0.8219, 0.9984, 0.9811, 0.9235, 0.8764, 0.7282, 1.0426, 1.0534,\n",
      "        0.5337, 0.3358, 0.4647, 0.9790, 0.9350, 0.9822, 1.1517, 1.0113, 0.8707,\n",
      "        1.0233, 0.7953, 1.1945, 0.5620, 0.8422, 1.0590, 1.1657, 1.2184, 0.5546,\n",
      "        0.5556, 0.8106, 0.6601, 0.9754, 1.2657, 1.0599, 0.7837, 0.2424, 1.0773,\n",
      "        0.3656, 0.8242, 0.4797, 0.9389, 1.1088, 0.9368, 0.9797, 0.8828, 0.5210,\n",
      "        0.7193, 1.8462, 3.1332, 0.6376, 1.0209, 0.9424, 0.3032, 0.8378, 0.9449,\n",
      "        0.9069, 0.7361, 0.0034, 0.8861, 0.8240, 0.4635, 1.0303, 0.2571, 0.8882,\n",
      "        0.3572, 0.5740, 0.9118, 0.9617, 0.7983, 0.8978, 0.8699, 0.7315, 0.9616,\n",
      "        0.6561, 0.4709, 1.8445, 0.4255, 0.8407, 1.0526, 0.5366, 0.7885, 0.9439,\n",
      "        0.8051, 1.1643, 0.9646, 0.6750, 1.2888, 0.9948, 1.0063, 0.9574, 0.8405,\n",
      "        0.3271, 0.8528, 1.0013, 0.9447, 0.9043, 0.8079, 0.5862, 0.5909, 0.9068,\n",
      "        1.0244, 1.0279, 0.9778, 0.6848, 1.0680, 0.7155, 0.9608, 1.1173, 1.0001,\n",
      "        0.0938, 1.1148, 0.2802, 1.0693, 0.9330, 0.4438], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.7733, 0.9941, 0.6619, 1.2813, 0.9594, 1.0679, 1.0855, 0.7184, 1.3815,\n",
      "        1.1162, 0.9941, 1.1556, 0.6129, 1.1316, 0.2330, 1.1555, 0.9453, 0.8881,\n",
      "        0.5631, 0.6716, 0.7504, 0.7454, 1.0891, 0.8461, 1.0538, 0.9869, 0.5657,\n",
      "        0.6023, 0.5456, 1.0959, 1.0984, 0.7783, 0.8056, 0.8048, 0.9849, 1.0626,\n",
      "        0.9631, 0.5554, 1.0146, 0.4274, 0.1197, 0.7879, 0.9481, 1.1029, 0.9111,\n",
      "        0.9346, 0.9793, 0.7384, 1.1183, 1.1481, 0.1145, 0.0427, 1.7499, 1.2328,\n",
      "        0.7426, 1.2246, 1.1411, 0.4461, 0.7835, 0.6986, 0.6247, 0.7494, 0.4964,\n",
      "        1.0146, 0.9067, 1.3171, 0.1966, 1.0525, 1.5554, 0.3352, 0.3021, 0.0340,\n",
      "        1.5805, 0.1233, 1.2006, 0.9800, 0.5633, 0.9791, 0.9537, 1.0802, 0.6895,\n",
      "        1.5528, 0.6483, 1.6631, 0.0109, 0.4432, 0.6315, 1.0549, 1.0039, 0.8842,\n",
      "        0.8485, 1.0887, 1.1506, 0.9554, 0.7899, 0.7699, 1.0030, 1.1615, 0.3169,\n",
      "        0.0891, 0.8762, 0.6682, 0.0305, 1.1133, 0.6137, 0.7677, 0.4869, 0.9040,\n",
      "        0.9384, 0.1355, 0.2535, 0.9350, 0.9986, 1.0298, 1.0120, 1.1381, 0.8124,\n",
      "        0.5218, 0.5158, 0.6743, 1.0313, 1.0029, 0.6506, 0.9111, 0.3286, 0.8386,\n",
      "        0.3051, 0.9633, 1.0511, 1.3148, 1.4132, 0.2258, 0.6005, 1.1871, 1.3299,\n",
      "        0.9601, 1.3960, 1.0823, 0.8865, 0.3215, 0.1070], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.1761e+00, 1.0648e+00, 2.1390e-01, 7.7004e-01, 1.3016e+00, 9.4908e-01,\n",
      "        5.7031e-01, 9.5933e-01, 3.5930e-01, 6.0662e-01, 1.1342e+00, 3.3619e-01,\n",
      "        6.8733e-01, 1.1470e+00, 2.4651e+00, 7.6663e-01, 3.3170e-01, 1.0900e+00,\n",
      "        1.2661e+00, 9.8824e-01, 1.5027e+00, 6.9258e-01, 9.8214e-01, 7.8158e-01,\n",
      "        6.0616e-01, 7.6447e-01, 3.4436e-03, 4.0876e+00, 2.7396e+00, 7.3336e-01,\n",
      "        4.1204e-01, 1.0500e+00, 1.0492e+00, 1.3699e+00, 8.2113e-01, 9.7538e-01,\n",
      "        6.8729e-01, 9.4043e-01, 8.3084e-01, 4.9627e-01, 1.0948e+00, 3.7898e-01,\n",
      "        5.3418e-01, 1.0460e+00, 9.7736e-01, 1.7732e+00, 1.0018e+00, 5.9446e-01,\n",
      "        1.4373e+00, 2.0813e-01, 5.8056e-01, 1.6929e+00, 8.8812e-01, 1.3333e+00,\n",
      "        3.1662e-01, 7.3285e-01, 8.1950e-04, 6.9134e-01, 4.9469e-01, 1.0122e+00,\n",
      "        1.0688e+00, 4.6102e-01, 2.6399e+00, 1.9004e+00, 2.1972e+00, 5.5327e-01,\n",
      "        7.4015e-01, 4.9108e-02, 7.0698e-01, 1.0265e+00, 6.0022e-01, 4.6183e-01,\n",
      "        3.3543e-01, 1.1320e+00, 6.2293e-01, 7.0809e-01, 1.2090e+00, 1.0923e+00,\n",
      "        7.2630e-01, 7.2901e-02, 9.1619e-01, 1.7672e+00, 8.4450e-01, 1.6513e+00,\n",
      "        6.7643e-01, 1.6922e+00, 1.6357e-02, 1.0842e+00, 6.2266e-01, 1.0876e+00,\n",
      "        8.9744e-02, 5.5878e-02, 1.0691e+00, 1.4243e+00, 9.8888e-01, 1.5506e+00,\n",
      "        3.7014e-01, 9.1472e-01, 9.7397e-01, 5.4689e-01, 1.0207e+00, 2.0055e-02,\n",
      "        5.0638e-02, 1.0102e+00, 6.3074e-01, 7.0591e-01, 1.2427e+00, 6.6631e-01,\n",
      "        9.2000e-01, 1.1566e+00, 8.6237e-01, 1.1829e+00, 1.0283e+00, 1.1380e+00,\n",
      "        1.2070e+00, 9.4468e-01, 9.5612e-01, 1.1525e+00, 8.9956e-01, 2.1448e+00,\n",
      "        8.2627e-01, 1.0805e+00, 1.4453e-01, 3.4265e-01, 1.0514e+00, 4.9267e-01,\n",
      "        6.3945e-01, 4.2613e-01, 1.4112e+00, 5.9121e-01, 1.9722e+00, 1.5668e+00,\n",
      "        1.1445e+00, 1.1567e+00, 1.0852e+00, 1.0276e+00, 8.3571e-01, 8.6626e-01,\n",
      "        7.7430e-01, 7.1516e-01, 4.0411e-02], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.3777, 0.4786, 1.0084, 0.6366, 0.0708, 0.8627, 2.4064, 0.8981, 1.2722,\n",
      "        1.6767, 0.9272, 0.9209, 0.8011, 0.7433, 1.9220, 1.1988, 1.0394, 0.7243,\n",
      "        1.2593, 1.6844, 1.0233, 1.0576, 0.9551, 0.4703, 1.0995, 0.6572, 1.0925,\n",
      "        1.5091, 0.3558, 0.4639, 0.8629, 0.0320, 1.9763, 0.2728, 0.2169, 0.7117,\n",
      "        1.0840, 1.0839, 0.5459, 0.5325, 2.4075, 0.8125, 0.8922, 1.1903, 0.4334,\n",
      "        0.6249, 1.3722, 0.7092, 1.5473, 1.1172, 1.0268, 0.7528, 0.4899, 0.8473,\n",
      "        0.1713, 0.2527, 0.3220, 0.6768, 1.1975, 0.5263, 0.3495, 0.8911, 1.3015,\n",
      "        0.4285, 0.7281, 0.8120, 2.1625, 1.2895, 0.0855, 0.0607, 0.8267, 1.2631,\n",
      "        0.8749, 0.5191, 0.6363, 0.8238, 0.9756, 0.6956, 0.6913, 1.0224, 0.4121,\n",
      "        1.0621, 0.4677, 0.4370, 1.4216, 0.8203, 2.6734, 0.5510, 0.0071, 0.3870,\n",
      "        0.7733, 0.0317, 0.6351, 0.6410, 1.5345, 0.5739, 0.6849, 1.5980, 0.8937,\n",
      "        0.9067, 0.8837, 0.6104, 1.1955, 0.4649, 0.5436, 0.2567, 0.4810, 0.8569,\n",
      "        0.9438, 0.8291, 0.8011, 0.6923, 0.4270, 1.7406, 0.0999, 0.3910, 0.7432,\n",
      "        0.0864, 0.5088, 0.7178], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.5210, 1.8742, 4.2279, 0.5227, 0.1074, 0.0661, 0.6012, 0.9297, 2.4224,\n",
      "        0.2182, 0.2485, 0.0691, 0.9048, 2.1626, 1.7335, 1.0043, 0.5792, 1.6134,\n",
      "        1.2565, 1.0625, 2.4485, 0.0626, 0.7977, 1.2297, 0.8861, 0.9424, 0.6460,\n",
      "        3.3922, 0.1388, 2.1564, 5.1252, 0.3396, 1.1952, 0.9980, 1.3724, 0.5055,\n",
      "        0.9504, 1.2375, 1.7923, 0.4763, 0.3512, 1.1267, 1.1269, 0.5367, 0.6775,\n",
      "        0.9884, 3.7984, 5.2261, 0.5085, 0.7500, 0.9516, 0.6933, 0.6938, 0.3162,\n",
      "        0.8984, 0.5094, 0.4143, 1.0432, 1.0879, 0.4679, 1.4483, 1.5287, 7.3698,\n",
      "        0.7878, 1.8940, 0.6229, 0.7088, 0.8378, 2.0761, 0.5101, 1.4933, 1.9562,\n",
      "        0.9811, 1.4003, 0.8004, 0.0086, 0.4015, 0.0237, 0.7983, 0.8660, 0.2343,\n",
      "        0.6921, 1.4968, 0.8119, 1.3895, 0.7449, 0.7064, 0.2770, 1.6180, 1.1546,\n",
      "        0.9375, 0.3992, 0.9152, 0.6805, 0.6797, 0.1381, 0.5902, 0.9885, 0.8875,\n",
      "        1.1606, 1.1532, 0.1662, 1.4612, 1.8344, 0.4122, 1.1147, 2.1204, 1.7604,\n",
      "        1.1185, 0.7689, 0.4013, 0.7916, 1.1936, 1.5261, 1.4154, 0.9164, 0.7485,\n",
      "        0.4602, 1.2594, 1.3046], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([2.4505, 0.4394, 2.3612, 1.0872, 0.5075, 0.3939, 5.2443, 3.6818, 0.3545,\n",
      "        0.9955, 1.4461, 0.6065, 0.7097, 0.1213, 0.1276, 0.6011, 0.3579, 0.0215,\n",
      "        1.6493, 0.4261, 1.4240, 1.2069, 1.6268, 0.7651, 0.1047, 0.1374, 0.9936,\n",
      "        0.9709, 1.7796, 1.2210, 1.6629, 1.0999, 3.0554, 1.2448, 0.9452, 0.8821,\n",
      "        1.7038, 1.1702, 0.7000, 0.3850, 2.7276, 0.1036, 0.6611, 0.4171, 0.9062,\n",
      "        3.9555, 5.5815, 1.0050, 1.0873, 1.8454, 0.7610, 2.4526, 0.1442, 2.2754,\n",
      "        0.8763, 0.8842, 1.3540, 0.8434, 1.0190, 0.4321, 0.9778, 0.8999, 0.4265,\n",
      "        0.2631, 1.3008, 0.1903, 1.3038, 1.0174, 1.7054, 1.9070, 0.9217, 1.1522,\n",
      "        0.6079, 0.7820, 1.0134, 3.3945, 1.3077, 0.2915, 0.7575, 0.7953, 0.0918,\n",
      "        0.7082, 1.0164, 0.7633, 0.1885, 1.0824, 1.5225, 2.3170, 2.4164, 0.0096,\n",
      "        0.6659, 1.2504, 1.9812, 2.5864, 0.4635, 2.8978, 0.1215, 0.0625, 1.4546,\n",
      "        0.8178, 1.0727, 0.0345, 1.3254, 0.5249, 1.5183, 1.7029, 0.7145, 0.0058,\n",
      "        0.6437, 1.5578, 1.6599, 1.3287, 0.8835, 1.2602, 0.9828, 0.6794, 1.8905,\n",
      "        0.4840, 1.5544], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.7574e+00, 4.8488e-01, 1.5091e+00, 5.9722e-01, 1.1759e+00, 8.4040e-01,\n",
      "        2.1069e-01, 9.3215e-01, 3.2852e-01, 6.6599e-01, 2.8554e-01, 1.7878e+00,\n",
      "        9.2641e-01, 1.8464e+00, 7.6795e-01, 2.0778e+00, 9.7652e-01, 1.0367e-02,\n",
      "        1.7438e-01, 8.7859e-01, 3.4252e-01, 3.1040e+00, 7.6884e-01, 1.0286e+00,\n",
      "        9.7667e-01, 4.9471e-01, 9.3656e-01, 8.2137e-01, 8.8404e-01, 9.2643e-01,\n",
      "        7.7835e-01, 6.4777e-01, 5.2821e-01, 8.0868e-01, 5.3082e-01, 1.8667e+00,\n",
      "        7.1549e-01, 8.5095e-01, 7.3826e-01, 1.6082e-01, 1.1163e+00, 1.1966e+00,\n",
      "        6.1306e-01, 3.9378e-01, 9.4890e-01, 3.1715e+01, 1.3696e+00, 1.1780e+01,\n",
      "        1.0211e+00, 5.3499e+00, 1.1814e-01, 1.1139e+00, 3.1959e-01, 7.8657e-01,\n",
      "        2.7057e-01, 3.5986e-01, 7.4220e-01, 7.3045e-01, 9.4271e-01, 6.4148e-01,\n",
      "        9.4163e-01, 5.4394e-01, 1.6704e+00, 1.6189e-01, 1.7078e-01, 3.7078e-01,\n",
      "        6.3146e-01, 1.0462e+00, 5.7899e-01, 4.0879e-01, 9.5087e-01, 4.5569e-02,\n",
      "        1.9328e-01, 7.8027e-01, 8.6774e-01, 2.2152e+00, 2.8634e+00, 2.9214e-01,\n",
      "        1.1480e+00, 1.6451e+00, 1.1562e+00, 8.1420e-01, 1.1532e+00, 6.4528e-01,\n",
      "        1.3410e+00, 5.4106e-02, 1.5448e+00, 1.2777e+00, 1.1116e+00, 1.5967e+00,\n",
      "        1.3496e+00, 4.7542e-01, 1.6832e-01, 2.3820e+00, 9.7510e-01, 9.8066e-01,\n",
      "        6.6823e-01, 9.8318e-01, 4.5758e-01, 9.7230e-01, 7.0799e-01, 1.1888e+00,\n",
      "        2.0241e+00, 8.2878e-01, 1.4557e+00, 2.2453e-02, 1.2494e+00, 1.0263e+00,\n",
      "        7.7763e-03, 6.2706e-01, 5.3605e-01, 7.7700e-01, 6.6425e-01, 3.7410e-01,\n",
      "        2.2985e-01, 6.0225e-01, 9.7811e-01, 7.4450e-01, 9.4582e-01, 9.0726e-01],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.2126, 1.0311, 1.0263, 1.1083, 0.3186, 0.1211, 0.4339, 0.5591, 0.8492,\n",
      "        0.6179, 0.7250, 0.8686, 0.7362, 1.5657, 1.1379, 0.3290, 1.0885, 0.8030,\n",
      "        0.8244, 0.8845, 0.2711, 0.2772, 0.8614, 0.0145, 0.9923, 0.1842, 0.9696,\n",
      "        0.4955, 0.4819, 0.1404, 0.4451, 0.5127, 0.4162, 0.0233, 0.9034, 1.0244,\n",
      "        0.7949, 0.6484, 1.0070, 1.0350, 1.0802, 0.6720, 0.6707, 0.6236, 0.6914,\n",
      "        0.9244, 1.3514, 1.2587, 0.2604, 1.4003, 0.1994, 0.7928, 0.4233, 1.2459,\n",
      "        0.2712, 0.5627, 0.5167, 1.0787, 0.6734, 0.3640, 0.5989, 0.7358, 0.6557,\n",
      "        0.8444, 0.8519, 0.6424, 2.0582, 1.1600, 0.3662, 0.9129, 0.8567, 0.7832,\n",
      "        0.9428, 0.6696, 0.7154, 0.3992, 0.3086, 1.0512, 1.0173, 0.5462, 0.8500,\n",
      "        0.9890, 1.0882, 1.0726, 1.1140, 0.0267, 0.8256, 0.9955, 0.6220, 0.7090,\n",
      "        0.7768, 1.0251, 0.8944, 0.8804, 0.0981, 0.4947, 0.7873, 0.8709, 0.8986,\n",
      "        0.3136, 0.1244, 0.8626, 0.0355, 1.1138, 1.2840, 1.0210, 1.0005, 0.1380,\n",
      "        0.9667, 1.0139, 0.7701, 0.3505, 1.1020, 0.3750, 0.5105, 0.1668, 0.5594,\n",
      "        0.7689, 0.6618, 0.6609], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([7.7906e-01, 2.6349e-01, 1.1272e+00, 3.8022e-01, 1.5318e-01, 3.4669e-01,\n",
      "        5.7803e-01, 4.5969e-01, 1.2136e+00, 1.4160e+00, 6.1223e-01, 8.3388e-02,\n",
      "        5.4539e-01, 8.3017e-01, 1.1903e+00, 9.7719e-01, 1.0219e+00, 1.0282e+00,\n",
      "        4.7442e-01, 3.8771e-01, 3.1114e-01, 4.4075e-01, 7.5654e-01, 3.5222e-01,\n",
      "        9.6656e-01, 7.4938e-01, 8.3398e-01, 6.0010e-01, 8.0076e-01, 1.3789e-03,\n",
      "        7.6082e-01, 7.4776e-01, 7.0792e-01, 5.2600e-01, 2.8976e-01, 7.6940e-01,\n",
      "        4.3198e-01, 2.8349e-01, 6.5144e-01, 7.5605e-01, 9.8434e-01, 4.0013e-01,\n",
      "        5.1705e-01, 1.2300e+00, 1.6906e-01, 7.3332e-01, 8.0640e-01, 1.3264e+00,\n",
      "        6.6599e-01, 1.3593e+00, 1.7302e+00, 1.0106e+00, 2.2455e-01, 9.9848e-01,\n",
      "        4.5946e-01, 2.2890e-01, 3.8836e-02, 4.5432e-01, 8.5887e-01, 1.0704e-01,\n",
      "        1.2736e+00, 6.8355e-01, 3.7964e-02, 8.1053e-01, 1.1338e+00, 9.9840e-01,\n",
      "        8.5714e-01, 1.0747e-01, 8.6267e-01, 5.5879e-01, 9.1618e-02, 1.1184e+00,\n",
      "        1.0805e+00, 8.9522e-01, 9.0837e-01, 1.5646e+00, 2.5683e+00, 2.1768e-01,\n",
      "        7.3321e-01, 1.1562e+00, 1.3502e+00, 2.2585e-01, 9.0087e-01, 5.1988e-01,\n",
      "        4.0025e-01, 9.0602e-01, 5.3249e-01, 4.9192e-01, 6.9757e-01, 1.5483e+00,\n",
      "        3.1505e-01, 1.0926e+00, 1.0193e+00, 8.8519e-01, 5.5958e-03, 6.9187e-01,\n",
      "        9.1152e-01, 1.0011e+00, 1.0152e+00, 1.0779e+00, 1.1242e+00, 1.4681e+00,\n",
      "        1.3221e+00, 1.8654e+00, 9.4328e-01, 1.0922e-01, 1.3819e+00, 9.8966e-01,\n",
      "        5.7653e-01, 7.4891e-01, 4.7077e-01, 9.1757e-01, 8.6836e-01, 7.9569e-01,\n",
      "        8.4936e-01, 1.0279e+00, 8.6718e-01, 9.8668e-01, 1.1622e+00, 2.0997e+00],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([6.4660e-01, 1.2118e+00, 1.7866e+00, 2.0497e-01, 1.0481e-01, 5.2255e-01,\n",
      "        9.2169e-01, 3.2426e-01, 1.6994e+00, 2.3048e+00, 3.5723e-01, 2.4328e-01,\n",
      "        9.3527e-01, 9.5312e-02, 8.7539e-01, 6.1172e-01, 9.3090e-01, 6.7154e-01,\n",
      "        2.4471e-01, 6.8315e-01, 3.0528e+00, 8.8997e-01, 6.8471e-01, 8.8808e-01,\n",
      "        5.8430e-02, 1.5376e-01, 5.9745e-01, 3.8679e-01, 8.6994e-01, 1.1154e+00,\n",
      "        6.6677e-02, 1.8274e+00, 4.9769e-01, 1.8023e+00, 6.2209e-01, 8.6443e-01,\n",
      "        8.4775e-01, 1.0714e+00, 2.7412e+00, 1.1856e+00, 5.7933e-01, 6.1180e-01,\n",
      "        5.5370e-01, 1.7347e-01, 1.8933e+00, 1.6602e+00, 5.8101e-01, 1.2367e-01,\n",
      "        1.5224e-03, 1.8812e+00, 1.0403e+00, 1.3386e+00, 1.9041e+00, 1.9135e+00,\n",
      "        1.7351e+00, 9.0806e-02, 6.5432e-01, 5.8506e-01, 1.0104e+00, 7.9939e-01,\n",
      "        5.3535e+00, 3.9653e+00, 6.6557e-01, 6.7246e-01, 1.3775e+00, 9.6608e-01,\n",
      "        4.3405e-01, 5.7210e+00, 3.7496e+00, 2.1478e+00, 7.6762e-01, 1.3219e+00,\n",
      "        3.5386e-01, 6.6570e-01, 7.4999e-01, 3.9481e-02, 1.7570e+00, 8.0850e-01],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.7111e+00, 2.8117e+00, 6.5329e-01, 1.2074e-03, 1.5839e+00, 3.6623e+00,\n",
      "        1.3663e+00, 5.4771e-01, 9.1590e-01, 3.7042e-01, 1.0528e+00, 1.3897e+00,\n",
      "        1.0116e+00, 8.1050e-01, 3.1120e-01, 1.6669e+00, 1.5948e+00, 3.6656e+00,\n",
      "        3.4069e+00, 6.0172e-01, 2.0489e+01, 3.1644e-01, 6.1942e-01, 1.2630e+00,\n",
      "        8.9493e-01, 1.0656e-01, 2.8975e+00, 5.9440e-02, 1.3138e+00, 4.3173e-01,\n",
      "        1.7354e+00, 1.6065e+00, 1.8864e-01, 5.9940e-01, 1.2644e+00, 2.0989e+00,\n",
      "        1.2210e+00, 2.2831e+00, 1.5400e-01, 1.6748e+00, 1.1676e-01, 1.6105e+00,\n",
      "        2.1988e+00, 9.5941e-01, 9.9408e-01, 1.3083e+00, 1.5344e+00, 2.5173e+00,\n",
      "        1.2454e+00, 1.8277e-01, 2.7132e+00, 5.9423e-01, 7.2660e-01, 2.6648e+00,\n",
      "        1.9756e-01, 7.4603e-01, 7.1996e-01, 3.3739e+00, 2.2017e+00, 9.9137e-01,\n",
      "        9.6584e-01, 1.0569e+00, 3.6551e-01, 6.1272e+00, 7.8474e-01, 2.7698e+00,\n",
      "        7.1919e-01, 8.6857e-01, 4.5386e+00, 4.6677e-01, 8.4365e-01, 2.1127e+00,\n",
      "        1.8537e+00, 5.0126e-01, 8.5602e-01, 5.9775e-01, 2.9359e-01, 1.0725e+00],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.0841, 1.2449, 2.1279, 0.8499, 1.6661, 1.2553, 1.8041, 0.7583, 1.2526,\n",
      "        0.3814, 1.5505, 0.5723, 0.7828, 0.3125, 1.7076, 0.1348, 1.0020, 1.9117,\n",
      "        0.8549, 0.7265, 0.5399, 0.0586, 0.9541, 0.0826, 0.2433, 0.5579, 0.8320,\n",
      "        0.4140, 0.4530, 0.9950, 0.2577, 0.6538, 0.8359, 0.0879, 0.9054, 0.2690,\n",
      "        1.5516, 0.1696, 0.5064, 1.8207, 1.1114, 1.7847, 0.5281, 1.0199, 1.4497,\n",
      "        0.9910, 0.0362, 0.9471, 2.1717, 0.7726, 1.0483, 0.7177, 0.1196, 0.5335,\n",
      "        2.4249, 0.9859, 1.1442, 0.7547, 0.4213, 0.5191, 1.9983, 1.0468, 4.6213,\n",
      "        1.0829, 2.2744, 1.4355, 1.2340, 0.7944, 0.9740, 0.5028, 0.3590, 1.0983,\n",
      "        0.7499, 1.1654, 0.3396, 0.9292, 0.9548, 0.5309], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([2.2862e-01, 7.6856e-01, 2.3178e+00, 1.1497e+00, 2.7901e+00, 9.3754e-01,\n",
      "        1.6365e+00, 1.2911e+00, 1.0392e+00, 9.7922e-01, 1.0492e+00, 1.7106e+00,\n",
      "        7.5339e-01, 3.5609e-01, 1.0900e-01, 5.1379e-01, 1.4188e+00, 8.7190e-01,\n",
      "        2.5570e+00, 4.0336e+00, 4.9922e-01, 5.7523e-01, 5.5524e-01, 8.7583e-01,\n",
      "        3.6819e-01, 4.7589e-01, 1.0520e+00, 1.3096e+00, 6.6400e-01, 1.2016e+00,\n",
      "        9.2438e-01, 1.4636e+00, 1.3324e-01, 9.2756e-03, 3.0228e-01, 1.0249e-03,\n",
      "        1.2585e+00, 3.3167e-02, 9.6924e-01, 1.5278e+00, 4.3388e-01, 5.6815e-01,\n",
      "        1.3113e+00, 2.0644e+00, 5.6540e-01, 7.8146e-01, 9.3523e-01, 8.2305e-02,\n",
      "        6.6790e-01, 1.4075e+00, 1.5777e+00, 6.5171e-01, 1.0010e+00, 3.5847e-01,\n",
      "        2.9000e-01, 1.0776e+00, 1.3173e+00, 4.7004e-01, 8.9807e-01, 3.4067e-01,\n",
      "        6.8176e-01, 6.0424e-01, 1.0367e+00, 4.3383e-01, 6.5562e-01, 7.0175e-01,\n",
      "        2.0864e+00, 1.6371e+00, 4.3171e+00, 1.2372e-01, 6.1729e-01, 9.5494e-02,\n",
      "        7.1513e-01, 3.9918e-01, 3.5623e-01, 6.1198e-01, 5.2550e-02, 6.1645e-01],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.4317, 1.1351, 0.5030, 0.8593, 1.2837, 0.9013, 0.4855, 0.6839, 1.1520,\n",
      "        1.1334, 0.2780, 0.4677, 0.2447, 0.5998, 0.8518, 0.9109, 0.3566, 0.6744,\n",
      "        0.7767, 0.2289, 0.7652, 1.4063, 1.9333, 0.6144, 0.5205, 0.4373, 0.5981,\n",
      "        0.0161, 0.0936, 0.6617, 0.6160, 0.4993, 0.2919, 0.0477, 1.0438, 0.8080,\n",
      "        0.3761, 0.7039, 2.5134, 0.3781, 0.9621, 1.0573, 1.0106, 0.7405, 0.2582,\n",
      "        1.0078, 2.5108, 0.4336, 1.2368, 1.0409, 1.5194, 0.8894, 1.1881, 0.9571,\n",
      "        2.2525, 0.7696, 0.7015, 0.3713, 0.4382, 0.9909, 0.6631, 0.3877, 0.3214,\n",
      "        0.7816, 0.2693, 2.3778, 0.4617, 0.6136, 0.7744, 0.6261, 1.0835, 0.6087,\n",
      "        1.3590, 0.6714, 0.9774, 0.5880, 0.8734, 0.8907], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9720, 1.3563, 0.8575, 2.7178, 1.8036, 0.1623, 1.1988, 0.6025, 0.9023,\n",
      "        2.4271, 0.0916, 1.5986, 0.6096, 0.6229, 0.8052, 1.0011, 1.5954, 1.2346,\n",
      "        0.4669, 1.5292, 0.8284, 0.4885, 1.0737, 0.2309, 0.5164, 0.9107, 0.5930,\n",
      "        1.5404, 1.2120, 0.9472, 0.6388, 1.4531, 0.0795, 0.4648, 0.9554, 1.4365,\n",
      "        0.8738, 0.7904, 1.1493, 1.6488, 0.6206, 0.5659, 0.9892, 0.6497, 0.8715,\n",
      "        0.8980, 1.3240, 1.5245, 0.0329, 1.3305, 0.4410, 0.9172, 0.7401, 1.1162,\n",
      "        0.9009, 0.0382, 1.0162, 0.1012, 0.6400, 0.7829, 0.9779, 1.3225, 0.3049,\n",
      "        1.4849, 0.6336, 0.2437, 0.3056, 0.2000, 0.9894, 0.0979, 1.0366, 1.3145,\n",
      "        1.0417, 1.3893, 0.3039, 0.3667, 0.8585, 0.7493], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.4356, 0.3044, 2.8469, 0.7401, 0.6178, 1.1955, 0.0539, 1.1972, 1.9384,\n",
      "        0.1353, 0.5794, 0.5712, 1.2044, 0.2636, 0.6318, 0.8837, 1.5026, 1.7912,\n",
      "        4.8417, 3.6996, 1.4486, 0.7993, 0.9653, 1.0219, 1.5812, 0.3570, 0.6887,\n",
      "        0.3994, 0.4382, 1.0627, 1.8225, 0.2329, 0.8125, 1.4873, 0.8366, 0.6057,\n",
      "        0.8359, 0.9449, 0.4858, 3.9508, 2.0718, 1.5369, 1.4095, 1.1841, 2.1279,\n",
      "        0.5382, 1.6090, 0.9858, 1.2180, 0.1123, 1.7298, 0.8847, 1.2359, 2.0600,\n",
      "        0.5247, 0.3966, 1.1626, 1.0846, 1.1626, 1.2773, 0.9454, 0.6450, 0.4172,\n",
      "        1.2383, 0.6064, 2.6129, 1.9480, 0.5699, 0.9742, 1.1503, 1.4501, 2.6006,\n",
      "        0.6597, 0.4035, 1.0873, 1.1891, 0.8873, 0.7298, 0.9554, 0.7602, 0.6493,\n",
      "        0.5011, 0.9373, 1.2559, 0.3420, 1.3074, 1.9858, 2.0311, 0.1831, 0.1729,\n",
      "        0.4204, 0.6696, 0.9944, 0.7168, 0.9096, 0.6847, 0.9234, 0.2815, 1.3405,\n",
      "        2.7335, 1.6804, 0.7801, 1.1584, 0.6058, 0.5721, 0.3467, 0.0370, 1.0769,\n",
      "        0.2270, 0.9163, 0.7257, 0.8438, 0.6625, 0.3001, 1.2144, 0.1710, 1.3077,\n",
      "        0.7783, 0.8296, 0.4612], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([8.5535e-01, 6.1491e-01, 4.9985e-01, 3.3824e+00, 1.0035e+00, 2.2450e+00,\n",
      "        2.0814e-01, 1.2918e+00, 1.8478e+00, 8.2915e-01, 3.4384e-01, 6.2598e-01,\n",
      "        4.6910e+00, 2.0986e+00, 1.0820e+00, 1.5238e+00, 5.4616e-01, 1.2549e+00,\n",
      "        5.3135e-01, 1.5556e+00, 1.1971e+00, 7.7687e+00, 4.7018e+00, 1.0679e+00,\n",
      "        7.8758e-02, 8.5902e-01, 9.4368e-01, 4.1018e-01, 6.7411e-01, 1.2746e-02,\n",
      "        9.1607e-01, 1.0984e+00, 9.3222e-04, 9.6110e-01, 7.4542e-01, 2.9410e-01,\n",
      "        1.0231e-01, 1.0289e+00, 3.2975e-01, 1.0137e+00, 1.0240e+00, 1.3282e+00,\n",
      "        9.2550e-01, 6.3012e-01, 4.0052e+00, 3.8735e-01, 4.6247e+00, 2.7997e+00,\n",
      "        1.7188e+00, 7.6510e-01, 4.3897e-01, 6.4175e-01, 1.8310e-01, 1.0790e+00,\n",
      "        9.6159e-01, 8.0910e-01, 1.2447e+00, 6.3971e-01, 1.0548e+00, 7.7590e-01,\n",
      "        1.8622e+00, 3.3262e-01, 5.3122e-01, 1.3566e+00, 8.0778e-01, 1.0677e+00,\n",
      "        1.0947e+00, 6.8614e-01, 6.0125e-01, 1.0026e+00, 2.0638e+00, 1.8101e+00,\n",
      "        5.7003e-01, 8.9222e-01, 8.3290e-03, 6.6128e-01, 2.2250e+00, 4.5694e-01,\n",
      "        2.7109e-01, 9.0232e-01, 1.0263e+00, 2.1763e+00, 1.5619e+00, 1.1469e+00,\n",
      "        3.6879e-02, 3.0963e-01, 3.5882e-01, 3.6854e+00, 2.6757e-01, 1.6145e+00,\n",
      "        1.2302e+00, 2.1096e+00, 3.0290e+00, 1.6340e+00, 2.2453e+00, 9.5940e-01,\n",
      "        1.1493e+00, 7.1152e-01, 2.1811e+00, 4.3799e-02, 9.3831e-01, 1.8309e+00,\n",
      "        9.3897e-01, 2.2175e+00, 1.2540e+00, 1.0847e+00, 4.4708e-01, 5.0781e-01,\n",
      "        3.8646e+00, 6.5110e+00, 2.1972e-01, 8.5516e-01, 2.5259e-01, 3.5285e-01,\n",
      "        8.2351e-02, 1.0238e+00, 2.4095e-01, 2.7802e-01, 1.7540e+00, 7.6254e-01],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.1103, 0.3725, 0.1108, 0.7438, 0.9126, 0.2623, 3.9649, 1.4307, 1.6025,\n",
      "        1.2395, 1.9396, 1.0144, 0.8129, 1.4490, 1.9104, 0.2401, 0.6358, 0.6214,\n",
      "        0.5793, 0.7397, 0.4982, 1.3195, 0.5894, 0.3243, 1.0851, 0.6811, 0.4641,\n",
      "        0.3013, 1.2012, 1.3378, 0.4724, 0.6442, 1.0261, 0.9392, 0.1493, 1.6348,\n",
      "        0.8384, 0.5523, 1.2360, 0.9923, 1.6062, 0.8969, 0.0778, 0.6982, 1.1762,\n",
      "        3.8792, 3.5354, 1.1807, 1.1203, 0.7335, 0.9727, 1.1926, 1.4535, 0.5533,\n",
      "        0.9655, 0.8891, 0.5948, 0.1927, 3.2048, 0.4782, 1.5334, 0.2930, 1.2464,\n",
      "        0.7993, 0.7233, 0.7719, 0.7997, 1.4404, 0.8740, 1.6164, 1.0049, 0.4530,\n",
      "        0.8912, 1.0776, 1.0353, 0.5638, 0.4841, 0.6440, 0.7235, 1.2148, 0.6482,\n",
      "        3.6020, 0.9785, 1.2379, 0.9873, 0.9550, 0.5886, 0.9823, 1.1291, 0.8586,\n",
      "        0.9330, 0.9232, 1.5336, 0.4648, 0.0794, 0.2013, 1.1778, 1.1880, 0.6721,\n",
      "        0.8767, 0.6923, 0.7555, 0.4790, 0.7910, 1.1166, 0.4719, 2.5298, 0.7032,\n",
      "        0.9292, 0.1534, 0.7281, 0.5776, 0.0490, 1.6360, 0.2599, 0.9156, 0.6375,\n",
      "        1.1057, 1.1199, 0.5651], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([7.2044e-01, 3.1285e-01, 8.2336e-01, 3.4695e-01, 8.7336e-01, 5.3187e-01,\n",
      "        7.7350e-01, 8.1192e-01, 1.2901e+00, 9.1921e-01, 6.7098e-01, 8.6720e-01,\n",
      "        7.1903e-01, 4.2226e-01, 1.1772e+00, 7.8581e-01, 7.3736e-01, 9.2763e-01,\n",
      "        8.8822e-01, 1.2708e+00, 2.8090e-01, 1.9392e-01, 1.0437e+00, 7.7290e-01,\n",
      "        9.0049e-01, 6.4328e-02, 8.2703e-01, 6.6783e-01, 4.0662e-01, 1.0447e+00,\n",
      "        7.6995e-02, 1.6757e-01, 1.0107e+00, 1.2942e-02, 1.0509e+00, 1.0429e+00,\n",
      "        7.8359e-01, 2.8325e-01, 2.5684e+00, 6.5860e-01, 1.1792e-01, 3.5080e-01,\n",
      "        2.2550e+00, 7.7645e-01, 2.6204e-01, 6.1433e-01, 1.2796e+00, 2.3261e+00,\n",
      "        2.7132e-01, 7.7009e-01, 1.0393e+00, 1.8333e+00, 1.3655e+00, 3.6427e-01,\n",
      "        8.3660e-01, 3.7909e-04, 3.5407e-01, 9.3875e-01, 1.1393e+00, 1.6847e+00,\n",
      "        8.9999e-01, 6.4365e-01, 1.2686e+00, 8.2632e-01, 1.4680e+00, 1.0636e+00,\n",
      "        1.1065e+00, 8.7365e-01, 1.4308e-01, 6.9251e-01, 2.0234e+00, 1.5863e+00,\n",
      "        1.1153e+00, 7.8668e-01, 8.8758e-01, 7.6076e-01, 1.0890e+00, 9.6698e-01,\n",
      "        7.1109e-01, 9.3676e-01, 8.9791e-03, 2.7820e+00, 1.0514e-01, 1.4648e+00,\n",
      "        8.8514e-01, 3.6737e-01, 9.9115e-01, 1.3328e+00, 2.5978e+00, 5.3882e-01,\n",
      "        6.2934e-01, 1.0392e+00, 6.1437e-01, 8.9945e-01, 1.3680e+00, 2.5974e-01,\n",
      "        2.1201e+00, 1.1453e+00, 1.3108e+00, 2.1367e-02, 1.9167e-01, 7.1305e-01,\n",
      "        7.3221e-01, 3.1121e-01, 4.0013e-01, 1.3186e+00, 1.4844e+00, 1.0665e+00,\n",
      "        9.6587e-01, 2.2187e-01, 3.2300e-01, 7.3388e-01, 1.0027e+00, 8.3574e-01,\n",
      "        1.0702e+00, 1.6720e+00, 2.3889e-01, 5.7615e-02, 9.8090e-01, 6.4398e-01],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([5.7383e-01, 5.0069e-01, 3.3994e-01, 3.3878e-01, 7.5752e-01, 8.0889e-01,\n",
      "        1.0074e+00, 1.0340e+00, 3.3655e-01, 6.5652e-01, 3.5241e-01, 4.8821e-01,\n",
      "        2.6462e+00, 1.1717e+00, 5.2795e-01, 7.5615e-01, 7.0974e-01, 3.2005e-01,\n",
      "        5.8413e-01, 1.0502e+00, 7.7467e-01, 5.5832e-01, 6.7903e-01, 7.9302e-01,\n",
      "        8.1552e-01, 1.7484e-01, 7.0428e-01, 1.6468e+00, 1.7010e+00, 8.6731e-02,\n",
      "        6.5420e-01, 3.3149e-01, 9.7671e-01, 2.1033e+00, 8.4221e-01, 2.0783e+00,\n",
      "        6.9810e-01, 1.8021e+00, 5.0154e-01, 3.3304e+00, 1.5302e+00, 4.2021e-01,\n",
      "        2.4196e-02, 2.6712e+00, 2.0715e+00, 6.8764e-01, 2.0778e-01, 2.9376e-01,\n",
      "        1.9226e-01, 7.4558e-01, 9.4362e-01, 1.0409e+00, 9.5347e-01, 1.0887e+00,\n",
      "        8.9307e-01, 7.3735e-02, 6.4814e-01, 4.9807e-01, 1.5144e+00, 2.3761e-01,\n",
      "        6.7164e-01, 2.5170e-01, 8.0931e-01, 3.2481e-01, 1.0592e+00, 3.5028e-03,\n",
      "        7.8045e-01, 1.1073e+00, 1.6419e-01, 4.4192e-01, 4.2682e-01, 2.6818e+00,\n",
      "        1.6918e+00, 1.0604e+00, 2.5456e-01, 9.6789e-01, 5.2548e-02, 6.5021e-01,\n",
      "        8.7250e-01, 8.8139e-02, 1.2703e+00, 3.7196e-01, 4.5719e-01, 4.5428e-01,\n",
      "        1.0077e+00, 2.4485e+00, 1.2505e+00, 9.6114e-01, 2.4402e+00, 2.8820e+00,\n",
      "        1.2902e+00, 6.6133e-01, 2.7472e-01, 9.5614e-01, 9.3364e-01, 1.0081e+00,\n",
      "        1.5071e+00, 7.0930e-01, 2.3774e-01, 2.7564e+00, 1.2274e-01, 6.5450e-01,\n",
      "        2.9036e-01, 6.3780e-01, 5.7161e-01, 1.0354e+00, 8.3730e-01, 6.8957e-01,\n",
      "        8.0473e-01, 1.1538e+00, 1.1850e+00, 1.8335e-01, 5.5988e-01, 1.5024e+00,\n",
      "        7.3493e-01, 6.0804e-01, 3.1383e-01, 6.5028e-01, 3.7249e-01, 1.4077e-03],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.1628, 0.4858, 0.2904, 1.7596, 1.1905, 0.8487, 0.2300, 1.0417, 0.0351,\n",
      "        0.1743, 0.7390, 1.6315, 3.3750, 1.7693, 1.5096, 0.3362, 1.1742, 1.3336,\n",
      "        0.9799, 1.8232, 0.2286, 0.7445, 1.9057, 1.8068, 1.7425, 0.6388, 1.2267,\n",
      "        0.9714, 1.2371, 0.4404, 0.6504, 0.5936, 0.7081, 0.4903, 0.4629, 1.0726,\n",
      "        0.9148, 0.1805, 1.3222, 0.9430, 1.2687, 1.0204, 0.8490, 1.4795, 0.9803,\n",
      "        6.2507, 3.9505, 0.3614, 0.4574, 2.1346, 1.8470, 0.7567, 0.4861, 0.9982,\n",
      "        2.3135, 1.1419, 0.5563, 3.2440, 2.7637, 0.8785, 1.0904, 0.8679, 1.9396,\n",
      "        0.9647, 0.2621, 0.2260, 0.6736, 0.4980, 0.5566, 2.1980, 1.4291, 2.5527,\n",
      "        1.6273, 0.1636, 2.0483, 2.2856, 1.8997, 0.3760, 1.2635, 1.6751, 0.5007,\n",
      "        0.7834, 0.7063, 0.0401, 0.4787, 2.4126, 1.2534, 1.1131, 1.8702, 0.0491,\n",
      "        1.7476, 2.1032, 3.1835, 1.1799, 1.1276, 0.1855, 0.2584, 1.1237, 1.0567,\n",
      "        0.8753, 0.7752, 1.7174, 4.4683, 1.8277, 0.4971, 0.5902, 0.7943, 0.0323,\n",
      "        0.9504, 0.2265, 1.1883, 0.3873, 0.9893, 2.2048, 0.5117, 0.7897, 2.5836,\n",
      "        2.9929, 0.5814, 3.6661], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([8.1529e-01, 1.1786e+00, 3.2705e-01, 8.1305e-01, 1.5787e+00, 1.1207e+00,\n",
      "        7.5661e-01, 8.1066e-01, 1.8694e+00, 7.5995e-01, 1.3663e+00, 6.0181e-02,\n",
      "        2.6870e+00, 9.3229e-02, 1.7167e+00, 3.6173e+00, 1.4082e+00, 3.5133e+00,\n",
      "        9.9112e-01, 1.2866e+00, 2.9402e-01, 2.5123e+00, 7.1941e-01, 1.2297e+00,\n",
      "        2.9635e-01, 4.9571e-01, 8.9650e-01, 8.6951e-01, 6.7105e-01, 1.3024e-01,\n",
      "        6.9211e-01, 1.3098e-01, 9.0079e-01, 1.2550e+00, 3.4483e-01, 8.8165e-01,\n",
      "        1.9621e+00, 3.1853e+00, 1.7625e+00, 2.9826e+00, 1.6025e+00, 7.5663e-01,\n",
      "        1.6484e+00, 1.0021e+00, 4.9831e-01, 2.6115e+00, 5.2720e+00, 6.8374e-01,\n",
      "        9.4204e-01, 7.4242e-01, 1.5675e+00, 2.6687e+00, 1.8764e+00, 7.5986e-01,\n",
      "        5.5303e-01, 7.5317e-01, 3.6616e-01, 1.4549e+00, 2.5915e+00, 1.6623e-01,\n",
      "        1.6378e+00, 5.4416e+00, 7.3765e+00, 7.4394e-01, 7.4702e-01, 2.1956e-01,\n",
      "        3.2996e-01, 5.3697e-01, 6.1699e-01, 7.8089e-01, 4.2575e+00, 1.1521e+00,\n",
      "        7.4597e-01, 1.7755e+00, 1.1005e+00, 1.7520e+00, 5.8306e-01, 1.1542e+00,\n",
      "        9.9681e-01, 1.4657e-01, 1.4727e+00, 1.0246e+00, 2.4582e+00, 2.4528e+00,\n",
      "        1.4071e+00, 2.3230e-01, 4.5826e-01, 1.7022e-01, 2.5884e+00, 5.5093e-01,\n",
      "        1.9943e+00, 4.5511e-01, 6.5003e-01, 8.7259e-01, 8.5617e-01, 5.0130e-01,\n",
      "        7.5075e-02, 1.7634e+00, 1.6855e+00, 1.8121e+00, 6.6484e-01, 1.5705e-01,\n",
      "        1.3550e+00, 3.8044e-01, 2.3311e-01, 3.6587e-01, 5.5456e-01, 3.3313e-01,\n",
      "        9.0534e-01, 6.1298e-01, 3.9233e-03, 2.3413e+00, 5.1374e-02, 2.2054e+00,\n",
      "        1.2637e-01, 1.5716e+00, 1.2482e+00, 5.0602e-01, 1.7337e-01, 5.8347e-01,\n",
      "        3.5392e-01, 1.4487e-01, 3.2057e-01], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.9874e+00, 3.0818e-01, 1.8975e-01, 3.9246e-01, 7.2060e-01, 2.8327e-01,\n",
      "        1.0715e+00, 1.5601e+00, 8.9073e-01, 8.4578e-01, 1.7935e+00, 1.0228e+00,\n",
      "        3.0539e-01, 1.7856e+00, 1.1596e+00, 4.5262e-01, 9.0703e-01, 3.8994e-03,\n",
      "        7.7465e-01, 7.6107e-01, 2.1472e+00, 9.0128e-01, 7.6087e-01, 1.4147e+00,\n",
      "        2.0705e+00, 2.3745e+00, 1.1421e+00, 7.0547e-01, 2.8626e-01, 5.8501e-01,\n",
      "        3.7383e-01, 3.9903e-01, 4.0383e-01, 3.6375e-01, 5.2997e+00, 3.2519e+00,\n",
      "        1.9847e+00, 9.6568e-01, 1.6884e+00, 8.0576e-01, 1.0562e+00, 1.1782e+00,\n",
      "        5.5569e-01, 8.1295e-01, 7.3248e-01, 8.1657e-01, 5.3439e-01, 1.3456e+00,\n",
      "        1.5832e+00, 8.9057e-01, 6.9476e-01, 3.6293e-01, 3.6787e+00, 5.5039e-02,\n",
      "        3.0465e+00, 2.1490e+00, 2.6420e-01, 1.3758e-01, 9.6995e-01, 4.4795e-02,\n",
      "        2.2891e-02, 4.8104e-01, 1.0066e+00, 6.6188e-01, 1.2559e+00, 2.2994e-01,\n",
      "        6.9523e-01, 7.6675e-01, 8.6303e-02, 2.1416e+00, 1.8108e+00, 4.7019e-02,\n",
      "        7.3102e-01, 2.2387e+00, 7.1742e-01, 2.1027e+00, 1.4211e+00, 1.5053e+00,\n",
      "        1.3564e+00, 6.9629e-01, 1.1673e+00, 1.0375e+00, 3.1857e-01, 5.9394e-01,\n",
      "        9.9539e-01, 7.8449e-03, 2.1908e-01, 1.0044e+00, 7.0337e-01, 1.2952e-01,\n",
      "        1.5193e+00, 1.1651e+00, 1.5814e+00, 4.2591e-01, 3.0229e-01, 1.3329e+00,\n",
      "        2.3519e+00, 1.5384e+00, 1.3326e+00, 1.4091e+00, 1.2900e+00, 6.4012e-01,\n",
      "        8.4433e-01, 7.5026e-01, 5.1288e-01, 3.7694e-02, 3.4598e-01, 2.0101e+00,\n",
      "        1.2138e+00, 4.1196e-01, 2.3822e-01, 9.0933e-01, 1.1909e+00, 1.9654e-01,\n",
      "        6.4598e-01, 1.5107e+00, 8.0156e-01, 4.8347e-01, 1.1588e+00, 1.3048e+00,\n",
      "        3.6930e-01, 7.2885e-01, 3.7559e-01], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.5796, 1.0324, 0.2091, 1.3787, 1.0701, 0.7512, 1.1550, 0.7538, 0.4553,\n",
      "        0.3144, 0.6149, 0.5954, 0.9646, 0.8667, 2.0305, 0.8909, 0.4022, 0.9413,\n",
      "        0.5199, 0.0448, 0.7145, 0.7240, 0.4016, 0.7575, 0.8216, 0.7277, 0.3783,\n",
      "        0.5787, 0.4131, 0.1775, 1.7416, 1.5866, 1.1106, 3.4125, 1.6639, 0.1547,\n",
      "        0.7045, 0.6028, 0.6430, 1.0452, 0.4371, 0.8245, 0.4929, 0.3381, 1.1352,\n",
      "        0.6550, 0.2465, 0.6979, 0.7899, 0.6890, 0.8948, 0.5078, 0.7526, 1.2564,\n",
      "        0.0773, 0.3936, 1.0172, 1.1500, 0.9346, 0.7320, 0.9548, 0.9910, 0.9154,\n",
      "        0.2406, 0.8416, 0.7395, 1.1139, 0.8952, 0.1830, 1.4414, 0.6635, 1.1353,\n",
      "        0.5516, 0.8890, 0.5394, 0.3730, 0.7508, 0.6619, 0.2357, 0.1456, 1.2570,\n",
      "        0.5924, 0.3362, 0.3791, 0.7717, 0.9598, 0.1049, 0.9348, 0.7376, 0.8258,\n",
      "        1.3766, 0.8019, 0.5564, 1.0769, 0.8118, 1.2178, 1.3353, 0.5975, 0.7607,\n",
      "        0.9500, 0.1490, 1.4114, 0.6008, 0.7405, 0.7576, 0.5804, 0.3392, 1.2074,\n",
      "        0.6301, 0.9458, 0.2401, 0.1173, 0.8327, 0.2153, 0.4826, 0.5737, 0.2429,\n",
      "        0.4354, 2.5586, 1.7366, 0.6807, 2.2136, 0.1830], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.2431, 0.5607, 0.3277, 0.8531, 0.8705, 0.5434, 1.0977, 0.2055, 0.0944,\n",
      "        0.7606, 0.6984, 0.2244, 0.4030, 0.1352, 0.5838, 1.3885, 0.8664, 0.1461,\n",
      "        0.9251, 0.9797, 1.5444, 0.1879, 1.0528, 0.3272, 0.8332, 0.7304, 0.3929,\n",
      "        0.0617, 0.1841, 0.5637, 1.2948, 0.1521, 1.5356, 1.0838, 0.6762, 0.7687,\n",
      "        0.7473, 1.3482, 1.0583, 0.7787, 0.5176, 0.3325, 0.5923, 0.8431, 1.0053,\n",
      "        0.8585, 0.3772, 1.0468, 0.1328, 1.1580, 0.9582, 0.9257, 1.5070, 1.3008,\n",
      "        1.1726, 0.1921, 0.7214, 0.8849, 0.9653, 0.7894, 0.7168, 0.7169, 0.8554,\n",
      "        0.9064, 0.5289, 0.3461, 1.1929, 0.0645, 1.3462, 0.5067, 1.2765, 1.8658,\n",
      "        1.3119, 1.2847, 0.6079, 0.5238, 0.8592, 0.8399, 0.8525, 1.0252, 0.8087,\n",
      "        1.2325, 0.1624, 1.0467, 1.2297, 1.6844, 0.9729, 0.7118, 0.2281, 0.0127,\n",
      "        0.9202, 0.2758, 1.0714, 1.6936, 2.3484, 0.4222, 1.2620, 1.1479, 1.4803,\n",
      "        0.3178, 0.4768, 0.8962, 1.3520, 1.2962, 0.7062, 0.8440, 1.0356, 1.0905,\n",
      "        1.4474, 0.2937, 0.2707, 0.7763, 0.0196, 1.3894, 0.4072, 0.5427, 0.8574,\n",
      "        0.8641, 1.0407, 0.1388, 0.9927, 0.9483, 0.8633], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([3.2915e-01, 2.7330e-01, 8.5090e-01, 1.8883e-01, 2.7389e-01, 1.0535e+00,\n",
      "        3.2416e-01, 1.6273e+00, 2.0712e+00, 4.8891e-02, 1.7482e+00, 9.5414e-01,\n",
      "        1.6379e+00, 1.1027e+00, 3.2619e-01, 1.7750e+00, 1.3689e+00, 8.3114e-01,\n",
      "        2.5482e-01, 9.4432e-01, 1.0771e+00, 9.4810e-01, 1.3102e+00, 6.7760e-01,\n",
      "        3.4470e-01, 1.0610e+00, 1.8504e-01, 1.1841e-02, 7.6508e-01, 1.2310e+00,\n",
      "        9.0700e-04, 4.8422e-01, 1.0854e+00, 1.0267e+00, 1.0535e+00, 4.5719e-01,\n",
      "        1.0805e+00, 1.1467e+00, 6.5654e-01, 1.8890e+00, 1.9450e+00, 1.7264e+00,\n",
      "        2.7319e-01, 1.9371e-01, 5.1872e-01, 2.2689e+00, 1.6703e+01, 3.1870e+01,\n",
      "        1.0876e+00, 4.0139e+00, 1.4861e+00, 8.6556e-01, 2.1296e+00, 8.3042e-01,\n",
      "        6.8136e-01, 1.1610e+00, 3.7742e+00, 5.5466e-02, 9.9406e-01, 1.8489e-01,\n",
      "        5.1878e-01, 5.4306e-01, 3.9623e-01, 8.9873e-01, 9.7123e-01, 6.4470e-02,\n",
      "        3.2220e-01, 3.3940e+00, 2.6711e+00, 1.1990e+00, 6.2765e-01, 4.7174e+00,\n",
      "        6.6543e-01, 1.4648e-01, 3.7366e-01, 3.0571e+00, 7.5683e-01, 2.1844e+00,\n",
      "        9.9319e-01, 1.2114e+00, 1.0780e+00, 1.0074e+00, 1.1084e+00, 2.7203e+00,\n",
      "        2.9661e+00, 8.0009e-01, 1.7683e-01, 7.9414e-01, 9.0365e-01, 7.9729e-01,\n",
      "        9.4513e-01, 6.5213e-01, 2.9862e+00, 5.1578e-02, 4.4803e-01, 5.7740e-01,\n",
      "        4.5024e-01, 1.0364e+00, 6.6137e-01, 6.1428e+00, 1.7430e-01, 2.2537e+00,\n",
      "        1.2716e+00, 1.3171e+00, 1.0217e+00, 1.9479e+00, 2.0751e+00, 1.4739e+00,\n",
      "        7.0010e-01, 1.3675e+00, 3.1592e-01, 9.3340e-01, 3.9172e-01, 1.1172e+00,\n",
      "        3.0407e-01, 1.5255e-01, 5.6918e-02, 6.2259e-01, 1.3064e+00, 2.2408e+00,\n",
      "        2.3282e+00, 6.0471e-01, 7.0696e-01], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([4.0443e-01, 8.9803e-01, 9.3161e-01, 1.5105e+00, 1.1763e+00, 1.4842e+00,\n",
      "        3.0907e-01, 7.7553e-01, 6.1651e-01, 1.2069e-01, 1.4576e+00, 2.1117e+00,\n",
      "        1.3189e-01, 1.8918e-01, 1.7045e-01, 1.3925e+00, 1.0964e+00, 1.1287e+00,\n",
      "        8.6166e-01, 7.5952e-01, 2.1211e+00, 1.8582e+00, 1.6446e+00, 8.9599e-01,\n",
      "        3.6574e-01, 3.3050e-01, 6.8510e-01, 5.4928e-01, 3.2246e-01, 4.1602e-01,\n",
      "        3.3274e-01, 9.1584e-01, 9.9632e-01, 6.7710e-02, 3.1092e+00, 1.3143e+00,\n",
      "        1.0408e+00, 4.3603e-01, 8.3502e-01, 4.6219e-01, 8.2666e-01, 4.1368e-01,\n",
      "        1.9756e+00, 5.0120e-01, 2.4904e+00, 5.2150e-01, 1.0063e-01, 3.5725e-01,\n",
      "        8.3111e-01, 1.0029e+00, 4.8529e-01, 3.6085e-01, 8.0561e-01, 1.1666e+00,\n",
      "        5.2533e-01, 1.2502e+00, 2.4446e-01, 1.6168e-01, 1.2555e+00, 4.0330e-01,\n",
      "        1.6422e+00, 1.0508e+00, 1.1327e+00, 7.5985e-01, 8.4553e-02, 1.2806e+00,\n",
      "        4.3190e-03, 2.1958e-01, 6.0670e-01, 1.0843e+00, 2.4098e-02, 4.9545e-01,\n",
      "        2.2275e-01, 9.6188e-01, 7.5336e-01, 1.2494e+00, 1.0218e+00, 4.9282e-01,\n",
      "        2.0642e+00, 1.5068e+00, 9.3300e-02, 1.6065e+00, 2.1094e+00, 1.3338e-01,\n",
      "        7.0826e-01, 1.4840e+00, 2.7204e-04, 6.0060e-01, 5.1492e-01, 1.1483e+00,\n",
      "        8.7072e-01, 3.7736e-01, 1.1230e+00, 3.7987e-01, 1.0117e+00, 4.0038e-01,\n",
      "        7.5123e-01, 3.9399e-01, 6.2666e-01, 2.2947e+00, 2.6097e+00, 8.5053e-01,\n",
      "        3.3185e-01, 1.0291e+00, 8.9625e-02, 9.7492e-01, 5.7045e-02, 4.2486e+00,\n",
      "        8.5495e-01, 7.5491e-01, 1.5177e-01, 2.4502e+00, 9.3972e-01, 1.8592e+00,\n",
      "        5.3288e-01, 8.9499e-02, 7.5101e-01, 1.8947e-01, 1.3438e+00, 7.4953e-01,\n",
      "        2.4615e-01, 1.1162e+00, 1.8236e+00], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([6.2019e-01, 1.6320e-04, 8.4926e-01, 5.3753e-01, 7.8149e-02, 9.4891e-01,\n",
      "        4.0967e-01, 1.9251e+00, 2.1941e-01, 7.4532e-02, 3.4012e-01, 4.5176e-01,\n",
      "        1.2055e+00, 4.5275e-01, 1.4861e+00, 9.1608e-01, 1.7526e-01, 1.1478e+00,\n",
      "        4.7614e-01, 4.0847e-01, 1.4038e-02, 6.8634e-01, 1.0007e+00, 1.1002e+00,\n",
      "        3.5163e+00, 9.4161e-01, 1.7224e+00, 3.5892e-01, 1.9012e+00, 6.6096e-01,\n",
      "        1.2044e+00, 4.1662e-01, 4.6924e-01, 4.7611e-01, 6.4348e-01, 1.8120e+00,\n",
      "        1.2801e-01, 1.3189e+00, 4.8668e-01, 1.2258e+00, 2.5552e-01, 5.3985e-01,\n",
      "        1.8228e-01, 1.5541e-01, 1.0426e+00, 3.2523e-01, 1.0834e+00, 1.7669e+00,\n",
      "        8.4988e-01, 5.1950e-01, 1.8295e-02, 8.7787e-01, 6.1700e-01, 1.4447e+00,\n",
      "        5.2635e-01, 2.2534e+00, 1.6843e-02, 8.4486e-01, 8.9669e-01, 8.3678e-01,\n",
      "        2.1717e-01, 4.9828e-02, 1.9904e+00, 2.6224e+00, 1.1739e-01, 1.7365e-01,\n",
      "        5.8133e-01, 4.3715e-01, 1.0581e+00, 5.0251e-01, 1.7234e+00, 1.2756e-01,\n",
      "        5.0953e-01, 1.5427e-01, 2.9612e-01, 5.8205e-01, 1.2690e+00, 1.0913e+00,\n",
      "        2.5126e-01, 4.4242e-01, 1.0492e+00, 9.8286e-01, 4.3354e-01, 6.4750e-01,\n",
      "        5.1808e-01, 3.5595e-01, 3.4267e-01, 1.0523e+00, 7.7918e-01, 3.7752e-01,\n",
      "        1.8145e-01, 6.5362e-01, 1.0234e+00, 8.6596e-01, 5.2741e-01, 5.8301e-01,\n",
      "        2.5944e-01, 9.9873e-01], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.7112, 0.5768, 0.7817, 0.7272, 0.6606, 0.5530, 3.1210, 0.4375, 0.8173,\n",
      "        0.0414, 1.2275, 0.2741, 1.7781, 1.6815, 1.2255, 1.1761, 0.8770, 1.2878,\n",
      "        3.0279, 2.1217, 0.8950, 0.8649, 2.3251, 2.1691, 1.2818, 1.8137, 0.6402,\n",
      "        1.5005, 1.8385, 1.8165, 1.4547, 0.7357, 0.0283, 0.7713, 0.8812, 0.1289,\n",
      "        0.6735, 1.5732, 1.3644, 0.6849, 0.7196, 0.1877, 1.3092, 0.2492, 0.5299,\n",
      "        1.6320, 1.5910, 0.8695, 2.2458, 2.1541, 0.6566, 0.2843, 0.0520, 0.3279,\n",
      "        0.5000, 0.4828, 0.2875, 1.7021, 1.5104, 0.5152, 1.6356, 0.0881, 0.9977,\n",
      "        2.2894, 2.7390, 4.8231, 0.7434, 1.1562, 0.5042, 0.1338, 0.7491, 1.1475,\n",
      "        1.5005, 1.0611, 0.3328, 0.5356, 2.1111, 0.7495, 1.2595, 0.2351, 1.1412,\n",
      "        1.1390, 1.1165, 1.0983, 1.1075, 1.5236, 1.0146, 1.2830, 0.3260, 0.8945,\n",
      "        2.0260, 0.5309, 1.2942, 1.8043, 0.9333, 0.6217, 0.3260, 0.6732, 1.1502],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0031, 0.4625, 0.2208, 0.7182, 0.3857, 1.0969, 0.4517, 1.9133, 0.7880,\n",
      "        0.2111, 0.6597, 1.0516, 0.5904, 1.1368, 1.1059, 1.2169, 0.1229, 0.5378,\n",
      "        0.9120, 0.9854, 0.5123, 1.7592, 0.5079, 1.6274, 2.2376, 0.7422, 0.9858,\n",
      "        2.0790, 2.9232, 0.4317, 2.0094, 2.2464, 1.3401, 2.2907, 2.6604, 1.3367,\n",
      "        2.7552, 2.8626, 0.1586, 0.3012, 1.2453, 0.5965, 0.1686, 0.2741, 0.4346,\n",
      "        2.3166, 1.4587, 0.2958, 0.3721, 0.9317, 1.0982, 0.4318, 1.2343, 0.2202,\n",
      "        1.0659, 0.0159, 0.4926, 0.5173, 0.2540, 0.8946, 0.5554, 0.0881, 0.5929,\n",
      "        1.5823, 0.9386, 1.2374, 0.1319, 0.0541, 0.7087, 0.3262, 0.3992, 0.5979,\n",
      "        1.9915, 0.9289, 0.9749, 1.0135, 1.5392, 1.4394, 1.9493, 1.7408, 1.4423,\n",
      "        2.6204, 2.6218, 0.1460, 2.8397, 1.5392, 0.3215, 4.2864, 2.5919, 0.4582,\n",
      "        4.1750, 0.9647, 4.3137, 0.0045, 0.4760, 0.9950, 0.3597, 0.4465, 2.0928],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([3.6927e-02, 9.7072e-01, 4.0158e-01, 4.5168e-01, 9.9028e-01, 5.5841e-02,\n",
      "        1.5874e-01, 6.8552e-01, 1.1422e+00, 4.2866e-01, 9.9941e-01, 1.3450e+00,\n",
      "        3.6523e-01, 1.2792e-01, 1.4821e+00, 6.9912e-01, 1.5895e+00, 9.3033e-01,\n",
      "        9.2267e-01, 1.1302e+00, 1.5482e+00, 1.4655e+00, 1.3694e+00, 2.8510e-01,\n",
      "        1.5401e-01, 3.5050e+00, 2.5939e+00, 2.7445e-01, 7.1601e-01, 8.8392e-01,\n",
      "        9.1248e-01, 1.2638e-02, 1.0547e+00, 6.2368e-01, 1.1722e+00, 2.9865e-01,\n",
      "        5.4596e-02, 9.5169e-01, 1.4905e+00, 1.7234e+00, 2.3991e+00, 8.4340e-01,\n",
      "        8.5984e-02, 2.8625e-01, 6.8739e-01, 7.7518e-01, 1.2163e+00, 8.3622e-01,\n",
      "        9.8237e-01, 2.8185e+00, 1.9171e+00, 3.5321e-01, 5.4428e-02, 1.3199e-01,\n",
      "        9.9856e-01, 2.9659e-01, 1.1935e+00, 8.2806e-01, 1.4175e+00, 8.7786e-01,\n",
      "        8.6485e-01, 1.8372e-01, 6.2923e-01, 6.1337e-01, 6.7709e-01, 1.1049e+00,\n",
      "        6.4920e-01, 1.7966e-03, 4.4828e-01, 8.8887e-01, 1.2835e+00, 3.2308e+00,\n",
      "        3.9234e-01, 9.1592e-01, 4.3813e-01, 6.9386e-01, 3.5143e-02, 4.9024e-01,\n",
      "        1.2239e+00, 1.9027e-01, 5.0113e-01, 3.1214e-01, 2.0943e-01, 5.6751e-01,\n",
      "        2.2314e-01, 8.6463e-01, 4.5931e-01, 1.4537e+00, 6.2815e-01, 1.5315e+00,\n",
      "        1.3721e+00, 4.4553e-01, 5.9395e-01, 1.1061e+00, 9.9634e-01, 1.0237e+00,\n",
      "        6.9271e-01, 4.7625e-01, 3.0555e-02], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.2831, 0.3856, 0.9336, 0.2372, 1.0741, 0.8646, 2.2828, 1.9566, 1.0265,\n",
      "        1.7118, 0.9018, 1.9205, 1.0126, 2.4050, 3.6295, 1.8700, 0.1890, 1.4258,\n",
      "        0.0765, 0.7147, 3.4235, 0.6918, 1.2688, 1.0036, 0.8708, 0.3813, 0.0412,\n",
      "        0.6811, 1.6993, 0.3473, 0.0122, 1.0475, 0.3251, 0.5265, 0.6908, 1.7685,\n",
      "        2.9254, 0.0088, 1.9118, 1.8178, 1.6738, 3.7261, 0.7021, 0.1506, 0.4513,\n",
      "        0.8836, 1.1724, 1.1668, 4.7998, 1.1828, 1.7598, 0.0540, 0.9530, 0.3097,\n",
      "        1.9861, 0.1631, 0.4934, 1.6009, 0.9602, 0.4743, 1.2613, 0.7686, 0.4806,\n",
      "        0.3506, 2.1890, 2.5499, 0.2461, 2.2273, 1.5414, 0.1959, 1.1615, 0.8221,\n",
      "        1.1216, 2.0974, 1.8443, 0.7652, 0.1993, 4.9542, 0.6692, 1.4647, 0.9665,\n",
      "        1.5158, 0.4257, 0.6457, 0.2703, 1.3409, 0.7859, 0.8676, 0.4616, 0.0632,\n",
      "        0.6227, 0.8957, 0.5354, 0.0488, 0.0176, 0.3001, 1.0507, 2.8067, 0.4710],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.1461, 0.9363, 0.6811, 0.4797, 0.6918, 0.7969, 1.2695, 0.6911, 0.7728,\n",
      "        1.8272, 0.1152, 0.2920, 7.6050, 1.7542, 9.5250, 1.3861, 0.4504, 0.9018,\n",
      "        1.4385, 1.3430, 4.3231, 0.2725, 0.1807, 2.1769, 2.0856, 1.7304, 2.1981,\n",
      "        0.3478, 0.6085, 0.3309, 0.9030, 0.6069, 1.7445, 0.2096, 0.5433, 0.0294,\n",
      "        2.1658, 1.8348, 1.0914, 0.3674, 4.2953, 0.8369, 1.1343, 0.4399, 0.0968,\n",
      "        1.3740, 1.7774, 0.3466, 0.2811, 0.2928, 1.2127, 0.9937, 0.5592, 0.0147,\n",
      "        1.0438, 1.3765, 1.0292, 0.0153, 0.1502, 0.2658, 0.5893, 0.6870, 0.7938,\n",
      "        0.7101, 1.5935, 1.0438, 1.1793, 1.1165, 0.6124, 1.0554, 0.8624, 0.8223,\n",
      "        0.7639, 0.4399, 0.8713, 0.0749, 0.7319, 0.6543, 0.0334, 0.9446, 0.5256,\n",
      "        0.0969, 0.5935, 0.6036, 0.3979, 0.2140, 0.2946, 0.2181, 0.2895, 0.3688,\n",
      "        1.4121, 0.8556, 1.1400, 0.2148, 0.7281, 0.5715, 0.4420, 0.4930, 0.2211],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0642, 1.2670, 1.3294, 0.1047, 0.9314, 2.1174, 0.8012, 0.2306, 0.3061,\n",
      "        0.8588, 0.3009, 0.0418, 1.8716, 3.2769, 0.0219, 1.9950, 2.4609, 0.3982,\n",
      "        0.0791, 0.2008, 1.1606, 2.3081, 1.5421, 2.2610, 0.9911, 1.1426, 1.0316,\n",
      "        1.0667, 0.4862, 0.3240, 0.5475, 0.7759, 0.2607, 1.8088, 0.6816, 0.3517,\n",
      "        1.8159, 0.1766, 0.0731, 0.3376, 0.4586], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.6312, 0.6622, 0.6082, 0.2572, 0.3844, 1.6715, 0.0800, 1.9318, 1.5965,\n",
      "        0.9910, 0.5166, 0.3701, 0.4651, 1.0238, 0.7303, 0.8489, 2.1461, 0.5693,\n",
      "        1.1784, 0.8337, 0.1093, 0.8875, 0.4764, 0.1234, 1.7176, 0.9297, 0.7676,\n",
      "        0.3970, 0.3133, 0.4231, 3.5432, 1.9749, 0.1138, 0.5886, 0.8222, 0.7965,\n",
      "        0.6921, 0.7310, 0.3035, 3.5062], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0436, 0.3821, 1.0467, 1.1652, 1.0077, 0.2361, 0.3442, 1.2926, 0.0281,\n",
      "        2.4255, 7.4072, 2.3083, 0.0883, 0.4304, 0.1817, 3.7973, 0.2396, 1.8804,\n",
      "        0.0194, 0.5512, 0.4381, 6.9467, 2.1061, 8.9417, 0.0218, 0.5488, 0.6533,\n",
      "        0.1375, 0.6451, 0.3129, 0.0715, 1.0090, 0.4710, 2.0286, 1.5694, 0.6509,\n",
      "        0.3760, 0.1635, 1.4377, 1.2253], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.6162, 0.6184, 0.0132, 0.7572, 0.4944, 0.0940, 1.3563, 1.7040, 1.1271,\n",
      "        0.6019, 0.6859, 0.6676, 1.7432, 1.4237, 0.3829, 1.2736, 0.2140, 0.4089,\n",
      "        0.6735, 1.5080, 0.6187, 0.0805, 0.3901, 0.5517, 0.3538, 1.3018, 2.4241,\n",
      "        1.6686, 0.2132, 0.3354, 1.4199, 1.3490, 0.5842, 0.2371, 0.1044, 0.5374,\n",
      "        1.7969, 0.1034, 0.8660], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([9.9439e-01, 6.6090e-01, 1.0872e+00, 4.9726e-01, 4.1891e-01, 8.2524e-01,\n",
      "        1.0986e+00, 9.5094e-01, 1.0180e+00, 2.1125e+00, 1.4464e+00, 9.0015e-01,\n",
      "        6.9037e-01, 1.0436e+00, 1.1640e+00, 1.0052e+00, 8.0824e-01, 3.5976e-01,\n",
      "        2.0879e+00, 9.7562e-01, 8.6961e-01, 7.6795e-01, 5.2932e-01, 1.2846e+00,\n",
      "        3.4876e-01, 7.6463e-01, 1.2706e-02, 6.1615e-01, 1.0947e+00, 7.8860e-01,\n",
      "        1.2313e+00, 2.6805e-01, 1.1739e+00, 1.1047e+00, 7.8244e-01, 1.0824e+00,\n",
      "        6.8135e-01, 2.8423e+00, 1.5859e-01, 1.1229e-02, 1.8400e-03],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.5456, 0.2459, 1.0561, 2.3039, 1.1809, 0.4097, 0.1044, 0.8989, 1.2926,\n",
      "        1.7080, 0.6247, 1.4464, 0.4943, 0.9404, 0.8647, 0.6308, 0.2226, 0.4656,\n",
      "        0.1632, 0.5242, 2.2554, 1.2137, 0.9199, 0.8533, 1.0118, 0.4420, 0.1096,\n",
      "        0.5679, 0.4489, 0.3909, 1.2564, 0.3219, 1.4628, 0.9045, 1.3331, 1.2732,\n",
      "        0.7043, 2.0947, 2.8576, 0.0943, 0.2357, 0.0430], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([2.2819e+00, 6.9889e-01, 2.2626e+00, 4.5767e-01, 5.2923e-01, 7.0136e-01,\n",
      "        2.7818e-01, 2.3433e+00, 1.0313e+00, 1.2360e-01, 3.3062e-01, 6.8653e-01,\n",
      "        2.3767e+00, 1.5403e+00, 4.8223e-01, 2.7885e+00, 3.1001e-01, 6.8611e-01,\n",
      "        3.2187e+00, 2.8528e-01, 1.7155e+00, 2.3027e+00, 1.0763e+00, 2.3363e+00,\n",
      "        4.4262e-01, 9.6721e-01, 2.4626e-01, 3.7098e-01, 1.5763e+00, 9.5484e-01,\n",
      "        9.9960e-01, 7.9652e-01, 1.4712e+00, 1.6114e+00, 6.1097e-01, 4.2574e+00,\n",
      "        1.2527e+00, 5.6328e+00, 8.8329e+00, 1.0766e+00, 5.2223e+00, 6.3003e-01,\n",
      "        8.3654e-01, 1.1562e+00, 4.8548e-01, 3.5323e+00, 3.2173e-01, 1.5542e+00,\n",
      "        7.6457e-01, 7.5115e-01, 6.2465e-02, 9.3297e-01, 8.0415e-01, 4.8958e-01,\n",
      "        8.2469e-04, 4.0483e+00, 2.0131e+00, 6.2855e-01, 1.5258e+00, 1.2958e+00,\n",
      "        9.6486e-01, 3.6717e-01, 2.7154e+00, 1.2069e+00, 8.7380e-01, 1.7103e+00,\n",
      "        7.6558e+00, 4.5876e+00, 2.3056e+00, 1.1027e+00, 3.1732e+00, 4.5490e+00,\n",
      "        3.6431e+00, 1.1442e+00, 8.1062e-01, 5.5282e-01, 1.1051e+00, 2.2664e+00,\n",
      "        1.5153e+00, 2.5408e-01, 8.1569e-01, 1.5618e+00, 9.9123e-01, 7.3492e-01,\n",
      "        7.5191e-01, 1.4058e+00, 4.0326e-01, 5.0439e-01, 7.6225e-01, 3.1574e+00,\n",
      "        1.7940e+00, 2.3670e-02, 2.1609e+00, 2.2455e+00, 4.4502e-01, 2.4744e+00,\n",
      "        9.4693e-01, 3.9288e+00, 1.2326e-01, 1.0263e-01, 6.1779e-01, 6.4975e-01,\n",
      "        2.0822e+00, 3.4301e+00, 6.9541e-01, 9.4042e-01, 2.8013e-01, 7.7763e-01,\n",
      "        9.1067e-01, 1.0219e+00, 1.1190e+00, 2.8643e-01, 3.2106e+00, 1.5039e+00,\n",
      "        3.7209e+00, 3.8039e-01, 1.8370e-01, 6.7297e-01, 1.1925e+00, 1.1751e+00,\n",
      "        6.0396e-01, 3.6888e+00, 3.5600e+00, 1.1307e+00, 2.3177e+00, 8.2276e-01],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.3991, 0.2424, 0.3857, 0.7608, 1.6943, 0.9834, 3.3917, 0.9032, 0.8029,\n",
      "        1.1975, 1.1995, 0.6908, 0.2900, 1.7751, 1.3940, 0.5603, 0.9177, 0.5036,\n",
      "        1.4574, 1.1319, 0.4569, 0.4213, 0.4501, 0.7080, 2.1794, 1.7198, 0.3095,\n",
      "        0.7561, 0.5792, 0.8346, 0.9944, 2.0127, 3.1120, 1.5942, 0.9254, 1.8149,\n",
      "        4.8109, 0.9607, 1.6158, 0.8508, 0.3690, 0.8566, 0.7044, 0.7420, 0.9413,\n",
      "        0.9340, 0.5947, 0.2872, 1.6699, 0.3570, 0.1583, 1.1587, 1.4117, 1.1126,\n",
      "        1.1943, 0.0690, 1.5543, 1.0959, 0.6924, 0.5886, 0.5217, 0.6471, 0.6410,\n",
      "        0.6901, 1.9092, 1.1501, 3.0177, 0.1268, 2.7260, 0.0716, 3.6085, 1.1957,\n",
      "        0.4147, 1.1185, 1.0746, 0.5683, 0.3451, 0.7597, 1.1590, 2.0498, 1.7294,\n",
      "        1.1045, 1.2946, 0.9899, 1.0812, 0.2292, 0.9776, 1.7599, 3.4083, 0.6538,\n",
      "        3.2241, 2.4450, 0.5956, 0.5910, 1.0710, 0.5231, 1.5664, 4.2080, 0.3734,\n",
      "        0.2249, 3.2679, 0.0114, 0.9899, 1.3247, 0.8585, 0.9598, 0.4101, 0.7906,\n",
      "        1.1246, 1.4105, 0.7010, 1.4591, 1.0333, 1.0561, 0.2534, 1.0403, 0.1018,\n",
      "        0.9561, 1.2390, 0.6102, 0.1931, 0.4711, 1.8307, 0.7145, 0.9267, 3.3802],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.5248, 1.1710, 1.3930, 0.7426, 0.5015, 1.1270, 0.1187, 1.2209, 1.0726,\n",
      "        1.7139, 0.4551, 0.6003, 0.9321, 0.7642, 1.1595, 0.9122, 1.3081, 0.3134,\n",
      "        0.2469, 0.3306, 0.2238, 0.4408, 0.8153, 1.3727, 8.4801, 5.7705, 0.1923,\n",
      "        1.0837, 0.7522, 1.1093, 0.3763, 0.4723, 0.2033, 1.0557, 0.8186, 0.4539,\n",
      "        0.2511, 0.7584, 0.4395, 0.1696, 0.5893, 0.3626, 0.8884, 0.6116, 0.3942,\n",
      "        0.5852, 0.0238, 0.2955, 1.1549, 0.9696, 0.7635, 1.9193, 0.7337, 1.0336,\n",
      "        1.2095, 0.6461, 1.0361, 0.9667, 0.3152, 0.6967, 0.3643, 1.2434, 0.1902,\n",
      "        0.4671, 1.2913, 0.9510, 0.4654, 0.9495, 0.7662, 1.3443, 0.7128, 0.4695,\n",
      "        0.8682, 0.0442, 1.2058, 0.6854, 0.7594, 0.5893, 0.3375, 0.2691, 0.0944,\n",
      "        0.3910, 0.2055, 0.4530, 1.0774, 1.0254, 1.5342, 0.4701, 3.0801, 0.9171,\n",
      "        1.2384, 1.4752, 2.6433, 0.6724, 2.4416, 1.1941, 0.0627, 1.1678, 0.7974,\n",
      "        1.2826, 0.9834, 0.7371, 0.8847, 0.4780, 0.2681, 1.0693, 0.0810, 0.5016,\n",
      "        1.0645, 1.0169, 0.4603, 0.8596, 1.1032, 0.1614, 0.9656, 0.6035, 1.1858,\n",
      "        2.2785, 1.3569, 0.5969, 0.8427, 1.0649, 0.5391, 0.5340, 0.2571, 0.4105],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.6478, 0.7071, 0.7286, 1.4281, 0.0848, 0.2097, 0.7319, 0.7604, 1.0592,\n",
      "        0.6079, 1.2785, 1.2068, 1.4308, 1.0705, 1.5015, 0.5461, 0.5636, 1.0459,\n",
      "        1.3596, 0.1270, 0.9108, 0.8123, 0.7286, 0.8377, 1.0355, 0.8326, 0.9194,\n",
      "        0.7934, 0.0105, 0.9396, 0.9224, 0.6934, 1.0878, 1.0259, 0.2242, 0.3755,\n",
      "        0.8288, 0.8080, 0.7694, 0.6677, 0.6308, 1.0798, 1.2228, 1.0783, 1.3833,\n",
      "        0.7842, 0.9645, 1.0272, 0.7258, 1.0940, 1.0057, 0.7004, 0.8066, 0.9215,\n",
      "        2.0929, 1.5619, 0.6761, 0.9801, 0.9196, 0.4975, 0.4267, 1.0167, 0.5229,\n",
      "        0.2790, 0.9582, 0.6987, 1.3572, 0.9900, 1.4760, 0.3047, 0.8747, 0.2191,\n",
      "        0.9973, 1.0055, 1.4432, 0.4559, 0.8073, 0.9804, 0.6636, 0.0103, 0.4109,\n",
      "        0.9122, 0.9580, 0.5711, 0.6599, 0.9041, 1.0943, 0.9192, 1.2726, 1.0090,\n",
      "        2.4546, 2.4822, 0.7594, 0.9464, 0.7926, 0.9576, 0.3862, 0.9779, 0.4474,\n",
      "        0.6511, 1.0061, 0.8442, 0.7539, 0.6781, 1.8174, 1.0401, 0.3172, 0.9050,\n",
      "        1.1201, 0.0860, 0.8790, 0.9281, 0.5879, 0.2184, 1.1066, 0.9981, 0.7468,\n",
      "        0.9881, 0.5905, 1.2862, 1.4775, 0.7809, 0.2539, 0.7410, 0.7222, 1.1726],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.2130, 0.6032, 1.1073, 0.9071, 0.6813, 1.1368, 0.9770, 0.8860, 0.4190,\n",
      "        0.8680, 0.5295, 1.3093, 0.2292, 1.3171, 0.1255, 1.0140, 1.1543, 0.9018,\n",
      "        1.0210, 1.9089, 2.9256, 0.2395, 0.7735, 0.8408, 1.1458, 0.4354, 1.8595,\n",
      "        0.4831, 1.1673, 1.4644, 0.5399, 0.7025, 0.5620, 0.5555, 1.1503, 1.0962,\n",
      "        0.7269, 0.5492, 0.5318, 0.9347, 0.8304, 0.9789, 0.0121, 0.7952, 0.6704,\n",
      "        1.0874, 0.9649, 0.4858, 0.0702, 0.8189, 0.9753, 0.5425, 0.5983, 0.9088,\n",
      "        0.8245, 1.4643, 1.4075, 0.3623, 0.5784, 1.0300, 1.1616, 0.9865, 0.6025,\n",
      "        0.2012, 1.0986, 0.7319, 0.6060, 1.5771, 0.7788, 0.4138, 0.7623, 0.8040,\n",
      "        1.3464, 0.1720, 0.6684, 0.7023, 1.9380, 1.1988, 0.0856, 0.9301, 1.3048,\n",
      "        0.0237, 0.8934, 0.4005, 1.0346, 2.2713, 1.7967, 0.9029, 1.1473, 1.2567,\n",
      "        1.2839, 1.2974, 0.7041, 1.4201, 0.4772, 1.5441, 0.1825, 1.8566, 1.0283,\n",
      "        0.6822, 0.5677, 0.7031, 0.1491, 0.0431, 0.2721, 0.8709, 0.8183, 0.0764,\n",
      "        0.0953, 1.2821, 0.9819, 0.3849, 0.6135, 0.5565, 0.1955, 1.1938, 0.2441,\n",
      "        1.1549, 0.7474, 0.8974, 0.8279, 1.3460, 1.1602, 0.3146, 0.3327, 0.3853],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0243, 0.9534, 1.0468, 0.0394, 0.3834, 0.6644, 2.5675, 1.3891, 1.3711,\n",
      "        1.0527, 0.7659, 0.1429, 0.7969, 1.2197, 0.6488, 0.4233, 0.3812, 1.7358,\n",
      "        1.1426, 0.0423, 0.8500, 1.0140, 0.8981, 0.9159, 1.2876, 0.3975, 0.5599,\n",
      "        1.0624, 0.9241, 0.9336, 1.4099, 0.2632, 0.1106, 0.4766, 0.9070, 0.8162,\n",
      "        0.7293, 0.9307, 0.8016, 0.9489, 1.4733, 0.5926, 0.2381, 2.2594, 0.8484,\n",
      "        0.5511, 0.4363, 0.2262, 0.8433, 2.0789, 0.0705, 0.9454, 0.0340, 0.5788,\n",
      "        1.2277, 0.9779, 1.6401, 0.6534, 0.3703, 0.3063, 0.0356, 0.4322, 0.6700,\n",
      "        0.8461, 1.3742, 0.4813, 0.4915, 1.1900, 1.4159, 2.5769, 0.8202, 1.4456,\n",
      "        0.7768, 1.2509, 1.1579, 1.1464, 0.8893, 0.9711, 0.0746, 0.6268, 0.5887,\n",
      "        0.4588, 0.6035, 0.6900, 0.2456, 1.3043, 0.8560, 0.6028, 0.1734, 1.0235,\n",
      "        0.9486, 0.4334, 0.7745, 0.1982, 2.0181, 1.1446, 0.5270, 0.3539, 0.7492,\n",
      "        0.5575, 1.0845, 0.6854, 0.7093, 1.0155, 0.1778, 0.4732, 0.5394, 0.1494,\n",
      "        2.2168, 1.3045, 0.6397, 1.2007, 1.1116, 0.9328, 0.2621, 0.5686, 0.2220,\n",
      "        0.7006, 0.2086, 0.8507, 0.8517, 0.3881, 0.8412, 1.3097, 0.4677, 1.1407],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.2317, 5.6545, 4.6034, 0.4942, 0.5344, 0.6218, 0.2618, 0.5099, 1.0900,\n",
      "        0.8289, 1.9037, 0.3092, 0.9901, 0.8874, 1.1083, 0.8567, 1.5868, 1.1810,\n",
      "        2.1679, 0.1483, 1.2197, 0.3299, 2.1586, 1.0069, 0.3088, 0.4968, 0.2908,\n",
      "        0.5023, 2.5725, 2.7401, 1.5142, 0.5340, 0.6974, 0.2362, 2.8483, 0.6184,\n",
      "        1.6088, 0.7553, 0.2316, 1.1462, 1.2136, 0.7420, 0.0822, 1.2234, 0.0582,\n",
      "        1.9216, 0.4748, 1.5644, 0.5083, 1.5557, 0.9635, 1.0320, 1.2479, 1.0883,\n",
      "        0.5000, 0.7915, 2.5112, 0.9908, 1.8458, 0.7965, 0.6265, 1.1057, 0.3611,\n",
      "        0.6966, 1.4557, 3.6223, 0.5648, 2.3585, 0.6874], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([ 0.8420,  3.9278,  2.2287,  0.5287,  4.8153,  2.1460,  0.5370,  1.6268,\n",
      "         0.5479,  0.7591,  2.0633,  2.2424,  3.3369,  1.2684,  1.9364,  0.7718,\n",
      "         0.6492,  1.3306,  0.4520,  3.8026,  4.4240,  0.0571,  7.5289,  5.9130,\n",
      "         1.4778,  0.4767,  1.5740,  0.7077,  0.8037,  0.8967,  0.3586,  8.9657,\n",
      "         7.6720,  0.8166,  0.0811,  3.3076,  0.4482,  0.6340,  1.1707,  4.0666,\n",
      "         7.7831,  0.3985,  0.2576,  0.3443,  0.1275,  0.8190,  1.8053,  0.8778,\n",
      "         0.1592,  1.7018,  8.9536,  0.8139,  0.2896,  0.2407,  1.0180,  1.4091,\n",
      "         1.6105,  1.0114,  0.5235,  1.5932,  3.0329,  1.8530,  1.7430,  0.1903,\n",
      "         8.4607, 13.4524,  3.5811,  8.8292,  2.3574], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0202, 0.1282, 0.5028, 1.1228, 1.2122, 0.9516, 0.5020, 0.9211, 0.2697,\n",
      "        0.4014, 1.0124, 1.0766, 0.6409, 1.0338, 0.9992, 1.0223, 1.6952, 1.8360,\n",
      "        1.0897, 0.2749, 0.3935, 1.1035, 0.0175, 0.2504, 0.3095, 0.6203, 1.1251,\n",
      "        0.8755, 0.8482, 0.8241, 0.1508, 1.7193, 0.8684, 0.8453, 0.9305, 0.9801,\n",
      "        0.7787, 0.8145, 0.3741, 0.9196, 0.7696, 1.0354, 0.7433, 0.5571, 0.1796,\n",
      "        0.9431, 0.5086, 1.4031, 1.2723, 0.1841, 0.8367, 1.2165, 0.9592, 0.2759,\n",
      "        0.6334, 0.5402, 1.0422, 1.0077, 1.7187, 1.9510, 0.9901, 1.1538, 0.3013,\n",
      "        0.9923, 1.6060, 1.3446, 0.9263, 0.7929, 1.5231], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.5511, 1.1700, 1.2271, 0.7858, 0.8722, 0.7948, 0.9118, 0.9749, 0.9262,\n",
      "        0.9500, 1.0545, 1.0665, 0.9731, 0.9670, 0.9530, 1.0217, 0.9419, 1.0077,\n",
      "        0.9991, 0.7480, 0.8733, 0.6257, 1.3443, 1.0219, 0.9501, 0.9790, 0.9620,\n",
      "        0.6636, 0.9360, 0.8447, 0.3268, 0.7546, 0.1629, 1.0217, 0.7465, 0.8888,\n",
      "        1.0307, 0.8550, 1.0173, 1.0041, 1.0411, 0.9037, 0.7964, 0.9261, 1.0302,\n",
      "        0.9136, 0.8558, 0.8078, 0.4719, 0.9875, 0.9025, 1.1042, 1.0865, 1.0088,\n",
      "        1.1174, 0.8860, 1.0074, 0.7615, 1.0026, 0.9938, 0.7763, 1.0188, 0.9272,\n",
      "        0.8303, 1.0096, 0.9721, 0.7107, 0.2610, 0.8295], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0042, 0.9612, 0.9996, 1.0018, 0.9799, 0.9715, 0.9822, 0.9585, 1.0261,\n",
      "        1.0283, 0.9447, 0.9651, 0.8242, 1.0825, 1.1369, 0.7625, 0.8612, 0.6869,\n",
      "        0.4090, 0.9964, 0.9117, 0.9826, 0.9751, 0.8686, 0.9253, 0.9987, 1.0611,\n",
      "        0.6896, 0.9776, 0.9373, 0.8110, 0.7343, 0.6331, 0.9428, 0.8995, 1.0103,\n",
      "        0.6291, 1.0092, 1.0126, 0.9358, 0.4880, 0.9837, 0.9735, 0.9647, 0.9162,\n",
      "        0.9992, 1.1970, 1.0988, 1.0466, 1.0063, 0.3237, 1.0778, 1.0002, 1.0130,\n",
      "        0.9633, 0.9445, 0.8777, 0.8883, 0.9054, 0.9092, 0.9508, 0.9238, 0.9846,\n",
      "        0.9522, 0.9879, 1.0343, 1.0134, 0.8924, 1.0404], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0261, 1.0552, 0.8683, 0.8970, 0.9847, 0.9298, 0.9540, 0.7546, 0.8514,\n",
      "        0.9729, 1.0051, 0.9604, 0.9915, 1.0179, 0.9862, 1.0799, 0.9873, 0.9929,\n",
      "        0.2220, 0.9084, 0.9738, 1.0082, 0.9931, 1.0093, 0.9923, 0.9447, 0.9393,\n",
      "        0.6082, 0.7709, 0.9513, 0.6826, 0.8622, 0.9801, 0.9970, 1.0390, 0.9195,\n",
      "        0.9946, 1.0013, 0.9917, 1.0553, 0.9992, 0.9293, 1.0201, 0.8614, 1.0191,\n",
      "        0.6431, 1.1550, 1.0067, 0.7698, 0.6983, 0.9622, 0.9732, 0.8925, 0.9786,\n",
      "        0.9491, 1.0056, 0.9737, 1.0016, 1.0115, 0.8857, 1.0352, 0.8991, 0.7991,\n",
      "        1.0683, 1.0423, 0.9099, 0.9742, 0.8078, 0.8850], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0848, 0.9331, 0.8498, 0.9891, 0.9315, 0.9947, 0.9807, 0.7935, 0.9584,\n",
      "        0.8548, 0.9788, 0.8843, 0.8618, 1.0233, 0.7412, 0.9622, 0.9898, 1.0435,\n",
      "        1.0159, 0.8815, 1.0226, 0.9522, 0.8909, 0.9581, 0.9176, 0.8876, 0.6715,\n",
      "        1.0542, 1.1174, 0.8683, 0.9943, 1.0345, 1.0691, 0.5978, 0.7496, 0.6127,\n",
      "        0.9452, 0.9364, 0.9929, 0.9380, 0.9514, 1.0693, 0.9880, 1.0084, 1.0001,\n",
      "        0.6651, 0.5099, 0.8056, 0.7212, 0.9350, 0.2702], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0084, 0.5631, 0.7383, 0.4720, 0.7780, 0.9679, 0.0393, 0.3523, 0.3693,\n",
      "        0.7535, 0.9458, 0.9793, 0.9900, 0.9679, 1.0659, 0.8813, 0.9879, 1.0905,\n",
      "        0.9815, 0.9557, 0.8090, 0.6607, 0.6149, 0.8519, 1.0778, 1.0096, 0.8922,\n",
      "        0.9861, 0.9801, 0.6979, 0.9072, 0.9842, 0.7722, 0.9327, 1.1677, 0.9739,\n",
      "        0.9629, 1.1189, 0.9955, 1.1098, 1.0444, 0.8330, 0.7971, 0.8498, 0.8596,\n",
      "        0.8354, 0.9519, 0.3078, 0.9647, 0.6074, 0.8172], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.8808, 0.9489, 0.7798, 0.6930, 0.9358, 0.8224, 0.8565, 0.7644, 0.3710,\n",
      "        0.9383, 1.0006, 0.7962, 1.0410, 1.1932, 1.0366, 0.6324, 0.9659, 1.0665,\n",
      "        0.8837, 0.7983, 0.7701, 0.9324, 0.4344, 0.4295, 0.9507, 1.0100, 0.6855,\n",
      "        0.7397, 0.8274, 1.0099, 1.4411, 0.9497, 0.7590, 1.1189, 1.0283, 1.0069,\n",
      "        1.0094, 0.6723, 0.9556, 0.9986, 1.0690, 1.0137, 0.9099, 0.4242, 0.7306,\n",
      "        0.4186, 0.9279, 1.0255, 0.8486, 0.9917, 1.0530], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9518, 0.8315, 0.3709, 0.9856, 0.9965, 0.9141, 0.9052, 0.8702, 0.9042,\n",
      "        0.3797, 0.3331, 0.9041, 0.9036, 0.8032, 1.0268, 0.4911, 1.0136, 1.0498,\n",
      "        0.6538, 0.2783, 0.3287, 0.2441, 0.6085, 0.6827, 1.0265, 0.2136, 0.3606,\n",
      "        0.6876, 0.6849, 0.9902, 0.9039, 0.8148, 1.1705, 0.9854, 0.9136, 1.0122,\n",
      "        1.0743, 1.0898, 0.1070, 0.9697, 1.0197, 0.8974, 0.1775, 0.1588, 0.4821,\n",
      "        0.9046, 0.2918, 0.5534, 0.2853, 1.0136, 0.8936], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.5848, 0.7211, 0.1393, 0.9516, 0.5686, 1.1202, 0.2654, 1.1069, 0.2139,\n",
      "        1.1385, 0.8218, 1.0877, 0.4044, 1.3570, 1.4536, 0.9089, 0.9428, 0.9969,\n",
      "        1.1560, 1.3578, 0.9324, 0.0892, 0.2906, 0.8552, 1.5171, 1.0770, 0.7558,\n",
      "        0.4837, 0.7446, 1.1174, 0.8671, 1.6394, 2.7167, 0.4961, 0.8158, 0.5515,\n",
      "        0.5699, 1.5834, 0.5125, 1.2087, 0.7609, 1.6654, 1.1115, 0.8172, 1.0115,\n",
      "        0.8556, 0.5322, 0.0184, 1.1088, 0.1720, 0.0766], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.9587, 0.7191, 1.9305, 0.8327, 1.1500, 0.7990, 0.2988, 0.6826, 1.4600,\n",
      "        1.0605, 0.8431, 0.7292, 0.7189, 0.9861, 0.8186, 0.6562, 2.3899, 0.2497,\n",
      "        1.0181, 0.0586, 0.4853, 0.6093, 1.5705, 0.6060, 1.1527, 1.1488, 0.2717,\n",
      "        3.5903, 0.1956, 3.5249, 1.7640, 0.1789, 0.7112, 2.0715, 0.8927, 0.5600,\n",
      "        1.3999, 1.2320, 2.3065, 1.6021, 0.2821, 1.5850, 0.9500, 1.0031, 0.4761,\n",
      "        0.6936, 0.8326, 0.3228, 1.0183, 0.8321, 0.9286], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.2479e-01, 7.4738e-01, 3.5649e-01, 1.4554e-01, 3.3307e-01, 5.5658e-01,\n",
      "        2.5518e-01, 4.2098e-01, 3.4503e-01, 1.2848e+00, 1.4496e-02, 9.7667e-01,\n",
      "        7.7684e-01, 1.1440e+00, 1.6673e+00, 8.3145e-01, 8.1883e-01, 2.4486e-01,\n",
      "        6.8610e-01, 8.2502e-02, 1.9919e-01, 1.6240e+00, 5.2214e-01, 1.2688e+00,\n",
      "        8.6335e-01, 8.3010e-01, 1.0543e-02, 9.3519e-01, 2.0287e+00, 8.7588e-02,\n",
      "        1.0722e+00, 4.6102e-01, 1.2208e+00, 1.9351e+00, 7.2558e-01, 5.5198e-01,\n",
      "        1.0503e+00, 5.6148e-02, 6.4923e-01, 4.7012e-01, 7.9580e-01, 1.0995e+00,\n",
      "        4.5527e-01, 7.1287e-01, 7.7709e-01, 1.1645e+00, 1.1179e+00, 1.9950e+00,\n",
      "        8.5118e-01, 7.6025e-01, 4.0004e-01, 9.7084e-01, 8.7175e-01, 6.7005e-01,\n",
      "        1.8565e+00, 1.6404e+00, 2.3713e-01, 8.9908e-01, 2.0206e+00, 2.8922e-01,\n",
      "        9.7518e-01, 5.3980e-01, 4.9864e-01, 1.8433e-01, 3.4229e-01, 2.9897e-01,\n",
      "        9.7547e-02, 1.0874e+00, 1.0558e+00, 6.9353e-01, 7.1484e-01, 1.5709e+00,\n",
      "        4.7812e+00, 6.3676e-01, 1.3876e+00, 8.5609e-01, 1.0907e+00, 1.3446e-01,\n",
      "        1.1138e+00, 2.1559e-01, 7.5727e-01, 1.7469e+00, 8.0070e-01, 1.6367e+00,\n",
      "        1.8711e+00, 3.4385e-01, 1.9711e+00, 9.2281e-01, 7.7569e-01, 5.4936e-01,\n",
      "        7.7521e-01, 4.8888e-01, 3.9763e-01, 6.1686e-01, 8.9983e-01, 7.2881e-01,\n",
      "        7.8009e-01, 1.2055e+00, 5.1372e-01, 1.0782e+00, 2.5090e-01, 3.8349e-01,\n",
      "        8.7324e-01, 7.6268e-01, 7.3517e-01, 2.6320e+00, 6.1108e-01, 1.2926e+00,\n",
      "        8.4673e-01, 1.5316e-01, 9.3979e-01, 3.8606e+00, 1.0467e+00, 9.5100e-01,\n",
      "        7.8593e-01, 9.2036e-01, 9.8753e-01, 3.7608e-03, 2.6295e-01, 9.2319e-01,\n",
      "        6.6594e-01, 4.2338e-01, 9.2217e-01, 3.5397e+00, 1.8662e-01, 6.4394e-01,\n",
      "        7.6222e-01, 9.7985e-01, 9.0039e-01, 4.5881e-01, 1.2567e+00, 2.7640e-01,\n",
      "        1.1926e+00, 4.2529e-01, 6.5375e-01, 1.9069e+00, 1.1272e+00, 4.7751e-01,\n",
      "        9.4564e-01, 7.3941e-01, 9.6694e-01, 2.9299e-01, 6.0618e-01, 1.0398e+00,\n",
      "        1.4514e+00, 1.2512e+00, 1.0512e+00, 4.1410e-01, 5.0768e-01, 1.6201e+00,\n",
      "        2.4387e-01, 9.9404e-02, 3.7870e-01, 4.7801e-01, 4.5236e-01, 1.0716e+00,\n",
      "        3.9826e-01, 1.0161e+00, 9.9299e-01, 6.9152e-01, 9.1820e-01, 6.5537e-02,\n",
      "        2.0521e+00, 6.8451e-01, 5.6399e-01], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9930, 0.3378, 0.7812, 5.7474, 3.6394, 1.0100, 1.6001, 0.8740, 0.2991,\n",
      "        0.0123, 0.8944, 0.2231, 1.6758, 1.6035, 1.0427, 0.2278, 7.9135, 7.0979,\n",
      "        0.5708, 0.2793, 0.6620, 0.6024, 0.7315, 0.9141, 1.0820, 0.9652, 2.0816,\n",
      "        1.5334, 1.7776, 1.6127, 0.9361, 0.1607, 1.8977, 1.2281, 1.4295, 3.3282,\n",
      "        0.8493, 0.5261, 0.3268, 6.8592, 1.7441, 4.3238, 0.9817, 1.1583, 0.0389,\n",
      "        0.0140, 1.9396, 0.9783, 0.2957, 3.3621, 3.7537, 0.2847, 0.4218, 0.7493,\n",
      "        0.4286, 0.3519, 0.7447, 1.4538, 0.4812, 0.4757, 0.7906, 0.4090, 2.0279,\n",
      "        0.8320, 0.6658, 1.3672, 1.4112, 0.3162, 0.0145, 1.0259, 1.7812, 1.4210,\n",
      "        0.3452, 0.4610, 0.1847, 2.1806, 0.2485, 0.6266, 1.4932, 0.5358, 1.6359,\n",
      "        1.6117, 0.2468, 1.4644, 1.6273, 3.9958, 9.7452, 0.6216, 0.9164, 3.1641,\n",
      "        0.4632, 0.5858, 1.2577, 1.1039, 0.3644, 1.0332, 0.6956, 1.8998, 0.9342,\n",
      "        0.7898, 0.6934, 0.4216, 0.2174, 0.3103, 0.6960, 1.6326, 4.6699, 0.3249,\n",
      "        0.9601, 0.1127, 0.4235, 0.8423, 1.0236, 0.9849, 3.1135, 1.2861, 0.0952,\n",
      "        0.0688, 1.0993, 1.1316, 1.0134, 0.2249, 2.2894, 2.8313, 0.4087, 0.8154,\n",
      "        0.1639, 1.1735, 2.5629, 0.6834, 0.5519, 2.1766, 1.1464, 0.5094, 0.5265,\n",
      "        0.0580, 0.3076, 1.9260, 0.0859, 0.6031, 2.0698, 1.4264, 0.3248, 8.2700,\n",
      "        0.6624, 1.5848, 0.2380, 0.1784, 0.5343, 1.1632, 1.3615, 0.9372, 0.6445,\n",
      "        0.9752, 0.7219, 0.0391, 1.7662, 1.0314, 0.8602, 1.6750, 0.6683, 0.4615,\n",
      "        0.5366, 1.4567, 1.7710], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.7077, 1.0506, 1.4868, 0.4135, 0.9375, 0.8290, 0.0327, 0.7943, 0.9589,\n",
      "        0.0824, 0.9429, 0.7218, 0.4410, 0.7315, 1.2447, 2.1480, 1.3619, 0.8392,\n",
      "        0.9574, 0.1915, 1.1471, 0.8876, 2.2020, 0.4868, 0.0714, 0.1999, 0.6401,\n",
      "        2.0238, 0.5467, 1.5361, 0.6174, 1.1147, 1.4011, 0.1228, 0.2778, 0.5585,\n",
      "        3.9672, 0.0687, 0.7172, 1.1687, 0.5634, 0.8175, 1.0042, 2.0045, 1.5486,\n",
      "        1.2227, 0.1538, 4.3407, 0.8741, 0.3292, 0.3514, 0.1506, 0.4862, 0.8305,\n",
      "        0.2535, 0.1841, 0.6922, 1.0390, 0.9993, 0.5369, 0.0091, 1.3792, 1.2745,\n",
      "        0.9002, 0.9250, 0.2418, 0.6569, 0.9255, 0.2684, 0.4753, 0.0088, 0.9073,\n",
      "        0.9464, 0.9479, 0.9888, 1.6175, 0.5869, 0.6672, 0.9874, 0.3447, 0.7005,\n",
      "        2.4179, 1.4913, 0.6474, 2.5658, 0.3120, 2.5662, 0.2136, 0.8969, 1.4067,\n",
      "        0.4786, 1.0065, 0.3496, 0.1814, 1.0450, 0.7052, 2.7852, 1.1657, 0.7377,\n",
      "        0.4891, 0.3592, 0.9211, 0.1948, 0.6258, 0.2268, 0.1130, 0.3818, 1.8336,\n",
      "        0.7218, 1.1709, 1.1442, 1.5949, 1.9715, 0.4382, 0.3921, 0.4697, 0.2758,\n",
      "        0.4418, 0.7733, 1.3077, 4.4913, 2.6380, 0.5960, 1.5716, 1.3295, 0.5780,\n",
      "        1.2496, 0.4052, 0.6034, 0.6645, 0.0086, 0.0354, 0.5453, 0.3849, 0.9373,\n",
      "        2.0227, 1.1333, 0.1741, 2.2490, 0.9128, 0.1326, 0.0547, 1.5730, 0.3744,\n",
      "        0.5166, 2.8542, 1.6622, 0.8390, 0.2037, 0.3760, 0.8288, 1.1134, 1.1752,\n",
      "        1.7035, 1.0794, 0.0479, 0.2780, 1.1693, 1.3797, 2.3912, 0.3270, 2.3398,\n",
      "        0.5422, 0.7471, 0.3489], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.4708, 0.6901, 0.2785, 1.2676, 1.2297, 0.1683, 1.6413, 0.0122, 0.0834,\n",
      "        0.3869, 0.8397, 2.0412, 0.6568, 0.5410, 0.9316, 0.6099, 0.7286, 1.6962,\n",
      "        2.6300, 2.3942, 0.9052, 1.2737, 1.0164, 0.1382, 0.4365, 0.6629, 0.0150,\n",
      "        1.2224, 1.2256, 0.6982, 0.7015, 0.2172, 0.3964, 0.6248, 1.4868, 3.4885,\n",
      "        0.0883, 1.1555, 1.1323, 0.0495, 0.9333, 0.4503, 1.0002, 0.9991, 0.9524,\n",
      "        1.0105, 0.0441, 0.0517, 0.8575, 0.9755, 0.1106, 0.8049, 0.8826, 1.0466,\n",
      "        1.1984, 1.4243, 0.9907, 0.3284, 1.6590, 1.6110, 1.3195, 2.6423, 0.4097,\n",
      "        0.6519, 0.5539, 1.0728, 1.0004, 0.0436, 1.0752, 1.1736, 0.7745, 0.2202,\n",
      "        0.9976, 1.0107, 0.7467, 1.0088, 0.9537, 0.3709, 0.6267, 0.0689, 0.3620,\n",
      "        0.1916, 0.2768, 0.4245, 0.4088, 0.8932, 1.1879, 0.8625, 1.2459, 0.7477,\n",
      "        0.6427, 0.4828, 0.9963, 0.2130, 0.9144, 0.2528, 0.2617, 0.2156, 0.0937,\n",
      "        0.5545, 0.8760, 1.3112, 0.2801, 1.9382, 0.6796, 0.5338, 1.3616, 1.4057,\n",
      "        1.1168, 0.6091, 1.1542, 1.3268, 0.8497, 0.7392, 0.4015, 0.5419, 0.6804,\n",
      "        0.3527, 0.9870, 0.9991, 0.1865, 0.2086, 0.9965, 0.2172, 0.4341, 0.5996,\n",
      "        0.4869, 3.2029, 2.8452, 1.0691, 0.8694, 0.6573, 0.4617, 0.4605, 0.4572,\n",
      "        0.5651, 0.3603, 0.7324, 1.1769, 0.4480, 0.7348, 2.0764, 2.9752, 0.8053,\n",
      "        0.7510, 0.9955, 0.9206, 0.7260, 0.9665, 0.6150, 0.3760, 0.6866, 0.2001,\n",
      "        3.3833, 1.5126, 0.8255, 0.8230, 0.0389, 0.1580, 0.0177, 0.9232, 0.8101,\n",
      "        0.3795, 0.0691, 0.2995], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([2.2788e-01, 4.9356e-01, 2.3421e-01, 7.9508e-01, 1.0404e+00, 8.8414e-01,\n",
      "        4.2042e-01, 5.6129e-01, 1.4241e+00, 1.4678e+00, 8.1817e-01, 6.9589e-01,\n",
      "        2.4305e-02, 1.8044e-01, 3.5893e-01, 9.9992e-01, 1.0382e+00, 8.6232e-01,\n",
      "        6.9302e-01, 3.4520e-01, 8.7570e-01, 3.6301e-01, 1.4773e+00, 7.7369e-01,\n",
      "        1.8789e+00, 7.0272e-01, 9.4829e-01, 8.9403e-01, 5.9812e-01, 7.6076e-01,\n",
      "        6.8686e-01, 4.7058e-01, 7.8253e-01, 2.1170e-01, 1.9709e+00, 8.1080e-01,\n",
      "        4.5095e-01, 2.6641e-01, 5.2501e-01, 1.4847e+00, 1.1840e-01, 6.7793e-01,\n",
      "        5.9104e-01, 1.9750e-01, 1.9143e-01, 7.5895e-01, 9.6330e-01, 8.3662e-01,\n",
      "        8.0546e-01, 9.0143e-01, 3.7255e-01, 1.4437e+00, 2.2294e-01, 1.0468e+00,\n",
      "        1.2795e+00, 4.3878e-01, 6.3640e-01, 2.4480e-01, 1.1153e+00, 5.0687e-01,\n",
      "        7.7081e-02, 9.3516e-01, 2.9874e-01, 3.4623e+00, 8.7410e-01, 2.1402e+00,\n",
      "        1.2204e+00, 1.4671e+00, 1.4406e+00, 5.9087e-01, 1.0246e+00, 2.3584e-01,\n",
      "        9.6532e-01, 1.7196e+00, 3.2781e+00, 1.3935e+00, 4.7814e-01, 9.3709e-01,\n",
      "        1.0944e+00, 7.1053e-01, 1.6834e-01, 4.0702e-01, 2.8346e-01, 3.3817e-01,\n",
      "        3.5915e-03, 1.9486e+00, 1.8153e+00, 4.6089e-01, 1.5062e+00, 8.3593e-01,\n",
      "        8.6451e-01, 1.6878e-01, 1.0355e+00, 9.5514e-01, 4.3819e-01, 3.5542e-01,\n",
      "        2.7568e-01, 9.3155e-01, 9.6263e-01, 5.2075e-01, 3.5354e-01, 1.0310e+00,\n",
      "        4.3525e-01, 1.0214e+00, 8.8063e-01, 9.1316e-01, 5.3327e-02, 7.8637e-01,\n",
      "        1.0987e+00, 1.0110e+00, 4.4546e-01, 3.4953e-01, 8.5688e-01, 2.4258e-01,\n",
      "        6.6145e-01, 4.8656e-01, 7.0225e-01, 9.4152e-01, 6.1333e-01, 4.6685e-02,\n",
      "        1.4130e+00, 1.4923e+00, 6.2492e-01, 2.6242e+00, 1.6595e+00, 1.4026e+00,\n",
      "        9.3967e-01, 7.3366e-01, 9.1615e-01, 7.8920e-01, 9.6809e-01, 3.5662e-01,\n",
      "        1.4847e-01, 9.0384e-01, 3.6582e-01, 9.0213e-01, 7.9850e-01, 1.3530e+00,\n",
      "        1.8287e+00, 4.2818e-01, 5.5502e+00, 2.4832e-01, 3.7669e-01, 1.8017e-01,\n",
      "        4.1396e-01, 4.1522e-01, 6.3604e-01, 1.2783e-01, 1.5610e-01, 8.9625e-01,\n",
      "        7.1890e-01, 9.1021e-01, 8.1062e-01, 2.1302e+00, 5.5828e-01, 3.3174e+00,\n",
      "        6.8002e-02, 6.5935e-01, 1.4601e+00, 7.6244e+00, 1.1255e+00, 7.4901e-01,\n",
      "        2.6599e-01, 8.9309e-01, 9.4583e-01], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([5.5021e-02, 1.8524e-02, 1.0035e+00, 2.3643e+00, 8.4833e-01, 9.1551e-01,\n",
      "        3.9402e-01, 1.0974e+00, 2.3410e-01, 1.7397e+00, 7.8095e-01, 6.8429e-01,\n",
      "        1.6913e-01, 8.6262e-01, 1.1407e+00, 1.1036e+00, 6.3410e-01, 5.7294e-01,\n",
      "        5.9890e-01, 1.4642e-01, 6.3147e-01, 1.0055e+00, 4.3422e-01, 8.3844e-01,\n",
      "        1.3130e+00, 7.0586e-02, 1.6464e+00, 4.3867e-01, 2.6770e+00, 8.0146e-01,\n",
      "        4.3255e-01, 4.3016e-01, 1.8764e+00, 3.2963e+00, 4.7590e-01, 1.2854e+00,\n",
      "        9.6994e-01, 3.9072e-01, 4.9830e-01, 7.2641e-01, 3.5917e-01, 9.8106e-01,\n",
      "        1.3373e+00, 1.7375e-01, 1.0265e+00, 4.2117e+00, 8.1714e-01, 8.6162e-01,\n",
      "        3.3922e-01, 3.5568e-01, 4.0582e-01, 4.5367e-01, 2.5485e-01, 4.4341e-01,\n",
      "        1.0019e+00, 1.0027e+00, 1.0397e+00, 9.1150e-01, 9.9435e-01, 2.2099e-01,\n",
      "        8.6755e-01, 2.9886e-01, 1.9011e+00, 7.0621e-01, 1.3529e+00, 1.0008e+00,\n",
      "        5.9602e-01, 9.9971e-01, 6.0275e-01, 5.1600e-01, 9.2114e-01, 9.9668e-01,\n",
      "        2.4151e-01, 6.2768e-01, 9.7182e-01, 1.3426e+00, 1.8413e+00, 3.3732e-01,\n",
      "        2.2587e-01, 4.4707e-01, 1.8980e+00, 1.0493e+00, 8.1932e-01, 1.1732e+00,\n",
      "        8.0646e-01, 3.8302e-01, 5.8447e-01, 2.9686e-01, 4.1010e-02, 7.4351e-01,\n",
      "        7.2869e-01, 6.7180e-01, 1.4426e+00, 1.3124e+00, 9.8635e-01, 1.0480e+00,\n",
      "        8.5822e-01, 1.5586e+00, 8.7137e-01, 1.0761e+00, 1.1218e+00, 1.5478e-01,\n",
      "        4.7807e-01, 2.4316e-01, 9.0839e-01, 6.8340e-01, 6.1026e-01, 2.8847e-01,\n",
      "        9.4665e-01, 6.7055e-01, 1.5462e+00, 1.0990e+00, 1.8944e-03, 7.2641e-01,\n",
      "        5.8951e-02, 7.7399e-01, 1.3197e+00, 8.3813e-01, 9.9950e-01, 1.8011e+00,\n",
      "        1.2534e+00, 1.1443e-01, 5.3352e-01, 8.4359e-03, 1.0527e+00, 1.2302e+00,\n",
      "        2.2711e-02, 1.0612e+00, 1.9274e-01, 9.1494e-01, 1.4609e-01, 3.4131e-01,\n",
      "        3.4932e-01, 4.2347e-01, 9.9504e-01, 9.3328e-01, 1.3085e+00, 9.4375e-01,\n",
      "        5.8497e-01, 6.0859e-01, 3.7615e-01, 7.3157e-02, 5.1856e-01, 9.9544e-01,\n",
      "        1.4160e+00, 6.0235e-01, 7.5214e-01, 2.4071e-01, 7.0408e-01, 2.1104e-02,\n",
      "        1.0903e+00, 1.2986e+00, 1.2397e+00, 7.7611e-01, 6.9318e-01, 2.3144e-01,\n",
      "        4.4191e-01, 8.2123e-02, 5.8627e-01, 3.6044e-01, 7.3585e-01, 5.7550e-01,\n",
      "        4.6543e-01, 8.4955e-01], device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [04:33<18:00, 135.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 02/10 LOSS: 1.0119 tensor([ 79.9771,   6.9032,  15.0976,  17.1235,  28.2978,  98.8012,   8.5610,\n",
      "        108.1576,   1.7469,  19.5355,   2.8446,  35.4882,  44.4491,  10.1770,\n",
      "         45.7215,  10.5877,   1.1044,   7.5530,  35.4151,   9.8341,  47.6233,\n",
      "         63.6645,  47.3286,  71.3572, 159.3850,  70.3525,   9.1882,   0.5386,\n",
      "         76.7852,  78.9236,  88.2306, 262.2958,  86.8061, 231.2738,  35.9536,\n",
      "        187.3986,  80.5420,  27.8371,  48.8189, 153.7679, 310.9901, 147.9766,\n",
      "        408.3677, 111.2057,   1.3133,  18.5587,  22.6203,   8.8069,   4.5712,\n",
      "         15.8250,  25.1122,  56.9905,   2.9567], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9540, 0.9239, 0.9820, 0.9988, 0.9046, 0.8506, 0.6857, 1.0341, 1.0095,\n",
      "        1.0239, 1.0163, 0.9981, 0.9886, 1.0049, 1.0079, 1.0762, 0.9074, 0.9771,\n",
      "        1.0727, 0.9429, 1.0053, 0.9739, 1.0303, 1.0016, 0.9965, 1.0127, 1.0059,\n",
      "        0.9361, 0.9600, 0.9102, 0.9653, 1.1052, 1.0554, 0.9389, 1.0040, 0.9779,\n",
      "        0.9932, 0.8961, 0.9519, 1.2286, 0.9073, 0.5175, 0.9540, 1.0789, 1.0128,\n",
      "        0.9895, 0.9397, 0.9918, 0.8715, 0.9279, 0.9941, 0.9949, 0.9815, 0.8335,\n",
      "        0.9911, 1.0000, 1.0038, 1.1030, 1.0547, 0.9654], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.6835, 4.3592, 0.9985, 0.5052, 0.8044, 0.8266, 0.9077, 0.6194, 1.2781,\n",
      "        0.7791, 1.1226, 2.5468, 0.8366, 1.5456, 1.4644, 0.2724, 1.3025, 1.4993,\n",
      "        0.0347, 0.7347, 0.0695, 0.7752, 1.1352, 1.1333, 0.1403, 1.0598, 1.0137,\n",
      "        0.9677, 0.1336, 0.5569, 0.6019, 0.9204, 0.1639, 0.2607, 0.9386, 0.5781,\n",
      "        1.8202, 0.1787, 1.4663, 0.5971, 0.6256, 0.3795, 0.0958, 2.4269, 1.6257,\n",
      "        1.3784, 0.8005, 1.3830, 1.5789, 1.2024, 1.0467, 0.8029, 0.6400, 0.8731,\n",
      "        7.1042, 1.4000, 0.3184, 1.1122, 1.4672, 0.6154], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([ 3.0959,  1.1115,  1.5837,  1.0411,  1.0543,  4.5827,  1.2655,  0.3048,\n",
      "         1.4107,  0.0889,  0.5417,  0.4568,  1.0616,  3.2476,  7.3807,  8.9781,\n",
      "         0.0782,  1.1278,  1.4195,  1.4643,  3.1640,  1.1500,  0.7848,  4.6969,\n",
      "         7.6672,  9.2966,  2.2860,  2.5207,  1.5725,  3.2142,  1.6917,  0.4186,\n",
      "         2.0524,  1.2836,  1.2734,  1.1901,  5.7433,  2.5217,  1.1342,  0.8060,\n",
      "         2.3454,  0.7080,  5.5187,  1.8043,  1.2213,  1.5469,  0.9100,  1.4374,\n",
      "         0.6044,  0.5588,  0.3464,  1.6434,  1.3339,  0.9031,  0.5092,  0.8612,\n",
      "         1.5376, 10.7103,  3.3399], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.8463e+00, 1.5327e+01, 5.5005e+01, 1.5348e+02, 4.6795e+00, 8.7682e+01,\n",
      "        6.4177e+00, 2.7034e+00, 9.7624e-01, 1.5339e+01, 5.3623e+00, 2.9205e+00,\n",
      "        1.4244e+00, 3.8181e+01, 3.8386e+01, 1.2139e+02, 7.2714e+00, 4.0611e+01,\n",
      "        5.8850e-01, 1.8457e+01, 3.6871e+01, 1.1106e+02, 1.8404e+00, 1.5671e+01,\n",
      "        1.0297e+01, 1.6032e+01, 2.7192e+01, 2.2575e+00, 3.2914e+01, 1.1069e+00,\n",
      "        1.5380e+00, 1.8729e+00, 1.2977e+01, 4.8048e+01, 2.3609e+02, 1.2955e+01,\n",
      "        1.5128e+01, 7.7680e+00, 9.0784e+01, 4.8561e+01, 1.9125e+01, 4.2947e+01,\n",
      "        5.9387e-01, 2.7667e+00, 1.6771e-02, 4.5047e+01, 8.7504e+01, 4.1629e+00,\n",
      "        3.6532e+01, 7.0620e+00, 3.0859e+01, 3.6368e+00, 2.6761e+01, 2.6627e+01,\n",
      "        9.4855e+00, 1.1598e+02, 1.2957e+02, 1.6298e+01, 1.6872e+01],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([7.1439e+02, 1.5154e+02, 1.7183e+01, 1.6708e+02, 6.2089e+01, 1.2822e+02,\n",
      "        1.6577e+02, 5.4868e+02, 1.0055e+02, 3.1567e+01, 8.0860e+03, 9.6710e+03,\n",
      "        2.3383e+02, 1.8000e+00, 3.4017e+02, 1.5287e+02, 1.2925e+02, 1.3314e+02,\n",
      "        1.9400e+01, 4.1803e+02, 1.0213e+02, 1.2924e+01, 2.2179e+02, 9.7106e+02,\n",
      "        1.3825e+02, 6.5791e+02, 3.7440e+02, 1.2128e+01, 1.3526e+02, 1.4982e+03,\n",
      "        2.2133e+03, 2.2958e+02, 5.3601e+01, 2.2148e+01, 2.5169e+01, 9.2208e+01,\n",
      "        1.5274e+02, 4.1535e+02, 1.5195e+02, 1.0051e+02, 6.0790e+02, 1.4140e+01,\n",
      "        3.7064e+00, 5.5606e+01, 2.8177e+03, 1.1789e+03, 1.6531e+03, 6.9506e+02,\n",
      "        3.0350e+02, 1.0678e+05, 7.2100e+04, 3.8854e+01, 9.4908e+02, 7.5354e+02,\n",
      "        9.9279e+03, 2.9233e+04, 2.3594e+02], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([8.0908e+21, 2.6535e+21, 3.5998e+22, 6.1185e+23, 8.8004e+23, 1.9951e+22,\n",
      "        3.8941e+22, 6.2675e+22, 9.1753e+19, 3.9970e+23, 5.2602e+23, 9.0651e+23,\n",
      "        6.2842e+22, 1.1711e+24, 2.0700e+22, 1.2069e+21, 4.8187e+21, 1.7065e+23,\n",
      "        2.8838e+21, 2.5042e+23, 2.8794e+23, 2.9349e+23, 3.1196e+23, 1.2177e+23,\n",
      "        2.5759e+22, 2.4337e+22, 2.4550e+21, 9.4773e+23, 8.3675e+23, 1.4443e+22,\n",
      "        1.4217e+24, 3.2729e+23, 8.6811e+23, 4.1367e+22, 1.6946e+24, 2.5485e+23,\n",
      "        3.8605e+22, 3.7132e+23, 9.7287e+23, 1.4649e+23, 7.5259e+19, 7.5696e+22,\n",
      "        1.1398e+23, 8.3981e+21, 6.3666e+22, 1.5250e+23, 8.2901e+21, 4.2660e+23,\n",
      "        1.7676e+23, 1.8934e+22, 4.0511e+22, 2.3703e+22, 5.6302e+22, 9.1156e+21,\n",
      "        4.6080e+23, 5.7820e+22, 1.5020e+23, 2.1742e+22, 3.1728e+22, 1.1283e+24,\n",
      "        1.7306e+24, 7.0583e+22, 2.4396e+22, 3.0304e+23, 6.7661e+22, 1.3804e+23,\n",
      "        1.4301e+23, 2.1976e+21, 2.6660e+23, 4.0605e+22, 2.8414e+23, 8.9194e+22,\n",
      "        9.4132e+22, 1.1786e+23, 6.0018e+23, 5.0119e+23, 3.1810e+21, 3.1964e+21,\n",
      "        4.3133e+23, 2.7416e+23], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [05:56<23:47, 178.48s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-15-60de3835e7c4>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[1;31m# start training\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 31\u001B[1;33m \u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_trainer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-14-aa7d0667a7f9>\u001B[0m in \u001B[0;36mrun_trainer\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     44\u001B[0m                     \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# one backward pass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     45\u001B[0m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 46\u001B[1;33m                     \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     47\u001B[0m                     \u001B[0minput\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     48\u001B[0m                     \u001B[0mtarget\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "\n",
    "# model\n",
    "embedding_net = EmbeddingNet()\n",
    "model = embedding_net.to(device)\n",
    "\n",
    "\n",
    "# margin value\n",
    "margin=1\n",
    "\n",
    "# criterion\n",
    "criterion = TripletLoss(margin,  Informative_Negative_TripletSelector(margin))\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(model=model,\n",
    "                  device=device,\n",
    "                  criterion=criterion,\n",
    "                  optimizer=optimizer,\n",
    "                  training_dict=train_loader_dict,\n",
    "                  validation_DataLoader=train_loader_dict,\n",
    "                  epochs=10)\n",
    "\n",
    "# start training\n",
    "trainer.run_trainer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "name = 'test_scnn2'\n",
    "state = {'net': model.state_dict(),'loss': 1.0}\n",
    "if not os.path.isdir('checkpoint'):\n",
    "    os.mkdir('checkpoint')\n",
    "torch.save(state, './checkpoint/%s.t7'%(name))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['annotated_images', 'annotated_images_labels', 'unseen_images', 'unseen_images_labels'])\n"
     ]
    }
   ],
   "source": [
    "# load the test data:\n",
    "\n",
    "data_dict_test = load_data('test_data_task1.pkl')\n",
    "# keys are 'annotated_images', 'annotated_images_labels', 'unseen_images', 'unseen_images_labels'.\n",
    "# These keys correspond to the annotated images with known labels for each test alphabet (the sets A);\n",
    "# labels of the images with known labels for each test alphabet;\n",
    "# to-be-labeled unseen images for each test alphabet (sets U);\n",
    "# and labels of the to-be-labeled unseen images for each alphabet, respectively.\n",
    "# For each alphabet, the labels of the unseen images should be predicted by the model.\n",
    "# The true labels of the unseen images can only be used to calculate evaluation metrics.\n",
    "print(data_dict_test.keys())\n",
    "\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f82021775a0a6fbf",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Kannada annotated images: torch.Size([41, 1, 105, 105])\n",
      "Number of Kannada annotated labels: 41\n",
      "Shape of Kannada unseen images: torch.Size([779, 1, 105, 105])\n",
      "Number of Kannada unseen labels: 779. Use the unseen labels only for evaluating your model!\n"
     ]
    }
   ],
   "source": [
    "# example: let's get some annotated images and their labels for an alphabet in the test data:\n",
    "\n",
    "alphabets_test = list(data_dict_test['annotated_images'].keys())\n",
    "alphabet_id = np.random.randint(0, len(alphabets_test))\n",
    "alphabet = alphabets_test[alphabet_id]\n",
    "\n",
    "alphabet_annotated = data_dict_test['annotated_images'][alphabet]  # a tensor of shape (num_images, 1, height, width)\n",
    "print(f'Shape of {alphabet} annotated images:', alphabet_annotated.shape)\n",
    "\n",
    "alphabet_annotated_labels = data_dict_test['annotated_images_labels'][alphabet]  # a list of length num_images\n",
    "print(f'Number of {alphabet} annotated labels:', len(alphabet_annotated_labels))  # equals num_images\n",
    "\n",
    "alphabet_unseen = data_dict_test['unseen_images'][alphabet]  # a tensor of shape (num_images, 1, height, width)\n",
    "print(f'Shape of {alphabet} unseen images:', alphabet_unseen.shape)\n",
    "\n",
    "alphabet_unseen_labels = data_dict_test['unseen_images_labels'][alphabet]  # a list of length num_images\n",
    "print(f'Number of {alphabet} unseen labels: {len(alphabet_unseen_labels)}. Use the unseen labels only for evaluating your model!')  # equals num_images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eedf16c955d94af7",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# evaluation of the model:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1966916fdd423fe",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1.t7 LOSS:\t 1.0\n"
     ]
    }
   ],
   "source": [
    "# device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "def load_net(name,architecture, path = \"checkpoint/\"):\n",
    "    checkpoint = torch.load(path+name,map_location='cpu')\n",
    "    architecture.load_state_dict(checkpoint['net'])\n",
    "    architecture.eval()\n",
    "    print(name+' LOSS:\\t',checkpoint['loss'])\n",
    "    return architecture\n",
    "model = EmbeddingNet()\n",
    "model = load_net('test1.t7', model).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "char_dict = {f\"character{i:02d}\": i - 1 for i in range(1, 100)}\n",
    "annotated_loader_dict = {}\n",
    "annotated_images_dict = data_dict_test['annotated_images']\n",
    "annotated_targets_dict = data_dict_test['annotated_images_labels']\n",
    "# Iterate over the dictionary items (label: images_list)\n",
    "for alphabet in alphabets_test:\n",
    "    images = annotated_images_dict[alphabet]\n",
    "    targets = annotated_targets_dict[alphabet]\n",
    "    targets = [char_dict[key] for key in targets]\n",
    "    annotated_loader = torch.utils.data.DataLoader(list(zip(images, targets)), batch_size=200)\n",
    "    annotated_loader_dict[alphabet] = annotated_loader\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "char_dict = {f\"character{i:02d}\": i - 1 for i in range(1, 100)}\n",
    "test_loader_dict = {}\n",
    "test_images_dict = data_dict_test['unseen_images']\n",
    "test_targets_dict = data_dict_test['unseen_images_labels']\n",
    "# Iterate over the dictionary items (label: images_list)\n",
    "for alphabet in alphabets_test:\n",
    "    images = test_images_dict[alphabet]\n",
    "    targets = test_targets_dict[alphabet]\n",
    "    targets = [char_dict[key] for key in targets]\n",
    "    test_loader = torch.utils.data.DataLoader(list(zip(images, targets)), batch_size=200)\n",
    "    test_loader_dict[alphabet] = test_loader\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "200\n",
      "Targets (labels):\n",
      "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "         8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10])\n",
      "Batch 1:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "200\n",
      "Targets (labels):\n",
      "tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15,\n",
      "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17,\n",
      "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18,\n",
      "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19,\n",
      "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "        20, 21])\n",
      "Batch 2:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "94\n",
      "Targets (labels):\n",
      "tensor([21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
      "        22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n",
      "        24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "        25, 25, 25, 25])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#print(len(annotated_loader_dict['Atemayar_Qelisayer']))\n",
    "i=0\n",
    "for batch_idx, (inputs, targets) in enumerate(test_loader_dict['Atemayar_Qelisayer']):\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(\"Inputs (features):\")\n",
    "    print(type(inputs))\n",
    "    print(len(targets))  # Print input data (features)\n",
    "    print(\"Targets (labels):\")\n",
    "    print(targets)\n",
    "    i+=1\n",
    "print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "10"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_layer = list(model.children())[-1]\n",
    "last_layer.out_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def extract_embeddings(dataloader, model, out_features):\n",
    "    cuda = torch.cuda.is_available()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        embeddings = np.zeros((len(dataloader.dataset), out_features))\n",
    "        labels = np.zeros(len(dataloader.dataset))\n",
    "        k = 0\n",
    "        for images, target in dataloader:\n",
    "            if cuda:\n",
    "                images = images.cuda()\n",
    "            embeddings[k:k+len(images)] = model.get_embedding(images).data.cpu().numpy()\n",
    "            labels[k:k+len(images)] = target.numpy()\n",
    "            k += len(images)\n",
    "    return embeddings, labels\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e832c436112fef2",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 256, 380, 0.6736842105263158)\n",
      "('Atemayar_Qelisayer', 536, 874, 0.6132723112128147)\n",
      "('Atlantean', 763, 1368, 0.5577485380116959)\n",
      "('Aurek-Besh', 1136, 1862, 0.6100966702470462)\n",
      "('Avesta', 1400, 2356, 0.5942275042444821)\n",
      "('Ge_ez', 1646, 2850, 0.5775438596491228)\n",
      "('Glagolitic', 2010, 3705, 0.5425101214574899)\n",
      "('Gurmukhi', 2342, 4560, 0.5135964912280702)\n",
      "('Kannada', 2590, 5339, 0.4851095710807267)\n",
      "('Keble', 2944, 5833, 0.5047145551174352)\n",
      "('Malayalam', 3344, 6726, 0.4971751412429379)\n",
      "('Manipuri', 3618, 7486, 0.48330216403954046)\n",
      "('Mongolian', 3887, 8056, 0.48249751737835156)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 4429, 8911, 0.49702614745819773)\n",
      "('Oriya', 4650, 9785, 0.4752171691364333)\n",
      "('Sylheti', 4838, 10317, 0.4689347678588737)\n",
      "('Syriac_(Serto)', 5030, 10754, 0.46773293658173704)\n",
      "('Tengwar', 5248, 11229, 0.46736129664262177)\n",
      "('Tibetan', 5617, 12027, 0.46703251018541614)\n",
      "('ULOG', 5924, 12521, 0.4731251497484226)\n",
      "0.4731251497484226\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.4731251497484226"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_results(model, annotated_loader_dict, test_loader_dict, k):\n",
    "    correct=0\n",
    "    total_images = 0\n",
    "    last_layer = list(model.children())[-1]\n",
    "    out_features = last_layer.out_features\n",
    "    for alphabet in annotated_loader_dict.keys():\n",
    "        annotated_embeddings, annotated_targets = extract_embeddings(annotated_loader_dict[alphabet], model, out_features)\n",
    "        test_embeddings, test_targets = extract_embeddings(test_loader_dict[alphabet], model, out_features)\n",
    "        distances=cdist(annotated_embeddings,test_embeddings)\n",
    "        all_image_distances=[]\n",
    "        for i in range(len(test_targets)):\n",
    "            image_distances= []\n",
    "            for j in range(len(distances)):\n",
    "                image_distances.append((distances[j][i], j))\n",
    "            all_image_distances.append(sorted(image_distances))\n",
    "\n",
    "        k_classification = []\n",
    "        for i in range(len(all_image_distances)):\n",
    "            k_classification.append([score[1] for score in all_image_distances[i]][:k])\n",
    "        #print(all_image_distances)\n",
    "        for i in range(len(k_classification)):\n",
    "\n",
    "            if test_targets[i] in k_classification[i]:\n",
    "                correct+=1\n",
    "        total_images+=len(test_targets)\n",
    "        print((alphabet, correct, total_images, correct/total_images))\n",
    "\n",
    "    top_k_accuracy = correct/total_images\n",
    "    print(top_k_accuracy)\n",
    "    return top_k_accuracy\n",
    "get_results(model, annotated_loader_dict, test_loader_dict, 1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e87003112448465",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 336, 380, 0.8842105263157894)\n",
      "('Atemayar_Qelisayer', 693, 874, 0.7929061784897025)\n",
      "('Atlantean', 980, 1368, 0.716374269005848)\n",
      "('Aurek-Besh', 1405, 1862, 0.7545649838882922)\n",
      "('Avesta', 1769, 2356, 0.7508488964346349)\n",
      "('Ge_ez', 2100, 2850, 0.7368421052631579)\n",
      "('Glagolitic', 2563, 3705, 0.6917678812415654)\n",
      "('Gurmukhi', 3054, 4560, 0.6697368421052632)\n",
      "('Kannada', 3438, 5339, 0.6439408128863083)\n",
      "('Keble', 3839, 5833, 0.6581518943939654)\n",
      "('Malayalam', 4381, 6726, 0.651352958667856)\n",
      "('Manipuri', 4772, 7486, 0.6374565856265028)\n",
      "('Mongolian', 5134, 8056, 0.6372889771598809)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 5820, 8911, 0.6531253506901582)\n",
      "('Oriya', 6163, 9785, 0.6298415942769545)\n",
      "('Sylheti', 6448, 10317, 0.624987884074828)\n",
      "('Syriac_(Serto)', 6698, 10754, 0.622838013762321)\n",
      "('Tengwar', 6995, 11229, 0.6229406002315433)\n",
      "('Tibetan', 7516, 12027, 0.6249272470275214)\n",
      "('ULOG', 7893, 12521, 0.6303809599872214)\n",
      "0.6303809599872214\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.6303809599872214"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results(model, annotated_loader_dict, test_loader_dict, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 360, 380, 0.9473684210526315)\n",
      "('Atemayar_Qelisayer', 785, 874, 0.8981693363844394)\n",
      "('Atlantean', 1150, 1368, 0.8406432748538012)\n",
      "('Aurek-Besh', 1593, 1862, 0.855531686358754)\n",
      "('Avesta', 2028, 2356, 0.8607809847198642)\n",
      "('Ge_ez', 2428, 2850, 0.8519298245614035)\n",
      "('Glagolitic', 3023, 3705, 0.8159244264507423)\n",
      "('Gurmukhi', 3687, 4560, 0.8085526315789474)\n",
      "('Kannada', 4188, 5339, 0.7844165574077543)\n",
      "('Keble', 4634, 5833, 0.7944453968798217)\n",
      "('Malayalam', 5322, 6726, 0.7912578055307761)\n",
      "('Manipuri', 5830, 7486, 0.7787870691958322)\n",
      "('Mongolian', 6292, 8056, 0.7810327706057597)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 7058, 8911, 0.7920547637751094)\n",
      "('Oriya', 7554, 9785, 0.7719979560551865)\n",
      "('Sylheti', 7951, 10317, 0.7706697683435108)\n",
      "('Syriac_(Serto)', 8284, 10754, 0.7703180212014135)\n",
      "('Tengwar', 8660, 11229, 0.7712173835604239)\n",
      "('Tibetan', 9335, 12027, 0.7761702835287271)\n",
      "('ULOG', 9757, 12521, 0.7792508585576232)\n",
      "0.7792508585576232\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7792508585576232"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results(model, annotated_loader_dict, test_loader_dict, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 373, 380, 0.9815789473684211)\n",
      "('Atemayar_Qelisayer', 849, 874, 0.971395881006865)\n",
      "('Atlantean', 1283, 1368, 0.9378654970760234)\n",
      "('Aurek-Besh', 1752, 1862, 0.9409237379162191)\n",
      "('Avesta', 2226, 2356, 0.9448217317487266)\n",
      "('Ge_ez', 2672, 2850, 0.9375438596491228)\n",
      "('Glagolitic', 3378, 3705, 0.9117408906882591)\n",
      "('Gurmukhi', 4154, 4560, 0.9109649122807018)\n",
      "('Kannada', 4779, 5339, 0.8951114440906537)\n",
      "('Keble', 5259, 5833, 0.9015943768215327)\n",
      "('Malayalam', 6059, 6726, 0.9008325899494499)\n",
      "('Manipuri', 6676, 7486, 0.8917980229762222)\n",
      "('Mongolian', 7214, 8056, 0.8954816285998014)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 8033, 8911, 0.9014700931433061)\n",
      "('Oriya', 8689, 9785, 0.8879918242207461)\n",
      "('Sylheti', 9162, 10317, 0.8880488514102937)\n",
      "('Syriac_(Serto)', 9556, 10754, 0.8885995908499164)\n",
      "('Tengwar', 9981, 11229, 0.8888592038471814)\n",
      "('Tibetan', 10734, 12027, 0.8924918932402095)\n",
      "('ULOG', 11194, 12521, 0.8940180496765434)\n",
      "0.8940180496765434\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.8940180496765434"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results(model, annotated_loader_dict, test_loader_dict, 8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 2: rotation problem"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f49a6fcc9bcd5994"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load the test data for task 2:\n",
    "# the structure of the test data of task 2 is exactly the same as for task 1,\n",
    "# but now the images are rotated by an unknown angle between 0 and 360 degrees.\n",
    "data_dict_test_task2 = load_data('test_data_task2.pkl')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "800d9fa43d711ae0",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['annotated_images', 'annotated_images_labels', 'unseen_images', 'unseen_images_labels'])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict_test_task2.keys()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfd690817a188882",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# solution and evaluation of task 2:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab7aa34500088f66",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "71298802fa5d6fb8",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4e6e3e82ce917c0f",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e701b2a68bd4d32a",
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 3: Domain knowledge injection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfdbe34799376c36"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['unseen_images_labels', 'annotated_images_labels', 'unseen_images', 'annotated_images', 'unseen_images_preceding_types', 'character_to_type_mapping', 'type_following_probs'])\n"
     ]
    }
   ],
   "source": [
    "# load the test data for task 3:\n",
    "# the structure of the data of task 3 is exactly the same as for task 1, but now our the loaded dictionary contains some additional keys.\n",
    "# These additional keys will be explained in the cells below:\n",
    "\n",
    "data_dict_test_task3 = load_data('test_data_task3.pkl')\n",
    "print(data_dict_test_task3.keys())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa248dbece85da5c",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# The keys 'annotated_images', 'annotated_images_labels', 'unseen_images', 'unseen_images_labels' are the same as for task 1, and the structure of the data is exactly the same. \n",
    "\n",
    "# The key 'unseen_images_preceding_types' maps to the type of the preceding character in the sequence where the unseen image was observed, for each alphabet.\n",
    "# The key 'character_to_type_mapping' maps to the mapping of each character to its type, for each alphabet.\n",
    "# The key 'type_following_probs' maps to the probabilities of each character type being followed by another character type, for each alphabet."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fb6a6237a187493",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphabet: Old_Church_Slavonic_(Cyrillic)\n",
      "Some character types that preceded unseen images from the Old_Church_Slavonic_(Cyrillic) alphabet: ['II' 'I' 'II' 'II' 'II']\n",
      "There are 855 preceding character types in the Old_Church_Slavonic_(Cyrillic) alphabet, and 855 unseen images.\n",
      "Type of character02 from the Old_Church_Slavonic_(Cyrillic) alphabet: II\n",
      "Probability of a character of type I following a character of type I in the Old_Church_Slavonic_(Cyrillic) alphabet: 0.1588447653429603\n"
     ]
    }
   ],
   "source": [
    "# examples:\n",
    "\n",
    "alphabet = np.random.choice(list(data_dict_test_task3['unseen_images_preceding_types'].keys()))\n",
    "print(f'Alphabet: {alphabet}')\n",
    "\n",
    "\n",
    "preceding_character_types_alphabet = data_dict_test_task3[\"unseen_images_preceding_types\"][alphabet]  # a list\n",
    "print(f'Some character types that preceded unseen images from the {alphabet} alphabet: {np.random.choice(preceding_character_types_alphabet, size=5)}')\n",
    "print(f'There are {len(preceding_character_types_alphabet)} preceding character types in the {alphabet} alphabet, and {len(data_dict_test_task3[\"unseen_images\"][alphabet])} unseen images.')\n",
    "\n",
    "\n",
    "character_to_type_mapping_alphabet = data_dict_test_task3[\"character_to_type_mapping\"][alphabet]  \n",
    "# this is a dict, with as keys the characters and as values the types\n",
    "random_character = np.random.choice(list(character_to_type_mapping_alphabet.keys()))\n",
    "print(f'Type of {random_character} from the {alphabet} alphabet: {character_to_type_mapping_alphabet[random_character]}')\n",
    "\n",
    "\n",
    "\n",
    "type_following_probs_alphabet = data_dict_test_task3[\"type_following_probs\"][alphabet]  # a dict of dicts\n",
    "preceding_type = np.random.choice(list(type_following_probs_alphabet.keys()))\n",
    "following_type = np.random.choice(list(type_following_probs_alphabet[preceding_type].keys()))\n",
    "print(f'Probability of a character of type {following_type} following a character of type {preceding_type} in the {alphabet} alphabet: {type_following_probs_alphabet[preceding_type][following_type]}')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef9bcef5572f0a78",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'Angelic': ['II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II'],\n 'Atemayar_Qelisayer': ['II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I'],\n 'Atlantean': ['I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II'],\n 'Aurek-Besh': ['II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II'],\n 'Avesta': ['I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II'],\n 'Ge_ez': ['II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I'],\n 'Glagolitic': ['II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II'],\n 'Gurmukhi': ['II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II'],\n 'Kannada': ['II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I'],\n 'Keble': ['I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II'],\n 'Malayalam': ['II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I'],\n 'Manipuri': ['I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II'],\n 'Mongolian': ['I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II'],\n 'Old_Church_Slavonic_(Cyrillic)': ['II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II'],\n 'Oriya': ['I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II'],\n 'Sylheti': ['I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II'],\n 'Syriac_(Serto)': ['I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II'],\n 'Tengwar': ['II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I'],\n 'Tibetan': ['II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II'],\n 'ULOG': ['I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II']}"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict_test_task3['unseen_images_preceding_types']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbaa137b41e610ce",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380\n",
      "494\n",
      "494\n",
      "494\n",
      "494\n",
      "494\n",
      "855\n",
      "855\n",
      "779\n",
      "494\n",
      "893\n",
      "760\n",
      "570\n",
      "855\n",
      "874\n",
      "532\n",
      "437\n",
      "475\n",
      "798\n",
      "494\n"
     ]
    }
   ],
   "source": [
    "char_dict = {f\"character{i:02d}\": i - 1 for i in range(1, 100)}\n",
    "char_dict_rev = {i-1:f\"character{i:02d}\" for i in range(1, 100)}\n",
    "annotated_loader_dict_task3 = {}\n",
    "annotated_images_dict_task3 = data_dict_test_task3['annotated_images']\n",
    "annotated_targets_dict_task3 = data_dict_test_task3['annotated_images_labels']\n",
    "# Iterate over the dictionary items (label: images_list)\n",
    "for alphabet in alphabets_test:\n",
    "    images = annotated_images_dict_task3[alphabet]\n",
    "    targets = annotated_targets_dict_task3[alphabet]\n",
    "    targets = [char_dict[key] for key in targets]\n",
    "    annotated_loader = torch.utils.data.DataLoader(list(zip(images, targets, targets)), batch_size=200)\n",
    "    annotated_loader_dict_task3[alphabet] = annotated_loader\n",
    "\n",
    "\n",
    "test_loader_dict_task3 = {}\n",
    "test_images_dict_task3 = data_dict_test_task3['unseen_images']\n",
    "test_targets_dict_task3 = data_dict_test_task3['unseen_images_labels']\n",
    "preceding_type_dict = data_dict_test_task3['unseen_images_preceding_types']\n",
    "mapping_type_dict = data_dict_test_task3['character_to_type_mapping']\n",
    "# Iterate over the dictionary items (label: images_list)\n",
    "for alphabet in alphabets_test:\n",
    "    images = test_images_dict[alphabet]\n",
    "    targets = test_targets_dict[alphabet]\n",
    "    targets = [char_dict[key] for key in targets]\n",
    "    preceding_type = preceding_type_dict[alphabet]\n",
    "    print(len(preceding_type))\n",
    "    #mapping_type = [mapping_type_dict[alphabet][char_dict_rev[target]] for target in targets]\n",
    "    test_loader = torch.utils.data.DataLoader(list(zip(images, targets, preceding_type)), batch_size=200)\n",
    "    test_loader_dict_task3[alphabet] = test_loader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "700c29e735fd10c5",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('II', 'II', 'II', 'II', 'II', 'II', 'I', 'I', 'II', 'I', 'II', 'II', 'II', 'I', 'II', 'I', 'II', 'II', 'II', 'I', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'II', 'II', 'I', 'II', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'I', 'II', 'I', 'II', 'II', 'I', 'II', 'I', 'II', 'I', 'I', 'II', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'II', 'I', 'II', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'I', 'II', 'II', 'II', 'II', 'I', 'II', 'II', 'I', 'I', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'II', 'I', 'II', 'I', 'II', 'II', 'II', 'I', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'I', 'I', 'I', 'II', 'II', 'II', 'I', 'I', 'II', 'I', 'II', 'II', 'II', 'II', 'I', 'II', 'II', 'I', 'I', 'II', 'II', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'I', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'I', 'I', 'I', 'I', 'II', 'I', 'II', 'I')\n",
      "200\n",
      "Batch 0:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "200\n",
      "Targets (labels):\n",
      "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "         8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10])\n",
      "('I', 'II', 'I', 'II', 'II', 'I', 'I', 'II', 'II', 'II', 'II', 'I', 'II', 'I', 'I', 'II', 'I', 'I', 'I', 'I', 'I', 'II', 'II', 'II', 'II', 'II', 'I', 'II', 'I', 'II', 'I', 'II', 'II', 'II', 'II', 'I', 'II', 'II', 'I', 'II', 'II', 'I', 'I', 'I', 'II', 'II', 'I', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'I', 'I', 'I', 'I', 'II', 'I', 'I', 'I', 'II', 'I', 'I', 'II', 'II', 'I', 'I', 'I', 'II', 'II', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'II', 'I', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'II', 'I', 'II', 'II', 'I', 'II', 'I', 'I', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'I', 'II', 'I', 'II', 'I', 'I', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'I', 'I', 'II', 'II', 'II', 'I', 'I', 'I', 'II', 'II', 'I', 'II', 'II', 'I', 'II', 'I', 'I', 'I', 'I', 'I', 'II', 'II')\n",
      "180\n",
      "Batch 1:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "180\n",
      "Targets (labels):\n",
      "tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15,\n",
      "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17,\n",
      "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18,\n",
      "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19,\n",
      "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#print(len(annotated_loader_dict['Atemayar_Qelisayer']))\n",
    "i=0\n",
    "for batch_idx, (inputs, targets, p) in enumerate(test_loader_dict_task3['Angelic']):\n",
    "    print(p)\n",
    "    print(len(p))\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(\"Inputs (features):\")\n",
    "    print(type(inputs))\n",
    "    print(len(targets))  # Print input data (features)\n",
    "    print(\"Targets (labels):\")\n",
    "    print(targets)\n",
    "    i+=1\n",
    "print(i)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb7d09f31839b40",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 'character01',\n 1: 'character02',\n 2: 'character03',\n 3: 'character04',\n 4: 'character05',\n 5: 'character06',\n 6: 'character07',\n 7: 'character08',\n 8: 'character09',\n 9: 'character10',\n 10: 'character11',\n 11: 'character12',\n 12: 'character13',\n 13: 'character14',\n 14: 'character15',\n 15: 'character16',\n 16: 'character17',\n 17: 'character18',\n 18: 'character19',\n 19: 'character20',\n 20: 'character21',\n 21: 'character22',\n 22: 'character23',\n 23: 'character24',\n 24: 'character25',\n 25: 'character26',\n 26: 'character27',\n 27: 'character28',\n 28: 'character29',\n 29: 'character30',\n 30: 'character31',\n 31: 'character32',\n 32: 'character33',\n 33: 'character34',\n 34: 'character35',\n 35: 'character36',\n 36: 'character37',\n 37: 'character38',\n 38: 'character39',\n 39: 'character40',\n 40: 'character41',\n 41: 'character42',\n 42: 'character43',\n 43: 'character44',\n 44: 'character45',\n 45: 'character46',\n 46: 'character47',\n 47: 'character48',\n 48: 'character49',\n 49: 'character50',\n 50: 'character51',\n 51: 'character52',\n 52: 'character53',\n 53: 'character54',\n 54: 'character55',\n 55: 'character56',\n 56: 'character57',\n 57: 'character58',\n 58: 'character59',\n 59: 'character60',\n 60: 'character61',\n 61: 'character62',\n 62: 'character63',\n 63: 'character64',\n 64: 'character65',\n 65: 'character66',\n 66: 'character67',\n 67: 'character68',\n 68: 'character69',\n 69: 'character70',\n 70: 'character71',\n 71: 'character72',\n 72: 'character73',\n 73: 'character74',\n 74: 'character75',\n 75: 'character76',\n 76: 'character77',\n 77: 'character78',\n 78: 'character79',\n 79: 'character80',\n 80: 'character81',\n 81: 'character82',\n 82: 'character83',\n 83: 'character84',\n 84: 'character85',\n 85: 'character86',\n 86: 'character87',\n 87: 'character88',\n 88: 'character89',\n 89: 'character90',\n 90: 'character91',\n 91: 'character92',\n 92: 'character93',\n 93: 'character94',\n 94: 'character95',\n 95: 'character96',\n 96: 'character97',\n 97: 'character98',\n 98: 'character99'}"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dict_rev"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Angelic': {'I': {'I': 0.2867647058823529, 'II': 0.7132352941176471},\n  'II': {'I': 0.5409836065573771, 'II': 0.45901639344262296}},\n 'Atemayar_Qelisayer': {'I': {'I': 0.0, 'II': 1.0},\n  'II': {'I': 0.8735632183908046, 'II': 0.12643678160919541}},\n 'Atlantean': {'I': {'I': 0.8113207547169812, 'II': 0.18867924528301888},\n  'II': {'I': 0.06382978723404255, 'II': 0.9361702127659575}},\n 'Aurek-Besh': {'I': {'I': 0.12096774193548387, 'II': 0.8790322580645161},\n  'II': {'I': 0.9351351351351351, 'II': 0.06486486486486487}},\n 'Avesta': {'I': {'I': 0.4, 'II': 0.6},\n  'II': {'I': 0.7990867579908676, 'II': 0.2009132420091324}},\n 'Ge_ez': {'I': {'I': 0.5808383233532934, 'II': 0.41916167664670656},\n  'II': {'I': 0.3425076452599388, 'II': 0.6574923547400612}},\n 'Glagolitic': {'I': {'I': 0.057692307692307696, 'II': 0.9423076923076923},\n  'II': {'I': 0.7311608961303462, 'II': 0.26883910386965376}},\n 'Gurmukhi': {'I': {'I': 0.8962472406181016, 'II': 0.10375275938189846},\n  'II': {'I': 0.17164179104477612, 'II': 0.8283582089552238}},\n 'Kannada': {'I': {'I': 0.7773851590106007, 'II': 0.2226148409893993},\n  'II': {'I': 0.1643192488262911, 'II': 0.8356807511737089}},\n 'Keble': {'I': {'I': 0.6237623762376238, 'II': 0.37623762376237624},\n  'II': {'I': 1.0, 'II': 0.0}},\n 'Malayalam': {'I': {'I': 0.3764172335600907, 'II': 0.6235827664399093},\n  'II': {'I': 0.5995575221238938, 'II': 0.4004424778761062}},\n 'Manipuri': {'I': {'I': 0.7532258064516129, 'II': 0.2467741935483871},\n  'II': {'I': 0.8714285714285714, 'II': 0.12857142857142856}},\n 'Mongolian': {'I': {'I': 0.0, 'II': 1.0},\n  'II': {'I': 0.5679347826086957, 'II': 0.4320652173913043}},\n 'Old_Church_Slavonic_(Cyrillic)': {'I': {'I': 0.1588447653429603,\n   'II': 0.8411552346570397},\n  'II': {'I': 0.6799307958477508, 'II': 0.32006920415224915}},\n 'Oriya': {'I': {'I': 0.6217105263157895, 'II': 0.3782894736842105},\n  'II': {'I': 0.793233082706767, 'II': 0.20676691729323307}},\n 'Sylheti': {'I': {'I': 0.7608695652173914, 'II': 0.2391304347826087},\n  'II': {'I': 0.36423841059602646, 'II': 0.6357615894039735}},\n 'Syriac_(Serto)': {'I': {'I': 0.7770700636942676, 'II': 0.2229299363057325},\n  'II': {'I': 0.9512195121951219, 'II': 0.04878048780487805}},\n 'Tengwar': {'I': {'I': 0.5041666666666667, 'II': 0.49583333333333335},\n  'II': {'I': 0.5361702127659574, 'II': 0.46382978723404256}},\n 'Tibetan': {'I': {'I': 0.9932885906040269, 'II': 0.006711409395973154},\n  'II': {'I': 0.016, 'II': 0.984}},\n 'ULOG': {'I': {'I': 0.4, 'II': 0.6},\n  'II': {'I': 0.5836431226765799, 'II': 0.4163568773234201}}}"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict_test_task3['type_following_probs']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 257, 380, 0.6763157894736842)\n",
      "('Atemayar_Qelisayer', 572, 874, 0.6544622425629291)\n",
      "('Atlantean', 828, 1368, 0.6052631578947368)\n",
      "('Aurek-Besh', 1203, 1862, 0.6460794844253491)\n",
      "('Avesta', 1478, 2356, 0.6273344651952462)\n",
      "('Ge_ez', 1725, 2850, 0.6052631578947368)\n",
      "('Glagolitic', 2128, 3705, 0.5743589743589743)\n",
      "('Gurmukhi', 2517, 4560, 0.5519736842105263)\n",
      "('Kannada', 2794, 5339, 0.52331897359056)\n",
      "('Keble', 3146, 5833, 0.5393451054345962)\n",
      "('Malayalam', 3542, 6726, 0.5266131430270592)\n",
      "('Manipuri', 3802, 7486, 0.5078813785733369)\n",
      "('Mongolian', 4097, 8056, 0.5085650446871897)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 4663, 8911, 0.523285826506565)\n",
      "('Oriya', 4883, 9785, 0.49902912621359224)\n",
      "('Sylheti', 5066, 10317, 0.4910342153726859)\n",
      "('Syriac_(Serto)', 5247, 10754, 0.4879114748000744)\n",
      "('Tengwar', 5466, 11229, 0.48677531391931605)\n",
      "('Tibetan', 5964, 12027, 0.49588426041406836)\n",
      "('ULOG', 6266, 12521, 0.5004392620397732)\n",
      "0.5004392620397732\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.5004392620397732"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_embeddings_task3(dataloader, model, out_features, test=False):\n",
    "    type_dict = {'I':0, 'II':1}\n",
    "    cuda = torch.cuda.is_available()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        embeddings = np.zeros((len(dataloader.dataset), out_features))\n",
    "        labels = np.zeros(len(dataloader.dataset))\n",
    "        preceding_types_list = np.zeros(len(dataloader.dataset))\n",
    "        k = 0\n",
    "        for images, target, preceding_type in dataloader:\n",
    "            if cuda:\n",
    "                images = images.cuda()\n",
    "            embeddings[k:k+len(images)] = model.get_embedding(images).data.cpu().numpy()\n",
    "            labels[k:k+len(images)] = target.numpy()\n",
    "            if test==True:\n",
    "                preceding_type = [type_dict[i] for i in preceding_type]\n",
    "                preceding_types_list[k:k+len(images)] = preceding_type\n",
    "            k += len(images)\n",
    "    return embeddings, labels, preceding_types_list\n",
    "\n",
    "def get_results_task3(model, annotated_loader_dict, test_loader_dict, data_dict, k):\n",
    "    char_dict_rev = {i-1:f\"character{i:02d}\" for i in range(1, 100)}\n",
    "    type_dict = {0:'I', 1:'II'}\n",
    "    correct=0\n",
    "    total_images = 0\n",
    "    last_layer = list(model.children())[-1]\n",
    "    out_features = last_layer.out_features\n",
    "    for alphabet in annotated_loader_dict.keys():\n",
    "        annotated_embeddings, annotated_targets, n = extract_embeddings_task3(annotated_loader_dict[alphabet], model, out_features)\n",
    "        test_embeddings, test_targets, preceding_types = extract_embeddings_task3(test_loader_dict[alphabet], model, out_features, test=True)\n",
    "        distances=cdist(annotated_embeddings,test_embeddings)\n",
    "        all_image_distances=[]\n",
    "        for i in range(len(test_targets)):\n",
    "            image_distances= []\n",
    "            for j in range(len(distances)):\n",
    "                character_type_mapping = data_dict['character_to_type_mapping'][alphabet][char_dict_rev[j]]\n",
    "                probability = data_dict['type_following_probs'][alphabet][type_dict[preceding_types[i]]][character_type_mapping]\n",
    "                if probability==0:\n",
    "                    probability=0.0000001\n",
    "                image_distances.append((distances[j][i] - probability,j))\n",
    "            all_image_distances.append(sorted(image_distances))\n",
    "        #print(all_image_distances)\n",
    "        k_classification = []\n",
    "        for i in range(len(all_image_distances)):\n",
    "            k_classification.append([score[1] for score in all_image_distances[i]][:k])\n",
    "        for i in range(len(k_classification)):\n",
    "            if test_targets[i] in k_classification[i]:\n",
    "                correct+=1\n",
    "        total_images+=len(test_targets)\n",
    "        print((alphabet, correct, total_images, correct/total_images))\n",
    "\n",
    "    top_k_accuracy = correct/total_images\n",
    "    print(top_k_accuracy)\n",
    "    return top_k_accuracy\n",
    "get_results_task3(model, annotated_loader_dict_task3, test_loader_dict_task3, data_dict_test_task3, 1)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "596ab2a615cb44e9",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 332, 380, 0.8736842105263158)\n",
      "('Atemayar_Qelisayer', 730, 874, 0.8352402745995423)\n",
      "('Atlantean', 1062, 1368, 0.7763157894736842)\n",
      "('Aurek-Besh', 1491, 1862, 0.8007518796992481)\n",
      "('Avesta', 1858, 2356, 0.7886247877758913)\n",
      "('Ge_ez', 2193, 2850, 0.7694736842105263)\n",
      "('Glagolitic', 2719, 3705, 0.7338731443994602)\n",
      "('Gurmukhi', 3283, 4560, 0.7199561403508772)\n",
      "('Kannada', 3692, 5339, 0.6915152650309047)\n",
      "('Keble', 4094, 5833, 0.7018686782101834)\n",
      "('Malayalam', 4646, 6726, 0.6907523044900387)\n",
      "('Manipuri', 5016, 7486, 0.6700507614213198)\n",
      "('Mongolian', 5404, 8056, 0.6708043694141013)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 6099, 8911, 0.6844349680170576)\n",
      "('Oriya', 6444, 9785, 0.6585590189064895)\n",
      "('Sylheti', 6741, 10317, 0.6533876126781041)\n",
      "('Syriac_(Serto)', 6989, 10754, 0.6498977124790776)\n",
      "('Tengwar', 7289, 11229, 0.6491228070175439)\n",
      "('Tibetan', 7915, 12027, 0.6581026024777584)\n",
      "('ULOG', 8291, 12521, 0.6621675585017172)\n",
      "0.6621675585017172\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.6621675585017172"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results_task3(model, annotated_loader_dict_task3, test_loader_dict_task3, data_dict_test_task3, 2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2656ede1e4adbe8",
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 359, 380, 0.9447368421052632)\n",
      "('Atemayar_Qelisayer', 812, 874, 0.9290617848970252)\n",
      "('Atlantean', 1200, 1368, 0.8771929824561403)\n",
      "('Aurek-Besh', 1652, 1862, 0.8872180451127819)\n",
      "('Avesta', 2092, 2356, 0.8879456706281834)\n",
      "('Ge_ez', 2501, 2850, 0.8775438596491228)\n",
      "('Glagolitic', 3145, 3705, 0.8488529014844804)\n",
      "('Gurmukhi', 3837, 4560, 0.8414473684210526)\n",
      "('Kannada', 4366, 5339, 0.8177561341075108)\n",
      "('Keble', 4811, 5833, 0.8247899879993142)\n",
      "('Malayalam', 5493, 6726, 0.8166815343443354)\n",
      "('Manipuri', 5985, 7486, 0.799492385786802)\n",
      "('Mongolian', 6463, 8056, 0.8022591857000994)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 7238, 8911, 0.812254516889238)\n",
      "('Oriya', 7716, 9785, 0.7885539090444558)\n",
      "('Sylheti', 8113, 10317, 0.7863720073664825)\n",
      "('Syriac_(Serto)', 8444, 10754, 0.7851962060628603)\n",
      "('Tengwar', 8818, 11229, 0.7852880933297711)\n",
      "('Tibetan', 9541, 12027, 0.7932984119065436)\n",
      "('ULOG', 9960, 12521, 0.7954636211165242)\n",
      "0.7954636211165242\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7954636211165242"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results_task3(model, annotated_loader_dict_task3, test_loader_dict_task3, data_dict_test_task3, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 374, 380, 0.9842105263157894)\n",
      "('Atemayar_Qelisayer', 858, 874, 0.9816933638443935)\n",
      "('Atlantean', 1311, 1368, 0.9583333333333334)\n",
      "('Aurek-Besh', 1795, 1862, 0.9640171858216972)\n",
      "('Avesta', 2271, 2356, 0.9639219015280136)\n",
      "('Ge_ez', 2714, 2850, 0.952280701754386)\n",
      "('Glagolitic', 3451, 3705, 0.9314439946018893)\n",
      "('Gurmukhi', 4248, 4560, 0.9315789473684211)\n",
      "('Kannada', 4893, 5339, 0.9164637572579135)\n",
      "('Keble', 5370, 5833, 0.9206240356591805)\n",
      "('Malayalam', 6168, 6726, 0.9170383586083853)\n",
      "('Manipuri', 6787, 7486, 0.9066257013091104)\n",
      "('Mongolian', 7327, 8056, 0.9095084409136047)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 8150, 8911, 0.9145999326674896)\n",
      "('Oriya', 8792, 9785, 0.8985181400102197)\n",
      "('Sylheti', 9274, 10317, 0.898904720364447)\n",
      "('Syriac_(Serto)', 9671, 10754, 0.8992932862190812)\n",
      "('Tengwar', 10096, 11229, 0.8991005432362632)\n",
      "('Tibetan', 10871, 12027, 0.9038829300740001)\n",
      "('ULOG', 11332, 12521, 0.9050395335835796)\n",
      "0.9050395335835796\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9050395335835796"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results_task3(model, annotated_loader_dict_task3, test_loader_dict_task3, data_dict_test_task3, 8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 'character01',\n 1: 'character02',\n 2: 'character03',\n 3: 'character04',\n 4: 'character05',\n 5: 'character06',\n 6: 'character07',\n 7: 'character08',\n 8: 'character09',\n 9: 'character10',\n 10: 'character11',\n 11: 'character12',\n 12: 'character13',\n 13: 'character14',\n 14: 'character15',\n 15: 'character16',\n 16: 'character17',\n 17: 'character18',\n 18: 'character19',\n 19: 'character20',\n 20: 'character21',\n 21: 'character22',\n 22: 'character23',\n 23: 'character24',\n 24: 'character25',\n 25: 'character26',\n 26: 'character27',\n 27: 'character28',\n 28: 'character29',\n 29: 'character30',\n 30: 'character31',\n 31: 'character32',\n 32: 'character33',\n 33: 'character34',\n 34: 'character35',\n 35: 'character36',\n 36: 'character37',\n 37: 'character38',\n 38: 'character39',\n 39: 'character40',\n 40: 'character41',\n 41: 'character42',\n 42: 'character43',\n 43: 'character44',\n 44: 'character45',\n 45: 'character46',\n 46: 'character47',\n 47: 'character48',\n 48: 'character49',\n 49: 'character50',\n 50: 'character51',\n 51: 'character52',\n 52: 'character53',\n 53: 'character54',\n 54: 'character55',\n 55: 'character56',\n 56: 'character57',\n 57: 'character58',\n 58: 'character59',\n 59: 'character60',\n 60: 'character61',\n 61: 'character62',\n 62: 'character63',\n 63: 'character64',\n 64: 'character65',\n 65: 'character66',\n 66: 'character67',\n 67: 'character68',\n 68: 'character69',\n 69: 'character70',\n 70: 'character71',\n 71: 'character72',\n 72: 'character73',\n 73: 'character74',\n 74: 'character75',\n 75: 'character76',\n 76: 'character77',\n 77: 'character78',\n 78: 'character79',\n 79: 'character80',\n 80: 'character81',\n 81: 'character82',\n 82: 'character83',\n 83: 'character84',\n 84: 'character85',\n 85: 'character86',\n 86: 'character87',\n 87: 'character88',\n 88: 'character89',\n 89: 'character90',\n 90: 'character91',\n 91: 'character92',\n 92: 'character93',\n 93: 'character94',\n 94: 'character95',\n 95: 'character96',\n 96: 'character97',\n 97: 'character98',\n 98: 'character99'}"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i-1:f\"character{i:02d}\" for i in range(1, 100)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 256, 380, 0.6736842105263158)\n",
      "('Atemayar_Qelisayer', 568, 874, 0.6498855835240275)\n",
      "('Atlantean', 815, 1368, 0.5957602339181286)\n",
      "('Aurek-Besh', 1189, 1862, 0.6385606874328679)\n",
      "('Avesta', 1461, 2356, 0.620118845500849)\n",
      "('Ge_ez', 1708, 2850, 0.5992982456140351)\n",
      "('Glagolitic', 2098, 3705, 0.5662618083670715)\n",
      "('Gurmukhi', 2482, 4560, 0.5442982456140351)\n",
      "('Kannada', 2761, 5339, 0.5171380408316164)\n",
      "('Keble', 3108, 5833, 0.5328304474541402)\n",
      "('Malayalam', 3496, 6726, 0.519774011299435)\n",
      "('Manipuri', 3737, 7486, 0.49919850387389797)\n",
      "('Mongolian', 4035, 8056, 0.5008689175769613)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 4576, 8911, 0.5135226125014027)\n",
      "('Oriya', 4788, 9785, 0.4893203883495146)\n",
      "('Sylheti', 4970, 10317, 0.48172918484055444)\n",
      "('Syriac_(Serto)', 5136, 10754, 0.4775897340524456)\n",
      "('Tengwar', 5357, 11229, 0.47706830528096894)\n",
      "('Tibetan', 5857, 12027, 0.48698761120811507)\n",
      "('ULOG', 6155, 12521, 0.49157415541889626)\n",
      "0.49157415541889626\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.49157415541889626"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_results_task3_v2(model, annotated_loader_dict, test_loader_dict, data_dict, k):\n",
    "    char_dict_rev = {i-1:f\"character{i:02d}\" for i in range(1, 100)}\n",
    "    type_dict = {0:'I', 1:'II'}\n",
    "    correct=0\n",
    "    total_images = 0\n",
    "    last_layer = list(model.children())[-1]\n",
    "    out_features = last_layer.out_features\n",
    "    for alphabet in annotated_loader_dict.keys():\n",
    "        annotated_embeddings, annotated_targets, n = extract_embeddings_task3(annotated_loader_dict[alphabet], model, out_features)\n",
    "        test_embeddings, test_targets, preceding_types = extract_embeddings_task3(test_loader_dict[alphabet], model, out_features, test=True)\n",
    "        distances=cdist(annotated_embeddings,test_embeddings)\n",
    "        all_image_distances=[]\n",
    "        for i in range(len(test_targets)):\n",
    "            image_distances= []\n",
    "            for j in range(len(distances)):\n",
    "                character_type_mapping = data_dict['character_to_type_mapping'][alphabet][char_dict_rev[j]]\n",
    "                probability = data_dict['type_following_probs'][alphabet][type_dict[preceding_types[i]]][character_type_mapping]\n",
    "                image_distances.append((distances[j][i] ,j, probability))\n",
    "            all_image_distances.append(image_distances)\n",
    "        #print(all_image_distances)\n",
    "        list_all_probabilties=[]\n",
    "        for i in range(len(all_image_distances)):\n",
    "            max_dist = max(all_image_distances[i])[0]\n",
    "            probabilities=[]\n",
    "            for j in range(len(all_image_distances[i])):\n",
    "                #print(all_image_distances[i][j][2])\n",
    "                dist_prob = (4*(1-(all_image_distances[i][j][0]/max_dist))+(all_image_distances[i][j][2]))/5\n",
    "                #print(dist_prob, (1-(all_image_distances[i][j][0]/max_dist)) )\n",
    "                probabilities.append((dist_prob, all_image_distances[i][j][1]))\n",
    "            probabilities.sort(reverse=True)\n",
    "            list_all_probabilties.append(probabilities)\n",
    "\n",
    "        #print(probabilities)\n",
    "        k_classification = []\n",
    "        for i in range(len(list_all_probabilties)):\n",
    "            k_classification.append([score[1] for score in list_all_probabilties[i]][:k])\n",
    "        #print(k_classification)\n",
    "        for i in range(len(k_classification)):\n",
    "            if test_targets[i] in k_classification[i]:\n",
    "                correct+=1\n",
    "        total_images+=len(test_targets)\n",
    "        print((alphabet, correct, total_images, correct/total_images))\n",
    "\n",
    "    top_k_accuracy = correct/total_images\n",
    "    print(top_k_accuracy)\n",
    "    return top_k_accuracy\n",
    "get_results_task3_v2(model, annotated_loader_dict_task3, test_loader_dict_task3, data_dict_test_task3, 1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42d46e71207afe47",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 334, 380, 0.8789473684210526)\n",
      "('Atemayar_Qelisayer', 719, 874, 0.8226544622425629)\n",
      "('Atlantean', 1049, 1368, 0.7668128654970761)\n",
      "('Aurek-Besh', 1467, 1862, 0.7878625134264232)\n",
      "('Avesta', 1828, 2356, 0.7758913412563667)\n",
      "('Ge_ez', 2163, 2850, 0.7589473684210526)\n",
      "('Glagolitic', 2669, 3705, 0.7203778677462888)\n",
      "('Gurmukhi', 3232, 4560, 0.7087719298245614)\n",
      "('Kannada', 3630, 5339, 0.6799026034837985)\n",
      "('Keble', 4024, 5833, 0.6898679924567118)\n",
      "('Malayalam', 4557, 6726, 0.6775200713648528)\n",
      "('Manipuri', 4901, 7486, 0.6546887523376971)\n",
      "('Mongolian', 5292, 8056, 0.656901688182721)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 5969, 8911, 0.6698462574346313)\n",
      "('Oriya', 6311, 9785, 0.6449667858967808)\n",
      "('Sylheti', 6602, 10317, 0.6399147038867888)\n",
      "('Syriac_(Serto)', 6844, 10754, 0.6364143574483913)\n",
      "('Tengwar', 7145, 11229, 0.636298868999911)\n",
      "('Tibetan', 7778, 12027, 0.6467115656439677)\n",
      "('ULOG', 8153, 12521, 0.651146074594681)\n",
      "0.651146074594681\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.651146074594681"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results_task3_v2(model, annotated_loader_dict_task3, test_loader_dict_task3, data_dict_test_task3, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 357, 380, 0.9394736842105263)\n",
      "('Atemayar_Qelisayer', 799, 874, 0.914187643020595)\n",
      "('Atlantean', 1179, 1368, 0.8618421052631579)\n",
      "('Aurek-Besh', 1633, 1862, 0.8770139634801289)\n",
      "('Avesta', 2065, 2356, 0.8764855687606112)\n",
      "('Ge_ez', 2466, 2850, 0.8652631578947368)\n",
      "('Glagolitic', 3099, 3705, 0.8364372469635628)\n",
      "('Gurmukhi', 3777, 4560, 0.8282894736842106)\n",
      "('Kannada', 4289, 5339, 0.8033339576699756)\n",
      "('Keble', 4732, 5833, 0.811246356934682)\n",
      "('Malayalam', 5413, 6726, 0.8047873922093369)\n",
      "('Manipuri', 5884, 7486, 0.7860005343307508)\n",
      "('Mongolian', 6364, 8056, 0.7899702085402185)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 7124, 8911, 0.7994613399169566)\n",
      "('Oriya', 7598, 9785, 0.7764946346448646)\n",
      "('Sylheti', 7995, 10317, 0.774934574004071)\n",
      "('Syriac_(Serto)', 8315, 10754, 0.7732006695183188)\n",
      "('Tengwar', 8688, 11229, 0.7737109270638525)\n",
      "('Tibetan', 9419, 12027, 0.7831545688866717)\n",
      "('ULOG', 9839, 12521, 0.7857998562415143)\n",
      "0.7857998562415143\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7857998562415143"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results_task3_v2(model, annotated_loader_dict_task3, test_loader_dict_task3, data_dict_test_task3, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 373, 380, 0.9815789473684211)\n",
      "('Atemayar_Qelisayer', 856, 874, 0.9794050343249427)\n",
      "('Atlantean', 1306, 1368, 0.9546783625730995)\n",
      "('Aurek-Besh', 1789, 1862, 0.9607948442534908)\n",
      "('Avesta', 2264, 2356, 0.9609507640067911)\n",
      "('Ge_ez', 2707, 2850, 0.9498245614035088)\n",
      "('Glagolitic', 3432, 3705, 0.9263157894736842)\n",
      "('Gurmukhi', 4214, 4560, 0.9241228070175439)\n",
      "('Kannada', 4846, 5339, 0.9076606106012362)\n",
      "('Keble', 5319, 5833, 0.9118806788959369)\n",
      "('Malayalam', 6118, 6726, 0.9096045197740112)\n",
      "('Manipuri', 6717, 7486, 0.897274913171253)\n",
      "('Mongolian', 7259, 8056, 0.9010675273088381)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 8074, 8911, 0.906071148019302)\n",
      "('Oriya', 8702, 9785, 0.8893203883495145)\n",
      "('Sylheti', 9180, 10317, 0.8897935446350683)\n",
      "('Syriac_(Serto)', 9574, 10754, 0.8902733866468291)\n",
      "('Tengwar', 9999, 11229, 0.8904621960993855)\n",
      "('Tibetan', 10773, 12027, 0.8957345971563981)\n",
      "('ULOG', 11234, 12521, 0.8972126826930756)\n",
      "0.8972126826930756\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.8972126826930756"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results_task3_v2(model, annotated_loader_dict_task3, test_loader_dict_task3, data_dict_test_task3, 8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 16, 380, 0.042105263157894736)\n",
      "('Atemayar_Qelisayer', 35, 874, 0.04004576659038902)\n",
      "('Atlantean', 55, 1368, 0.0402046783625731)\n",
      "('Aurek-Besh', 67, 1862, 0.0359828141783029)\n",
      "('Avesta', 79, 2356, 0.03353140916808149)\n",
      "('Ge_ez', 101, 2850, 0.03543859649122807)\n",
      "('Glagolitic', 123, 3705, 0.03319838056680162)\n",
      "('Gurmukhi', 147, 4560, 0.03223684210526316)\n",
      "('Kannada', 179, 5339, 0.03352687769245177)\n",
      "('Keble', 194, 5833, 0.03325904337390708)\n",
      "('Malayalam', 221, 6726, 0.03285756764793339)\n",
      "('Manipuri', 240, 7486, 0.03205984504408229)\n",
      "('Mongolian', 256, 8056, 0.031777557100297914)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 280, 8911, 0.031421838177533384)\n",
      "('Oriya', 298, 9785, 0.03045477772100153)\n",
      "('Sylheti', 315, 10317, 0.030532131433556268)\n",
      "('Syriac_(Serto)', 333, 10754, 0.030965222242886368)\n",
      "('Tengwar', 349, 11229, 0.03108023866773533)\n",
      "('Tibetan', 367, 12027, 0.03051467531387711)\n",
      "('ULOG', 394, 12521, 0.031467135212842424)\n",
      "0.031467135212842424\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.031467135212842424"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "def get_results_random(model, test_loader_dict, k):\n",
    "    correct=0\n",
    "    total_images = 0\n",
    "    last_layer = list(model.children())[-1]\n",
    "    out_features = last_layer.out_features\n",
    "    for alphabet in test_loader_dict.keys():\n",
    "        test_embeddings, test_targets, n = extract_embeddings_task3(test_loader_dict[alphabet], model, out_features)\n",
    "        random_pred = [random.choices(list(set(test_targets)), k=k) for i in range(len(test_targets))]\n",
    "        for i in range(len(test_targets)):\n",
    "            if test_targets[i] in random_pred[i]:\n",
    "                correct+=1\n",
    "        total_images+=len(test_targets)\n",
    "        print((alphabet, correct, total_images, correct/total_images))\n",
    "\n",
    "    top_k_accuracy = correct/total_images\n",
    "    print(top_k_accuracy)\n",
    "    return top_k_accuracy\n",
    "get_results_random(model, test_loader_dict_task3, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 33, 380, 0.0868421052631579)\n",
      "('Atemayar_Qelisayer', 72, 874, 0.08237986270022883)\n",
      "('Atlantean', 113, 1368, 0.08260233918128655)\n",
      "('Aurek-Besh', 158, 1862, 0.08485499462943072)\n",
      "('Avesta', 202, 2356, 0.08573853989813243)\n",
      "('Ge_ez', 237, 2850, 0.08315789473684211)\n",
      "('Glagolitic', 284, 3705, 0.0766531713900135)\n",
      "('Gurmukhi', 324, 4560, 0.07105263157894737)\n",
      "('Kannada', 353, 5339, 0.06611725042142723)\n",
      "('Keble', 397, 5833, 0.0680610320589748)\n",
      "('Malayalam', 436, 6726, 0.0648230746357419)\n",
      "('Manipuri', 485, 7486, 0.06478760352658296)\n",
      "('Mongolian', 523, 8056, 0.06492055610724926)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 565, 8911, 0.06340478060823701)\n",
      "('Oriya', 604, 9785, 0.06172713336739908)\n",
      "('Sylheti', 639, 10317, 0.06193660947949985)\n",
      "('Syriac_(Serto)', 677, 10754, 0.0629533196949972)\n",
      "('Tengwar', 721, 11229, 0.06420874521328702)\n",
      "('Tibetan', 758, 12027, 0.06302486073002411)\n",
      "('ULOG', 796, 12521, 0.0635731970289913)\n",
      "0.0635731970289913\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.0635731970289913"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results_random(model, test_loader_dict_task3, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 58, 380, 0.15263157894736842)\n",
      "('Atemayar_Qelisayer', 131, 874, 0.14988558352402745)\n",
      "('Atlantean', 216, 1368, 0.15789473684210525)\n",
      "('Aurek-Besh', 294, 1862, 0.15789473684210525)\n",
      "('Avesta', 372, 2356, 0.15789473684210525)\n",
      "('Ge_ez', 445, 2850, 0.156140350877193)\n",
      "('Glagolitic', 523, 3705, 0.14116059379217274)\n",
      "('Gurmukhi', 612, 4560, 0.13421052631578947)\n",
      "('Kannada', 687, 5339, 0.1286757819816445)\n",
      "('Keble', 763, 5833, 0.13080747471284074)\n",
      "('Malayalam', 823, 6726, 0.1223609872137972)\n",
      "('Manipuri', 904, 7486, 0.12075874966604327)\n",
      "('Mongolian', 985, 8056, 0.12226911618669314)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 1072, 8911, 0.12030075187969924)\n",
      "('Oriya', 1153, 9785, 0.11783341849770056)\n",
      "('Sylheti', 1220, 10317, 0.1182514296791703)\n",
      "('Syriac_(Serto)', 1289, 10754, 0.11986237679003162)\n",
      "('Tengwar', 1352, 11229, 0.12040252916555348)\n",
      "('Tibetan', 1441, 12027, 0.11981375239045482)\n",
      "('ULOG', 1527, 12521, 0.12195511540611773)\n",
      "0.12195511540611773\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.12195511540611773"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results_random(model, test_loader_dict_task3, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 134, 380, 0.3526315789473684)\n",
      "('Atemayar_Qelisayer', 262, 874, 0.2997711670480549)\n",
      "('Atlantean', 404, 1368, 0.2953216374269006)\n",
      "('Aurek-Besh', 538, 1862, 0.2889366272824919)\n",
      "('Avesta', 660, 2356, 0.2801358234295416)\n",
      "('Ge_ez', 788, 2850, 0.27649122807017545)\n",
      "('Glagolitic', 922, 3705, 0.24885290148448044)\n",
      "('Gurmukhi', 1057, 4560, 0.2317982456140351)\n",
      "('Kannada', 1185, 5339, 0.22195167634388463)\n",
      "('Keble', 1321, 5833, 0.2264700840048003)\n",
      "('Malayalam', 1466, 6726, 0.21796015462384777)\n",
      "('Manipuri', 1616, 7486, 0.21586962329682075)\n",
      "('Mongolian', 1734, 8056, 0.21524329692154914)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 1860, 8911, 0.20873078217932892)\n",
      "('Oriya', 1988, 9785, 0.20316811446090954)\n",
      "('Sylheti', 2121, 10317, 0.20558301831927886)\n",
      "('Syriac_(Serto)', 2246, 10754, 0.2088525199925609)\n",
      "('Tengwar', 2375, 11229, 0.21150592216582065)\n",
      "('Tibetan', 2530, 12027, 0.21036002328095119)\n",
      "('ULOG', 2658, 12521, 0.2122833639485664)\n",
      "0.2122833639485664\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.2122833639485664"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results_random(model, test_loader_dict_task3, 8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 26, 380, 0.06842105263157895)\n",
      "('Atemayar_Qelisayer', 64, 874, 0.07322654462242563)\n",
      "('Atlantean', 96, 1368, 0.07017543859649122)\n",
      "('Aurek-Besh', 127, 1862, 0.0682062298603652)\n",
      "('Avesta', 153, 2356, 0.06494057724957555)\n",
      "('Ge_ez', 178, 2850, 0.062456140350877196)\n",
      "('Glagolitic', 212, 3705, 0.057219973009446694)\n",
      "('Gurmukhi', 244, 4560, 0.05350877192982456)\n",
      "('Kannada', 274, 5339, 0.05132047199850159)\n",
      "('Keble', 293, 5833, 0.050231441796674096)\n",
      "('Malayalam', 314, 6726, 0.046684507879869164)\n",
      "('Manipuri', 333, 7486, 0.04448303499866417)\n",
      "('Mongolian', 361, 8056, 0.04481132075471698)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 391, 8911, 0.043878352597912694)\n",
      "('Oriya', 410, 9785, 0.04190086867654573)\n",
      "('Sylheti', 437, 10317, 0.0423572744014733)\n",
      "('Syriac_(Serto)', 456, 10754, 0.04240282685512368)\n",
      "('Tengwar', 475, 11229, 0.04230118443316413)\n",
      "('Tibetan', 512, 12027, 0.04257088218175771)\n",
      "('ULOG', 537, 12521, 0.04288794824694513)\n",
      "0.04288794824694513\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.04288794824694513"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_results_by_type(model, annotated_loader_dict, test_loader_dict, data_dict, k):\n",
    "    char_dict_rev = {i-1:f\"character{i:02d}\" for i in range(1, 100)}\n",
    "    type_dict = {0:'I', 1:'II'}\n",
    "    correct=0\n",
    "    total_images = 0\n",
    "    last_layer = list(model.children())[-1]\n",
    "    out_features = last_layer.out_features\n",
    "    for alphabet in annotated_loader_dict.keys():\n",
    "        annotated_embeddings, annotated_targets, n = extract_embeddings_task3(annotated_loader_dict[alphabet], model, out_features)\n",
    "        test_embeddings, test_targets, preceding_types = extract_embeddings_task3(test_loader_dict[alphabet], model, out_features, test=True)\n",
    "        distances=cdist(annotated_embeddings,test_embeddings)\n",
    "        all_image_distances=[]\n",
    "        for i in range(len(test_targets)):\n",
    "            image_distances= []\n",
    "            for j in range(len(distances)):\n",
    "                character_type_mapping = data_dict['character_to_type_mapping'][alphabet][char_dict_rev[j]]\n",
    "                probability = data_dict['type_following_probs'][alphabet][type_dict[preceding_types[i]]][character_type_mapping]\n",
    "                image_distances.append((distances[j][i] ,j, probability))\n",
    "            all_image_distances.append(image_distances)\n",
    "        #print(all_image_distances)\n",
    "        list_all_probabilties=[]\n",
    "        for i in range(len(all_image_distances)):\n",
    "            max_dist = max(all_image_distances[i])[0]\n",
    "            probabilities=[]\n",
    "            for j in range(len(all_image_distances[i])):\n",
    "                #print(all_image_distances[i][j][2])\n",
    "                dist_prob = (0*(1-(all_image_distances[i][j][0]/max_dist))+(all_image_distances[i][j][2]))\n",
    "                #print(dist_prob, (1-(all_image_distances[i][j][0]/max_dist)) )\n",
    "                probabilities.append((dist_prob, all_image_distances[i][j][1]))\n",
    "            probabilities.sort(reverse=True)\n",
    "            list_all_probabilties.append(probabilities)\n",
    "        #print(probabilities)\n",
    "        k_classification = []\n",
    "        for i in range(len(list_all_probabilties)):\n",
    "            k_classification.append([score[1] for score in list_all_probabilties[i]][:k])\n",
    "        #print(k_classification)\n",
    "        for i in range(len(k_classification)):\n",
    "            if test_targets[i] in k_classification[i]:\n",
    "                correct+=1\n",
    "        total_images+=len(test_targets)\n",
    "        print((alphabet, correct, total_images, correct/total_images))\n",
    "\n",
    "    top_k_accuracy = correct/total_images\n",
    "    print(top_k_accuracy)\n",
    "    return top_k_accuracy\n",
    "get_results_by_type(model, annotated_loader_dict_task3, test_loader_dict_task3, data_dict_test_task3, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 49, 380, 0.12894736842105264)\n",
      "('Atemayar_Qelisayer', 123, 874, 0.14073226544622425)\n",
      "('Atlantean', 188, 1368, 0.13742690058479531)\n",
      "('Aurek-Besh', 253, 1862, 0.13587540279269603)\n",
      "('Avesta', 310, 2356, 0.13157894736842105)\n",
      "('Ge_ez', 360, 2850, 0.12631578947368421)\n",
      "('Glagolitic', 429, 3705, 0.11578947368421053)\n",
      "('Gurmukhi', 494, 4560, 0.10833333333333334)\n",
      "('Kannada', 553, 5339, 0.10357744896047949)\n",
      "('Keble', 591, 5833, 0.10132007543288188)\n",
      "('Malayalam', 636, 6726, 0.09455842997323818)\n",
      "('Manipuri', 674, 7486, 0.09003473149879776)\n",
      "('Mongolian', 728, 8056, 0.0903674280039722)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 790, 8911, 0.08865447200089777)\n",
      "('Oriya', 828, 9785, 0.08461931527848748)\n",
      "('Sylheti', 883, 10317, 0.08558689541533392)\n",
      "('Syriac_(Serto)', 921, 10754, 0.08564255160870374)\n",
      "('Tengwar', 959, 11229, 0.08540386499243031)\n",
      "('Tibetan', 1034, 12027, 0.08597322690612788)\n",
      "('ULOG', 1080, 12521, 0.0862550914463701)\n",
      "0.0862550914463701\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.0862550914463701"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results_by_type(model, annotated_loader_dict_task3, test_loader_dict_task3, data_dict_test_task3, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 101, 380, 0.2657894736842105)\n",
      "('Atemayar_Qelisayer', 247, 874, 0.2826086956521739)\n",
      "('Atlantean', 382, 1368, 0.27923976608187134)\n",
      "('Aurek-Besh', 518, 1862, 0.2781954887218045)\n",
      "('Avesta', 628, 2356, 0.266553480475382)\n",
      "('Ge_ez', 730, 2850, 0.256140350877193)\n",
      "('Glagolitic', 856, 3705, 0.2310391363022942)\n",
      "('Gurmukhi', 982, 4560, 0.21535087719298246)\n",
      "('Kannada', 1099, 5339, 0.20584379097209216)\n",
      "('Keble', 1175, 5833, 0.2014400822904166)\n",
      "('Malayalam', 1269, 6726, 0.1886708296164139)\n",
      "('Manipuri', 1345, 7486, 0.17966871493454448)\n",
      "('Mongolian', 1462, 8056, 0.18147964250248264)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 1581, 8911, 0.1774211648524296)\n",
      "('Oriya', 1657, 9785, 0.16934082779764947)\n",
      "('Sylheti', 1766, 10317, 0.17117379083066783)\n",
      "('Syriac_(Serto)', 1842, 10754, 0.17128510321740748)\n",
      "('Tengwar', 1918, 11229, 0.17080772998486063)\n",
      "('Tibetan', 2069, 12027, 0.172029600066517)\n",
      "('ULOG', 2163, 12521, 0.17274978036898012)\n",
      "0.17274978036898012\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.17274978036898012"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results_by_type(model, annotated_loader_dict_task3, test_loader_dict_task3, data_dict_test_task3, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 193, 380, 0.5078947368421053)\n",
      "('Atemayar_Qelisayer', 479, 874, 0.5480549199084668)\n",
      "('Atlantean', 745, 1368, 0.5445906432748538)\n",
      "('Aurek-Besh', 998, 1862, 0.5359828141783028)\n",
      "('Avesta', 1212, 2356, 0.5144312393887945)\n",
      "('Ge_ez', 1401, 2850, 0.49157894736842106)\n",
      "('Glagolitic', 1654, 3705, 0.44642375168690956)\n",
      "('Gurmukhi', 1912, 4560, 0.4192982456140351)\n",
      "('Kannada', 2140, 5339, 0.40082412436785914)\n",
      "('Keble', 2292, 5833, 0.3929367392422424)\n",
      "('Malayalam', 2473, 6726, 0.36767766874814156)\n",
      "('Manipuri', 2625, 7486, 0.35065455516965)\n",
      "('Mongolian', 2861, 8056, 0.3551390268123138)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 3088, 8911, 0.3465379867579396)\n",
      "('Oriya', 3240, 9785, 0.3311190597853858)\n",
      "('Sylheti', 3455, 10317, 0.33488417175535523)\n",
      "('Syriac_(Serto)', 3607, 10754, 0.33541007997024364)\n",
      "('Tengwar', 3759, 11229, 0.33475821533529254)\n",
      "('Tibetan', 4060, 12027, 0.33757379230065687)\n",
      "('ULOG', 4245, 12521, 0.3390304288794825)\n",
      "0.3390304288794825\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.3390304288794825"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results_by_type(model, annotated_loader_dict_task3, test_loader_dict_task3, data_dict_test_task3, 8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.6335772957710113, 19), (0.555798704228342, 17), (0.5027876718401266, 11), (0.4921791291639118, 12), (0.4755256481560117, 8), (0.46938965439380675, 1), (0.46708596007368064, 16), (0.45256975741575584, 14), (0.41796127369354186, 13), (0.4081434240556763, 9), (0.3714641322007841, 7), (0.3556161022677766, 5), (0.32282127311316106, 10), (0.30228985609079706, 3), (0.23874464989395, 4), (0.2235308930063381, 6), (0.21205742757281912, 0), (0.2023456922367462, 18), (0.18208020894342083, 15), (0.0918032786885246, 2)]\n",
      "('Angelic', 256, 380, 0.6736842105263158)\n",
      "[(0.8426805415316936, 25), (0.7701955947607322, 2), (0.713501513124509, 10), (0.7041862209045129, 22), (0.6839940903941276, 9), (0.6782485955147581, 19), (0.6455380374345203, 21), (0.6150729323167767, 15), (0.6102719914560848, 4), (0.5876289818653067, 1), (0.5852371459122432, 12), (0.5440201930825996, 7), (0.5373938448992461, 13), (0.5350611193993549, 3), (0.532521732105346, 8), (0.528261834975925, 14), (0.5186666483545119, 5), (0.45401884996828734, 11), (0.41974474742409273, 16), (0.4146540723672941, 24), (0.41356206610303714, 6), (0.35075739458674865, 17), (0.32493914735352825, 20), (0.2559152040372439, 18), (0.2551007525564723, 0), (0.0, 23)]\n",
      "('Atemayar_Qelisayer', 568, 874, 0.6498855835240275)\n",
      "[(0.7942516255931057, 25), (0.7802623682193593, 21), (0.7589385621469292, 24), (0.6314295768068514, 18), (0.6281171327260345, 6), (0.6245418385642874, 14), (0.587431020736733, 10), (0.5816784117101207, 0), (0.5663276494598675, 3), (0.5269619319253436, 2), (0.5140461566407257, 9), (0.4475485554520145, 8), (0.44078697704024405, 23), (0.43828139987958525, 15), (0.41796162761063493, 19), (0.3696512729414296, 12), (0.3610126070963372, 4), (0.3486175818834101, 22), (0.27279956157273166, 20), (0.18885540674672222, 11), (0.1872340425531915, 7), (0.18652484928159094, 1), (0.16980845400986208, 16), (0.15319559302376887, 17), (0.14820267519248526, 5), (0.10459508853281749, 13)]\n",
      "('Atlantean', 815, 1368, 0.5957602339181286)\n",
      "[(0.7131225333884074, 22), (0.678648862008885, 1), (0.6750257402761123, 6), (0.6706353514374871, 9), (0.6563680033138664, 5), (0.6286493245861392, 20), (0.6247970641884579, 25), (0.6037159748554919, 0), (0.5599622723767387, 14), (0.5107788864488981, 10), (0.5046922213269537, 7), (0.4741370584579991, 23), (0.46934155256034826, 17), (0.43931600023829065, 19), (0.43828761760450397, 11), (0.4255044657213276, 12), (0.41713155181312156, 13), (0.41142138262218386, 3), (0.406481001683179, 15), (0.3626138259103574, 24), (0.35557504195126477, 8), (0.29795407740236635, 21), (0.2791773255860829, 16), (0.2770782605462371, 4), (0.26535096176451584, 18), (0.18702702702702703, 2)]\n",
      "('Aurek-Besh', 1189, 1862, 0.6385606874328679)\n",
      "[(0.8746229247232248, 25), (0.7451950978698527, 17), (0.6967633910207884, 1), (0.6883956614031813, 2), (0.6843970209882579, 5), (0.6447552507633796, 10), (0.6409280076201427, 3), (0.616376482327434, 22), (0.6044255718946332, 13), (0.5962241982985276, 21), (0.5819322415992925, 16), (0.5733694759501549, 8), (0.5449311916642499, 14), (0.5447759804028094, 12), (0.5115724683456687, 6), (0.4913809021559805, 24), (0.4843409753824542, 20), (0.44070843075741983, 19), (0.42846313034041106, 18), (0.41298725952921433, 15), (0.40247294187149185, 0), (0.3169736918923028, 9), (0.27758256717214774, 23), (0.2678262687497212, 7), (0.22976276822900413, 4), (0.15981735159817353, 11)]\n",
      "('Avesta', 1461, 2356, 0.620118845500849)\n",
      "[(0.5722267731817962, 9), (0.5562746638365863, 16), (0.5161527600185776, 25), (0.4876087197187886, 0), (0.48748189755214005, 1), (0.47337563109598463, 8), (0.46464285486419626, 19), (0.4475163947912152, 12), (0.4233582496435377, 6), (0.4215071684880416, 17), (0.4206666876989128, 15), (0.4196651135136872, 20), (0.41218548913412917, 13), (0.411135909703392, 14), (0.41012702771175163, 4), (0.399186541493424, 2), (0.3762709505785695, 5), (0.3647730348190676, 10), (0.32558137494439277, 7), (0.3207442641752185, 3), (0.3192437393299068, 11), (0.2924012976956729, 22), (0.29025203747258116, 18), (0.2878125095869666, 23), (0.2327280727180061, 24), (0.08383233532934131, 21)]\n",
      "('Ge_ez', 1708, 2850, 0.5992982456140351)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-57-7d06bcb2a8c3>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     46\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtop_k_accuracy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     47\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mtop_k_accuracy\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 48\u001B[1;33m \u001B[0mget_results_by_type_v2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mannotated_loader_dict_task3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_loader_dict_task3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata_dict_test_task3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-57-7d06bcb2a8c3>\u001B[0m in \u001B[0;36mget_results_by_type_v2\u001B[1;34m(model, annotated_loader_dict, test_loader_dict, data_dict, k)\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0malphabet\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mannotated_loader_dict\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m         \u001B[0mannotated_embeddings\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mannotated_targets\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mextract_embeddings_task3\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mannotated_loader_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0malphabet\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout_features\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m         \u001B[0mtest_embeddings\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_targets\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpreceding_types\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mextract_embeddings_task3\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_loader_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0malphabet\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout_features\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m         \u001B[0mdistances\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcdist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mannotated_embeddings\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtest_embeddings\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m         \u001B[0mall_image_distances\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-41-4efc9ba4dd61>\u001B[0m in \u001B[0;36mextract_embeddings_task3\u001B[1;34m(dataloader, model, out_features, test)\u001B[0m\n\u001B[0;32m     11\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mcuda\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m                 \u001B[0mimages\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimages\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m             \u001B[0membeddings\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_embedding\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m             \u001B[0mlabels\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mtest\u001B[0m\u001B[1;33m==\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def get_results_by_type_v2(model, annotated_loader_dict, test_loader_dict, data_dict, k):\n",
    "    char_dict_rev = {i-1:f\"character{i:02d}\" for i in range(1, 100)}\n",
    "    type_dict = {0:'I', 1:'II'}\n",
    "    correct=0\n",
    "    total_images = 0\n",
    "    last_layer = list(model.children())[-1]\n",
    "    out_features = last_layer.out_features\n",
    "    for alphabet in annotated_loader_dict.keys():\n",
    "        annotated_embeddings, annotated_targets, n = extract_embeddings_task3(annotated_loader_dict[alphabet], model, out_features)\n",
    "        test_embeddings, test_targets, preceding_types = extract_embeddings_task3(test_loader_dict[alphabet], model, out_features, test=True)\n",
    "        distances=cdist(annotated_embeddings,test_embeddings)\n",
    "        all_image_distances=[]\n",
    "        for i in range(len(test_targets)):\n",
    "            image_distances= []\n",
    "            for j in range(len(distances)):\n",
    "                character_type_mapping = data_dict['character_to_type_mapping'][alphabet][char_dict_rev[j]]\n",
    "                probability = data_dict['type_following_probs'][alphabet][type_dict[preceding_types[i]]][character_type_mapping]\n",
    "                image_distances.append((distances[j][i] ,j, probability))\n",
    "            all_image_distances.append(image_distances)\n",
    "        #print(all_image_distances)\n",
    "        list_all_probabilties=[]\n",
    "        for i in range(len(all_image_distances)):\n",
    "            max_dist = max(all_image_distances[i])[0]\n",
    "            probabilities=[]\n",
    "            for j in range(len(all_image_distances[i])):\n",
    "                #print(all_image_distances[i][j][2])\n",
    "                dist_prob = (0.8*(1-(all_image_distances[i][j][0]/max_dist))+0.2*(all_image_distances[i][j][2]))\n",
    "                #print(dist_prob, (1-(all_image_distances[i][j][0]/max_dist)) )\n",
    "\n",
    "                probabilities.append((dist_prob, all_image_distances[i][j][1]))\n",
    "            probabilities.sort(reverse=True)\n",
    "\n",
    "            list_all_probabilties.append(probabilities)\n",
    "        #print(probabilities)\n",
    "        k_classification = []\n",
    "        for i in range(len(list_all_probabilties)):\n",
    "            k_classification.append([score[1] for score in list_all_probabilties[i]][:k])\n",
    "        #print(k_classification)\n",
    "        for i in range(len(k_classification)):\n",
    "            if test_targets[i] in k_classification[i]:\n",
    "                correct+=1\n",
    "        total_images+=len(test_targets)\n",
    "        print((alphabet, correct, total_images, correct/total_images))\n",
    "\n",
    "    top_k_accuracy = correct/total_images\n",
    "    print(top_k_accuracy)\n",
    "    return top_k_accuracy\n",
    "get_results_by_type_v2(model, annotated_loader_dict_task3, test_loader_dict_task3, data_dict_test_task3, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
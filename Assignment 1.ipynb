{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment 1 2AMM10 2023-2024\n",
    "\n",
    "## Group: [Fill in your group name]\n",
    "### Member 1: [Fill in your name]\n",
    "### Member 2: [Fill in your name]\n",
    "### Member 3: [Fill in your name]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc4f04c033b0e00"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from scipy.spatial.distance import cdist\n",
    "import os\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# function for loading the training data:\n",
    "\n",
    "def load_data(file):\n",
    "    \"\"\"\n",
    "    This function loads the data from the specified pickle file and returns a dictionary with the data\n",
    "    :param filename: the pickle file\n",
    "    :return: dict with data -- keys and values differ for the train data and test data for each task.\n",
    "     Please see the cells with example code below for explanations and examples of the data structure per data set.\n",
    "    \"\"\"\n",
    "    with open(file, 'rb') as f:\n",
    "        data_dict = pickle.load(f)\n",
    "    return data_dict"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d19b9de0e3461531",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data = load_data('train_data.pkl')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0da60a825f5080b",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example alphabet names: ['Alphabet_of_the_Magi', 'Anglo-Saxon_Futhorc', 'Arcadian', 'Armenian', 'Asomtavruli_(Georgian)']\n",
      "\n",
      "\n",
      "how to get an example image for a specific character:\n",
      "shape of image 2 of character character06 of alphabet Asomtavruli_(Georgian): torch.Size([1, 105, 105])\n"
     ]
    }
   ],
   "source": [
    "# the structure of the training data is a dict, where the keys are strings indicating the alphabet.\n",
    "# The values are again dicts, with the keys being the character and the values being a list of images of that character.\n",
    "\n",
    "# see the code below for examples of working with the train data\n",
    "\n",
    "alphabets = list(train_data.keys())\n",
    "\n",
    "\n",
    "print('example alphabet names:', alphabets[:5])\n",
    "print('\\n')\n",
    "print('how to get an example image for a specific character:')\n",
    "\n",
    "alphabet_id = 4\n",
    "alphabet = alphabets[alphabet_id]  # a dict\n",
    "characters_for_this_alphabet = list(train_data[alphabet].keys())\n",
    "character_id = 5\n",
    "character = characters_for_this_alphabet[character_id]\n",
    "image_id = 2\n",
    "\n",
    "print(f'shape of image {image_id} of character {character} of alphabet {alphabet}:', train_data[alphabet][character][image_id].shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "289b9d9817ddf745",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2991163aba746526",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# function for plotting some examples:\n",
    "\n",
    "def plot_example_data(data_dict):\n",
    "    \"\"\"\n",
    "    This function plots some examples of the data\n",
    "    :param data_dict: dict with as keys a string specifying the alphabet, and as values a dict with as keys the character of the alphabet, and as values a list om images of the alphabet\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    alphabets_to_plot = np.random.choice(list(data_dict.keys()), size=10, replace=False)\n",
    "    \n",
    "    for i, alphabet in enumerate(alphabets_to_plot):\n",
    "        characters = data_dict[alphabet]\n",
    "        character_to_plot = np.random.choice(list(characters.keys()), size=1)[0]\n",
    "        images = characters[character_to_plot]\n",
    "        im_idx = np.random.choice(len(images), size=1)[0]\n",
    "        axs[i//5, i%5].imshow(images[im_idx].permute(1, 2, 0))\n",
    "        axs[i//5, i%5].set_title(alphabet + '\\n' + character_to_plot, fontsize=8)\n",
    "        axs[i//5, i%5].axis('off')\n",
    "    # plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f68bfac0812b8988",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1080x432 with 10 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plot_example_data(train_data)\n",
    "# plt.savefig('example_data.png', dpi=600)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "511e9fbc1b85e80f",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 1: character recognition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6449bef2185716"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"CNN Builder.\"\"\"\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "\n",
    "        self.front_layer = nn.Sequential(\n",
    "            # Conv Layer block 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Conv Layer block 2\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "            # Conv Layer block 3\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            Lambda(lambda x: x.view(x.size(0), -1)),\n",
    "\n",
    "            nn.Linear(256 * 13 * 13, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.last_layer = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward.\"\"\"\n",
    "        # conv layers\n",
    "        x = self.front_layer(x)\n",
    "        x = self.last_layer(x)\n",
    "        return x\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.forward(x)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f78ab6a6133991a4",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class EmbeddingNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"CNN Builder.\"\"\"\n",
    "        super(EmbeddingNet2, self).__init__()\n",
    "\n",
    "        self.convolutional_layers = nn.Sequential(\n",
    "            # Convolutional Block 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Convolutional Block 2\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Convolutional Block 3\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Convolutional Block 4\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            #nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Flatten\n",
    "            Lambda(lambda x: x.view(x.size(0), -1)),\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(13*13*512, 1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward.\"\"\"\n",
    "        # conv layers\n",
    "        x = self.convolutional_layers(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.forward(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import BatchSampler\n",
    "import numpy as np\n",
    "class BalancedBatchSampler(BatchSampler):\n",
    "    \"\"\"\n",
    "    Returns batches of size n_classes * n_samples\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, labels, n_classes, n_samples):\n",
    "        self.labels = labels\n",
    "        self.labels_set = list(set(self.labels))\n",
    "        self.label_to_indices = {label: np.where(  np.array(self.labels) == label)[0]\n",
    "                                 for label in self.labels_set}\n",
    "        for l in self.labels_set:\n",
    "            np.random.shuffle(self.label_to_indices[l])\n",
    "        self.used_label_indices_count = {label: 0 for label in self.labels_set}\n",
    "        self.count = 0\n",
    "        self.n_classes = n_classes\n",
    "        self.n_samples = n_samples\n",
    "        self.n_dataset = len(self.labels)\n",
    "        self.batch_size = self.n_samples * self.n_classes\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.count = 0\n",
    "        while self.count + self.batch_size <= self.n_dataset:\n",
    "            classes = np.random.choice(self.labels_set, self.n_classes, replace=False)\n",
    "            indices = []\n",
    "            for class_ in classes:\n",
    "                indices.extend(self.label_to_indices[class_][\n",
    "                               self.used_label_indices_count[class_]:self.used_label_indices_count[\n",
    "                                                                         class_] + self.n_samples])\n",
    "                self.used_label_indices_count[class_] += self.n_samples\n",
    "                if self.used_label_indices_count[class_] + self.n_samples > len(self.label_to_indices[class_]):\n",
    "                    np.random.shuffle(self.label_to_indices[class_])\n",
    "                    self.used_label_indices_count[class_] = 0\n",
    "            yield indices\n",
    "            self.count += self.n_classes * self.n_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_dataset // self.batch_size"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16b4aff5112f09b7",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Triplets loss\n",
    "    Takes a batch of embeddings and corresponding labels.\n",
    "    Triplets are generated using triplet_selector object that take embeddings and targets and return indices of\n",
    "    triplets\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin, triplet_selector):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.triplet_selector = triplet_selector\n",
    "\n",
    "    def forward(self, embeddings, target):\n",
    "\n",
    "        triplets = self.triplet_selector.get_triplets(embeddings, target)\n",
    "\n",
    "        if embeddings.is_cuda:\n",
    "            triplets = triplets.cuda()\n",
    "\n",
    "\n",
    "        anchor_idx= triplets[:, 0]\n",
    "        positive_idx= triplets[:, 1]\n",
    "        negative_idx= triplets[:, 2]\n",
    "\n",
    "\n",
    "        ap_distances = (embeddings[anchor_idx] - embeddings[positive_idx]).pow(2).sum(1)  # .pow(.5)\n",
    "        an_distances = (embeddings[anchor_idx] - embeddings[negative_idx]).pow(2).sum(1)  # .pow(.5)\n",
    "        losses = F.relu(ap_distances - an_distances + self.margin)\n",
    "        print(losses)\n",
    "        return losses.mean()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "948e55a5ea036e8a",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "char_dict = {f\"character{i:02d}\": i - 1 for i in range(1, 100)}\n",
    "train_loader_dict = {}\n",
    "# Iterate over the dictionary items (label: images_list)\n",
    "for alphabet in alphabets:\n",
    "    data_alphabet = train_data[alphabet]\n",
    "    image_label_list = []\n",
    "    targets = []\n",
    "    for label, images in data_alphabet.items():\n",
    "        # Append each image-label pair as a tuple to the list\n",
    "        for image in images:\n",
    "            targets.append(char_dict[label])\n",
    "            image_label_list.append((image, char_dict[label]))\n",
    "    #print(len(targets)/len(set(targets)))\n",
    "    train_batch_sampler = BalancedBatchSampler(targets, n_classes=len(set(targets)), n_samples=3)\n",
    "    triplets_train_loader = torch.utils.data.DataLoader(image_label_list, batch_sampler=train_batch_sampler)\n",
    "    train_loader_dict[alphabet] = triplets_train_loader\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Batch 0:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([21, 21, 21, 12, 12, 12,  8,  8,  8, 18, 18, 18,  5,  5,  5,  1,  1,  1,\n",
      "         6,  6,  6,  4,  4,  4, 14, 14, 14,  2,  2,  2, 23, 23, 23, 24, 24, 24,\n",
      "        25, 25, 25,  3,  3,  3,  7,  7,  7, 22, 22, 22, 11, 11, 11, 16, 16, 16,\n",
      "         9,  9,  9, 10, 10, 10, 17, 17, 17, 20, 20, 20, 13, 13, 13, 19, 19, 19,\n",
      "        15, 15, 15,  0,  0,  0])\n",
      "Batch 1:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([18, 18, 18, 25, 25, 25, 23, 23, 23, 19, 19, 19, 14, 14, 14, 17, 17, 17,\n",
      "        21, 21, 21, 22, 22, 22,  7,  7,  7,  2,  2,  2,  5,  5,  5, 11, 11, 11,\n",
      "        10, 10, 10,  6,  6,  6, 20, 20, 20,  3,  3,  3,  8,  8,  8, 24, 24, 24,\n",
      "        16, 16, 16, 12, 12, 12,  9,  9,  9,  0,  0,  0,  1,  1,  1, 15, 15, 15,\n",
      "        13, 13, 13,  4,  4,  4])\n",
      "Batch 2:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([ 9,  9,  9, 12, 12, 12, 25, 25, 25, 11, 11, 11, 15, 15, 15,  7,  7,  7,\n",
      "         8,  8,  8, 18, 18, 18, 19, 19, 19, 22, 22, 22,  0,  0,  0, 17, 17, 17,\n",
      "        10, 10, 10,  5,  5,  5, 23, 23, 23, 13, 13, 13, 20, 20, 20, 16, 16, 16,\n",
      "         6,  6,  6,  4,  4,  4, 24, 24, 24,  2,  2,  2,  3,  3,  3, 14, 14, 14,\n",
      "        21, 21, 21,  1,  1,  1])\n",
      "Batch 3:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([ 8,  8,  8, 14, 14, 14,  1,  1,  1,  4,  4,  4,  3,  3,  3, 21, 21, 21,\n",
      "        20, 20, 20, 17, 17, 17, 19, 19, 19,  2,  2,  2,  7,  7,  7, 15, 15, 15,\n",
      "        24, 24, 24, 12, 12, 12,  0,  0,  0, 13, 13, 13,  5,  5,  5, 22, 22, 22,\n",
      "        10, 10, 10, 18, 18, 18, 16, 16, 16, 11, 11, 11,  6,  6,  6,  9,  9,  9,\n",
      "        23, 23, 23, 25, 25, 25])\n",
      "Batch 4:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([ 8,  8,  8,  7,  7,  7,  5,  5,  5,  1,  1,  1,  0,  0,  0, 11, 11, 11,\n",
      "        25, 25, 25,  3,  3,  3,  9,  9,  9, 13, 13, 13, 19, 19, 19,  4,  4,  4,\n",
      "        10, 10, 10,  6,  6,  6, 20, 20, 20, 16, 16, 16, 18, 18, 18, 21, 21, 21,\n",
      "         2,  2,  2, 24, 24, 24, 12, 12, 12, 17, 17, 17, 23, 23, 23, 22, 22, 22,\n",
      "        15, 15, 15, 14, 14, 14])\n",
      "Batch 5:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "78\n",
      "Targets (labels):\n",
      "tensor([ 2,  2,  2,  9,  9,  9, 18, 18, 18, 24, 24, 24,  8,  8,  8,  7,  7,  7,\n",
      "        21, 21, 21,  4,  4,  4, 13, 13, 13, 25, 25, 25, 15, 15, 15, 11, 11, 11,\n",
      "        12, 12, 12, 22, 22, 22, 19, 19, 19,  1,  1,  1, 17, 17, 17,  3,  3,  3,\n",
      "         0,  0,  0,  5,  5,  5, 10, 10, 10, 16, 16, 16, 14, 14, 14, 20, 20, 20,\n",
      "         6,  6,  6, 23, 23, 23])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader_dict['Latin']))\n",
    "i=0\n",
    "for batch_idx, (inputs, targets) in enumerate(train_loader_dict['Latin']):\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(\"Inputs (features):\")\n",
    "    print(type(inputs))\n",
    "    print(len(targets))  # Print input data (features)\n",
    "    print(\"Targets (labels):\")\n",
    "    print(targets)\n",
    "    i+=1\n",
    "print(i)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n",
    "def pdist(vectors):\n",
    "    distance_matrix = -2 * vectors.mm(torch.t(vectors)) + vectors.pow(2).sum(dim=1).view(1, -1) + vectors.pow(2).sum(\n",
    "        dim=1).view(-1, 1)\n",
    "    return distance_matrix\n",
    "\n",
    "\n",
    "class Informative_Negative_TripletSelector():\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        super(Informative_Negative_TripletSelector, self).__init__()\n",
    "\n",
    "        self.margin = margin\n",
    "\n",
    "    # Our goal is to mining informative triplets.\n",
    "    def informative_negative(self, loss_values):\n",
    "\n",
    "        informative_negative = np.where(loss_values > 0)[0]\n",
    "        return np.random.choice(informative_negative) if len(informative_negative) > 0 else None\n",
    "\n",
    "    def get_triplets(self, embeddings, labels):\n",
    "\n",
    "        if torch.cuda.is_available() == False:\n",
    "            embeddings = embeddings.cpu()\n",
    "        distance_matrix = pdist(embeddings)\n",
    "        distance_matrix = distance_matrix.cpu()\n",
    "\n",
    "        labels = labels.cpu().data.numpy()\n",
    "        triplets = []\n",
    "\n",
    "        for label in set(labels):\n",
    "            label_mask = (labels == label)\n",
    "            label_indices = np.where(label_mask)[0]\n",
    "            if len(label_indices) < 2:\n",
    "                continue\n",
    "            negative_indices = np.where(np.logical_not(label_mask))[0]\n",
    "            anchor_positives = list(combinations(label_indices, 2))  # All anchor-positive pairs\n",
    "            anchor_positives = np.array(anchor_positives)\n",
    "\n",
    "            ap_distances = distance_matrix[anchor_positives[:, 0], anchor_positives[:, 1]]\n",
    "            for anchor_positive, ap_distance in zip(anchor_positives, ap_distances):\n",
    "                loss_values = ap_distance - distance_matrix[\n",
    "                    torch.LongTensor(np.array([anchor_positive[0]])), torch.LongTensor(negative_indices)] + self.margin\n",
    "                loss_values = loss_values.data.cpu().numpy()\n",
    "\n",
    "                hard_negative = self.informative_negative(loss_values)\n",
    "                if hard_negative is not None:\n",
    "                    hard_negative = negative_indices[hard_negative]\n",
    "                    triplets.append([anchor_positive[0], anchor_positive[1], hard_negative])\n",
    "\n",
    "        if len(triplets) == 0:\n",
    "            triplets.append([anchor_positive[0], anchor_positive[1], negative_indices[0]])\n",
    "\n",
    "        triplets = np.array(triplets)\n",
    "        #print(len(triplets))\n",
    "        return torch.LongTensor(triplets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module,\n",
    "                 device: torch.device,\n",
    "                 criterion: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 training_dict: torch.utils.data.Dataset,\n",
    "                 validation_DataLoader: torch.utils.data.Dataset ,\n",
    "                 epochs: int\n",
    "                 ):\n",
    "\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.training_dict= training_dict\n",
    "        self.validation_DataLoader = validation_DataLoader\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def run_trainer(self):\n",
    "\n",
    "\n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "\n",
    "            self.model.train()  # train mode\n",
    "            alphabets = self.training_dict.keys()\n",
    "            train_losses=[]\n",
    "            for alphabet in alphabets:\n",
    "                data_loader = self.training_dict[alphabet]\n",
    "                for batch in data_loader:\n",
    "                    #print('test')\n",
    "                    x,y=batch\n",
    "                    input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)\n",
    "                    self.optimizer.zero_grad()  # zerograd the parameters\n",
    "                    out = self.model(input)  # one forward pass\n",
    "                    loss = self.criterion(out, target)  # calculate loss\n",
    "\n",
    "                    loss_value = loss.item()\n",
    "                    train_losses.append(loss_value)\n",
    "\n",
    "                    loss.backward()  # one backward pass\n",
    "                    self.optimizer.step()\n",
    "                    loss.cpu()\n",
    "                    input.cpu()\n",
    "                    target.cpu()\n",
    "                    del loss#update the parameters\n",
    "                    del input\n",
    "                    del target\n",
    "                #print('\\n')\n",
    "                self.model.eval()  # evaluation mode\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # print the results\n",
    "            print(\n",
    "                f'EPOCH: {epoch+1:0>{len(str(self.epochs))}}/{self.epochs}',\n",
    "                end=' '\n",
    "            )\n",
    "            print(f'LOSS: {np.mean(train_losses):.4f}',end=' ')\n",
    "            #print(f'VAL-LOSS: {np.mean(valid_losses):.4f}',end='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0015, 1.0000, 0.9996, 0.9982, 1.0001, 0.9974, 0.9976, 0.9947, 0.9992,\n",
      "        0.9953, 0.9980, 0.9987, 1.0020, 0.9991, 0.9993, 0.9846, 0.9983, 1.0077,\n",
      "        0.9993, 0.9983, 0.9828, 1.0066, 0.9872, 1.0049, 0.9980, 0.9987, 0.9895,\n",
      "        0.9942, 1.0007, 0.9989, 0.9952, 0.9933, 1.0061, 0.9939, 1.0026, 1.0049,\n",
      "        0.9987, 0.9950, 0.9971, 1.0000, 1.0046, 0.9988, 0.9986, 0.9971, 1.0059,\n",
      "        0.9993, 1.0028, 1.0047, 0.9982, 0.9999, 0.9991, 1.0022, 0.9987, 0.9997,\n",
      "        0.9905, 0.9882, 0.9968, 0.9932, 1.0004, 1.0111], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0059, 0.9959, 0.9924, 0.9919, 0.9886, 1.0002, 0.9984, 1.0072, 1.0047,\n",
      "        0.9949, 0.9938, 0.9906, 0.9980, 0.9983, 1.0001, 1.0042, 0.9998, 1.0009,\n",
      "        0.9970, 0.9999, 1.0013, 1.0035, 1.0012, 0.9962, 0.9961, 1.0071, 1.0019,\n",
      "        0.9942, 1.0032, 0.9998, 1.0039, 1.0019, 0.9975, 1.0015, 0.9999, 0.9969,\n",
      "        0.9985, 1.0071, 0.9955, 0.9974, 0.9985, 1.0052, 0.9981, 0.9955, 0.9957,\n",
      "        0.9963, 1.0077, 1.0021, 1.0047, 0.9895, 0.9951, 0.9956, 0.9929, 1.0055,\n",
      "        1.0061, 0.9932, 1.0023, 0.9972, 0.9982, 0.9963], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9946, 0.9958, 1.0029, 0.9926, 1.0054, 0.9939, 0.9939, 0.9913, 0.9959,\n",
      "        0.9933, 1.0006, 0.9874, 0.9929, 0.9968, 1.0012, 0.9983, 1.0055, 0.9966,\n",
      "        0.9956, 0.9998, 0.9997, 0.9944, 0.9921, 1.0006, 0.9878, 0.9839, 0.9957,\n",
      "        0.9986, 0.9929, 0.9942, 0.9891, 1.0063, 0.9990, 1.0071, 0.9981, 0.9908,\n",
      "        0.9896, 1.0024, 0.9970, 0.9985, 1.0002, 0.9995, 0.9969, 0.9945, 0.9949,\n",
      "        0.9983, 0.9964, 0.9942, 0.9861, 0.9930, 1.0081, 1.0035, 0.9972, 1.0000,\n",
      "        0.9944, 0.9906, 0.9911, 1.0101, 0.9927, 1.0027], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9976, 1.0013, 0.9934, 0.9984, 0.9866, 0.9920, 1.0016, 0.9969, 0.9988,\n",
      "        0.9945, 1.0012, 0.9943, 0.9941, 1.0035, 1.0047, 0.9938, 0.9981, 0.9949,\n",
      "        0.9915, 0.9959, 0.9986, 0.9989, 0.9930, 1.0038, 1.0041, 0.9997, 0.9939,\n",
      "        1.0023, 0.9834, 0.9901, 0.9975, 0.9976, 1.0041, 1.0015, 1.0039, 1.0068,\n",
      "        0.9904, 0.9979, 1.0027, 0.9910, 1.0001, 1.0011, 0.9995, 1.0143, 1.0167,\n",
      "        0.9967, 1.0065, 1.0006, 0.9956, 0.9941, 0.9926, 1.0001, 1.0046, 1.0019,\n",
      "        1.0001, 0.9923, 0.9810, 1.0084, 1.0005, 0.9954], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9903, 0.9844, 0.9924, 0.9996, 0.9834, 0.9949, 1.0001, 0.9859, 0.9928,\n",
      "        0.9946, 0.9949, 0.9847, 0.9983, 0.9952, 1.0002, 0.9925, 1.0048, 0.9968,\n",
      "        0.9978, 0.9923, 0.9916, 0.9994, 0.9937, 0.9948, 0.9956, 0.9784, 0.9981,\n",
      "        0.9946, 0.9986, 1.0023, 0.9985, 0.9949, 1.0075, 1.0081, 0.9939, 0.9977,\n",
      "        0.9974, 0.9980, 0.9993, 0.9835, 1.0030, 1.0006, 1.0004, 0.9845, 1.0005,\n",
      "        1.0017, 0.9828, 1.0018, 0.9725, 0.9927, 0.9894, 0.9993, 0.9942, 0.9957,\n",
      "        0.9916, 1.0033, 1.0052, 0.9922, 1.0027, 1.0073], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9932, 0.9792, 0.9796, 0.9909, 0.9987, 0.9697, 1.0065, 0.9957, 0.9979,\n",
      "        0.9811, 0.9788, 0.9754, 0.9776, 0.9645, 0.9885, 0.9749, 0.9965, 1.0045,\n",
      "        0.9453, 0.9915, 0.9868, 1.0028, 0.9791, 1.0073, 0.9786, 0.9741, 0.9804,\n",
      "        0.9836, 0.9991, 0.9673, 0.9844, 1.0012, 0.9808, 1.0067, 0.9661, 0.9921,\n",
      "        0.9937, 0.9954, 0.9903, 0.9970, 0.9948, 0.9843, 0.9954, 0.9781, 0.9647,\n",
      "        0.9954, 1.0028, 0.9871, 0.9821, 0.9891, 1.0049, 1.0026, 0.9962, 0.9955,\n",
      "        0.9999, 0.9818, 0.9821, 1.0239, 0.9878, 0.9523], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [02:25<21:50, 145.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 01/10 LOSS: 0.9999 tensor([0.8453, 0.2469, 0.2466, 0.9871, 0.9050, 0.6907, 0.7383, 1.0121, 0.9613,\n",
      "        0.6252, 0.1395, 0.7112, 0.9801, 0.9169, 0.7978, 0.7348, 0.9455, 0.3014,\n",
      "        0.4665, 0.2454, 0.4434, 0.7680, 0.8137, 0.3917, 1.0433, 0.7673, 0.5461,\n",
      "        0.3669, 0.5956, 0.9599, 0.9874, 0.7031, 0.9276, 0.8850, 1.0151, 0.9371,\n",
      "        0.9228, 0.5815, 1.0863, 0.9178, 0.4139, 0.0085, 0.7151, 1.0272, 1.0448,\n",
      "        0.9562, 0.8061, 0.9579, 0.0438, 0.7142, 0.9726, 1.0404, 1.0512, 0.9410,\n",
      "        0.1612, 0.0848, 0.9306, 1.0179, 0.9130, 0.9859], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0545, 0.3057, 0.6504, 0.8610, 0.3896, 0.7807, 0.0471, 0.9439, 0.7938,\n",
      "        0.2676, 0.5388, 0.2099, 0.2707, 0.6849, 0.6699, 0.5847, 0.8969, 0.5813,\n",
      "        1.0040, 0.2947, 0.3351, 0.9055, 0.1981, 0.8130, 0.1258, 0.7229, 0.3923,\n",
      "        0.7579, 0.6992, 1.2015, 0.3290, 1.1377, 1.0282, 0.4242, 1.6370, 1.4495,\n",
      "        0.9280, 0.9022, 0.9305, 0.9265, 0.9240, 0.7725, 0.6634, 0.2204, 0.1550,\n",
      "        0.3327, 0.6817, 0.2568, 1.1288, 1.0463, 0.8146, 1.5284, 0.8181, 1.3152,\n",
      "        0.8309, 1.2314, 0.9088, 1.0088, 1.0925, 0.8470], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.4733, 1.1307, 0.0354, 0.7476, 0.0030, 0.7116, 1.1964, 0.8893, 0.7230,\n",
      "        0.5211, 0.0101, 0.0268, 0.2967, 0.7574, 0.9504, 1.1894, 0.1835, 0.2921,\n",
      "        0.4402, 0.6365, 1.0662, 0.7550, 0.4935, 1.3386, 0.0979, 0.9250, 0.2688,\n",
      "        0.8609, 0.6629, 0.3433, 0.7641, 0.5602, 0.5320, 1.8947, 0.5312, 1.1757,\n",
      "        1.4753, 0.7847, 0.2367, 1.5565, 1.5033, 0.2259, 0.6650, 1.2651, 0.5759,\n",
      "        0.4923, 2.4330, 0.9602, 0.3167, 1.0706, 0.9790, 0.6739, 0.4071, 1.0246,\n",
      "        0.4428, 0.5631, 0.8081, 0.7691, 1.2019, 0.6585], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([3.5690e-01, 1.1262e-01, 1.1351e+00, 6.4302e-01, 1.1881e+00, 8.7659e-01,\n",
      "        3.2671e-01, 1.6392e-01, 7.1418e-01, 5.0714e-01, 2.5494e-01, 1.5507e+00,\n",
      "        4.0026e-01, 1.3105e+00, 2.0710e-01, 1.2701e+00, 1.5149e+00, 9.7812e-01,\n",
      "        2.0297e-01, 2.7890e+00, 5.6363e-01, 4.8562e-01, 3.7689e+00, 2.4670e+00,\n",
      "        6.6548e-01, 7.8176e-01, 7.1935e-03, 8.2829e-01, 1.1900e+00, 2.7955e-01,\n",
      "        1.9923e+00, 4.9786e+00, 9.3388e+00, 2.1139e+00, 1.4224e+00, 1.2836e+00,\n",
      "        3.9881e-02, 5.1977e-01, 2.5517e+00, 3.4913e-01, 4.2318e+00, 8.9072e-01,\n",
      "        2.1403e+00, 1.3424e+00, 1.9309e+00, 6.7444e-01, 3.2183e+00, 5.8239e-01,\n",
      "        4.7184e-01, 8.5216e-01, 7.7432e-01, 3.4356e-01, 5.0061e-01, 5.6621e+00,\n",
      "        3.6871e-03, 1.9633e+00, 8.7162e-01, 3.3720e-01, 4.0501e-01],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([ 0.3059, 11.8523,  7.5206,  0.1587,  0.3262,  0.6688,  2.1500,  3.6498,\n",
      "         0.6638,  0.1468,  0.1054,  0.2226,  0.1525,  1.4864,  0.4361,  2.1235,\n",
      "         1.0518,  1.2492,  1.4959,  0.6073,  1.6438,  0.1380,  3.2220,  0.3601,\n",
      "         0.5799,  0.8484,  1.0974,  1.2665,  4.6602,  0.7521,  1.7580,  0.9833,\n",
      "         0.8456,  1.2998,  0.6031,  0.1031,  1.1125,  0.7622,  0.1754,  3.2079,\n",
      "         0.3473,  1.8273,  0.2055, 10.4033,  8.4842,  0.1278,  0.4897,  0.7711,\n",
      "         0.8982,  0.4390,  0.1077,  0.4259,  3.7591,  0.6771,  1.4509,  0.3706,\n",
      "         0.0468,  0.8098], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([3.5958, 4.8084, 0.3047, 0.7125, 0.3319, 0.1056, 2.6544, 3.0958, 0.9376,\n",
      "        0.1748, 0.1000, 0.6984, 0.8404, 0.7727, 0.3610, 0.1561, 1.1324, 0.7075,\n",
      "        0.8423, 1.8361, 0.8631, 2.1056, 0.1157, 3.3973, 0.9137, 0.2225, 0.2852,\n",
      "        0.0406, 0.5402, 0.4322, 1.8490, 1.9211, 0.2813, 0.2678, 1.3583, 0.1429,\n",
      "        0.8622, 0.4272, 1.8591, 0.8929, 1.3957, 0.1634, 0.3168, 0.7718, 0.7581,\n",
      "        2.1748, 0.8306, 0.2467, 0.5702, 3.7580, 0.6571, 1.9363, 0.7693, 0.2309,\n",
      "        0.1836, 1.5291, 1.9514], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9998, 0.9994, 0.9989, 0.9994, 1.0000, 0.9998, 0.9989, 0.9982, 0.9993,\n",
      "        0.9971, 1.0000, 0.9999, 1.0000, 1.0000, 1.0002, 1.0000, 1.0005, 0.9995,\n",
      "        0.9998, 0.9996, 0.9996, 0.9989, 0.9989, 0.9998, 0.9998, 0.9997, 0.9997,\n",
      "        0.9987, 1.0005, 1.0000, 0.9980, 0.9983, 0.9998, 0.9999, 0.9989, 1.0002,\n",
      "        0.9998, 0.9996, 1.0000, 0.9991, 0.9985, 0.9997, 0.9999, 0.9991, 0.9987,\n",
      "        0.9989, 0.9997, 0.9999, 0.9988, 1.0000, 0.9995, 0.9995, 0.9981, 0.9977,\n",
      "        1.0004, 0.9992, 0.9981, 0.9972, 0.9991, 0.9989, 0.9999, 0.9995, 0.9998,\n",
      "        0.9984, 0.9983, 0.9984, 1.0000, 0.9996, 0.9986, 1.0002, 0.9997, 0.9972,\n",
      "        0.9997, 0.9985, 0.9992, 0.9992, 0.9999, 0.9994, 0.9992, 0.9998, 0.9994,\n",
      "        0.9992, 0.9996, 0.9993, 0.9989, 0.9992, 1.0002], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9973, 0.9990, 0.9999, 0.9976, 1.0005, 0.9980, 0.9992, 0.9979, 0.9980,\n",
      "        0.9978, 0.9980, 1.0001, 1.0001, 0.9993, 0.9978, 0.9995, 1.0004, 0.9992,\n",
      "        1.0008, 0.9966, 0.9978, 0.9976, 0.9987, 0.9992, 0.9987, 0.9992, 0.9982,\n",
      "        0.9982, 0.9995, 0.9998, 0.9975, 0.9974, 0.9961, 0.9993, 0.9989, 0.9967,\n",
      "        0.9999, 0.9985, 1.0004, 1.0000, 0.9997, 0.9976, 1.0003, 0.9985, 0.9993,\n",
      "        0.9990, 0.9999, 0.9992, 0.9988, 0.9987, 0.9950, 0.9995, 0.9986, 0.9987,\n",
      "        0.9987, 0.9997, 1.0006, 0.9972, 0.9954, 0.9989, 1.0025, 0.9994, 0.9979,\n",
      "        1.0005, 1.0003, 0.9996, 0.9972, 0.9973, 0.9983, 0.9967, 0.9997, 0.9932,\n",
      "        0.9939, 0.9964, 0.9991, 0.9985, 0.9988, 0.9997, 0.9988, 0.9990, 0.9977,\n",
      "        0.9979, 0.9964, 0.9994, 0.9966, 0.9989, 1.0000], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9988, 1.0000, 0.9987, 1.0000, 1.0011, 1.0007, 1.0004, 0.9999, 1.0001,\n",
      "        0.9992, 0.9981, 0.9987, 0.9995, 1.0000, 0.9986, 0.9994, 0.9963, 0.9961,\n",
      "        0.9938, 0.9956, 0.9989, 0.9881, 0.9960, 1.0001, 0.9971, 0.9969, 0.9998,\n",
      "        0.9997, 0.9997, 0.9955, 0.9966, 0.9971, 0.9975, 0.9984, 0.9922, 0.9975,\n",
      "        1.0000, 0.9980, 0.9949, 0.9996, 0.9981, 0.9992, 0.9961, 1.0004, 0.9942,\n",
      "        0.9997, 0.9994, 1.0009, 0.9983, 0.9986, 0.9985, 0.9985, 0.9998, 0.9977,\n",
      "        0.9979, 0.9934, 0.9932, 0.9967, 0.9940, 0.9984, 0.9999, 0.9957, 0.9958,\n",
      "        0.9923, 1.0003, 0.9999, 0.9987, 0.9989, 0.9972, 0.9953, 0.9942, 0.9911,\n",
      "        0.9994, 0.9924, 0.9989, 0.9978, 0.9945, 1.0000, 0.9967, 0.9971, 0.9969,\n",
      "        0.9991, 0.9959, 1.0015, 0.9996, 0.9974, 0.9960], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9960, 1.0036, 0.9973, 0.9861, 1.0022, 0.9986, 0.9880, 0.9995, 0.9969,\n",
      "        1.0008, 0.9982, 0.9966, 1.0000, 0.9948, 0.9994, 0.9872, 0.9926, 0.9937,\n",
      "        0.9999, 1.0023, 0.9959, 0.9957, 0.9961, 0.9995, 0.9901, 0.9958, 0.9798,\n",
      "        1.0000, 0.9899, 0.9910, 0.9959, 0.9995, 0.9892, 0.9834, 0.9983, 0.9907,\n",
      "        0.9998, 0.9906, 0.9944, 0.9984, 0.9887, 0.9789, 0.9971, 0.9955, 0.9970,\n",
      "        0.9998, 0.9938, 0.9998, 0.9919, 0.9986, 0.9989, 0.9988, 0.9987, 0.9979,\n",
      "        0.9995, 0.9889, 1.0002, 0.9973, 0.9993, 0.9928, 0.9936, 1.0005, 1.0021,\n",
      "        0.9993, 0.9968, 0.9953, 0.9953, 0.9934, 0.9999, 0.9912, 0.9963, 0.9907,\n",
      "        1.0049, 0.9990, 0.9985, 0.9981, 0.9984, 0.9983, 1.0030, 0.9975, 0.9997,\n",
      "        0.9979, 0.9899, 0.9919, 0.9827, 0.9941, 0.9889], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9971, 0.9982, 0.9833, 0.9756, 0.9819, 0.9907, 0.9988, 0.9981, 0.9941,\n",
      "        0.9933, 0.9898, 1.0000, 0.9970, 0.9979, 0.9991, 0.9979, 0.9786, 0.9984,\n",
      "        0.9954, 0.9962, 1.0000, 0.9800, 0.9982, 0.9964, 0.9880, 0.9970, 0.9928,\n",
      "        0.9985, 0.9799, 0.9978, 0.9817, 0.9753, 0.9874, 0.9698, 0.9968, 0.9834,\n",
      "        0.9864, 1.0001, 0.9820, 1.0000, 0.9753, 0.9936, 0.9977, 0.9886, 0.9919,\n",
      "        1.0024, 1.0097, 1.0042, 0.9971, 0.9984, 0.9940, 0.9844, 0.9926, 0.9996,\n",
      "        1.0003, 0.9774, 1.0026, 1.0051, 1.0056, 0.9864, 1.0037, 0.9999, 0.9890,\n",
      "        0.9984, 0.9989, 0.9886, 0.9906, 0.9768, 0.9991, 0.9751, 0.9814, 0.9803,\n",
      "        0.9909, 0.9865, 0.9889, 0.9828, 0.9836, 0.9981, 0.9995, 0.9978, 1.0012,\n",
      "        0.9927, 0.9956, 0.9820, 0.9889, 1.0017, 0.9894], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9908, 0.9941, 0.9959, 0.9676, 0.9580, 0.9696, 1.0052, 1.0112, 0.9764,\n",
      "        0.9914, 0.9520, 0.9478, 1.0137, 0.9908, 1.0056, 0.9912, 0.9804, 0.9929,\n",
      "        0.9933, 0.9941, 0.9989, 0.9784, 1.0077, 0.9785, 0.9995, 0.9966, 0.9879,\n",
      "        0.9947, 0.9626, 0.9652, 0.9854, 0.9736, 0.9599, 0.9986, 0.9874, 1.0034,\n",
      "        1.0201, 1.0136, 0.9845, 1.0071, 0.9660, 1.0055, 0.9676, 0.9577, 0.9516,\n",
      "        0.9754, 0.9937, 1.0119, 0.9759, 0.9970, 0.9845, 0.9758, 0.9818, 0.9897,\n",
      "        0.9943, 1.0000, 0.9728, 0.9652, 1.0189, 0.9967, 0.9649, 0.9698, 1.0018,\n",
      "        1.0008, 0.9976, 1.0029, 0.9960, 0.9840, 0.9841, 0.9908, 0.9803, 0.9995,\n",
      "        0.9876, 0.9935, 1.0004, 0.9709, 1.0110, 1.0088, 0.9595, 0.9866, 0.9738,\n",
      "        0.9825, 0.9759, 0.9794, 0.9789, 0.9662, 0.9388], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9949, 0.9983, 0.9134, 1.0121, 0.9660, 0.9827, 0.9869, 0.9817, 0.9835,\n",
      "        1.0192, 1.0406, 0.9976, 0.9910, 0.9776, 1.0096, 0.9817, 0.9835, 0.9881,\n",
      "        1.0138, 0.9706, 0.9578, 0.9797, 1.0144, 0.9837, 0.9376, 0.9986, 0.9884,\n",
      "        1.0047, 1.0044, 0.9758, 0.9979, 1.0283, 1.0015, 1.0190, 0.9774, 0.9975,\n",
      "        1.0066, 1.0081, 0.9952, 0.9800, 1.0009, 0.9785, 0.9189, 0.9464, 1.0041,\n",
      "        0.9991, 0.9992, 0.9886, 0.9767, 0.9888, 0.9949, 0.9837, 0.9556, 0.9991,\n",
      "        0.9888, 1.0031, 0.9945, 0.9907, 1.0046, 0.9941, 0.9936, 1.0013, 0.9986,\n",
      "        0.9717, 0.9923, 0.9878, 1.0142, 0.9958, 1.0074, 0.9593, 0.9984, 1.0202,\n",
      "        0.9971, 0.9919, 0.9970, 0.9811, 0.9989, 0.9933], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0546, 1.0014, 0.9481, 1.0554, 0.9735, 0.9541, 0.9795, 0.9615, 1.0044,\n",
      "        1.0104, 0.9948, 0.9190, 0.9999, 1.0075, 1.0143, 0.9898, 0.9864, 1.0230,\n",
      "        1.0246, 0.9913, 1.0306, 1.0073, 0.9768, 0.9558, 0.9808, 0.9579, 1.0227,\n",
      "        0.9783, 0.9997, 0.9787, 0.9988, 1.0142, 1.0029, 0.9648, 1.0002, 0.9846,\n",
      "        0.8460, 1.0832, 0.9933, 0.9771, 0.9622, 0.9914, 1.0191, 0.9537, 1.0336,\n",
      "        1.0825, 0.9484, 1.0138, 0.9979, 0.9554, 1.0142, 0.9428, 0.9940, 0.9823,\n",
      "        1.0062, 1.0264, 0.9870, 0.9867, 0.9954, 1.0251, 0.9879, 0.9861, 0.9584,\n",
      "        0.9777, 0.9918, 1.0018, 0.9641, 0.9850, 0.9657, 0.9879, 1.0055, 0.9657,\n",
      "        1.0223, 1.0207, 0.9992, 1.0190, 0.9911, 0.9553], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9179, 0.8996, 0.6415, 0.9906, 0.9677, 0.9854, 0.9610, 0.9641, 0.8953,\n",
      "        1.2098, 1.0990, 1.0745, 1.0128, 0.9930, 0.9892, 0.8768, 1.0337, 0.9477,\n",
      "        0.9777, 0.9552, 0.9707, 0.8727, 0.8524, 0.9663, 0.9710, 0.9729, 0.9971,\n",
      "        0.9425, 1.0151, 1.0030, 0.9641, 0.9497, 1.0093, 0.9954, 1.0451, 1.0513,\n",
      "        0.9634, 0.9580, 1.0643, 0.9020, 1.0020, 0.9245, 0.9386, 0.8830, 0.8995,\n",
      "        1.0081, 0.9969, 0.9896, 0.9928, 0.9814, 1.0142, 1.0394, 0.9746, 0.9954,\n",
      "        1.0047, 1.0274, 0.9961, 0.9824, 0.9418, 0.9575, 1.0011, 1.0080, 0.9367,\n",
      "        0.9609, 0.9544, 0.8888, 1.0087, 0.9533, 1.0104, 0.8575, 0.9669, 0.8800,\n",
      "        0.9855, 0.9700, 0.9037, 0.9961, 0.9772, 0.9779], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9078, 0.9936, 0.9745, 0.8337, 0.9307, 1.1116, 0.9348, 0.4782, 1.0144,\n",
      "        0.4392, 1.0255, 0.4787, 1.0115, 1.0191, 0.9180, 1.1103, 0.8147, 0.4359,\n",
      "        0.8921, 0.8581, 0.9249, 0.9671, 0.4846, 1.0532, 0.5534, 1.2561, 0.9506,\n",
      "        1.3990, 1.1332, 1.7430, 1.1869, 0.8188, 1.0566, 0.9111, 0.9891, 0.9767,\n",
      "        1.1368, 1.0724, 0.9836, 0.9867, 1.0184, 0.9835, 0.9851, 0.8892, 1.0165,\n",
      "        0.9813, 0.9920, 0.9703, 0.9392, 0.9036, 0.9417, 0.8763, 0.8626, 1.1649,\n",
      "        1.0900, 1.0417, 0.7472, 0.9769, 1.0430, 0.9581, 0.8651, 0.8653, 0.9567,\n",
      "        1.1615, 1.0604, 0.9906, 1.0248, 0.9739, 0.9675, 0.8897, 0.9032, 0.9214,\n",
      "        1.0181, 0.7976, 0.8099, 0.9518, 0.9254, 0.4796], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9710, 1.2000, 0.9324, 0.8741, 0.1979, 0.8834, 1.3483, 0.7732, 1.6178,\n",
      "        0.4025, 0.3514, 1.0985, 0.7897, 1.0564, 0.6803, 0.9490, 0.8157, 1.1440,\n",
      "        1.0347, 1.2819, 1.2885, 0.3894, 0.2076, 0.6076, 1.4487, 0.5007, 1.5348,\n",
      "        0.6078, 0.3940, 0.9086, 1.0696, 0.8096, 0.9734, 0.7246, 0.3085, 1.3181,\n",
      "        0.7248, 0.5816, 0.9978, 0.3427, 0.9424, 1.1441, 1.6105, 1.0059, 0.1721,\n",
      "        1.0153, 0.6779, 1.2678, 1.0171, 0.7791, 0.7708, 0.8481, 0.9250, 1.2954,\n",
      "        0.8728, 1.2086, 0.3051, 1.1118, 0.3443, 0.3069, 0.6968, 0.8129, 0.9148,\n",
      "        1.7190, 1.5773, 0.8200, 0.7473, 0.5593, 0.8840, 0.9247, 0.9024, 1.1355,\n",
      "        0.9525, 1.0394, 0.8492, 0.9290, 0.9356, 0.8110], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.9333, 2.4420, 0.2174, 0.7617, 0.4191, 0.6421, 0.2784, 1.0694, 0.6755,\n",
      "        1.0419, 1.4195, 4.0609, 0.7212, 1.1259, 0.2789, 0.5784, 0.5703, 1.8813,\n",
      "        2.7051, 0.3675, 0.6611, 1.0663, 1.1103, 0.8571, 0.0444, 0.1855, 0.8968,\n",
      "        1.7138, 1.0212, 1.8621, 3.0490, 3.7608, 0.5102, 1.0760, 1.0328, 0.8777,\n",
      "        0.9578, 1.3529, 0.2724, 1.0254, 1.4036, 0.8444, 0.9450, 1.5589, 0.0128,\n",
      "        0.4364, 0.6095, 0.4440, 0.9486, 0.6857, 0.9455, 0.9296, 1.5179, 0.9501,\n",
      "        1.4893, 0.5546, 1.0529, 2.3991, 1.9320, 0.7820, 0.7594, 0.8453, 1.0685,\n",
      "        1.4118, 0.4988, 0.1659, 0.2840, 1.1712, 0.7876, 0.5842, 0.9405, 0.9711,\n",
      "        0.5884, 1.0214, 2.1454, 0.4934, 1.5316, 0.7265], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0276, 1.8474, 1.3761, 2.2919, 4.1205, 0.0132, 0.3975, 0.0925, 0.9969,\n",
      "        2.7644, 1.0223, 1.6994, 2.4951, 0.2180, 0.5795, 3.6370, 1.2038, 0.5743,\n",
      "        1.9232, 1.2918, 0.2892, 1.0323, 6.1111, 1.4744, 0.7833, 4.2868, 2.1711,\n",
      "        0.0778, 1.9771, 0.5748, 0.9169, 1.6758, 0.6365, 0.6105, 0.3788, 0.0428,\n",
      "        1.5107, 1.7705, 0.8962, 2.2481, 1.5628, 1.4901, 0.6143, 2.7267, 1.4217,\n",
      "        1.7072, 0.5158, 1.3187, 1.7028, 1.7204, 1.0143, 2.2666, 1.9989, 1.2542,\n",
      "        0.2048, 0.2088, 0.8994, 1.6378, 1.2158, 0.8686, 0.9313, 1.7503, 0.2292,\n",
      "        1.2624, 2.0196, 1.1413, 1.7016, 0.1113, 1.6913, 6.1117, 1.1005, 1.0024,\n",
      "        2.5929, 1.9932, 1.0211, 2.3463, 0.4566, 0.4257, 0.6417, 1.3739, 0.3367,\n",
      "        0.0986, 1.1079, 0.9623, 2.1218, 0.4453, 0.5920, 0.5512, 0.2532, 0.1608,\n",
      "        0.7844, 0.8246, 0.9090, 1.5073, 0.8052, 1.4322, 0.0130, 1.6987, 0.0572,\n",
      "        0.0481, 0.9471, 0.2746, 4.2953, 0.0221, 3.3722, 0.9497, 0.5813, 2.5808,\n",
      "        1.7597, 1.3681, 0.6536, 0.7738, 0.0164, 3.4920, 0.8502, 0.8879, 0.1606,\n",
      "        0.5933, 0.8832, 1.2940, 0.8350, 0.8134, 1.1607], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.3661, 1.6920, 0.8333, 0.2558, 0.3982, 0.0956, 0.6023, 0.6683, 0.4475,\n",
      "        0.9205, 0.3045, 1.5655, 0.2991, 0.9834, 0.4027, 0.5779, 0.4717, 0.2954,\n",
      "        0.4536, 1.1121, 0.5631, 0.2388, 0.0083, 0.3564, 0.1363, 0.8069, 1.3099,\n",
      "        0.4611, 1.3083, 0.2983, 0.7765, 1.2291, 2.7954, 0.9959, 1.0711, 1.1611,\n",
      "        0.6919, 1.1610, 0.6200, 1.7336, 0.1377, 0.8276, 2.0516, 0.0599, 2.3131,\n",
      "        0.7721, 1.2534, 1.6219, 0.8780, 0.5698, 0.4069, 2.5236, 0.9309, 1.5936,\n",
      "        0.8667, 0.1855, 0.0157, 1.5616, 0.8524, 0.6874, 0.7822, 0.5017, 0.9424,\n",
      "        1.7703, 1.3363, 0.4823, 1.5760, 0.5733, 0.8137, 2.2145, 0.7976, 0.3292,\n",
      "        0.6189, 0.7703, 1.1610, 2.5390, 0.7134, 4.1317, 1.1064, 0.5942, 0.5407,\n",
      "        1.0564, 0.9998, 0.9354, 0.5225, 0.8846, 1.3981, 1.2103, 0.2949, 0.8996,\n",
      "        0.4895, 0.4069, 1.0484, 0.3531, 3.8075, 3.7806, 2.5441, 1.3282, 2.0971,\n",
      "        1.1702, 0.9494, 1.2662, 2.7721, 0.5047, 0.8689, 1.3255, 3.4826, 5.1348,\n",
      "        1.7092, 0.8811, 1.1170, 1.4891, 0.0531, 0.2614, 0.6592, 1.2870, 1.0366,\n",
      "        0.9616, 0.6913, 1.1401, 0.6142, 0.6563, 0.9781], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0538, 1.6999, 0.5206, 0.0959, 0.0375, 0.2414, 0.8657, 0.4145, 1.0028,\n",
      "        1.4459, 0.1554, 1.7937, 1.3968, 1.0168, 0.2988, 1.3460, 1.2686, 0.9652,\n",
      "        1.1637, 1.7749, 0.0421, 1.5068, 0.6999, 0.5986, 0.7775, 2.1903, 2.5375,\n",
      "        1.0755, 0.8732, 0.0291, 0.0718, 1.5495, 1.0649, 3.1197, 0.3471, 0.8872,\n",
      "        0.1567, 0.0689, 1.3778, 0.6055, 0.3424, 0.7632, 0.0918, 1.1852, 1.6940,\n",
      "        0.5211, 1.7014, 1.9784, 0.4904, 0.6826, 1.3231, 1.1096, 3.5855, 3.9852,\n",
      "        1.1588, 0.5390, 1.8403, 1.1179, 1.1155, 1.6264, 0.8554, 1.5694, 0.0767,\n",
      "        0.0087, 0.5224, 1.2519, 0.1010, 0.3042, 0.8301, 1.2368, 4.1126, 2.3815,\n",
      "        1.2925, 1.1415, 0.0401, 0.1876, 1.3525, 0.7251, 0.1372, 0.7798, 0.0124,\n",
      "        0.4527, 1.1112, 0.4861, 0.4350, 0.5047, 0.3160, 0.8452, 1.0534, 0.8989,\n",
      "        1.1416, 0.4841, 0.6662, 0.7773, 1.7116, 0.5234, 1.2065, 1.0716, 0.8833,\n",
      "        1.1606, 0.0785, 0.2218, 0.2953, 0.7419, 0.8770, 1.6732, 0.6036, 0.7287,\n",
      "        1.0800, 1.0287, 1.3378, 0.4999, 0.2454, 1.1206, 0.2328, 1.2444, 0.2033,\n",
      "        0.1299, 0.1466, 0.1419, 1.1543, 1.1308, 1.0659], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.2252, 1.1636, 1.2282, 0.2424, 0.9153, 0.7904, 0.0915, 0.6184, 0.2278,\n",
      "        0.9352, 0.1805, 1.4035, 1.2685, 0.3405, 1.2810, 0.7335, 0.9162, 0.2614,\n",
      "        0.9004, 1.4384, 0.4269, 0.9760, 0.7967, 0.3682, 0.7102, 1.2927, 2.1460,\n",
      "        0.3263, 0.5205, 0.4312, 0.8704, 0.4674, 0.6289, 0.3193, 1.2683, 0.4489,\n",
      "        0.5878, 0.6577, 1.6614, 1.8707, 1.1141, 0.8671, 0.7859, 0.7340, 0.7104,\n",
      "        0.0265, 0.8525, 1.7236, 0.7148, 1.0975, 0.8169, 0.5489, 0.8226, 1.1386,\n",
      "        1.3313, 0.1249, 1.0121, 1.9772, 0.9757, 2.7157, 0.6719, 0.6091, 1.1241,\n",
      "        1.0033, 0.8820, 0.7847, 1.0218, 1.8738, 0.0839, 1.3125, 0.5159, 0.0250,\n",
      "        1.7943, 1.3938, 1.3479, 1.7326, 1.1946, 0.6897, 1.3717, 0.0617, 0.7529,\n",
      "        0.7563, 0.5137, 0.6726, 0.7067, 1.0562, 0.0681, 0.6712, 0.0566, 0.7926,\n",
      "        0.4681, 1.6148, 2.2285, 0.3324, 0.3696, 1.7505, 0.9589, 0.9042, 0.3793,\n",
      "        0.6748, 0.6946, 1.0190, 0.8470, 1.1438, 0.5557, 0.7590, 1.1133, 0.9251,\n",
      "        0.9975, 0.7096, 0.1789, 0.4993, 0.8532, 0.8990, 1.5862, 0.4827, 1.5458,\n",
      "        0.6445, 1.1673, 0.5336, 0.9156, 0.7160, 0.2005], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.4550, 0.0563, 0.1933, 0.7151, 0.1026, 1.5132, 0.6239, 0.5946, 0.8668,\n",
      "        2.7276, 1.8555, 3.6448, 0.7073, 1.3439, 0.9602, 1.2101, 3.4603, 2.9020,\n",
      "        0.6948, 0.9910, 0.3849, 0.3104, 0.1223, 0.3435, 0.6299, 0.9145, 2.2580,\n",
      "        0.6043, 0.4987, 0.7939, 2.7959, 1.1529, 1.0155, 0.2879, 0.8054, 0.1973,\n",
      "        0.2906, 0.4552, 0.2788, 0.8289, 1.1989, 1.7099, 0.2470, 1.1078, 0.3343,\n",
      "        0.5560, 0.5663, 0.0052, 1.7479, 0.5515, 0.3126, 2.9747, 1.3392, 0.3432,\n",
      "        0.6652, 1.0967, 2.0185, 0.1571, 0.6099, 1.3652, 0.5876, 0.0728, 1.1411,\n",
      "        1.3921, 0.1895, 0.6485, 2.4480, 1.4798, 0.0402, 1.2795, 0.7489, 1.6800,\n",
      "        1.4654, 1.4326, 1.0820, 2.2048, 0.8036, 0.2981, 1.0031, 1.2254, 0.3444,\n",
      "        1.1591, 1.1746, 1.2624, 0.0187, 0.6953, 0.2224, 1.3448, 0.5190, 0.4475,\n",
      "        0.7186, 0.2953, 0.6488, 0.7334, 0.2359, 1.4520, 0.4371, 0.9850, 0.9813,\n",
      "        0.9318, 0.9084, 1.2417, 0.5417, 0.1621, 0.9821, 0.5537, 1.0766, 1.0562,\n",
      "        0.9519, 0.7799, 0.6863, 0.1637, 0.8075, 0.3504, 0.3794, 1.2762, 0.8254,\n",
      "        0.1788, 1.1361, 0.1731, 0.6578, 0.1300, 1.0428], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9877, 0.4600, 0.4476, 3.9275, 0.7180, 2.6970, 2.2100, 0.4903, 1.3370,\n",
      "        1.1808, 0.3831, 0.5663, 2.3571, 0.6578, 2.8372, 0.1264, 0.6997, 0.0404,\n",
      "        2.2164, 1.7158, 0.1309, 0.8561, 1.1746, 1.4951, 0.6199, 0.2530, 0.3881,\n",
      "        0.5809, 2.0768, 0.0535, 0.2569, 0.9906, 0.3755, 1.5786, 1.2302, 2.8752,\n",
      "        0.2566, 0.7228, 1.7278, 3.7868, 1.5577, 2.5698, 2.0623, 0.5182, 1.0136,\n",
      "        0.6881, 1.2703, 0.8131, 1.2578, 0.5515, 0.4020, 1.2606, 1.7499, 0.4275,\n",
      "        0.8198, 0.6471, 0.2007, 3.7864, 0.6934, 4.5403, 0.5128, 1.7373, 0.8489,\n",
      "        0.2589, 1.6485, 0.7934, 0.5697, 0.1721, 1.3269, 0.5862, 0.0760, 0.6074,\n",
      "        1.2866, 1.0765, 0.2244, 1.4856, 0.3205, 0.4873, 0.8941, 0.8809, 0.8607,\n",
      "        2.8417, 2.4184, 0.2936, 2.0965, 0.5237, 3.1597, 0.6372, 2.1390, 4.3478,\n",
      "        0.3819, 0.9553, 0.9134, 1.1121, 0.8357, 0.1261, 0.9079, 0.3766, 2.7743,\n",
      "        1.4527, 1.0771, 1.6264, 0.2050, 0.1646, 0.3941, 0.8935, 0.6284, 0.0782,\n",
      "        1.0435, 0.1264, 2.2849, 0.3129, 0.8510, 0.6911, 0.6708, 1.1798, 1.0907,\n",
      "        0.9273, 1.0102, 0.4430, 0.0241, 1.0095, 0.7984], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.6045, 0.8421, 1.6172, 0.6137, 1.0969, 0.5092, 1.3348, 0.1741, 0.1883,\n",
      "        0.1460, 0.1478, 0.5325, 0.6860, 0.6971, 0.8146, 0.0738, 0.6091, 1.2437,\n",
      "        0.5626, 0.0386, 0.8230, 0.3914, 0.3494, 0.7594, 0.6213, 0.1440, 0.5417,\n",
      "        1.1635, 1.8395, 1.1210, 4.6658, 0.9876, 1.1562, 0.9905, 0.8636, 1.5934,\n",
      "        1.3954, 0.6265, 2.4953, 0.8197, 0.3036, 0.6578, 8.4750, 1.3079, 1.0127,\n",
      "        0.5568, 0.1334, 0.4206, 0.1162, 0.7540, 1.3545, 0.1947, 0.2804, 1.4148,\n",
      "        0.4763, 0.6395, 0.2244, 3.3157, 2.4249, 2.1200, 0.9828, 0.8387, 0.8597,\n",
      "        0.9303, 1.1250, 3.8310, 0.0210, 0.3693, 1.6473, 0.1671, 2.6197, 0.7032,\n",
      "        1.0297, 0.3697, 0.4584, 0.7868, 1.5484, 2.5909, 1.1449, 0.9180, 0.2836,\n",
      "        2.6005, 0.0241, 1.6612, 0.0608, 0.8838, 1.3338, 0.5875, 0.2456, 0.4205,\n",
      "        1.7001, 1.1781, 0.8142, 0.0486, 0.4280, 1.1728, 0.8944, 1.8051, 0.8206,\n",
      "        1.1091, 0.8895, 1.5833, 0.8676, 1.7429, 0.9629, 0.9774, 1.0357, 0.0819,\n",
      "        0.0384, 0.8296, 2.1717, 0.6915, 1.3228, 0.6161, 1.8970, 3.9815, 0.1119,\n",
      "        3.5516], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9321, 3.7951, 2.5969, 0.7711, 0.7558, 1.5681, 1.1314, 0.2914, 0.9990,\n",
      "        1.1335, 1.2150, 0.9196, 2.1337, 1.0620, 3.8735, 0.6080, 4.9610, 2.0588,\n",
      "        0.9297, 1.5154, 1.7762, 0.8380, 0.0725, 0.6578, 0.4520, 0.0270, 0.8917,\n",
      "        0.1747, 0.2633, 1.2870, 0.1544, 0.9527, 1.1919, 1.1097, 2.2671, 0.2878,\n",
      "        0.3905, 1.5599, 0.9538, 0.0277, 0.1865, 0.8789, 1.6258, 0.0187, 1.0241,\n",
      "        0.4589, 0.8214, 0.4727, 0.9575, 0.8838, 0.4450, 0.8035, 0.7412, 0.0684,\n",
      "        0.5787, 0.8492, 1.2530, 3.4388, 0.7912, 1.9491, 0.6616, 0.0409, 1.0629,\n",
      "        0.1922, 1.4668, 0.6476, 1.2518, 1.8271, 0.8757, 1.0111, 0.0259, 0.4339,\n",
      "        1.3843, 1.1341, 1.0489, 0.0825, 0.2010, 0.8557, 2.7410, 0.0495, 0.5086,\n",
      "        0.3052, 0.1729, 0.1717, 0.3082, 0.3862, 1.2314, 2.2996, 0.5497, 0.6075,\n",
      "        0.0738, 1.1784, 0.7364, 1.2510, 1.1083, 0.5351, 1.7051, 0.0313, 0.1079,\n",
      "        1.1212, 1.4899, 0.3265, 0.7848, 0.0673, 1.6911, 1.1262, 1.9567, 1.1208,\n",
      "        0.1381, 0.7036, 0.1887, 1.4095, 0.5057, 0.8924, 0.4544, 0.2255, 1.4197,\n",
      "        0.2937, 2.9179, 0.1010], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.7961, 0.1162, 1.6083, 0.9018, 1.1871, 0.1111, 1.0222, 0.4623, 0.4892,\n",
      "        0.3299, 1.8041, 0.6366, 1.0792, 2.1884, 0.5624, 0.9834, 0.2118, 0.2986,\n",
      "        1.9823, 0.3718, 3.9102, 2.1677, 0.5645, 3.2205, 1.0106, 1.7937, 0.1864,\n",
      "        1.0954, 0.9986, 0.3147, 0.2430, 0.6231, 1.0715, 0.2824, 0.1146, 0.3442,\n",
      "        0.6102, 1.0028, 0.6245, 0.5404, 1.1207, 0.8688, 0.2781, 0.0095, 0.9132,\n",
      "        0.3587, 0.5896, 0.8884, 0.9081, 0.7611, 0.1430, 1.5412, 0.4195, 0.0989,\n",
      "        0.3906, 1.2459, 0.8875, 0.3555, 0.3821, 1.2879, 5.1900, 1.0235, 0.7097,\n",
      "        0.9428, 0.2327, 1.6735, 2.2041, 0.3882, 0.5622, 2.0405, 0.2672, 0.3798,\n",
      "        0.3559, 1.2791, 0.1875, 0.1577, 0.5006, 4.9777, 2.7177, 0.1561, 1.6252,\n",
      "        0.7514, 0.5157, 0.4598, 2.1175, 0.8188, 0.8211, 0.2756, 0.9173, 0.1433,\n",
      "        0.2347, 0.4727, 1.1139, 0.0491, 1.9027, 0.8626, 0.0168, 0.5845, 0.8933,\n",
      "        0.6242, 0.0635, 1.1172, 1.3936, 0.1981, 1.3257, 3.0796, 0.9275, 0.8213,\n",
      "        0.7456, 0.1204, 0.8438, 0.0616, 2.6149, 0.6821, 3.3459, 0.1521, 0.2616],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([8.8690e-01, 3.9967e-01, 3.3731e-01, 3.6710e-01, 3.3265e-01, 1.1565e+00,\n",
      "        2.7275e-01, 8.1808e-01, 8.4563e-01, 1.5364e+00, 8.3885e-01, 9.3894e-01,\n",
      "        2.9063e+00, 1.5846e+00, 8.2683e-01, 7.6737e-01, 8.8637e-02, 3.7142e-01,\n",
      "        1.8780e+00, 9.6806e-01, 1.1726e+00, 1.5787e+00, 8.8284e-01, 6.8503e-02,\n",
      "        3.5679e-01, 5.4387e-01, 5.4150e-01, 7.0824e-01, 9.9285e-01, 3.9404e-01,\n",
      "        8.6838e-01, 2.8458e-01, 1.4454e-01, 8.8692e-01, 6.9407e-01, 3.9004e-01,\n",
      "        3.4587e-01, 8.8364e-01, 1.2640e+00, 6.0549e-02, 5.1846e-01, 1.6423e-01,\n",
      "        3.3861e+00, 1.2466e+00, 8.1839e-01, 3.2802e-01, 1.0015e+00, 9.3841e-01,\n",
      "        1.1986e+00, 1.6486e+00, 7.1728e-01, 1.3913e+00, 1.5942e-01, 5.0119e-02,\n",
      "        1.8532e+00, 3.3526e-01, 1.3435e-01, 3.2937e+00, 1.2631e+00, 2.3223e+00,\n",
      "        9.0355e-01, 1.3500e-02, 5.3546e-01, 4.6807e-01, 7.6567e-01, 2.5072e+00,\n",
      "        2.4131e-01, 2.0880e-02, 1.0047e+00, 3.1427e-01, 1.7941e+00, 2.6071e+00,\n",
      "        9.4893e-01, 6.5066e-01, 1.0691e+00, 7.0568e-01, 1.9940e-01, 7.3086e-01,\n",
      "        2.0850e+00, 1.0976e+00, 3.2032e-01, 5.0496e-01, 2.1488e-01, 7.3031e-01,\n",
      "        2.4461e+00, 2.5824e-02, 3.3847e-01, 2.5868e-03, 1.4572e-01, 7.6796e-01,\n",
      "        1.9141e+00, 6.3404e-01, 1.0065e+00, 7.1203e-01, 4.7116e+00, 3.2969e+00,\n",
      "        7.9928e-01, 1.1317e+00, 2.2686e+00, 1.9125e+00, 1.3667e+00, 4.6315e-01,\n",
      "        1.9767e+00, 5.4477e-01, 3.0202e-01, 1.3335e-01, 7.6815e-01, 7.5779e-01,\n",
      "        2.0101e-01, 1.8750e+00, 1.7709e+00, 3.2124e-01, 7.5586e-01, 2.5270e+00,\n",
      "        4.8653e-01, 1.1892e+00, 1.4702e+00, 6.1875e-01, 2.0806e-01],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([ 0.0207,  1.9712,  0.5907,  2.9832,  0.1370,  0.9390,  2.1504,  3.0155,\n",
      "         0.2293,  4.1327,  0.4666,  4.4838,  4.9553,  6.2247,  1.3728,  1.1013,\n",
      "         1.1220,  0.1949,  0.6771,  1.7952,  0.0767,  1.8883,  1.4535,  0.4793,\n",
      "         0.2796,  1.0409,  0.2579,  2.2159,  3.1094,  0.0738,  1.4239,  0.6602,\n",
      "         0.8607,  4.2327,  2.9691,  2.5176,  6.8695,  0.3341,  1.1244,  0.5519,\n",
      "         0.5451,  0.4182,  1.3034,  1.2291,  0.3911,  0.5214,  0.5417,  0.2234,\n",
      "         0.2871,  1.0240,  1.1969,  2.0324,  0.0643,  1.8112, 13.5104,  0.5412,\n",
      "         0.3840,  0.9138,  0.9819,  0.4400,  0.3483,  1.1045,  0.8789,  0.4358,\n",
      "         0.4635,  1.1459,  1.0652,  0.9783,  2.0422,  1.0207,  7.2949,  0.6052,\n",
      "         2.9220,  0.2046,  0.9241,  4.8392,  1.2166,  0.3791,  1.7392,  0.3669,\n",
      "         0.3022,  0.1104,  3.7496,  1.6910,  2.9769,  0.0143,  0.2276,  2.2311,\n",
      "         1.0051,  8.6563,  0.7272,  0.9928,  0.0914,  0.7515,  0.1747,  0.1413,\n",
      "         1.2185,  1.1345,  1.1124,  0.3189,  0.8511,  0.3564,  4.7258,  1.0236,\n",
      "         0.3222,  0.4741,  2.3058,  2.9172,  0.3279,  1.3973,  0.3760,  0.0159,\n",
      "         0.5627,  0.9275,  0.6939,  0.1636,  0.7956,  0.5905], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.8666, 0.6043, 0.7477, 3.9645, 4.6824, 0.5669, 0.2788, 0.4946, 0.7164,\n",
      "        0.5967, 0.8388, 1.3717, 2.1327, 1.6712, 1.2942, 1.1923, 0.3698, 0.1396,\n",
      "        0.4668, 0.5916, 1.8841, 0.8223, 1.6750, 0.2697, 1.0002, 0.5114, 2.5548,\n",
      "        2.5647, 0.9069, 2.8572, 1.5203, 0.5174, 1.0247, 0.9794, 0.9662, 2.3619,\n",
      "        0.6969, 0.3195, 0.8801, 1.2450, 1.0729, 0.4685, 0.4304, 2.3010, 1.1030,\n",
      "        0.1883, 0.2747, 0.2605, 1.4999, 0.2224, 1.8378, 0.0804, 0.1097, 0.0224,\n",
      "        0.5711, 0.0204, 0.4010, 0.8772, 0.6679, 0.4769, 0.8428, 0.3385, 0.6871,\n",
      "        0.8902, 0.1448, 0.1610, 0.1587, 0.3974, 0.0567, 1.6325, 0.6393, 2.8122,\n",
      "        0.8483, 0.2448, 1.2647, 1.4421, 0.2389, 0.0543, 1.2096, 0.1488, 0.5312,\n",
      "        0.2679, 0.1861, 0.3279, 1.0393, 1.1655, 0.4267, 1.8057, 1.1195, 0.0820,\n",
      "        0.6519, 0.1324, 2.8217, 1.9868, 0.5398, 1.9424, 2.7484, 0.1600, 0.0430,\n",
      "        0.4616, 0.8081, 0.5742, 0.6481, 0.0104, 0.9944, 0.6424, 0.4803, 0.3143,\n",
      "        0.3946, 0.4628, 1.8994, 0.5892, 3.0205, 0.3883, 0.5657, 0.8335, 1.7534,\n",
      "        0.5520], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([ 0.3653,  1.3909,  0.7075,  0.8582,  1.6216,  1.9150,  2.0617,  1.0156,\n",
      "         0.0274,  0.2487,  2.2338,  1.2168,  1.0647,  0.1540,  1.8554,  0.3571,\n",
      "         2.2504,  2.9105,  1.7294,  0.8958,  1.2490,  3.1888,  2.7527,  0.9967,\n",
      "         4.9132,  0.9494,  2.5738,  0.5042,  2.5376,  0.4298,  0.2461,  0.0312,\n",
      "         0.2207,  3.0022,  0.8871,  1.5247, 10.2598,  0.5099,  0.9722,  0.2651,\n",
      "         0.0215,  0.6758,  0.8525,  0.8278,  1.2112,  1.5618,  1.3887,  0.8839,\n",
      "         0.8009,  1.3154,  1.0120,  0.6533,  0.9566,  1.0102,  0.7990,  2.2680,\n",
      "         1.4519,  0.7271,  3.1057,  3.9796,  0.2063,  0.3190,  0.5054,  1.0613,\n",
      "         0.8775,  1.4338,  6.0428,  2.7130,  0.8521,  0.8055,  9.9172,  3.8121],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0122, 1.1432, 0.8142, 0.9441, 0.7099, 0.8504, 0.8249, 0.8678, 0.6589,\n",
      "        1.2758, 0.9694, 1.0107, 0.3959, 0.8807, 0.4383, 0.9508, 0.0433, 0.4677,\n",
      "        0.7968, 1.2779, 1.0557, 0.3224, 1.0119, 0.7120, 1.0438, 1.0091, 0.9645,\n",
      "        0.8500, 0.9513, 0.9038, 0.7803, 1.0238, 0.9196, 0.9710, 0.9587, 0.9886,\n",
      "        1.1059, 0.8347, 1.0132, 0.4304, 0.0490, 0.3544, 1.0591, 1.2732, 1.1183,\n",
      "        1.1244, 0.8761, 0.7134, 1.0167, 0.7426, 0.9203, 1.0955, 0.5849, 0.8396,\n",
      "        1.0048, 1.0400, 0.9671, 0.9221, 0.7289, 0.7970, 0.9056, 0.7051, 1.0090,\n",
      "        1.0150, 1.0245, 1.0148, 0.9784, 0.8814, 0.9686, 0.1499, 0.9898, 1.0129],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9896, 1.0049, 0.9897, 1.0073, 0.9976, 1.0056, 1.0080, 0.9924, 1.0209,\n",
      "        0.9831, 0.9800, 0.9963, 0.9292, 0.9761, 0.8553, 0.8455, 0.9888, 0.9930,\n",
      "        0.9808, 0.9756, 0.9301, 1.0107, 0.9658, 0.9807, 0.9497, 1.0002, 0.9844,\n",
      "        0.9867, 0.9861, 0.9836, 1.0166, 0.9907, 0.9998, 1.0255, 1.0143, 0.9684,\n",
      "        0.9293, 0.9967, 1.0027, 0.8558, 0.9068, 0.7896, 0.9858, 0.9705, 1.0196,\n",
      "        1.0277, 1.0027, 0.9608, 1.0116, 0.9538, 1.0174, 0.9796, 1.0240, 0.9226,\n",
      "        0.9750, 0.8651, 1.0117, 1.0840, 0.9783, 0.9648, 0.9990, 1.0080, 0.9609,\n",
      "        0.9555, 0.9252, 0.9793, 0.9887, 0.9740, 1.0379, 1.0117, 0.9272, 0.8485],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9991, 0.9971, 0.9947, 1.0154, 0.9808, 1.0051, 1.0012, 1.0024, 1.0014,\n",
      "        0.9940, 0.9926, 1.0013, 0.9764, 0.9838, 0.9954, 0.9838, 0.9744, 0.9930,\n",
      "        0.9968, 0.9973, 0.9923, 0.9970, 1.0040, 1.0040, 1.0000, 0.9945, 1.0027,\n",
      "        1.0017, 0.9876, 0.9978, 1.0001, 1.0019, 1.0025, 0.9772, 1.0087, 1.0029,\n",
      "        0.9879, 0.9955, 0.9979, 0.9581, 0.9887, 0.9971, 0.9966, 0.9999, 1.0003,\n",
      "        0.9963, 0.9999, 1.0014, 0.9977, 0.9912, 0.9821, 0.9951, 1.0015, 0.9982,\n",
      "        1.0043, 0.9825, 0.9869, 1.0010, 0.9994, 0.9950, 0.9967, 1.0052, 0.9872,\n",
      "        1.0045, 1.0027, 0.9630, 0.9933, 1.0013, 0.9980, 0.9890, 0.9964, 0.9825],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0011, 0.9993, 0.9995, 0.9976, 0.9993, 0.9994, 0.9999, 0.9996, 0.9989,\n",
      "        1.0007, 1.0000, 1.0042, 1.0000, 0.9964, 0.9977, 1.0002, 0.9949, 0.9936,\n",
      "        0.9946, 0.9989, 0.9975, 1.0063, 1.0014, 1.0120, 1.0009, 0.9998, 0.9907,\n",
      "        1.0069, 1.0001, 0.9988, 1.0034, 0.9984, 1.0010, 1.0011, 1.0009, 0.9974,\n",
      "        1.0014, 1.0069, 1.0054, 0.9852, 0.9851, 0.9847, 0.9933, 1.0004, 0.9957,\n",
      "        1.0001, 1.0128, 1.0159, 1.0002, 0.9982, 1.0016, 0.9887, 0.9944, 0.9967,\n",
      "        0.9972, 0.9911, 0.9979, 0.9891, 1.0019, 0.9968, 0.9949, 1.0000, 1.0003,\n",
      "        1.0019, 0.9989, 0.9787, 1.0013, 0.9967, 0.9968, 0.9929, 0.9980, 0.9973],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9921, 0.9993, 0.9996, 0.9945, 1.0005, 0.9999, 1.0000, 0.9987, 1.0030,\n",
      "        0.9997, 0.9974, 0.9998, 0.9959, 0.9995, 1.0025, 1.0027, 0.9999, 0.9982,\n",
      "        0.9991, 0.9975, 0.9958, 0.9985, 0.9984, 0.9925, 0.9999, 1.0035, 1.0000,\n",
      "        0.9976, 1.0020, 0.9888, 0.9939, 0.9850, 0.9924, 0.9996, 1.0010, 1.0000,\n",
      "        0.9991, 0.9996, 0.9993, 0.9998, 0.9928, 0.9944, 0.9965, 1.0015, 0.9977,\n",
      "        0.9964, 1.0032, 1.0007, 0.9995, 1.0014, 1.0054, 1.0002, 0.9989, 1.0001,\n",
      "        1.0004, 1.0022, 1.0001, 0.9990, 0.9997, 1.0006, 0.9944, 0.9935, 1.0009,\n",
      "        1.0017, 0.9991, 0.9978, 1.0026, 1.0012, 1.0005, 0.9973, 1.0012, 0.9976],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9992, 0.9978, 1.0005, 0.9981, 0.9991, 0.9981, 1.0010, 0.9998, 1.0000,\n",
      "        0.9999, 1.0001, 0.9994, 0.9999, 1.0002, 1.0001, 1.0002, 0.9997, 0.9981,\n",
      "        1.0002, 0.9995, 0.9997, 0.9969, 0.9991, 0.9998, 0.9989, 0.9994, 0.9907,\n",
      "        0.9994, 0.9993, 0.9986, 0.9995, 1.0004, 0.9996, 0.9996, 0.9997, 1.0001,\n",
      "        1.0005, 1.0009, 0.9987, 1.0006, 0.9988, 1.0007, 0.9994, 0.9995, 0.9995,\n",
      "        1.0006, 1.0010, 1.0040, 0.9997, 0.9991, 0.9989, 0.9984, 0.9978, 1.0004,\n",
      "        0.9997, 0.9974, 0.9979, 0.9970, 0.9996, 1.0002, 0.9976, 0.9990, 1.0003,\n",
      "        1.0000, 0.9998, 0.9999, 0.9998, 0.9987, 0.9997, 1.0003, 1.0000, 1.0004,\n",
      "        0.9972, 0.9974, 1.0002, 1.0011, 1.0005, 0.9995, 1.0000, 0.9992, 1.0004,\n",
      "        1.0004, 0.9995, 1.0005, 1.0004, 1.0003, 0.9992, 0.9992, 1.0001, 0.9993,\n",
      "        0.9999, 0.9995, 1.0001, 0.9995, 0.9991, 0.9996, 0.9990, 1.0007, 1.0003,\n",
      "        0.9988, 1.0000, 0.9987, 1.0002, 1.0000, 0.9989, 0.9989, 1.0000, 1.0000,\n",
      "        0.9998, 0.9994, 0.9996, 0.9982, 0.9990, 0.9983, 0.9997, 0.9994, 0.9996,\n",
      "        1.0027, 0.9979, 0.9998, 0.9999, 1.0003, 0.9998, 0.9998, 0.9995, 1.0003,\n",
      "        0.9999, 0.9992, 0.9997, 0.9926, 0.9988, 0.9997, 0.9995, 0.9991, 1.0001,\n",
      "        0.9971, 0.9999, 0.9991], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9994, 0.9998, 0.9998, 0.9968, 0.9975, 0.9998, 1.0010, 0.9983, 1.0000,\n",
      "        1.0005, 0.9977, 1.0000, 0.9991, 0.9976, 0.9997, 0.9981, 0.9989, 0.9978,\n",
      "        0.9992, 0.9989, 0.9991, 0.9974, 0.9994, 0.9988, 0.9989, 0.9977, 0.9995,\n",
      "        0.9992, 0.9993, 0.9998, 1.0008, 1.0022, 0.9994, 1.0000, 0.9991, 1.0000,\n",
      "        0.9997, 0.9998, 1.0000, 0.9998, 0.9997, 0.9995, 1.0003, 1.0008, 1.0001,\n",
      "        1.0000, 0.9998, 0.9998, 0.9998, 0.9993, 0.9990, 0.9997, 1.0004, 0.9995,\n",
      "        1.0004, 0.9996, 1.0000, 0.9985, 0.9995, 1.0001, 0.9998, 0.9992, 1.0003,\n",
      "        0.9996, 0.9998, 1.0000, 1.0001, 0.9993, 1.0001, 0.9994, 0.9998, 1.0005,\n",
      "        0.9984, 0.9969, 0.9990, 0.9997, 1.0003, 1.0000, 1.0001, 1.0001, 1.0002,\n",
      "        1.0008, 1.0002, 0.9978, 0.9994, 0.9997, 0.9997, 0.9984, 0.9991, 0.9999,\n",
      "        1.0009, 0.9997, 1.0003, 1.0010, 1.0005, 0.9997, 0.9999, 1.0002, 1.0002,\n",
      "        0.9995, 1.0002, 1.0003, 1.0002, 1.0000, 1.0005, 0.9998, 0.9998, 1.0003,\n",
      "        1.0007, 1.0002, 0.9994, 0.9997, 1.0010, 1.0009, 0.9993, 0.9998, 0.9998,\n",
      "        0.9996, 0.9984, 1.0001, 1.0003, 0.9996, 0.9998, 0.9995, 0.9998, 0.9987,\n",
      "        0.9990, 0.9994, 1.0000, 0.9999, 1.0002, 0.9998, 0.9995, 0.9998, 0.9997,\n",
      "        0.9989, 0.9988, 0.9994], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9991, 0.9989, 0.9989, 0.9984, 0.9988, 0.9990, 0.9999, 0.9995, 0.9998,\n",
      "        0.9993, 1.0004, 1.0011, 0.9997, 1.0002, 0.9999, 1.0008, 1.0008, 0.9986,\n",
      "        1.0002, 0.9994, 1.0001, 1.0002, 0.9994, 0.9992, 0.9995, 0.9999, 0.9993,\n",
      "        1.0011, 1.0008, 0.9979, 0.9982, 0.9984, 0.9986, 0.9992, 0.9986, 0.9999,\n",
      "        1.0004, 0.9998, 1.0001, 1.0003, 1.0005, 0.9996, 0.9996, 0.9996, 0.9995,\n",
      "        1.0000, 0.9994, 1.0006, 0.9995, 0.9990, 1.0000, 0.9991, 0.9995, 0.9984,\n",
      "        0.9999, 0.9987, 0.9992, 1.0011, 1.0003, 0.9982, 1.0003, 0.9989, 1.0001,\n",
      "        0.9994, 0.9992, 1.0003, 0.9995, 0.9995, 0.9999, 1.0006, 0.9995, 0.9990,\n",
      "        0.9998, 0.9996, 0.9976, 0.9999, 1.0001, 0.9999, 0.9996, 1.0003, 0.9999,\n",
      "        1.0003, 0.9997, 0.9997, 0.9977, 0.9993, 0.9991, 1.0000, 0.9991, 1.0005,\n",
      "        0.9996, 0.9995, 0.9991, 0.9990, 0.9999, 0.9993, 0.9991, 0.9993, 0.9984,\n",
      "        0.9992, 0.9995, 0.9996, 1.0002, 0.9998, 0.9995, 0.9993, 1.0002, 1.0012,\n",
      "        1.0003, 0.9997, 0.9995, 0.9994, 1.0004, 0.9990, 0.9998, 0.9997, 1.0000,\n",
      "        0.9993, 0.9995, 0.9999, 0.9996, 0.9995, 0.9988, 1.0001, 0.9996, 0.9994,\n",
      "        0.9992, 1.0001, 0.9999, 0.9999, 1.0000, 0.9992, 1.0005, 1.0002, 1.0000,\n",
      "        0.9989, 0.9989, 0.9965], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9997, 0.9994, 0.9995, 0.9997, 0.9995, 1.0000, 0.9999, 0.9999, 0.9988,\n",
      "        1.0005, 0.9998, 1.0007, 0.9998, 0.9999, 0.9997, 1.0001, 0.9993, 0.9998,\n",
      "        0.9999, 1.0001, 0.9986, 0.9989, 0.9993, 1.0004, 0.9992, 0.9998, 0.9993,\n",
      "        0.9998, 1.0003, 1.0000, 1.0012, 0.9993, 0.9994, 1.0009, 0.9985, 1.0003,\n",
      "        1.0000, 0.9999, 0.9999, 1.0001, 1.0004, 0.9998, 0.9987, 0.9995, 0.9991,\n",
      "        1.0001, 0.9994, 1.0000, 1.0003, 0.9988, 0.9986, 0.9991, 0.9994, 0.9998,\n",
      "        0.9996, 0.9997, 0.9992, 0.9984, 1.0002, 0.9994, 0.9999, 0.9994, 0.9995,\n",
      "        0.9992, 1.0001, 1.0005, 0.9986, 0.9998, 1.0000, 0.9999, 1.0001, 0.9995,\n",
      "        0.9995, 0.9998, 0.9994, 1.0005, 0.9998, 0.9996, 0.9993, 0.9995, 1.0002,\n",
      "        0.9999, 0.9995, 0.9988, 1.0001, 0.9997, 0.9999, 0.9997, 1.0003, 1.0001,\n",
      "        0.9997, 1.0002, 1.0001, 1.0006, 1.0000, 1.0001, 0.9998, 0.9999, 0.9998,\n",
      "        1.0001, 0.9999, 1.0001, 1.0000, 1.0000, 0.9999, 1.0009, 1.0001, 0.9998,\n",
      "        0.9990, 1.0002, 1.0009, 1.0000, 0.9995, 0.9999, 0.9998, 0.9996, 1.0000,\n",
      "        0.9996, 0.9999, 0.9998, 1.0000, 1.0000, 0.9994, 1.0004, 0.9997, 0.9998,\n",
      "        0.9997, 1.0000, 0.9996, 1.0002, 1.0000, 1.0002, 0.9998, 0.9999, 1.0001,\n",
      "        0.9994, 0.9993, 0.9999], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9997, 0.9998, 0.9997, 0.9989, 0.9999, 1.0010, 0.9996, 1.0000, 0.9997,\n",
      "        1.0000, 0.9994, 1.0000, 0.9992, 0.9994, 0.9998, 0.9998, 1.0005, 1.0004,\n",
      "        0.9995, 0.9998, 0.9995, 1.0000, 1.0002, 0.9996, 0.9997, 0.9999, 0.9998,\n",
      "        1.0001, 0.9999, 0.9994, 0.9990, 0.9993, 0.9998, 1.0000, 1.0002, 1.0003,\n",
      "        0.9999, 1.0001, 1.0001, 0.9999, 0.9998, 0.9999, 0.9994, 0.9980, 0.9999,\n",
      "        0.9998, 0.9995, 1.0001, 0.9998, 0.9998, 0.9998, 0.9997, 0.9988, 1.0003,\n",
      "        0.9992, 0.9997, 0.9995, 0.9989, 0.9998, 1.0001, 0.9996, 1.0008, 1.0002,\n",
      "        0.9999, 0.9992, 1.0002, 1.0000, 0.9995, 1.0000, 0.9999, 0.9997, 0.9999,\n",
      "        0.9998, 0.9992, 0.9991, 1.0003, 0.9995, 0.9997, 1.0002, 1.0000, 0.9994,\n",
      "        0.9994, 0.9998, 0.9997, 0.9995, 0.9999, 0.9998, 0.9998, 1.0000, 1.0001,\n",
      "        0.9997, 1.0001, 1.0002, 0.9995, 0.9997, 1.0002, 1.0000, 1.0002, 1.0000,\n",
      "        1.0000, 1.0005, 1.0002, 0.9999, 1.0000, 0.9997, 0.9994, 1.0000, 0.9993,\n",
      "        1.0001, 1.0001, 0.9995, 1.0002, 0.9990, 1.0000, 1.0002, 0.9999, 0.9996,\n",
      "        1.0003, 1.0000, 1.0003, 0.9999, 0.9996, 0.9996, 1.0003, 0.9999, 1.0001,\n",
      "        0.9996, 0.9998, 0.9995, 1.0008, 0.9996, 0.9999, 0.9991, 0.9998, 0.9998,\n",
      "        0.9986, 0.9988, 0.9994], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0000, 0.9995, 0.9995, 1.0003, 1.0006, 0.9991, 1.0000, 0.9999, 0.9997,\n",
      "        0.9998, 0.9998, 1.0001, 0.9998, 0.9998, 0.9997, 0.9993, 0.9995, 0.9994,\n",
      "        0.9999, 0.9999, 0.9999, 0.9997, 1.0000, 1.0005, 0.9996, 0.9986, 0.9996,\n",
      "        1.0002, 1.0005, 0.9999, 0.9993, 0.9996, 0.9994, 0.9999, 0.9996, 0.9996,\n",
      "        1.0001, 0.9998, 0.9993, 1.0001, 0.9997, 1.0004, 1.0001, 0.9997, 1.0002,\n",
      "        1.0004, 1.0000, 1.0004, 0.9992, 0.9988, 0.9991, 1.0002, 0.9999, 0.9998,\n",
      "        0.9984, 0.9982, 0.9996, 0.9997, 0.9999, 0.9995, 0.9999, 0.9998, 0.9993,\n",
      "        0.9996, 1.0000, 0.9996, 1.0001, 1.0004, 1.0003, 1.0000, 0.9996, 1.0000,\n",
      "        0.9993, 0.9998, 0.9997, 0.9990, 0.9998, 0.9990, 1.0001, 0.9984, 0.9995,\n",
      "        0.9998, 0.9992, 1.0005, 0.9997, 1.0005, 1.0002, 0.9990, 0.9988, 1.0000,\n",
      "        0.9999, 0.9998, 0.9998, 0.9999, 0.9998, 1.0005, 0.9999, 0.9994, 0.9995,\n",
      "        0.9998, 0.9998, 1.0000, 0.9999, 0.9994, 1.0002, 1.0002, 0.9988, 0.9999,\n",
      "        0.9997, 0.9995, 1.0000, 0.9994, 1.0006, 1.0003, 0.9998, 1.0000, 1.0001,\n",
      "        1.0001, 1.0000, 0.9994, 0.9997, 0.9999, 1.0004, 0.9997, 0.9995, 0.9993,\n",
      "        0.9990, 0.9997, 0.9995, 0.9998, 0.9999, 0.9997, 0.9998, 0.9996, 0.9998,\n",
      "        1.0000, 0.9999, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9992, 0.9997, 0.9976, 0.9976, 0.9995, 0.9976, 0.9998, 0.9993, 0.9993,\n",
      "        0.9995, 0.9997, 0.9980, 1.0001, 0.9995, 0.9994, 1.0000, 0.9998, 0.9992,\n",
      "        1.0000, 0.9998, 0.9999, 1.0000, 0.9997, 0.9989, 1.0001, 1.0003, 1.0003,\n",
      "        0.9986, 1.0000, 0.9996, 0.9992, 0.9998, 0.9957, 0.9970, 0.9979, 0.9994,\n",
      "        0.9993, 0.9998, 0.9996, 0.9989, 0.9998, 0.9977], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9992, 0.9983, 0.9983, 1.0000, 0.9991, 0.9975, 0.9985, 0.9993, 0.9987,\n",
      "        0.9975, 0.9985, 0.9986, 0.9996, 0.9995, 0.9994, 0.9986, 1.0000, 0.9999,\n",
      "        1.0001, 0.9985, 0.9997, 0.9988, 0.9998, 0.9989, 1.0002, 1.0001, 1.0001,\n",
      "        0.9982, 0.9999, 0.9999, 0.9988, 0.9996, 0.9991, 0.9980, 0.9974, 0.9996,\n",
      "        0.9989, 1.0004, 1.0001, 0.9990, 1.0002, 0.9995], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9966, 0.9997, 0.9984, 0.9973, 0.9965, 0.9983, 0.9986, 0.9995, 0.9991,\n",
      "        0.9989, 0.9999, 0.9991, 0.9978, 0.9982, 0.9989, 0.9995, 0.9970, 1.0001,\n",
      "        0.9999, 0.9998, 1.0001, 0.9997, 0.9993, 0.9989, 0.9977, 0.9981, 0.9999,\n",
      "        1.0000, 0.9992, 0.9990, 0.9999, 1.0002, 0.9993, 0.9996, 0.9985, 0.9960,\n",
      "        0.9996, 1.0000, 0.9987, 0.9981, 1.0001, 0.9989], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0014, 0.9997, 1.0017, 0.9991, 0.9980, 0.9966, 0.9985, 0.9993, 0.9991,\n",
      "        0.9998, 0.9988, 0.9975, 0.9992, 0.9993, 0.9996, 0.9986, 1.0000, 1.0007,\n",
      "        0.9993, 0.9997, 0.9996, 0.9985, 0.9997, 0.9990, 0.9979, 0.9986, 0.9990,\n",
      "        0.9988, 1.0000, 0.9992, 0.9987, 0.9998, 1.0001, 0.9964, 0.9981, 0.9973,\n",
      "        1.0000, 1.0000, 0.9999, 0.9995, 0.9985, 0.9999], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9973, 0.9973, 0.9979, 0.9983, 0.9985, 0.9995, 0.9960, 0.9973, 1.0002,\n",
      "        0.9983, 0.9971, 0.9987, 0.9984, 0.9984, 0.9989, 0.9997, 0.9993, 0.9987,\n",
      "        0.9984, 0.9992, 0.9991, 0.9990, 0.9992, 0.9986, 1.0000, 0.9984, 1.0000,\n",
      "        0.9996, 0.9999, 0.9992, 0.9960, 0.9998, 0.9998, 0.9971, 0.9979, 0.9982,\n",
      "        1.0000, 0.9989, 0.9993, 0.9991, 1.0016, 1.0001], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9989, 0.9990, 1.0001, 0.9961, 0.9976, 0.9979, 0.9973, 0.9998, 1.0003,\n",
      "        0.9995, 0.9988, 0.9995, 1.0001, 0.9994, 0.9999, 1.0000, 1.0000, 0.9998,\n",
      "        0.9997, 0.9996, 0.9978, 0.9986, 0.9986, 0.9992, 0.9996, 0.9994, 1.0001,\n",
      "        0.9999, 0.9992, 1.0000, 1.0002, 0.9977, 0.9987, 1.0002, 1.0002, 1.0007,\n",
      "        0.9991, 1.0001, 0.9978, 0.9991, 0.9999, 0.9984], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9997, 0.9999, 0.9996, 1.0000, 1.0001, 1.0003, 0.9999, 0.9989, 0.9996,\n",
      "        0.9999, 1.0000, 0.9982, 0.9999, 1.0001, 0.9993, 0.9994, 0.9978, 0.9995,\n",
      "        0.9979, 1.0001, 1.0000, 0.9997, 1.0003, 0.9963, 0.9994, 1.0000, 1.0001,\n",
      "        0.9994, 1.0004, 1.0002, 1.0006, 1.0001, 1.0007, 0.9994, 0.9998, 1.0003,\n",
      "        0.9994, 0.9991, 0.9979, 0.9994, 0.9997, 0.9997, 0.9997, 1.0001, 0.9998,\n",
      "        0.9998, 0.9993, 0.9994, 0.9998, 0.9971, 1.0003, 1.0001, 0.9998, 1.0005,\n",
      "        0.9998, 1.0005, 0.9990, 1.0002, 1.0006, 0.9997, 1.0001, 0.9999, 0.9997,\n",
      "        0.9999, 0.9995, 0.9997, 0.9987, 0.9967, 0.9995, 1.0000, 0.9984, 0.9997,\n",
      "        1.0000, 1.0002, 1.0001, 0.9998, 0.9999, 0.9999], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9995, 0.9999, 0.9992, 1.0003, 1.0003, 0.9997, 0.9999, 0.9988, 0.9973,\n",
      "        0.9997, 0.9993, 0.9997, 0.9993, 0.9996, 0.9997, 0.9993, 1.0002, 0.9990,\n",
      "        0.9998, 0.9990, 0.9995, 1.0000, 0.9994, 1.0000, 0.9998, 0.9999, 0.9996,\n",
      "        1.0016, 1.0001, 0.9981, 0.9998, 1.0001, 1.0001, 1.0002, 1.0000, 0.9999,\n",
      "        1.0003, 1.0001, 0.9999, 0.9975, 0.9996, 1.0002, 1.0000, 1.0004, 1.0008,\n",
      "        0.9979, 0.9994, 0.9995, 1.0001, 0.9996, 0.9985, 0.9996, 0.9999, 0.9991,\n",
      "        1.0008, 0.9992, 0.9998, 0.9985, 0.9998, 0.9993, 1.0003, 0.9989, 1.0000,\n",
      "        0.9993, 0.9999, 0.9991, 1.0003, 1.0003, 0.9982, 0.9999, 1.0003, 1.0002,\n",
      "        0.9995, 1.0006, 1.0002, 1.0005, 0.9997, 0.9996], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9995, 0.9994, 0.9992, 0.9973, 0.9989, 0.9993, 0.9992, 0.9998, 0.9999,\n",
      "        0.9998, 0.9996, 0.9995, 1.0000, 0.9975, 1.0001, 0.9997, 1.0011, 1.0004,\n",
      "        0.9991, 0.9987, 0.9976, 0.9995, 1.0001, 0.9989, 0.9999, 0.9994, 1.0009,\n",
      "        0.9999, 0.9990, 0.9997, 0.9998, 0.9999, 0.9993, 1.0003, 1.0003, 0.9978,\n",
      "        0.9990, 0.9995, 0.9985, 0.9991, 1.0003, 0.9996, 0.9990, 0.9963, 0.9958,\n",
      "        0.9989, 0.9992, 1.0000, 0.9999, 0.9999, 0.9989, 1.0005, 0.9995, 1.0004,\n",
      "        0.9994, 1.0000, 0.9981, 1.0014, 0.9993, 0.9982, 0.9998, 0.9996, 1.0003,\n",
      "        1.0000, 1.0003, 1.0007, 0.9989, 0.9992, 0.9993, 0.9999, 1.0002, 0.9999,\n",
      "        1.0010, 0.9990, 0.9996, 1.0001, 0.9998, 0.9992], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9994, 0.9998, 1.0001, 0.9990, 1.0009, 0.9995, 0.9996, 0.9986, 0.9995,\n",
      "        0.9993, 0.9998, 0.9987, 1.0012, 1.0006, 0.9997, 1.0005, 1.0009, 0.9975,\n",
      "        1.0006, 0.9996, 1.0000, 0.9994, 0.9999, 0.9996, 0.9996, 1.0003, 0.9996,\n",
      "        1.0001, 1.0002, 1.0000, 0.9997, 1.0000, 0.9990, 1.0013, 1.0001, 1.0004,\n",
      "        1.0000, 0.9996, 0.9988, 1.0008, 1.0001, 1.0002, 0.9999, 1.0002, 1.0004,\n",
      "        1.0003, 0.9999, 1.0003, 1.0001, 1.0001, 0.9988, 1.0002, 0.9999, 0.9997,\n",
      "        0.9999, 0.9991, 1.0005, 1.0005, 0.9978, 0.9992, 0.9996, 0.9996, 0.9990,\n",
      "        0.9998, 0.9994, 1.0001, 0.9983, 1.0009, 1.0001, 0.9999, 0.9993, 0.9997,\n",
      "        0.9980, 1.0004, 0.9993, 0.9999, 0.9997, 0.9995], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9998, 0.9990, 0.9995, 0.9995, 0.9981, 1.0005, 0.9991, 0.9997, 1.0000,\n",
      "        0.9998, 0.9968, 0.9996, 1.0003, 0.9970, 1.0002, 0.9997, 1.0012, 1.0010,\n",
      "        1.0008, 0.9996, 0.9997, 0.9980, 1.0003, 0.9988, 1.0002, 0.9984, 1.0001,\n",
      "        1.0013, 0.9989, 1.0003, 0.9992, 0.9995, 0.9997, 0.9993, 0.9997, 1.0013,\n",
      "        0.9996, 0.9994, 1.0000, 0.9999, 1.0000, 0.9983, 0.9996, 0.9994, 0.9979,\n",
      "        0.9999, 1.0003, 0.9999, 1.0005, 1.0005, 0.9995, 0.9998, 1.0001, 0.9999,\n",
      "        0.9997, 0.9992, 0.9997, 1.0000, 0.9997, 0.9998, 0.9991, 1.0007, 1.0013,\n",
      "        0.9984, 0.9998, 0.9996, 0.9950, 0.9985, 0.9995, 0.9961, 0.9995, 1.0000,\n",
      "        0.9998, 0.9995, 1.0000, 0.9998, 0.9954, 1.0002], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9999, 0.9998, 1.0000, 0.9995, 1.0005, 1.0003, 0.9996, 1.0005, 1.0001,\n",
      "        1.0014, 0.9980, 0.9997, 1.0001, 0.9974, 0.9995, 1.0003, 1.0003, 0.9994,\n",
      "        0.9972, 0.9977, 0.9981, 0.9981, 1.0009, 0.9999, 0.9977, 1.0001, 1.0004,\n",
      "        0.9998, 1.0004, 0.9993, 0.9995, 0.9995, 0.9992, 0.9994, 0.9997, 0.9998,\n",
      "        0.9999, 1.0006, 0.9987, 0.9994, 0.9980, 1.0006, 1.0000, 0.9989, 1.0000,\n",
      "        0.9997, 1.0006, 0.9997, 0.9980, 1.0000, 0.9997, 0.9997, 0.9967, 0.9992,\n",
      "        1.0003, 0.9995, 0.9996, 1.0007, 1.0005, 0.9999, 0.9984, 0.9998, 0.9997,\n",
      "        0.9998, 1.0000, 0.9973, 1.0001, 1.0001, 1.0010, 1.0004, 1.0005, 0.9993,\n",
      "        0.9986, 0.9956, 1.0000, 0.9999, 1.0003, 1.0006], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9983, 0.9998, 0.9998, 0.9999, 0.9987, 0.9996, 1.0002, 1.0011, 0.9987,\n",
      "        0.9995, 1.0001, 1.0002, 0.9995, 0.9985, 0.9999, 0.9998, 0.9999, 0.9992,\n",
      "        1.0014, 1.0002, 1.0002, 1.0001, 0.9999, 0.9991, 0.9984, 0.9975, 0.9993,\n",
      "        0.9994, 0.9996, 0.9999, 0.9980, 0.9992, 0.9993, 1.0000, 0.9999, 0.9998,\n",
      "        0.9998, 0.9997, 0.9993, 1.0000, 0.9999, 0.9992, 0.9994, 0.9977, 1.0000,\n",
      "        0.9993, 1.0002, 0.9990, 0.9994, 0.9993, 0.9984, 0.9979, 0.9994, 0.9999,\n",
      "        0.9990, 0.9986, 0.9995, 1.0001, 0.9997, 0.9987, 0.9987, 0.9982, 0.9990,\n",
      "        1.0000, 0.9997, 0.9999, 0.9985, 0.9998, 0.9999, 0.9998, 1.0000, 1.0000,\n",
      "        0.9996, 0.9997, 1.0000, 0.9991, 0.9991, 0.9997, 0.9993, 1.0002, 0.9994,\n",
      "        0.9997, 0.9997, 0.9995, 1.0001, 1.0000, 1.0003, 0.9970, 0.9992, 0.9994,\n",
      "        1.0003, 0.9996, 0.9998, 0.9993, 0.9997, 0.9999, 0.9995, 0.9993, 1.0003,\n",
      "        0.9994, 0.9991, 1.0007], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0012, 0.9999, 1.0002, 1.0000, 1.0001, 1.0000, 1.0008, 0.9994, 0.9984,\n",
      "        0.9993, 0.9996, 1.0001, 0.9992, 0.9998, 0.9996, 0.9996, 0.9982, 1.0000,\n",
      "        1.0001, 0.9991, 0.9998, 1.0001, 1.0007, 0.9999, 0.9993, 0.9969, 0.9995,\n",
      "        0.9993, 0.9993, 1.0002, 0.9995, 0.9992, 0.9972, 0.9997, 0.9989, 1.0000,\n",
      "        0.9990, 0.9994, 0.9981, 1.0000, 0.9981, 1.0000, 1.0000, 1.0003, 0.9998,\n",
      "        1.0011, 1.0027, 1.0001, 0.9998, 0.9997, 0.9995, 0.9993, 1.0011, 1.0003,\n",
      "        0.9967, 0.9997, 0.9990, 1.0001, 0.9996, 0.9991, 1.0007, 1.0010, 0.9999,\n",
      "        0.9997, 1.0008, 1.0001, 1.0005, 1.0002, 0.9992, 1.0004, 0.9996, 0.9993,\n",
      "        0.9999, 0.9994, 0.9999, 1.0000, 1.0001, 0.9993, 0.9993, 1.0000, 0.9998,\n",
      "        0.9980, 0.9995, 1.0003, 1.0003, 1.0008, 0.9998, 1.0004, 1.0001, 0.9999,\n",
      "        0.9999, 0.9998, 0.9999, 1.0003, 0.9985, 0.9998, 0.9988, 0.9990, 0.9999,\n",
      "        0.9994, 1.0007, 1.0001], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9999, 1.0002, 0.9977, 0.9993, 1.0000, 0.9998, 0.9996, 1.0004, 0.9986,\n",
      "        0.9999, 0.9988, 0.9996, 0.9997, 1.0001, 0.9991, 1.0004, 0.9995, 0.9997,\n",
      "        0.9999, 0.9993, 0.9996, 0.9994, 1.0001, 1.0002, 0.9983, 0.9995, 0.9999,\n",
      "        0.9997, 0.9996, 0.9998, 0.9973, 0.9980, 0.9982, 1.0003, 0.9999, 1.0002,\n",
      "        0.9998, 0.9989, 1.0000, 0.9996, 0.9984, 0.9998, 0.9996, 0.9998, 1.0000,\n",
      "        1.0001, 0.9997, 0.9996, 1.0006, 1.0000, 0.9990, 0.9996, 1.0000, 1.0000,\n",
      "        0.9995, 0.9993, 0.9998, 0.9995, 1.0009, 0.9990, 1.0004, 0.9990, 1.0004,\n",
      "        1.0001, 0.9997, 0.9998, 0.9998, 1.0000, 1.0010, 0.9998, 1.0001, 0.9991,\n",
      "        0.9990, 1.0004, 1.0003, 0.9995, 0.9999, 0.9999, 1.0003, 0.9998, 1.0000,\n",
      "        1.0012, 1.0004, 1.0002, 0.9995, 0.9996, 0.9994, 0.9995, 1.0008, 1.0007,\n",
      "        0.9991, 1.0006, 1.0003, 0.9997, 1.0001, 1.0003, 0.9996, 0.9983, 0.9985,\n",
      "        0.9996, 0.9980, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9989, 0.9989, 0.9999, 0.9980, 0.9996, 1.0000, 0.9984, 0.9995, 0.9994,\n",
      "        0.9965, 1.0000, 1.0002, 0.9999, 0.9997, 0.9998, 1.0005, 1.0000, 1.0008,\n",
      "        1.0000, 1.0015, 1.0015, 0.9975, 1.0000, 0.9996, 0.9984, 0.9995, 0.9985,\n",
      "        1.0004, 1.0000, 0.9996, 0.9977, 0.9952, 0.9991, 0.9999, 0.9994, 1.0000,\n",
      "        0.9990, 0.9989, 1.0003, 0.9991, 0.9987, 0.9986, 1.0011, 0.9999, 0.9992,\n",
      "        1.0003, 0.9962, 0.9994, 0.9995, 0.9983, 0.9997, 0.9993, 1.0002, 1.0001,\n",
      "        0.9990, 1.0006, 1.0000, 1.0002, 0.9998, 1.0008, 1.0010, 1.0021, 1.0016,\n",
      "        0.9999, 0.9976, 0.9997, 0.9996, 1.0010, 0.9994, 0.9996, 1.0000, 1.0002,\n",
      "        1.0010, 0.9999, 1.0004, 1.0005, 1.0000, 0.9996, 1.0002, 1.0004, 1.0002,\n",
      "        0.9988, 0.9995, 1.0007, 1.0004, 1.0001, 1.0003, 0.9983, 1.0000, 0.9995,\n",
      "        0.9993, 0.9991, 0.9995, 0.9996, 1.0000, 1.0001, 0.9994, 0.9994, 0.9992,\n",
      "        1.0003, 1.0007, 0.9994], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9991, 1.0004, 1.0002, 0.9987, 1.0007, 0.9989, 0.9997, 1.0016, 1.0006,\n",
      "        0.9987, 0.9962, 0.9991, 0.9995, 0.9998, 0.9994, 0.9993, 0.9995, 1.0003,\n",
      "        0.9988, 0.9983, 0.9997, 0.9999, 0.9997, 0.9994, 1.0000, 0.9989, 0.9988,\n",
      "        0.9996, 0.9989, 0.9999, 0.9999, 0.9989, 0.9963, 1.0000, 0.9988, 1.0000,\n",
      "        1.0004, 0.9997, 0.9998, 0.9995, 0.9997, 0.9999, 1.0000, 1.0007, 1.0000,\n",
      "        0.9991, 1.0005, 0.9989, 1.0000, 0.9997, 0.9986, 0.9999, 1.0005, 1.0014,\n",
      "        0.9964, 0.9999, 0.9989, 0.9993, 0.9985, 0.9986, 1.0052, 0.9996, 0.9974,\n",
      "        0.9999, 0.9986, 0.9999, 0.9994, 0.9995, 0.9996, 1.0002, 1.0001, 1.0007,\n",
      "        0.9992, 0.9984, 0.9983, 0.9998, 0.9993, 1.0001, 0.9993, 0.9994, 1.0001,\n",
      "        0.9999, 1.0000, 1.0008, 0.9993, 0.9991, 0.9998, 1.0011, 0.9991, 0.9987,\n",
      "        1.0000, 0.9999, 0.9998, 1.0002, 1.0001, 1.0003, 1.0000, 0.9999, 0.9997,\n",
      "        0.9988, 1.0005, 1.0004], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9975, 1.0004, 1.0002, 0.9997, 0.9981, 0.9998, 1.0004, 0.9994, 0.9979,\n",
      "        0.9999, 1.0000, 1.0002, 0.9986, 0.9998, 0.9988, 1.0004, 0.9990, 0.9995,\n",
      "        0.9998, 1.0008, 1.0010, 1.0001, 1.0005, 1.0001, 0.9991, 0.9992, 1.0005,\n",
      "        0.9993, 0.9986, 1.0000, 0.9990, 0.9989, 0.9986, 0.9990, 1.0003, 0.9996,\n",
      "        1.0000, 0.9975, 0.9999, 0.9998, 0.9984, 0.9991, 0.9996, 0.9995, 0.9988,\n",
      "        1.0031, 0.9995, 1.0034, 1.0001, 0.9996, 1.0003, 0.9995, 1.0000, 0.9997,\n",
      "        1.0002, 0.9997, 0.9998, 1.0000, 0.9996, 1.0005, 0.9988, 0.9995, 0.9993,\n",
      "        0.9995, 0.9999, 1.0000, 0.9994, 0.9990, 0.9990, 1.0002, 0.9997, 0.9974,\n",
      "        1.0001, 0.9996, 0.9993, 0.9980, 1.0004, 1.0005, 0.9996, 0.9998, 0.9999,\n",
      "        1.0003, 0.9998, 0.9984, 1.0005, 0.9991, 0.9993, 0.9995, 1.0000, 0.9994,\n",
      "        0.9987, 1.0003, 1.0007, 1.0002, 0.9996, 0.9993, 0.9982, 1.0002, 0.9998,\n",
      "        0.9998, 0.9995, 0.9990], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9996, 0.9995, 0.9994, 0.9998, 0.9998, 0.9994, 0.9995, 0.9981, 0.9977,\n",
      "        0.9986, 0.9971, 0.9955, 0.9999, 0.9997, 0.9990, 0.9976, 0.9994, 0.9994,\n",
      "        1.0002, 0.9995, 1.0001, 0.9998, 0.9997, 0.9988, 0.9995, 0.9977, 0.9995,\n",
      "        0.9990, 0.9994, 1.0011, 0.9986, 0.9993, 0.9992, 0.9996, 1.0000, 1.0002,\n",
      "        0.9980, 0.9999, 0.9993, 0.9999, 1.0003, 1.0002, 0.9987, 0.9998, 0.9999,\n",
      "        0.9998, 0.9995, 0.9987, 0.9999, 1.0003, 0.9983, 0.9990, 0.9980, 0.9994,\n",
      "        0.9990, 0.9999, 0.9992, 0.9999, 0.9998, 0.9993, 0.9986, 0.9996, 0.9994,\n",
      "        0.9981, 0.9953, 0.9986, 0.9996, 0.9994, 1.0005, 0.9998, 0.9983, 0.9996,\n",
      "        0.9990, 0.9990, 0.9996, 1.0046, 1.0002, 0.9996, 1.0003, 1.0005, 1.0008,\n",
      "        0.9993, 0.9998, 0.9995, 0.9991, 0.9998, 0.9996, 0.9996, 0.9967, 0.9980,\n",
      "        1.0000, 0.9985, 1.0002, 1.0002, 1.0000, 1.0003, 0.9993, 0.9982, 0.9998],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0003, 1.0000, 0.9999, 1.0006, 1.0003, 0.9997, 1.0005, 1.0000, 1.0000,\n",
      "        0.9999, 0.9976, 1.0001, 0.9998, 0.9963, 0.9999, 0.9999, 0.9977, 1.0001,\n",
      "        0.9987, 1.0000, 0.9996, 1.0015, 0.9975, 0.9978, 0.9998, 1.0007, 0.9998,\n",
      "        1.0005, 1.0004, 1.0020, 0.9987, 0.9994, 0.9995, 0.9997, 1.0011, 1.0007,\n",
      "        0.9995, 0.9999, 1.0000, 1.0027, 0.9970, 1.0033, 0.9998, 0.9993, 0.9995,\n",
      "        0.9987, 0.9999, 1.0004, 0.9997, 0.9979, 0.9987, 0.9995, 0.9945, 0.9989,\n",
      "        0.9997, 0.9997, 0.9987, 0.9995, 0.9986, 0.9991, 0.9999, 1.0004, 1.0001,\n",
      "        0.9959, 0.9985, 1.0012, 1.0001, 0.9998, 0.9998, 0.9985, 0.9986, 0.9996,\n",
      "        0.9997, 1.0002, 0.9990, 0.9998, 1.0001, 0.9998, 0.9996, 0.9979, 0.9991,\n",
      "        0.9990, 0.9989, 0.9981, 0.9973, 0.9964, 0.9984, 0.9978, 1.0007, 0.9977,\n",
      "        1.0001, 0.9998, 0.9999, 0.9972, 0.9994, 1.0002, 0.9993, 1.0003, 0.9998],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9996, 1.0009, 0.9997, 0.9999, 0.9981, 0.9994, 1.0002, 0.9984, 1.0013,\n",
      "        0.9983, 0.9979, 0.9993, 1.0023, 1.0000, 0.9993, 0.9990, 1.0001, 0.9990,\n",
      "        0.9973, 0.9995, 0.9996, 0.9997, 0.9997, 0.9992, 0.9988, 0.9999, 0.9991,\n",
      "        0.9981, 1.0002, 0.9998, 1.0000, 0.9973, 0.9973, 1.0003, 1.0019, 1.0007,\n",
      "        0.9999, 0.9991, 1.0002, 0.9990, 0.9998, 0.9994, 1.0008, 0.9995, 0.9996,\n",
      "        0.9997, 0.9988, 0.9995, 1.0002, 0.9999, 0.9997, 0.9988, 0.9969, 0.9981,\n",
      "        0.9992, 0.9957, 0.9998, 1.0002, 0.9967, 0.9995, 0.9999, 0.9994, 0.9981,\n",
      "        0.9983, 0.9974, 0.9984, 0.9994, 0.9993, 0.9983, 0.9963, 0.9991, 0.9982,\n",
      "        1.0002, 1.0010, 0.9999, 0.9988, 0.9991, 1.0002, 0.9983, 1.0002, 1.0006,\n",
      "        0.9965, 0.9982, 1.0003, 0.9972, 0.9994, 0.9987, 0.9985, 0.9988, 0.9996,\n",
      "        1.0002, 0.9996, 0.9987, 0.9998, 0.9998, 0.9992, 0.9979, 0.9995, 0.9991],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9995, 0.9999, 1.0021, 0.9988, 0.9994, 1.0000, 1.0001, 1.0004, 1.0001,\n",
      "        0.9943, 0.9996, 0.9967, 0.9990, 0.9995, 0.9999, 0.9997, 0.9982, 0.9982,\n",
      "        1.0001, 1.0002, 0.9998, 0.9997, 0.9992, 0.9994, 1.0000, 0.9994, 0.9998,\n",
      "        0.9974, 0.9990, 0.9989, 0.9993, 0.9971, 1.0000, 0.9995, 1.0002, 1.0015,\n",
      "        0.9997, 0.9986, 0.9972, 0.9933, 0.9985, 0.9987, 0.9988, 0.9995, 1.0001,\n",
      "        0.9995, 0.9999, 1.0007, 1.0000, 0.9994, 0.9977, 0.9996, 0.9979, 0.9963,\n",
      "        0.9994, 0.9991, 0.9989, 0.9967, 0.9997, 1.0000, 0.9979, 0.9996, 0.9962,\n",
      "        1.0007, 1.0004, 0.9986, 0.9998, 0.9999, 1.0007, 1.0000, 0.9998, 1.0005,\n",
      "        0.9998, 0.9978, 0.9983, 1.0002, 0.9998, 0.9993, 0.9998, 0.9992, 0.9999,\n",
      "        0.9935, 0.9954, 0.9986, 0.9997, 0.9995, 0.9995, 0.9978, 0.9965, 0.9990,\n",
      "        0.9999, 0.9998, 1.0000, 0.9999, 0.9987, 0.9999, 0.9998, 1.0002, 0.9993],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9996, 0.9992, 1.0007, 0.9995, 1.0000, 0.9988, 0.9993, 0.9997, 0.9993,\n",
      "        0.9980, 0.9968, 0.9969, 0.9982, 0.9990, 0.9993, 1.0009, 1.0012, 0.9997,\n",
      "        1.0008, 0.9972, 0.9979, 0.9965, 0.9993, 1.0013, 1.0002, 0.9988, 1.0002,\n",
      "        0.9997, 0.9980, 0.9993, 1.0013, 0.9996, 1.0012, 1.0003, 0.9999, 0.9964,\n",
      "        1.0004, 1.0016, 1.0002, 1.0003, 0.9966, 1.0003, 1.0001, 0.9999, 0.9984,\n",
      "        0.9980, 0.9974, 0.9999, 0.9978, 0.9975, 0.9982, 0.9996, 0.9974, 0.9977,\n",
      "        0.9996, 0.9989, 1.0002, 0.9992, 0.9954, 0.9977, 0.9979, 0.9988, 0.9990,\n",
      "        0.9976, 1.0007, 0.9970, 0.9997, 0.9969, 0.9998, 0.9984, 0.9990, 0.9991,\n",
      "        0.9999, 0.9992, 0.9980, 0.9991, 1.0000, 0.9980, 0.9993, 0.9959, 0.9991,\n",
      "        0.9982, 0.9965, 0.9979, 0.9945, 0.9987, 0.9981, 0.9984, 0.9983, 0.9999,\n",
      "        0.9967, 0.9986, 0.9997, 0.9998, 0.9998, 0.9997, 1.0000, 0.9993, 0.9995],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9986, 1.0011, 1.0001, 0.9999, 0.9975, 0.9986, 0.9996, 1.0004, 0.9999,\n",
      "        0.9974, 0.9960, 0.9982, 0.9949, 0.9999, 0.9980, 0.9987, 1.0000, 0.9992,\n",
      "        0.9984, 0.9946, 0.9990, 0.9998, 0.9977, 0.9986, 0.9974, 0.9990, 1.0001,\n",
      "        0.9974, 0.9992, 0.9976, 0.9990, 0.9996, 0.9997, 0.9995, 0.9994, 0.9993,\n",
      "        0.9960, 0.9980, 1.0001, 0.9894, 0.9961, 0.9898, 0.9993, 1.0003, 0.9988,\n",
      "        1.0004, 0.9988, 1.0000, 0.9973, 0.9993, 0.9988, 0.9992, 1.0000, 0.9984,\n",
      "        0.9966, 0.9984, 0.9985, 1.0007, 0.9994, 0.9998, 1.0017, 1.0000, 0.9992,\n",
      "        0.9955, 0.9960, 0.9985, 1.0012, 0.9992, 0.9981, 1.0002, 0.9992, 0.9986,\n",
      "        1.0010, 0.9997, 0.9974, 0.9956, 1.0001, 1.0011, 0.9984, 0.9966, 0.9959,\n",
      "        0.9964, 0.9964, 0.9984, 0.9980, 0.9975, 0.9995, 0.9987, 0.9946, 1.0002,\n",
      "        0.9978, 1.0004, 0.9992, 1.0012, 0.9999, 0.9965, 0.9993, 0.9960, 0.9999],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9992, 1.0000, 0.9998, 0.9973, 0.9990, 0.9987, 0.9997, 0.9994, 0.9990,\n",
      "        0.9998, 0.9993, 0.9994, 0.9999, 0.9996, 0.9987, 0.9992, 1.0008, 1.0002,\n",
      "        1.0000, 0.9995, 0.9993, 0.9974, 1.0017, 0.9980, 0.9963, 0.9985, 0.9941,\n",
      "        1.0001, 1.0002, 0.9977, 1.0013, 1.0006, 0.9991, 0.9984, 0.9982, 0.9968,\n",
      "        0.9995, 1.0010, 1.0001, 0.9981, 0.9977, 0.9980, 0.9997, 0.9995, 1.0022,\n",
      "        0.9996, 0.9988, 0.9996, 1.0016, 1.0005, 0.9986, 0.9973, 0.9993, 0.9954,\n",
      "        0.9975, 0.9996, 0.9981, 0.9993, 1.0004, 0.9989, 1.0024, 1.0030, 0.9975,\n",
      "        0.9989, 1.0001, 0.9992], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9991, 0.9982, 0.9975, 0.9949, 0.9999, 0.9940, 1.0035, 0.9995, 0.9988,\n",
      "        0.9993, 0.9996, 0.9976, 0.9989, 0.9998, 0.9989, 0.9992, 0.9991, 0.9975,\n",
      "        0.9985, 0.9996, 1.0003, 0.9994, 0.9995, 0.9961, 0.9997, 1.0002, 0.9979,\n",
      "        0.9983, 0.9990, 0.9998, 0.9975, 1.0022, 0.9979, 0.9979, 0.9986, 0.9999,\n",
      "        1.0000, 0.9968, 0.9984, 0.9982, 0.9993, 0.9996, 0.9973, 0.9985, 0.9996,\n",
      "        0.9992, 0.9992, 0.9987, 1.0008, 1.0014, 1.0037, 0.9988, 0.9972, 0.9972,\n",
      "        0.9992, 0.9980, 0.9974, 0.9990, 0.9990, 0.9985, 0.9977, 0.9947, 0.9986,\n",
      "        1.0001, 0.9933, 0.9970], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0006, 0.9999, 1.0006, 1.0005, 1.0007, 0.9992, 1.0010, 0.9984, 1.0017,\n",
      "        0.9980, 0.9997, 1.0019, 0.9984, 0.9994, 0.9996, 1.0000, 0.9988, 0.9996,\n",
      "        0.9999, 0.9964, 0.9983, 0.9947, 0.9963, 0.9987, 1.0000, 0.9992, 1.0002,\n",
      "        0.9978, 0.9981, 0.9995, 0.9992, 0.9972, 0.9996, 0.9998, 0.9982, 0.9951,\n",
      "        0.9992, 0.9994, 0.9989, 1.0007, 0.9986, 0.9987, 0.9999, 0.9966, 0.9987,\n",
      "        1.0000, 0.9997, 0.9975, 1.0001, 0.9994, 0.9946, 0.9986, 0.9942, 0.9969,\n",
      "        0.9969, 0.9975, 0.9980, 0.9986, 0.9952, 1.0000, 0.9996, 0.9975, 0.9997,\n",
      "        0.9983, 0.9985, 0.9997], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9995, 0.9980, 0.9991, 1.0030, 1.0001, 1.0002, 0.9985, 0.9983, 0.9998,\n",
      "        0.9986, 1.0001, 1.0024, 0.9995, 1.0012, 0.9993, 0.9997, 1.0007, 0.9999,\n",
      "        0.9985, 0.9990, 0.9995, 1.0007, 0.9948, 0.9918, 0.9981, 0.9999, 0.9902,\n",
      "        1.0000, 0.9991, 0.9981, 1.0000, 0.9996, 0.9988, 0.9922, 0.9956, 0.9940,\n",
      "        1.0008, 0.9995, 0.9997, 0.9972, 0.9994, 0.9992, 0.9995, 0.9981, 0.9995,\n",
      "        0.9985, 0.9994, 1.0003, 0.9950, 0.9996, 0.9980, 0.9985, 0.9984, 0.9973,\n",
      "        0.9910, 0.9960, 0.9989, 0.9995, 1.0002, 0.9961, 0.9968, 0.9994, 0.9952,\n",
      "        0.9993, 0.9989, 0.9974], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9991, 0.9998, 0.9990, 1.0000, 1.0004, 1.0013, 0.9999, 0.9986, 1.0000,\n",
      "        1.0033, 0.9988, 1.0000, 0.9999, 0.9997, 0.9998, 0.9997, 0.9982, 1.0017,\n",
      "        0.9992, 0.9997, 0.9988, 0.9962, 0.9970, 0.9992, 1.0006, 0.9994, 0.9939,\n",
      "        0.9991, 0.9978, 0.9936, 0.9998, 0.9990, 0.9979, 0.9997, 1.0002, 0.9987,\n",
      "        0.9988, 1.0000, 0.9999, 0.9994, 0.9984, 1.0026, 0.9985, 0.9994, 0.9963,\n",
      "        0.9977, 0.9973, 0.9997, 0.9971, 1.0015, 1.0026, 0.9982, 0.9976, 0.9994,\n",
      "        1.0009, 0.9987, 0.9989, 0.9990, 0.9987, 0.9966, 0.9976, 0.9981, 0.9989,\n",
      "        1.0002, 0.9994, 0.9992], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9989, 1.0008, 0.9986, 0.9996, 0.9985, 0.9990, 0.9981, 1.0001, 0.9984,\n",
      "        0.9992, 0.9939, 0.9975, 0.9956, 1.0001, 0.9985, 0.9988, 1.0001, 1.0001,\n",
      "        0.9980, 0.9989, 0.9999, 0.9997, 0.9984, 0.9972, 1.0000, 0.9943, 1.0005,\n",
      "        0.9897, 1.0014, 0.9971, 0.9992, 0.9999, 1.0005, 0.9999, 0.9992, 0.9986,\n",
      "        1.0006, 0.9996, 0.9970, 1.0009, 0.9996, 0.9951, 0.9984, 0.9984, 0.9974,\n",
      "        0.9993, 0.9991, 0.9959, 0.9994, 1.0003, 0.9998, 0.9988, 0.9986, 0.9963,\n",
      "        0.9973, 1.0009, 0.9989, 0.9999, 0.9989, 0.9975, 0.9990, 0.9995, 1.0000,\n",
      "        0.9986, 0.9994, 0.9948], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0013, 1.0002, 0.9980, 0.9997, 0.9942, 0.9999, 1.0019, 0.9977, 0.9999,\n",
      "        1.0000, 0.9966, 0.9998, 0.9999, 1.0003, 1.0013, 0.9990, 1.0001, 0.9970,\n",
      "        0.9957, 0.9977, 0.9984, 0.9978, 0.9996, 1.0000, 0.9983, 0.9982, 1.0002,\n",
      "        0.9973, 0.9981, 0.9990, 0.9987, 0.9958, 0.9953, 1.0003, 1.0010, 0.9986,\n",
      "        0.9987, 0.9971, 0.9993, 1.0005, 0.9996, 0.9984, 0.9922, 0.9976, 0.9987,\n",
      "        0.9999, 0.9996, 0.9999, 1.0010, 0.9974, 1.0002, 0.9997, 1.0023, 0.9955,\n",
      "        0.9994, 0.9922, 1.0003, 0.9989, 0.9974, 0.9817, 0.9945, 0.9894, 0.9939,\n",
      "        1.0009, 0.9922, 0.9999, 0.9900, 0.9969, 0.9955, 0.9990, 1.0019, 1.0007,\n",
      "        0.9994, 0.9981, 0.9985, 0.9998, 0.9993, 1.0042], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0017, 0.9957, 1.0001, 0.9986, 1.0000, 0.9984, 1.0065, 0.9991, 1.0030,\n",
      "        0.9987, 1.0015, 0.9947, 1.0008, 0.9995, 1.0009, 0.9968, 0.9980, 0.9992,\n",
      "        0.9922, 0.9897, 1.0002, 0.9999, 1.0004, 0.9964, 0.9983, 0.9991, 0.9918,\n",
      "        0.9978, 0.9991, 1.0001, 0.9976, 0.9998, 0.9996, 0.9974, 1.0009, 0.9991,\n",
      "        0.9997, 0.9998, 0.9962, 0.9975, 0.9990, 0.9964, 0.9995, 1.0001, 1.0034,\n",
      "        1.0025, 0.9990, 1.0032, 0.9986, 1.0036, 0.9992, 1.0003, 1.0015, 0.9978,\n",
      "        0.9976, 0.9991, 0.9985, 0.9950, 0.9943, 0.9916, 1.0034, 1.0004, 0.9999,\n",
      "        1.0000, 0.9994, 0.9959, 0.9938, 0.9823, 0.9946, 1.0005, 0.9979, 1.0007,\n",
      "        0.9981, 0.9996, 0.9991, 0.9992, 0.9972, 0.9982], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9998, 1.0011, 1.0018, 0.9898, 0.9952, 0.9981, 0.9990, 0.9993, 0.9961,\n",
      "        0.9995, 0.9961, 0.9977, 1.0071, 1.0001, 0.9980, 0.9965, 1.0021, 1.0011,\n",
      "        0.9876, 0.9993, 1.0000, 1.0004, 0.9993, 0.9979, 0.9977, 1.0000, 0.9999,\n",
      "        1.0007, 0.9993, 0.9975, 1.0022, 0.9987, 0.9994, 0.9995, 1.0004, 0.9993,\n",
      "        1.0001, 1.0032, 1.0005, 1.0012, 1.0001, 1.0023, 0.9971, 1.0000, 1.0016,\n",
      "        0.9994, 0.9986, 0.9928, 1.0002, 0.9988, 0.9987, 0.9995, 1.0016, 0.9920,\n",
      "        1.0004, 0.9976, 0.9990, 0.9913, 0.9930, 0.9975, 0.9991, 0.9991, 0.9993,\n",
      "        0.9970, 0.9957, 0.9948, 1.0015, 0.9993, 0.9984, 0.9978, 0.9974, 0.9985,\n",
      "        0.9997, 1.0010, 0.9991, 1.0026, 0.9957, 0.9986], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9968, 0.9951, 0.9974, 0.9966, 0.9979, 0.9970, 0.9973, 0.9989, 0.9979,\n",
      "        1.0001, 0.9733, 0.9996, 1.0008, 0.9980, 1.0016, 0.9990, 0.9989, 0.9964,\n",
      "        0.9961, 0.9999, 0.9968, 0.9955, 0.9976, 0.9953, 0.9971, 1.0009, 0.9968,\n",
      "        0.9986, 0.9973, 0.9996, 1.0005, 1.0011, 1.0017, 1.0031, 1.0023, 1.0020,\n",
      "        0.9988, 1.0033, 1.0029, 1.0016, 0.9995, 1.0000, 1.0015, 0.9952, 0.9986,\n",
      "        0.9978, 1.0268, 1.0208, 1.0025, 1.0022, 0.9986, 1.0050, 1.0020, 0.9987,\n",
      "        1.0037, 0.9993, 0.9972, 0.9906, 0.9993, 0.9950, 1.0026, 0.9958, 1.0006,\n",
      "        0.9969, 0.9982, 1.0009, 0.9930, 0.9930, 0.9960, 0.9995, 0.9994, 0.9979,\n",
      "        1.0020, 0.9967, 0.9904, 1.0013, 0.9986, 0.9988], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9976, 0.9999, 0.9975, 1.0015, 0.9911, 0.9996, 1.0001, 0.9977, 0.9973,\n",
      "        1.0004, 0.9903, 0.9989, 1.0004, 1.0002, 1.0008, 1.0011, 0.9966, 0.9997,\n",
      "        0.9997, 1.0010, 1.0004, 0.9965, 0.9990, 0.9999, 1.0009, 0.9949, 0.9963,\n",
      "        0.9992, 0.9977, 0.9987, 1.0027, 0.9997, 1.0020, 1.0007, 0.9951, 1.0000,\n",
      "        1.0009, 0.9996, 0.9951, 1.0014, 1.0013, 0.9998, 0.9998, 0.9920, 1.0014,\n",
      "        0.9982, 0.9988, 0.9953, 0.9952, 1.0005, 0.9983, 1.0003, 0.9952, 1.0005,\n",
      "        1.0021, 0.9989, 0.9982, 0.9946, 0.9963, 0.9882, 0.9991, 1.0057, 0.9996,\n",
      "        1.0000, 0.9988, 0.9968, 1.0004, 0.9890, 0.9994, 0.9998, 0.9980, 0.9955,\n",
      "        0.9986, 0.9997, 0.9993, 1.0000, 0.9985, 0.9996], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9989, 1.0000, 0.9990, 0.9997, 1.0002, 0.9946, 0.9993, 0.9951, 0.9978,\n",
      "        0.9989, 0.9991, 0.9993, 0.9973, 1.0010, 1.0035, 0.9975, 0.9985, 1.0009,\n",
      "        0.9966, 0.9980, 1.0001, 1.0009, 0.9976, 0.9988, 1.0028, 1.0053, 0.9979,\n",
      "        0.9978, 0.9985, 0.9992, 0.9999, 1.0067, 0.9998, 0.9931, 1.0012, 0.9978,\n",
      "        0.9987, 1.0008, 0.9968, 0.9976, 1.0016, 1.0002, 1.0000, 0.9965, 1.0020,\n",
      "        0.9990, 0.9995, 0.9987, 0.9964, 0.9967, 1.0001, 0.9975, 0.9948, 1.0002,\n",
      "        0.9986, 1.0001, 0.9991, 0.9990, 0.9913, 0.9995, 0.9981, 0.9939, 0.9962,\n",
      "        0.9998, 0.9986, 0.9976, 1.0015, 1.0034, 0.9977, 0.9993, 0.9987, 1.0001,\n",
      "        1.0018, 0.9999, 1.0011, 0.9989, 0.9956, 1.0006], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9988, 0.9999, 0.9990, 0.9985, 0.9989, 0.9974, 1.0003, 0.9992, 0.9998,\n",
      "        0.9998, 0.9993, 0.9994, 0.9978, 0.9999, 0.9947, 0.9893, 1.0000, 1.0007,\n",
      "        1.0005, 0.9997, 1.0001, 0.9985, 0.9994, 0.9972, 0.9990, 1.0002, 0.9974,\n",
      "        1.0013, 1.0003, 0.9913, 0.9937, 0.9994, 0.9997, 0.9991, 0.9990, 0.9956,\n",
      "        0.9997, 1.0003, 0.9993, 1.0006, 0.9985, 0.9990, 0.9989, 1.0004, 1.0012,\n",
      "        0.9994, 0.9999, 0.9995, 0.9984, 0.9999, 1.0005, 0.9989, 0.9954, 1.0001,\n",
      "        1.0024, 1.0002, 1.0035, 0.9999, 0.9990, 1.0031, 1.0001, 1.0001, 0.9993,\n",
      "        0.9999, 1.0002, 1.0009, 0.9941, 0.9969, 0.9980, 0.9993, 1.0000, 0.9925,\n",
      "        0.9991, 1.0002, 0.9991, 0.9989, 0.9992, 0.9981, 0.9995, 0.9969, 0.9991,\n",
      "        1.0000, 0.9986, 0.9971, 0.9998, 1.0001, 1.0003, 0.9999, 0.9993, 0.9998,\n",
      "        0.9993, 0.9989, 0.9998, 1.0000, 0.9998, 0.9999, 1.0000, 0.9999, 1.0000,\n",
      "        1.0004, 0.9985, 1.0023, 0.9994, 0.9997, 1.0000, 0.9958, 0.9986, 0.9974,\n",
      "        0.9990, 0.9998, 0.9972, 1.0000, 1.0002, 0.9991, 1.0026, 1.0027, 0.9909,\n",
      "        1.0002, 1.0000, 0.9991, 0.9987, 1.0007, 1.0005, 1.0005, 1.0003, 1.0001,\n",
      "        0.9992, 0.9995, 0.9993], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9994, 0.9989, 1.0012, 0.9974, 0.9998, 0.9943, 0.9986, 1.0002, 0.9967,\n",
      "        1.0012, 0.9996, 0.9997, 0.9907, 0.9957, 0.9965, 1.0002, 0.9999, 0.9943,\n",
      "        0.9992, 1.0016, 0.9983, 0.9994, 0.9990, 0.9976, 0.9956, 0.9960, 0.9995,\n",
      "        0.9977, 0.9986, 0.9904, 0.9946, 1.0019, 0.9979, 1.0007, 0.9937, 1.0011,\n",
      "        0.9980, 0.9959, 1.0006, 1.0002, 0.9990, 1.0001, 0.9967, 0.9986, 0.9917,\n",
      "        1.0011, 0.9986, 0.9991, 1.0004, 0.9975, 0.9976, 0.9997, 0.9995, 0.9998,\n",
      "        0.9969, 1.0003, 0.9995, 0.9994, 0.9999, 1.0005, 0.9995, 1.0008, 1.0019,\n",
      "        1.0037, 1.0001, 1.0000, 0.9964, 0.9904, 0.9937, 0.9990, 1.0005, 1.0011,\n",
      "        0.9993, 0.9997, 0.9997, 0.9998, 1.0000, 1.0002, 0.9991, 0.9999, 0.9988,\n",
      "        1.0006, 0.9999, 0.9995, 1.0003, 0.9970, 0.9997, 0.9948, 0.9987, 0.9980,\n",
      "        0.9938, 1.0010, 1.0011, 0.9989, 0.9969, 1.0000, 0.9998, 0.9998, 0.9999,\n",
      "        0.9976, 0.9942, 0.9990, 0.9967, 0.9974, 1.0000, 0.9993, 0.9990, 0.9983,\n",
      "        1.0001, 0.9994, 0.9950, 1.0010, 0.9998, 0.9960, 1.0007, 0.9996, 1.0006,\n",
      "        0.9969, 0.9930, 1.0020, 1.0012, 0.9944, 0.9972, 1.0014, 1.0024, 0.9992,\n",
      "        0.9958, 0.9998, 1.0001], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9995, 0.9999, 1.0010, 1.0003, 0.9991, 1.0007, 1.0002, 0.9997, 1.0000,\n",
      "        0.9969, 0.9978, 1.0002, 0.9966, 1.0012, 1.0001, 0.9959, 0.9984, 0.9933,\n",
      "        0.9990, 0.9999, 0.9999, 1.0005, 0.9995, 1.0028, 0.9984, 0.9994, 0.9992,\n",
      "        0.9923, 0.9973, 0.9986, 0.9982, 0.9991, 0.9992, 1.0007, 0.9997, 0.9978,\n",
      "        1.0010, 1.0031, 0.9948, 0.9981, 0.9937, 0.9998, 0.9932, 0.9985, 1.0002,\n",
      "        1.0009, 1.0015, 0.9995, 0.9987, 0.9970, 1.0019, 1.0006, 1.0000, 0.9997,\n",
      "        0.9991, 0.9984, 1.0030, 1.0000, 0.9913, 0.9996, 1.0004, 1.0011, 0.9971,\n",
      "        1.0004, 1.0006, 1.0032, 0.9971, 0.9930, 0.9923, 0.9999, 0.9956, 0.9966,\n",
      "        0.9971, 1.0020, 0.9988, 1.0007, 0.9982, 0.9964, 0.9937, 0.9997, 0.9975,\n",
      "        0.9976, 0.9989, 0.9991, 0.9988, 0.9988, 0.9939, 1.0000, 1.0003, 0.9971,\n",
      "        0.9991, 0.9972, 0.9974, 0.9988, 0.9983, 0.9996, 1.0005, 1.0004, 0.9996,\n",
      "        0.9990, 1.0013, 1.0009, 0.9999, 1.0001, 0.9978, 0.9989, 0.9952, 0.9997,\n",
      "        0.9998, 0.9934, 0.9996, 0.9997, 0.9966, 0.9988, 0.9997, 1.0036, 1.0019,\n",
      "        1.0003, 1.0001, 1.0002, 1.0002, 1.0000, 0.9977, 0.9971, 0.9982, 1.0002,\n",
      "        1.0004, 0.9995, 1.0000], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9998, 1.0000, 0.9997, 0.9986, 0.9982, 0.9992, 0.9980, 0.9953, 0.9994,\n",
      "        0.9984, 0.9989, 0.9996, 0.9989, 0.9970, 0.9973, 1.0018, 0.9990, 0.9982,\n",
      "        1.0002, 1.0028, 1.0000, 1.0006, 1.0002, 0.9958, 0.9902, 0.9911, 0.9999,\n",
      "        0.9995, 0.9903, 0.9978, 0.9982, 1.0000, 0.9977, 0.9996, 0.9931, 0.9928,\n",
      "        1.0008, 0.9942, 1.0008, 0.9980, 0.9996, 0.9990, 0.9969, 0.9998, 0.9996,\n",
      "        1.0018, 0.9994, 0.9983, 0.9982, 0.9954, 0.9987, 0.9939, 0.9996, 0.9988,\n",
      "        1.0001, 0.9990, 0.9998, 1.0002, 0.9992, 0.9993, 0.9995, 0.9941, 0.9999,\n",
      "        0.9968, 0.9986, 0.9994, 0.9933, 0.9940, 0.9971, 0.9978, 0.9965, 0.9976,\n",
      "        1.0003, 0.9999, 1.0001, 0.9998, 0.9991, 0.9997, 1.0003, 1.0055, 1.0017,\n",
      "        1.0007, 0.9995, 0.9985, 1.0012, 0.9976, 0.9985, 0.9996, 0.9994, 0.9994,\n",
      "        0.9987, 0.9994, 0.9998, 1.0002, 0.9914, 0.9994, 0.9994, 0.9945, 0.9962,\n",
      "        0.9992, 0.9998, 0.9979, 1.0023, 0.9919, 1.0014, 0.9971, 0.9878, 1.0004,\n",
      "        0.9921, 0.9994, 0.9960, 1.0001, 0.9992, 1.0012, 0.9982, 0.9952, 1.0003,\n",
      "        0.9986, 1.0002, 1.0004, 1.0043, 0.9922, 0.9987, 1.0003, 0.9982, 0.9942,\n",
      "        0.9975, 0.9997, 0.9998], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9942, 0.9973, 0.9945, 1.0015, 0.9999, 0.9937, 1.0000, 1.0000, 0.9971,\n",
      "        0.9934, 0.9995, 1.0005, 0.9940, 0.9970, 0.9997, 0.9990, 0.9986, 0.9999,\n",
      "        1.0002, 1.0003, 1.0005, 1.0012, 1.0006, 0.9962, 0.9974, 0.9959, 0.9983,\n",
      "        0.9965, 0.9850, 1.0001, 0.9994, 1.0031, 1.0015, 0.9963, 0.9994, 0.9908,\n",
      "        0.9975, 0.9992, 0.9985, 1.0005, 0.9989, 0.9953, 1.0014, 1.0008, 0.9991,\n",
      "        0.9995, 1.0022, 1.0000, 0.9996, 0.9999, 1.0000, 0.9946, 0.9983, 1.0001,\n",
      "        0.9977, 1.0004, 0.9959, 1.0032, 1.0016, 1.0004, 0.9970, 0.9948, 0.9977,\n",
      "        0.9968, 1.0014, 1.0021, 0.9968, 0.9964, 0.9967, 0.9955, 0.9897, 0.9972,\n",
      "        1.0005, 0.9971, 0.9992, 0.9973, 1.0039, 0.9982, 1.0024, 1.0043, 0.9947,\n",
      "        1.0003, 0.9963, 1.0007, 1.0002, 0.9997, 0.9985, 1.0001, 0.9926, 0.9949,\n",
      "        1.0004, 1.0029, 1.0022, 0.9972, 0.9949, 0.9996, 0.9998, 0.9992, 0.9947,\n",
      "        0.9981, 0.9997, 0.9913, 0.9989, 0.9999, 0.9994, 0.9961, 0.9998, 0.9981,\n",
      "        1.0010, 0.9949, 0.9996, 0.9961, 0.9985, 0.9994, 0.9981, 1.0011, 0.9987,\n",
      "        1.0003, 0.9897, 0.9942, 0.9982, 1.0003, 0.9943, 0.9951, 0.9916, 0.9931,\n",
      "        0.9987, 0.9988, 1.0020], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0038, 0.9985, 1.0018, 0.9998, 1.0003, 0.9973, 0.9966, 0.9991, 0.9981,\n",
      "        0.9992, 1.0011, 0.9998, 0.9911, 0.9911, 0.9854, 0.9997, 0.9998, 0.9937,\n",
      "        0.9999, 0.9994, 1.0009, 1.0025, 0.9999, 1.0023, 0.9985, 0.9965, 1.0022,\n",
      "        0.9921, 0.9951, 0.9808, 0.9952, 0.9984, 0.9995, 1.0001, 0.9988, 0.9971,\n",
      "        0.9980, 0.9924, 0.9994, 1.0061, 0.9968, 0.9997, 0.9970, 0.9960, 1.0005,\n",
      "        1.0001, 0.9994, 0.9999, 0.9979, 0.9967, 0.9965, 0.9984, 0.9842, 0.9995,\n",
      "        0.9976, 0.9991, 0.9906, 0.9989, 0.9977, 0.9973, 0.9997, 0.9998, 0.9988,\n",
      "        0.9999, 1.0007, 0.9996, 0.9996, 0.9976, 0.9938, 0.9922, 0.9911, 0.9896,\n",
      "        0.9974, 0.9967, 1.0011, 0.9994, 0.9992, 0.9954, 1.0023, 0.9946, 0.9997,\n",
      "        0.9967, 0.9768, 0.9941, 0.9993, 0.9989, 0.9993, 0.9972, 0.9935, 0.9990,\n",
      "        0.9996, 1.0000, 0.9991, 0.9994, 0.9955, 0.9994, 0.9991, 1.0015, 1.0027,\n",
      "        0.9994, 0.9990, 0.9990, 0.9965, 1.0002, 0.9999, 0.9955, 0.9994, 0.9984,\n",
      "        0.9924, 1.0029, 1.0015, 0.9996, 1.0009, 0.9984, 1.0000, 0.9989, 1.0013,\n",
      "        0.9963, 1.0019, 1.0001, 1.0008, 0.9999, 0.9991, 1.0007, 0.9987, 0.9916,\n",
      "        0.9933, 1.0001, 0.9956], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9958, 0.9945, 0.9967, 0.9980, 0.9958, 0.9944, 0.9991, 0.9987, 0.9977,\n",
      "        1.0001, 1.0019, 0.9994, 1.0013, 0.9967, 0.9957, 0.9983, 0.9996, 0.9996,\n",
      "        1.0012, 0.9888, 0.9978, 0.9952, 0.9981, 0.9900, 0.9943, 0.9811, 0.9946,\n",
      "        1.0013, 1.0001, 0.9974, 0.9999, 0.9922, 1.0025, 1.0029, 1.0021, 0.9999,\n",
      "        0.9957, 0.9993, 0.9948, 0.9969, 0.9815, 0.9980, 0.9982, 0.9907, 0.9943,\n",
      "        0.9990, 1.0005, 1.0029, 0.9898, 0.9987, 0.9991, 1.0012, 1.0093, 0.9987,\n",
      "        0.9992, 1.0017, 0.9950, 0.9962, 1.0001, 1.0013, 0.9977, 0.9873, 1.0011,\n",
      "        0.9987, 0.9980, 0.9945, 0.9841, 0.9893, 0.9866, 0.9983, 0.9938, 0.9886],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9889, 0.9968, 0.9843, 1.0041, 0.9981, 0.9901, 0.9989, 0.9931, 0.9988,\n",
      "        0.9928, 1.0076, 0.9998, 0.9912, 0.9976, 0.9991, 0.9959, 0.9971, 1.0031,\n",
      "        0.9957, 1.0019, 0.9933, 1.0006, 0.9892, 0.9943, 0.9703, 0.9924, 0.9703,\n",
      "        1.0005, 1.0038, 1.0011, 1.0003, 0.9663, 0.9976, 1.0015, 0.9976, 1.0005,\n",
      "        1.0044, 0.9945, 0.9862, 0.9970, 0.9974, 0.9950, 0.9998, 1.0009, 0.9995,\n",
      "        1.0003, 1.0004, 0.9935, 0.9871, 0.9974, 0.9982, 0.9942, 0.9976, 0.9959,\n",
      "        0.9999, 1.0004, 0.9906, 1.0014, 0.9987, 1.0014, 0.9956, 0.9933, 0.9960,\n",
      "        1.0011, 1.0010, 0.9942, 1.0009, 0.9986, 0.9815, 0.9926, 0.9750, 1.0006],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9859, 0.9880, 0.9971, 1.0018, 0.9870, 0.9997, 0.9949, 0.9997, 0.9966,\n",
      "        1.0013, 0.9887, 0.9967, 1.0006, 1.0021, 1.0046, 0.9815, 0.9814, 0.9911,\n",
      "        1.0013, 1.0029, 1.0049, 1.0030, 1.0001, 0.9995, 0.9928, 0.9799, 0.9967,\n",
      "        0.9991, 1.0014, 0.9991, 0.9890, 0.9994, 0.9998, 0.9983, 1.0011, 0.9943,\n",
      "        0.9980, 1.0006, 0.9958, 1.0042, 1.0027, 0.9949, 0.9997, 0.9980, 0.9967,\n",
      "        0.9946, 0.9782, 0.9945, 0.9923, 1.0000, 0.9908, 0.9901, 1.0027, 0.9910,\n",
      "        0.9966, 0.9969, 1.0017, 0.9909, 1.0009, 0.9939, 1.0018, 0.9910, 1.0050,\n",
      "        1.0019, 1.0060, 1.0065, 0.9989, 0.9966, 0.9872, 0.9994, 1.0087, 0.9744],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9766, 0.9977, 0.9785, 0.9936, 0.9950, 0.9956, 1.0053, 1.0005, 0.9933,\n",
      "        0.9985, 1.0006, 0.9988, 0.9953, 0.9967, 0.9959, 1.0049, 1.0004, 0.9863,\n",
      "        0.9983, 0.9937, 1.0001, 0.9959, 0.9927, 0.9968, 0.9788, 0.9788, 0.9940,\n",
      "        0.9984, 1.0023, 0.9959, 0.9700, 1.0052, 1.0008, 0.9951, 1.0019, 0.9988,\n",
      "        1.0023, 1.0033, 0.9957, 1.0000, 0.9971, 0.9972, 0.9918, 1.0013, 0.9744,\n",
      "        0.9987, 0.9992, 1.0002, 0.9895, 1.0113, 1.0098, 0.9993, 0.9855, 0.9984,\n",
      "        1.0012, 0.9818, 0.9942, 1.0015, 1.0037, 0.9750, 0.9974, 0.9997, 0.9632,\n",
      "        1.0007, 0.9947, 0.9997, 1.0041, 1.0052, 0.9737, 0.9900, 0.9993, 1.0005],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0120, 0.9995, 1.0124, 0.9971, 1.0017, 0.9755, 1.0057, 0.9935, 0.9992,\n",
      "        0.9891, 0.9950, 0.9933, 0.9989, 0.9989, 0.9996, 0.9934, 0.9979, 1.0002,\n",
      "        0.9901, 0.9988, 0.9803, 0.9894, 0.9896, 0.9932, 0.9858, 0.9988, 0.9756,\n",
      "        0.9935, 0.9997, 0.9965, 0.9849, 0.9972, 0.9974, 0.9999, 0.9873, 1.0053,\n",
      "        0.9981, 0.9958, 0.9996, 0.9996, 0.9981, 0.9989, 1.0075, 0.9975, 1.0197,\n",
      "        0.9865, 1.0017, 0.9944, 0.9951, 1.0008, 0.9985, 0.9940, 0.9965, 0.9954,\n",
      "        0.9886, 1.0054, 1.0006, 0.9878, 0.9978, 0.9985, 0.9858, 1.0037, 0.9827,\n",
      "        0.9981, 1.0004, 0.9909, 0.9836, 0.9961, 1.0051, 1.0038, 1.0030, 1.0015],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9849, 0.9984, 0.9986, 0.9962, 1.0001, 0.9944, 0.9988, 1.0097, 0.9935,\n",
      "        0.9998, 1.0011, 0.9973, 1.0002, 0.9975, 0.9955, 1.0004, 0.9991, 0.9926,\n",
      "        0.9992, 0.9997, 0.9699, 1.0098, 0.9978, 0.9924, 0.9815, 0.9835, 0.9945,\n",
      "        0.9966, 1.0001, 0.9997, 0.9782, 0.9709, 0.9939, 0.9877, 1.0045, 0.9991,\n",
      "        1.0061, 0.9935, 1.0048, 0.9825, 0.9978, 0.9898, 0.9978, 0.9951, 0.9953,\n",
      "        0.9996, 1.0008, 1.0000, 0.9967, 0.9905, 1.0005, 1.0016, 1.0030, 1.0034,\n",
      "        0.9983, 1.0011, 0.9906, 1.0002, 1.0005, 0.9963, 1.0086, 0.9816, 0.9990,\n",
      "        1.0003, 0.9985, 1.0007, 0.9961, 0.9745, 1.0036, 1.0071, 0.9933, 0.9905],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9457, 1.0065, 0.9998, 0.9775, 0.9559, 0.9987, 0.9806, 1.0066, 1.0107,\n",
      "        1.0000, 0.9959, 1.0027, 0.9838, 1.0022, 1.0049, 0.9852, 0.9941, 1.0026,\n",
      "        1.0005, 0.9985, 0.9970, 1.0053, 0.9723, 0.9984, 0.9966, 0.9654, 0.9858,\n",
      "        1.0036, 0.9938, 0.9777, 0.9646, 0.9886, 1.0003, 0.9624, 0.9942, 0.9767,\n",
      "        1.0015, 0.9494, 0.9927, 0.9857, 0.9657, 0.8594, 0.9968, 0.9974, 1.0010,\n",
      "        0.9846, 1.0043, 0.9977, 1.0001, 0.9963, 0.9906, 0.9985, 0.9989, 0.9773,\n",
      "        0.9809, 0.9977, 0.9849, 0.9935, 1.0042, 0.9974, 1.0106, 0.9965, 1.0003,\n",
      "        0.9981, 1.0036, 1.0001, 0.9898, 0.9907, 0.9901, 1.0012, 0.9871, 0.9909,\n",
      "        0.9781, 0.9942, 0.9859, 0.9960, 1.0067, 0.9964, 0.9826, 0.9782, 0.9896,\n",
      "        0.9790, 0.9694, 1.0111, 0.9907, 0.9928, 0.9824, 0.9931, 0.9941, 0.9875,\n",
      "        0.9975, 0.9991, 1.0015, 0.9746, 0.9873, 0.9918, 0.9958, 0.9830, 1.0082,\n",
      "        1.0003, 0.9936, 1.0023, 0.9995, 1.0081, 0.9867, 0.9928, 1.0031, 0.9991,\n",
      "        0.9869, 0.9918, 0.9951, 0.9958, 0.9965, 0.9643, 0.9983, 0.9946, 0.9991,\n",
      "        0.9987, 0.9977, 1.0006, 0.9894, 0.9928, 0.9926, 0.9815, 0.9986, 0.9977,\n",
      "        0.9969, 0.9827, 0.9995, 0.9888, 1.0086, 0.9899, 0.9967, 1.0051, 1.0013,\n",
      "        1.0002, 0.9957, 0.9899, 0.9983, 0.9915, 0.9991, 1.0087, 1.0271, 0.9588],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9945, 1.0069, 1.0074, 0.9787, 1.0021, 0.9869, 0.9915, 0.9837, 0.9921,\n",
      "        0.9795, 1.0041, 0.9768, 0.9403, 0.9905, 0.9849, 0.9548, 0.9720, 0.9816,\n",
      "        1.0063, 0.9953, 1.0067, 0.9988, 0.9969, 0.9990, 0.9797, 0.9963, 0.9792,\n",
      "        0.9986, 1.0009, 0.9763, 1.0015, 0.9831, 0.9757, 1.0085, 0.9915, 1.0155,\n",
      "        0.9776, 0.9805, 1.0051, 0.9813, 0.9680, 0.9630, 0.9965, 0.9907, 1.0005,\n",
      "        0.9970, 0.9880, 0.9997, 0.9966, 0.9927, 0.9688, 1.0015, 0.9994, 1.0061,\n",
      "        0.9868, 1.0015, 1.0046, 1.0011, 0.9974, 0.9961, 0.9806, 1.0012, 0.9962,\n",
      "        1.0028, 1.0082, 0.9978, 0.9917, 0.9949, 0.9843, 1.0045, 1.0045, 0.9965,\n",
      "        0.9680, 0.9574, 0.9258, 0.9725, 0.9773, 0.9715, 1.0027, 0.9372, 0.9654,\n",
      "        1.0083, 0.9964, 0.9924, 0.9793, 0.9780, 1.0023, 0.9951, 1.0066, 0.9799,\n",
      "        0.9965, 0.9839, 0.9998, 0.9749, 0.9495, 0.9857, 0.9775, 0.9881, 0.9956,\n",
      "        0.9906, 0.9971, 0.9964, 1.0016, 0.9898, 1.0063, 0.9911, 0.9914, 1.0023,\n",
      "        0.9826, 0.9885, 0.9872, 1.0012, 1.0008, 0.9896, 1.0022, 1.0068, 0.9979,\n",
      "        0.9940, 0.9981, 0.9931, 0.9835, 1.0042, 1.0021, 0.9973, 0.9981, 1.0000,\n",
      "        0.9964, 1.0173, 0.9892, 0.9971, 1.0051, 0.9998, 0.9969, 0.9962, 0.9780,\n",
      "        0.9988, 1.0015, 0.9927, 0.9996, 0.9855, 0.9950, 0.9978, 0.9970, 0.9910],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9632, 1.0136, 1.0104, 1.0004, 0.9928, 0.9968, 1.0008, 0.9736, 0.9813,\n",
      "        0.9892, 0.9834, 0.9800, 0.9822, 1.0044, 1.0062, 0.9877, 0.9975, 0.9970,\n",
      "        0.9876, 0.9917, 0.9953, 1.0086, 0.9964, 0.9773, 0.9823, 0.9855, 0.9757,\n",
      "        1.0082, 0.9883, 1.0000, 0.9112, 0.9524, 0.9861, 0.9952, 0.9559, 0.9835,\n",
      "        0.9891, 0.9913, 0.9651, 0.9485, 0.9281, 1.0006, 0.9796, 1.0002, 0.9875,\n",
      "        1.0095, 1.0057, 0.9987, 0.9943, 0.9849, 0.9910, 0.9966, 0.9858, 0.9878,\n",
      "        0.9659, 0.9959, 0.9668, 0.9863, 0.9917, 0.9990, 0.9975, 1.0087, 0.9978,\n",
      "        0.9913, 1.0004, 0.9900, 0.9985, 0.9998, 0.9950, 1.0031, 1.0089, 0.9805,\n",
      "        0.9996, 0.9911, 0.9807, 0.9824, 0.9851, 0.9983, 1.0001, 0.9917, 0.9761,\n",
      "        0.9479, 1.0062, 1.0055, 0.9836, 1.0031, 1.0096, 0.9961, 1.0160, 0.9875,\n",
      "        0.9948, 0.9972, 1.0007, 0.9714, 0.9666, 0.9838, 0.9950, 0.9731, 0.9938,\n",
      "        1.0012, 1.0066, 0.9979, 0.9843, 1.0070, 1.0060, 0.9942, 0.9877, 0.9780,\n",
      "        1.0000, 0.9990, 0.9939, 1.0091, 1.0017, 0.9795, 0.9760, 1.0002, 0.9957,\n",
      "        1.0018, 1.0008, 0.9992, 0.9927, 0.9919, 0.9859, 1.0006, 0.9965, 0.9728,\n",
      "        0.9916, 0.9811, 0.9921, 0.9968, 0.9727, 1.0186, 1.0040, 1.0114, 1.0030,\n",
      "        0.9939, 0.9964, 0.9400, 0.9887, 0.9993, 0.9863, 0.9871, 0.9778, 0.9924],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9944, 0.9953, 0.9938, 1.0037, 1.0187, 0.9872, 0.9967, 0.9981, 1.0004,\n",
      "        0.9672, 1.0031, 0.9963, 0.9934, 1.0025, 1.0007, 0.9703, 0.9647, 0.9745,\n",
      "        0.9976, 0.9997, 0.9845, 1.0070, 0.9905, 0.9877, 0.9925, 0.9973, 0.9595,\n",
      "        1.0137, 1.0078, 0.9316, 0.9566, 0.8864, 0.9959, 0.9872, 0.9937, 0.9883,\n",
      "        0.9690, 0.8651, 0.9325, 0.9556, 1.0027, 0.9510, 0.9645, 0.9768, 0.9707,\n",
      "        0.9979, 0.9994, 1.0009, 0.9857, 0.9963, 0.9929, 0.9995, 1.0089, 1.0016,\n",
      "        0.9570, 0.9775, 1.0029, 0.9915, 0.9872, 0.9939, 0.9689, 1.0256, 1.0012,\n",
      "        0.9905, 0.9950, 1.0047, 0.9811, 1.0025, 0.9965, 0.9940, 0.9753, 1.0024,\n",
      "        0.9833, 1.0102, 0.9850, 1.0023, 0.9979, 0.9744, 0.9926, 0.9887, 0.9934,\n",
      "        1.0447, 1.0007, 0.9627, 0.9991, 0.9940, 0.9837, 0.9971, 0.9967, 0.9942,\n",
      "        0.9751, 0.9765, 0.9911, 0.9971, 1.0012, 0.9913, 1.0053, 0.9413, 0.9910,\n",
      "        0.9537, 0.9890, 1.0033, 0.9521, 1.0025, 0.9929, 0.9858, 0.9975, 0.9995,\n",
      "        1.0079, 0.9993, 1.0113, 0.9716, 1.0006, 1.0046, 0.9946, 0.9941, 0.9734,\n",
      "        0.9963, 0.9184, 0.9997, 0.9721, 0.9642, 0.9544, 0.9943, 1.0018, 0.9955,\n",
      "        0.9980, 0.9716, 0.9988, 0.9977, 1.0122, 0.9609, 1.0109, 0.9798, 0.9966,\n",
      "        0.9545, 0.9989, 1.0051, 0.9955, 0.9961, 0.9960, 0.9749, 0.9633, 0.9885],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9631, 0.9957, 0.9960, 0.9639, 0.9361, 0.9518, 0.9954, 0.9904, 1.0012,\n",
      "        1.0102, 0.9682, 0.9896, 0.9936, 0.9654, 0.9962, 0.9999, 1.0019, 0.9908,\n",
      "        0.9887, 0.9790, 1.0037, 0.9970, 0.9759, 0.9967, 0.9866, 0.9870, 0.9587,\n",
      "        0.9683, 0.9722, 0.9936, 1.0633, 1.0019, 1.0432, 0.9552, 1.0029, 1.0017,\n",
      "        0.9847, 0.9521, 0.8727, 0.9984, 0.9892, 0.9118, 0.9961, 1.0031, 0.9931,\n",
      "        0.9909, 0.9948, 1.0023, 0.9762, 1.0139, 0.9776, 0.9959, 1.0113, 1.0043,\n",
      "        0.9933, 0.9979, 1.0005, 1.0046, 1.0048, 1.0044, 1.0046, 0.9724, 0.9875,\n",
      "        1.0048, 1.0047, 0.9874, 1.0105, 0.9865, 1.0169, 0.9961, 1.0008, 0.9914,\n",
      "        0.9948, 0.9933, 0.9911, 0.9876, 0.9977, 0.9274, 0.9726, 0.9389, 0.9451,\n",
      "        0.9340, 0.9742, 0.9806, 0.9683, 0.9660, 0.9753, 0.9850, 0.9883, 1.0010,\n",
      "        1.0144, 0.9961, 0.9866, 0.9835, 0.9143, 1.0003, 0.9836, 1.0056, 0.9943,\n",
      "        0.9860, 0.9971, 0.9844, 1.0032, 0.9955, 0.9963, 0.9992, 0.9763, 1.0073,\n",
      "        0.9982, 0.9667, 0.9656, 0.9920, 0.9611, 0.9735, 1.0073, 1.0206, 0.9706,\n",
      "        0.9587, 1.0006, 1.0045, 0.9970, 1.0054, 0.9899, 0.9943, 0.9986, 0.9956,\n",
      "        0.9920, 0.9993, 0.9996, 0.9927, 0.9912, 1.0015, 0.9903, 1.0054, 0.9935,\n",
      "        1.0250, 0.9994, 1.0169, 1.0022, 0.9972, 1.0014, 0.9954, 1.0213, 1.0153],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9832, 1.0032, 0.9998, 0.9452, 0.9589, 0.9674, 0.9550, 0.9947, 0.9994,\n",
      "        0.9739, 0.9269, 1.0119, 0.9571, 1.0324, 0.9967, 0.9529, 0.9794, 0.9879,\n",
      "        0.9463, 1.0016, 0.9586, 0.9859, 1.0059, 0.9732, 1.0006, 0.9829, 0.9651,\n",
      "        0.9927, 0.9799, 0.9934, 0.8750, 1.0076, 0.9993, 0.9823, 1.0464, 1.0015,\n",
      "        1.0025, 1.0036, 0.9665, 0.9818, 0.9424, 0.9294, 0.9851, 0.9656, 0.9946,\n",
      "        0.9916, 0.9820, 0.9728, 0.9703, 0.9636, 0.9728, 0.9750, 1.0031, 1.0265,\n",
      "        0.9598, 0.9466, 0.9628, 1.0082, 1.0003, 1.0075, 0.9948, 0.9601, 0.9792,\n",
      "        0.9839, 1.0388, 1.0484, 0.9929, 0.9805, 0.9978, 1.0050, 0.9833, 1.0050,\n",
      "        1.0186, 1.0040, 0.9959, 1.0387, 0.9590, 1.0031, 1.0010, 0.9891, 0.9396,\n",
      "        0.9874, 0.9742, 1.0112, 1.0009, 0.9223, 1.0188, 0.9954, 1.0070, 0.9803,\n",
      "        0.9858, 0.9720, 0.9980, 0.9953, 0.9916, 0.8341, 0.9937, 0.9761, 0.9963,\n",
      "        0.8815, 0.9738, 0.9917, 0.9984, 0.9947, 0.9884, 0.9952, 0.9811, 0.9943,\n",
      "        0.9644, 0.9926, 1.0275, 0.9976, 1.0098, 0.9718, 0.9947, 0.9759, 1.0116,\n",
      "        0.9968, 0.9907, 0.9720, 1.0048, 0.9553, 0.9976, 0.9881, 0.9721, 1.0035,\n",
      "        0.9883, 0.9744, 0.9698, 0.9827, 0.9712, 0.9802, 1.0047, 0.9856, 0.9805,\n",
      "        1.0297, 1.0126, 0.9734, 0.9936, 0.9460, 0.9924, 0.8094, 0.8918, 0.9840],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0371, 0.9672, 0.9922, 0.9814, 1.0036, 0.9903, 1.0007, 1.0142, 1.0085,\n",
      "        0.9872, 0.9794, 1.0036, 1.0211, 1.0230, 0.9868, 0.9812, 0.9777, 0.8476,\n",
      "        1.0004, 1.0189, 1.0468, 0.9506, 0.9687, 0.9751, 0.9779, 0.9736, 0.9864,\n",
      "        0.9724, 0.9731, 0.9858, 0.9961, 0.9974, 0.9785, 0.9859, 0.9927, 0.9504,\n",
      "        0.9426, 1.0053, 1.0065, 0.9621, 0.8273, 0.9586, 0.9856, 0.9832, 0.9941,\n",
      "        0.9650, 0.9854, 0.9307, 0.9788, 0.9256, 0.9873, 0.9648, 0.9828, 0.9514,\n",
      "        0.9443, 0.9902, 0.9926, 0.9572, 0.9257, 0.9931, 0.8107, 0.9633, 0.8660,\n",
      "        1.0002, 1.0053, 1.0055], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9802, 0.9430, 0.9588, 1.0091, 1.0176, 0.9964, 1.0590, 0.9568, 1.0424,\n",
      "        0.9866, 0.9997, 0.9788, 0.9933, 0.7899, 1.0077, 0.9915, 1.0331, 1.0180,\n",
      "        0.9810, 0.9749, 0.9832, 1.0148, 0.9675, 1.0066, 0.9488, 0.9515, 0.9409,\n",
      "        0.9778, 0.9305, 0.8158, 0.9373, 0.9929, 0.9785, 1.0216, 0.9944, 1.0076,\n",
      "        0.9944, 0.9574, 1.0059, 0.9078, 0.7128, 1.0154, 1.0198, 0.9789, 0.9704,\n",
      "        0.9881, 1.0169, 1.0272, 0.9703, 1.0059, 0.9781, 0.9739, 1.0382, 1.0667,\n",
      "        0.8732, 1.0848, 0.9996, 1.0004, 0.8707, 0.9606, 0.8463, 0.9102, 0.5969,\n",
      "        0.9966, 0.9727, 0.9681], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0235, 0.9986, 0.7982, 0.9652, 0.9970, 0.9439, 0.8411, 1.0939, 1.0405,\n",
      "        0.9762, 0.9978, 1.0466, 0.9783, 0.9975, 0.9466, 0.9825, 0.8568, 0.7951,\n",
      "        0.8354, 0.9417, 0.9741, 0.9253, 0.9788, 1.0016, 0.7394, 0.9984, 0.8258,\n",
      "        0.9117, 1.0215, 1.0195, 0.9803, 1.0020, 1.0115, 1.0102, 0.8199, 0.8609,\n",
      "        0.9803, 0.9613, 1.0219, 1.1152, 0.8834, 1.0034, 0.9716, 0.9287, 0.9373,\n",
      "        0.9219, 1.0608, 1.0285, 0.9417, 0.9898, 1.0122, 0.8940, 0.9574, 0.9837,\n",
      "        0.8577, 0.9134, 0.9683, 0.9891, 0.9623, 0.9593, 0.7949, 0.7397, 0.6540,\n",
      "        0.9862, 1.0283, 1.0133], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9872, 0.9990, 1.0015, 0.9467, 0.9052, 0.7513, 0.9993, 1.0130, 1.0118,\n",
      "        1.0623, 0.9892, 1.0245, 1.0096, 1.0632, 1.0037, 0.7790, 0.5490, 0.7430,\n",
      "        0.8987, 0.9382, 1.0149, 0.7576, 0.8974, 0.9815, 0.9738, 0.9825, 1.0164,\n",
      "        1.0030, 0.9602, 1.0444, 1.0161, 0.9909, 1.0011, 0.9895, 0.9826, 0.9594,\n",
      "        1.0247, 0.9659, 0.9045, 0.9719, 0.8582, 0.8164, 0.9670, 1.0145, 0.9348,\n",
      "        1.0023, 1.0063, 1.0708, 0.8789, 0.8365, 0.9766, 0.9090, 0.7616, 0.9369,\n",
      "        0.9030, 1.0268, 1.0361, 0.9194, 1.0176, 0.9873, 1.0656, 0.7196, 1.1122,\n",
      "        0.9508, 0.9827, 0.9600], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0389, 0.9226, 1.0604, 0.9434, 1.0948, 0.4344, 1.0095, 1.1029, 0.7565,\n",
      "        0.8516, 0.7366, 0.9127, 0.7015, 0.6036, 1.0150, 0.8798, 1.0263, 0.0347,\n",
      "        0.8950, 0.7782, 0.9268, 0.9913, 0.8679, 0.9770, 0.7128, 0.8741, 0.9134,\n",
      "        0.7186, 0.2319, 0.6493, 0.9949, 0.9946, 0.9908, 0.5604, 0.2775, 0.8854,\n",
      "        0.9616, 0.9267, 0.8089, 0.4527, 1.0779, 0.6578, 0.4271, 1.0721, 1.2115,\n",
      "        0.5978, 1.1690, 0.4710, 0.8038, 0.6021, 0.9607, 1.1014, 0.6869, 0.8436,\n",
      "        0.9026, 0.2923, 1.0123, 1.0060, 0.5737, 0.7992, 0.9757, 0.5020, 0.0711,\n",
      "        1.0049, 1.0103, 1.0190], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9976, 0.9157, 0.1342, 0.0940, 0.8470, 0.2537, 0.8218, 0.6664, 0.8741,\n",
      "        1.2358, 0.2517, 0.9772, 0.5043, 1.1954, 0.9365, 0.6928, 0.3678, 0.5834,\n",
      "        1.3583, 0.9260, 1.0684, 0.9372, 0.9736, 0.4810, 1.0017, 0.9671, 1.1311,\n",
      "        0.7571, 0.9545, 0.7936, 0.5056, 1.0040, 0.7317, 0.5788, 0.6771, 1.0206,\n",
      "        1.3464, 0.2765, 1.1597, 1.0341, 0.9275, 0.7176, 1.1215, 0.8880, 1.4069,\n",
      "        0.0577, 0.9736, 0.5247, 0.5748, 1.0314, 1.2551, 0.5476, 0.8440, 0.3155,\n",
      "        0.8390, 0.9548, 0.6929, 0.2758, 0.9404, 0.6683, 0.5547, 0.6855, 0.8923,\n",
      "        0.9553, 0.7765, 0.6280], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.1399, 0.7366, 1.0168, 0.9074, 0.8384, 1.0838, 1.0965, 0.9165, 0.9298,\n",
      "        1.2143, 1.1481, 1.0319, 0.5455, 0.6899, 0.4350, 0.8236, 0.1636, 0.1459,\n",
      "        0.1304, 0.1943, 0.0234, 0.5451, 0.9805, 2.3976, 0.3988, 0.9949, 0.8745,\n",
      "        0.5140, 0.6999, 1.1260, 1.2476, 0.8453, 0.8986, 0.9310, 0.7674, 0.8537,\n",
      "        0.6908, 2.2101, 1.4740, 0.6763, 0.3741, 0.2373, 0.4961, 0.8209, 0.5073,\n",
      "        0.2679, 0.8500, 0.8306], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([5.9035e-01, 3.4433e-01, 3.7329e-01, 5.6552e-01, 7.6846e-01, 1.3010e+00,\n",
      "        3.3255e-01, 1.0803e+00, 5.4065e-01, 6.1185e-01, 5.3467e-01, 1.3932e+00,\n",
      "        3.9676e-02, 4.0773e-01, 9.3576e-01, 2.6721e+00, 8.5904e-01, 1.0429e+00,\n",
      "        1.5081e+00, 6.4939e-01, 2.0015e-03, 1.2682e-01, 5.6094e-01, 3.0106e-01,\n",
      "        2.4656e+00, 3.1632e+00, 5.7988e-01, 2.3771e+00, 1.3026e+00, 5.8596e-01,\n",
      "        4.4188e-02, 1.4947e-01, 3.0312e+00, 3.6390e-02, 2.9218e-01, 2.8964e-01,\n",
      "        3.7484e-01, 3.3789e-01, 8.0760e-01, 3.1663e-01, 5.3018e-01, 3.7190e-01,\n",
      "        2.4830e-01, 6.3168e+00, 9.5040e-01, 4.0215e+00, 1.8157e+00, 2.9487e+00],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([9.8462e+00, 3.6420e+00, 3.9923e-01, 3.0604e+00, 2.9545e+00, 4.7078e-01,\n",
      "        3.0385e+00, 1.5811e+00, 1.1794e+00, 2.9635e-01, 2.9316e-01, 3.0808e-02,\n",
      "        8.7457e-01, 5.9106e-01, 5.7709e-01, 3.7641e+00, 4.8488e+00, 1.8142e+01,\n",
      "        5.2242e+00, 2.2934e+01, 1.3023e+00, 1.4399e+00, 5.6311e+00, 9.5554e-01,\n",
      "        1.7229e-01, 1.6011e+00, 2.4087e-03, 2.3421e+00, 6.0250e-01, 9.7337e-01,\n",
      "        7.1862e-01, 3.6730e+00, 4.9549e+00, 5.8478e-01, 1.7739e+00, 9.6271e-01,\n",
      "        2.1754e+00, 1.7112e+00, 1.2332e+00, 2.3354e+00, 1.4844e+00, 2.5970e+00,\n",
      "        6.0308e+00, 1.7565e+01, 4.8302e-01, 2.7810e-01, 1.9210e+00],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.2631, 0.1371, 1.7503, 0.6327, 0.2472, 0.4949, 0.7964, 0.7762, 1.2104,\n",
      "        0.9056, 1.0583, 0.7566, 0.3757, 0.4513, 0.1352, 0.2600, 0.3384, 0.8180,\n",
      "        1.0521, 0.2573, 0.3168, 0.1140, 0.6829, 0.1273, 1.0736, 0.9678, 0.7187,\n",
      "        0.1392, 0.7260, 0.5843, 1.1540, 1.0996, 1.0656, 0.3603, 0.3584, 0.5240,\n",
      "        0.6191, 0.7845, 1.6907, 0.5846, 0.3953, 0.7839, 0.0643, 0.6481, 1.4915,\n",
      "        1.8352, 0.7711], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.8526, 0.3339, 0.7894, 1.0435, 0.4389, 0.9374, 0.8928, 0.9023, 0.8039,\n",
      "        0.8949, 0.8603, 0.9437, 0.6345, 0.5048, 0.8211, 0.7510, 0.7492, 0.7024,\n",
      "        0.4199, 0.7847, 0.2981, 0.1935, 0.3787, 1.0320, 0.7048, 0.9869, 0.8038,\n",
      "        0.8362, 0.8960, 0.8094, 1.0066, 0.1006, 0.4202, 0.8417, 0.6868, 0.4514,\n",
      "        0.5891, 0.6492, 0.3286, 1.0987, 1.0355, 0.8929, 0.7140, 1.0115, 0.9089,\n",
      "        0.9867, 0.9472, 0.8585], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0034, 0.9209, 0.3938, 0.4922, 0.7357, 1.0247, 0.8690, 0.9735, 0.9435,\n",
      "        0.7694, 0.9995, 0.9944, 0.9933, 0.9758, 0.8281, 0.6120, 0.9148, 0.7087,\n",
      "        0.9632, 1.0023, 0.8873, 0.9911, 0.9403, 1.0482, 0.8346, 1.0278, 0.9838,\n",
      "        0.9878, 0.9667, 0.9459, 0.9946, 0.8223, 0.9993, 0.4278, 0.2718, 0.9520,\n",
      "        0.8382, 0.6194, 0.9632, 0.0674, 0.7366, 0.0358, 0.0541, 0.9942, 0.0730,\n",
      "        0.8853, 1.0449, 1.0201], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.1021, 0.9766, 0.4919, 0.9816, 0.6826, 0.7403, 0.9861, 1.1651, 0.9583,\n",
      "        0.9889, 0.9508, 1.0238, 0.9744, 1.0819, 0.9970, 0.7560, 1.0330, 1.0312,\n",
      "        0.8806, 0.7640, 0.8476, 0.4320, 0.7638, 0.5167, 0.9808, 0.5971, 0.7097,\n",
      "        1.0287, 0.2233, 0.6339, 0.2525, 0.9902, 0.5689, 0.7978, 0.2098, 0.8088,\n",
      "        0.0276, 0.9805, 0.7773, 0.5937, 0.9377, 1.0971, 0.9383, 0.9804, 0.8459,\n",
      "        1.0077, 1.0271, 0.7322, 0.9825, 0.5750, 0.9784, 0.6498, 0.6745, 0.9559,\n",
      "        0.6417, 0.9976, 0.9668, 0.7484, 0.7130, 0.8700, 0.9139, 1.0159, 0.9749,\n",
      "        0.8415, 0.8409, 0.9685, 1.3736, 0.7843, 1.2666, 0.3394, 0.4417, 0.8685,\n",
      "        1.0147, 0.9944, 0.9205, 0.3541, 0.8361, 0.9911, 1.0761, 0.9455, 1.0412,\n",
      "        0.9098, 1.0626, 1.0412, 0.9525, 0.8246, 0.0129, 0.9784, 0.5721, 0.8582,\n",
      "        0.8477, 0.9263, 0.8259, 0.9712, 0.9891, 0.9569, 0.7782, 0.9831, 0.9255,\n",
      "        1.4929, 1.5890, 0.6970, 0.9614, 1.0576, 0.9005, 1.0692, 1.0701, 0.5824,\n",
      "        0.1168, 0.4210, 0.7151, 1.1229, 0.9408, 0.6408, 0.8691, 0.8410, 0.9091,\n",
      "        0.7452, 0.9905, 1.0274, 1.1831, 1.0488, 0.9240, 0.7504, 1.2475, 1.3743,\n",
      "        0.6800, 0.7548, 0.9692, 0.9248, 0.8728, 0.8762, 0.7493, 0.5477, 0.9987,\n",
      "        0.8452, 1.0000, 0.5914, 0.8151, 0.6604, 0.8544, 1.6860, 0.8245, 1.5370,\n",
      "        1.0049, 0.4294, 0.2930, 0.5412, 0.8493, 1.0221, 0.7794, 0.9434, 0.9415,\n",
      "        0.9808, 0.9612, 0.9679], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.1518, 0.1457, 0.7753, 0.6871, 0.4084, 0.2247, 0.3989, 0.8545, 1.4086,\n",
      "        1.0348, 0.8661, 0.9567, 1.1361, 1.1689, 1.0113, 1.1658, 1.1963, 0.6786,\n",
      "        1.0991, 0.6503, 0.5266, 0.3490, 0.2017, 0.3474, 0.9420, 0.9883, 0.9453,\n",
      "        0.1872, 0.5365, 0.3691, 0.9939, 0.7525, 0.0676, 0.7600, 0.7413, 0.7305,\n",
      "        0.8933, 0.6167, 1.0071, 0.6477, 1.2633, 1.1738, 1.0899, 0.9988, 1.0549,\n",
      "        0.9554, 1.0389, 1.0310, 1.2990, 1.1101, 0.0196, 0.4869, 0.8909, 0.7170,\n",
      "        0.6127, 1.3864, 1.3132, 0.9535, 0.7010, 0.7928, 0.8983, 0.4782, 1.1052,\n",
      "        0.6983, 1.1140, 0.6843, 1.0227, 0.9077, 1.0053, 0.8268, 0.7584, 0.9224,\n",
      "        0.1512, 1.0276, 0.7377, 1.2464, 1.0346, 0.4226, 0.9773, 0.9724, 0.9629,\n",
      "        1.0501, 0.9354, 1.1065, 0.3903, 0.4010, 0.8204, 0.4372, 0.7240, 0.9092,\n",
      "        0.8149, 0.9525, 0.6825, 1.0801, 0.6395, 1.1181, 1.2354, 1.2788, 0.8470,\n",
      "        1.1642, 0.3212, 0.9920, 1.1255, 0.5181, 0.8862, 0.9923, 0.9770, 1.0105,\n",
      "        0.3855, 1.0975, 1.0119, 0.9482, 0.8244, 1.0019, 0.9941, 1.0860, 0.8854,\n",
      "        0.9899, 0.9862, 0.6054, 1.0146, 0.7292, 1.1421, 0.7315, 0.8654, 0.7135,\n",
      "        0.9716, 0.8848, 0.7507, 1.0529, 0.8517, 1.3089, 0.9315, 0.9579, 1.0025,\n",
      "        0.3741, 1.0216, 1.3155, 1.5242, 1.4843, 0.3657, 1.3705, 1.1237, 1.0168,\n",
      "        0.8882, 0.9313, 0.8045, 1.0193, 0.2987, 0.9888, 0.8454, 0.9179, 0.4404,\n",
      "        0.8053, 1.0546, 0.9651], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.9426, 0.9361, 0.9297, 0.7838, 0.2770, 0.8422, 1.4522, 0.8799, 1.1840,\n",
      "        1.0977, 0.5605, 1.0133, 1.0490, 1.1667, 0.2432, 1.0977, 0.6881, 1.0191,\n",
      "        1.1738, 1.2483, 0.9325, 0.5855, 0.3840, 0.2141, 1.3647, 0.0732, 1.0897,\n",
      "        0.0749, 0.3235, 0.0863, 1.7607, 1.6834, 0.3740, 0.1802, 0.3465, 1.0672,\n",
      "        1.5028, 1.6314, 0.8525, 0.0324, 0.5064, 0.7960, 0.7014, 0.9220, 0.1697,\n",
      "        1.3823, 0.9511, 1.0445, 0.9681, 0.9870, 0.1195, 0.5483, 0.8373, 1.1447,\n",
      "        0.8002, 0.8600, 0.5976, 0.6546, 0.2363, 0.2970, 1.5311, 1.2909, 0.1508,\n",
      "        0.3367, 1.7777, 1.6398, 0.0822, 0.7923, 0.7971, 0.8072, 0.9595, 0.9092,\n",
      "        0.9069, 0.8775, 0.8654, 0.9934, 1.1184, 0.2919, 0.9338, 0.8863, 0.7111,\n",
      "        1.0996, 0.5503, 1.0706, 0.6442, 1.5848, 1.7355, 0.4851, 0.9924, 0.9246,\n",
      "        1.0380, 0.9454, 0.5721, 0.7212, 1.0444, 1.2563, 0.3609, 0.1222, 0.8148,\n",
      "        0.4822, 0.6848, 0.5990, 0.8090, 1.4043, 0.1468, 1.0930, 1.0012, 1.0049,\n",
      "        1.5114, 1.7362, 0.8963, 0.3146, 1.0056, 0.8641, 1.1506, 0.9204, 0.9580,\n",
      "        1.2088, 1.2404, 0.9356, 0.9437, 1.1423, 0.2063, 0.9155, 0.9554, 0.8205,\n",
      "        1.0948, 0.7598, 0.9230, 0.6574, 1.4250, 0.9941, 1.1282, 0.8602, 0.9690,\n",
      "        0.9120, 0.9446, 0.2833, 0.9969, 1.3622, 0.8748, 0.9983, 0.7586, 0.7727,\n",
      "        0.5765, 0.6529, 2.4163, 1.0032, 0.9061, 0.9764, 0.9182, 0.8535, 1.0129,\n",
      "        1.2196, 1.1284, 0.1189], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.3923, 0.6800, 1.2953, 1.2944, 1.6128, 0.3301, 1.0163, 0.7239, 1.0217,\n",
      "        0.5468, 2.8899, 1.4376, 1.6402, 0.9506, 1.0533, 1.1492, 0.9359, 1.0244,\n",
      "        2.5911, 0.8377, 1.9854, 0.3417, 0.6781, 0.3936, 1.1784, 1.4428, 0.6553,\n",
      "        0.7936, 1.6892, 2.4214, 0.6939, 1.0956, 0.4037, 0.5023, 0.6811, 0.1712,\n",
      "        0.2813, 0.3114, 0.3823, 0.9804, 0.8677, 0.3071, 0.6013, 3.4456, 3.7511,\n",
      "        0.9517, 1.6757, 0.2607, 0.3907, 1.1048, 1.0904, 0.8814, 0.0096, 0.8892,\n",
      "        0.7494, 0.3540, 0.9634, 1.1171, 2.8352, 1.1101, 1.4057, 1.7532, 0.6847,\n",
      "        0.3554, 0.0737, 0.3633, 0.7580, 0.9738, 1.0405, 0.6219, 1.0416, 1.0329,\n",
      "        0.8051, 0.9934, 0.7183, 1.1728, 0.6834, 1.0101, 0.9736, 1.1016, 1.0078,\n",
      "        0.2475, 1.5954, 0.7666, 0.7054, 1.2083, 1.1515, 0.9280, 0.8910, 0.3689,\n",
      "        0.0572, 0.1647, 0.1069, 0.9854, 0.3392, 0.9839, 0.5796, 0.2109, 0.8460,\n",
      "        1.5784, 0.3718, 1.0293, 1.2650, 0.6261, 1.2406, 0.9026, 1.1230, 1.3173,\n",
      "        0.3380, 1.2143, 1.0024, 0.8937, 0.7950, 1.0601, 1.1581, 0.8949, 0.1612,\n",
      "        0.9441, 1.1721, 0.8224, 0.8814, 0.7170, 0.9889, 0.9751, 1.0801, 0.8256,\n",
      "        0.9052, 1.6024, 1.1683, 1.7373, 1.4684, 0.9471, 1.3799, 0.7404, 1.4418,\n",
      "        1.5415, 0.6762, 0.5099, 1.4062, 1.4000, 0.8595, 1.3275, 1.3738, 0.5167,\n",
      "        0.4873, 0.1934, 1.0452, 0.3259, 1.2426, 0.6944, 1.2675, 1.0230, 0.3238,\n",
      "        1.4445, 0.5212, 0.2193], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.7676, 0.5412, 1.0214, 1.0124, 2.2540, 0.9660, 0.1823, 0.6858, 1.8628,\n",
      "        0.0406, 0.2749, 0.7250, 0.2869, 2.4385, 2.1054, 1.0532, 1.5094, 1.4494,\n",
      "        1.7942, 1.3762, 0.9133, 0.6082, 0.5831, 0.8647, 0.1548, 1.3848, 1.1458,\n",
      "        1.1747, 1.2783, 0.1601, 1.6072, 0.7527, 1.0608, 0.7734, 0.8526, 0.7920,\n",
      "        1.6348, 1.3200, 0.1768, 0.2582, 1.0992, 0.2617, 0.2786, 2.3075, 6.2008,\n",
      "        2.3335, 0.3030, 0.5001, 1.4045, 0.4933, 1.2922, 0.2121, 0.4753, 0.7584,\n",
      "        1.2366, 0.5976, 3.6354, 0.1435, 0.5578, 0.1791, 0.4644, 0.7273, 0.5388,\n",
      "        0.8770, 2.3378, 2.1884, 0.1824, 0.0506, 0.7247, 0.7770, 1.7688, 0.2481,\n",
      "        1.5746, 0.9192, 2.3389, 0.7769, 0.9493, 0.9327, 1.9234, 0.8040, 1.6751,\n",
      "        0.5627, 1.2837, 0.2713, 0.9654, 1.3909, 2.3119, 0.3230, 0.7405, 1.0564,\n",
      "        0.6422, 0.2346, 1.6795, 0.9217, 0.7946, 0.6748, 7.0565, 0.9589, 1.9730,\n",
      "        0.3197, 0.0176, 1.3122, 0.8863, 0.8765, 1.0428, 0.9137, 0.2556, 2.5391,\n",
      "        0.7108, 1.0034, 1.0233, 1.1090, 1.0836, 0.1494, 1.7532, 0.0700, 1.1656,\n",
      "        1.2745, 1.0774, 1.8409, 1.3353, 1.0928, 1.3236, 0.6049, 0.2769, 2.2429,\n",
      "        1.4306, 0.1038, 1.4625, 1.9894, 0.8962, 1.1913, 1.7309, 2.9932, 0.4874,\n",
      "        2.4246, 1.1084, 1.8716, 0.3069, 0.9286, 0.7345, 1.2531, 8.0570, 4.9663,\n",
      "        1.9979, 1.1234, 1.9248, 0.8902, 0.6933, 0.2947, 1.7597, 0.1713, 1.1685,\n",
      "        0.7079, 1.4671, 0.4684], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0617e+00, 1.0532e+00, 7.3641e-01, 1.9095e-01, 6.4077e-01, 6.7970e-01,\n",
      "        5.1972e-01, 7.0036e-01, 5.2309e-01, 2.6476e+00, 1.9577e+00, 7.4708e-01,\n",
      "        7.6215e-01, 1.8626e+00, 1.7660e+00, 2.2671e+00, 8.7907e-01, 9.5979e-01,\n",
      "        1.5446e+00, 5.4057e+00, 1.9463e+00, 9.5213e-01, 3.2685e+00, 4.3011e-02,\n",
      "        4.2090e-02, 1.5665e-01, 5.9082e-01, 1.7396e-01, 9.5717e-01, 1.3868e-01,\n",
      "        1.2986e+00, 2.1240e+00, 6.0462e+00, 2.1024e-01, 4.4125e-01, 1.0689e+00,\n",
      "        9.4469e-01, 1.1618e+00, 9.2011e-01, 1.5992e+00, 9.3827e-01, 1.1466e+00,\n",
      "        4.9966e-01, 1.7882e-01, 1.1464e+00, 2.6928e+00, 1.3875e+00, 6.0935e-01,\n",
      "        5.3188e-01, 1.0605e+00, 7.8173e-01, 5.7928e-01, 7.2533e-01, 6.0084e-01,\n",
      "        9.7154e-01, 8.6774e-01, 4.9271e-01, 5.6243e-01, 3.8626e-01, 6.5657e-02,\n",
      "        5.1338e+00, 5.9926e-01, 3.3755e+00, 1.4533e+00, 2.0895e+00, 1.0981e+00,\n",
      "        5.9663e-01, 1.4866e+00, 5.0372e-01, 7.4948e-01, 2.1985e+00, 1.7289e+00,\n",
      "        2.1324e+00, 6.4018e-02, 9.9853e-01, 1.4859e+00, 9.9101e-01, 1.0425e-01,\n",
      "        9.8903e-01, 6.7925e-01, 1.6078e-01, 9.1563e-01, 3.1528e+00, 7.1583e-02,\n",
      "        9.3661e+00, 4.9132e+00, 7.7464e-01, 1.5851e-03, 9.1835e-01, 6.5192e-01,\n",
      "        1.0591e-01, 2.9080e-01, 4.7233e-01, 3.3616e+00, 5.9224e+00, 8.6247e-01,\n",
      "        7.8911e-02, 4.1013e-01, 5.5433e-01, 1.6570e+00, 1.8870e+00, 1.0806e+00,\n",
      "        2.1122e-01, 8.2894e-01, 1.0128e+00, 1.0629e+00, 1.6780e+00, 2.6985e+00,\n",
      "        7.8029e-01, 1.6124e+00, 1.6315e+00, 1.2238e+00, 1.1470e+00, 1.0335e+00,\n",
      "        1.1185e+00, 4.3864e-01, 1.2297e+00, 1.3324e+00, 1.5876e+00, 7.6887e-01,\n",
      "        1.4264e+00, 1.6253e+00, 1.0818e+00, 9.0475e-01, 3.0308e+00, 1.0729e+00,\n",
      "        3.2914e+00, 2.7484e-02, 3.2121e+00, 1.5355e+00, 4.9537e-01, 1.0107e+00,\n",
      "        4.7509e+00, 3.0969e+00, 9.2015e+00, 3.5582e-01, 1.1165e+00, 1.1933e+00,\n",
      "        5.2076e-01, 5.9305e-01, 6.6825e-01, 2.0125e+00, 4.3056e-01, 3.0185e-02,\n",
      "        2.2143e-01, 1.4944e+00, 1.0570e+00, 8.4603e-01, 5.4269e-01, 5.9113e-01,\n",
      "        7.6834e-01, 1.0608e+00, 1.0889e+00, 1.5991e+00, 1.0642e+00, 1.9070e+00],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.3242, 1.3999, 0.7400, 0.3804, 0.3961, 0.8060, 1.2981, 0.9009, 0.5861,\n",
      "        3.2012, 1.0100, 5.2726, 0.9405, 2.7574, 0.6752, 1.5201, 0.4772, 0.8870,\n",
      "        1.2415, 0.5948, 1.6434, 0.5078, 0.7596, 0.0128, 0.7011, 1.1803, 2.3810,\n",
      "        0.9728, 0.9482, 0.8557, 1.6367, 0.4180, 0.9524, 0.9608, 1.8909, 1.1308,\n",
      "        1.4047, 0.4272, 1.1787, 0.9097, 0.9903, 1.0843, 1.5141, 0.8142, 0.6140,\n",
      "        0.6283, 1.1657, 2.9083, 1.5561, 0.2723, 0.7079, 1.8176, 0.6524, 1.0722,\n",
      "        1.3483, 2.4291, 2.4826, 0.4858, 1.4567, 1.9526, 0.4827, 0.7091, 0.8268,\n",
      "        1.8154, 0.2243, 0.7457, 0.5467, 0.9363, 0.9553, 0.0149, 0.0328, 1.8513,\n",
      "        2.4650, 0.2501, 1.2385, 0.8698, 0.9780, 0.1135, 2.8828, 0.8920, 0.4495,\n",
      "        0.3253, 1.8853, 1.5993, 0.2311, 0.6542, 1.0459, 1.6137, 0.9446, 1.2326,\n",
      "        1.3604, 1.3871, 0.7525, 0.9076, 1.3362, 2.7802, 2.7251, 0.4340, 1.9659,\n",
      "        1.3807, 0.8978, 0.1538, 1.9753, 1.0997, 0.5647, 0.2327, 1.2271, 1.1031,\n",
      "        2.4762, 1.1698, 4.0367, 1.4123, 0.1714, 0.5562, 0.1980, 0.5685, 1.1117,\n",
      "        0.5743, 0.5215, 0.4995, 1.2460, 0.9114, 1.2500, 1.0019, 0.9912, 0.1588,\n",
      "        0.9939, 0.7538, 0.7669, 0.4874, 1.3627, 0.3332, 1.1932, 1.0375, 0.9923,\n",
      "        0.8734, 0.7744, 2.8353, 2.2502, 0.0677], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.2665, 0.7895, 1.8722, 1.2254, 1.3723, 0.6535, 0.1130, 1.2076, 0.6151,\n",
      "        0.8802, 3.3254, 4.4891, 1.0519, 0.5222, 1.5785, 0.9093, 2.2523, 1.0708,\n",
      "        1.4097, 1.0215, 0.5425, 1.4141, 0.8667, 1.0935, 0.7128, 0.3272, 0.9565,\n",
      "        1.0010, 0.9002, 0.1179, 1.3616, 0.9746, 1.2481, 1.0234, 0.6651, 0.4890,\n",
      "        1.1489, 0.8188, 1.5474, 0.8676, 0.8782, 0.7133, 1.7100, 5.8690, 0.7320,\n",
      "        1.0887, 0.8901, 0.6815, 1.1203, 0.8801, 1.2734, 0.9510, 0.2966, 1.1820,\n",
      "        0.7137, 1.1218, 2.8728, 1.3577, 0.6390, 1.3881, 1.5102, 1.5741, 0.9827,\n",
      "        0.2172, 0.9602, 1.3569, 0.8549, 0.7988, 0.5727, 0.1971, 0.0885, 0.0641,\n",
      "        1.0030, 1.5245, 2.3270, 0.1806, 1.2029, 1.0861, 0.9174, 1.0301, 0.2668,\n",
      "        2.2863, 0.8059, 1.4578, 3.8218, 1.5451, 0.6739, 3.5023, 0.8062, 1.9815,\n",
      "        1.2310, 0.8752, 1.5589, 0.1650, 1.1613, 1.0307, 2.3472, 0.7235, 0.1341,\n",
      "        1.1971, 1.5158, 0.8897, 0.7349, 0.2174, 0.8892, 1.2448, 2.8676, 0.5007,\n",
      "        1.6866, 0.0598, 1.8125, 0.8982, 1.5587, 1.5171, 0.9059, 0.4273, 1.4595,\n",
      "        1.9883, 0.8306, 0.8384, 0.9722, 0.6178, 0.3379, 0.8163, 1.1038, 0.7047,\n",
      "        0.8774, 1.1264, 1.6276, 1.1319, 0.5151, 0.9243, 2.5405, 1.3809, 1.0311,\n",
      "        0.5571, 1.1779, 1.1804, 0.7108, 0.4304, 0.9592], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.7787, 1.7137, 0.6688, 1.3313, 1.0922, 0.8387, 0.6921, 0.8841, 0.9061,\n",
      "        1.0256, 1.0056, 0.8443, 1.0200, 0.9455, 1.2990, 0.3409, 1.0021, 1.0944,\n",
      "        0.8058, 0.0630, 1.3014, 0.7713, 0.5119, 0.9027, 0.4437, 0.9975, 0.9893,\n",
      "        0.2755, 0.5384, 0.8943, 0.5619, 0.8667, 0.8118, 0.5462, 1.0697, 1.2384,\n",
      "        0.6620, 0.6051, 0.9928, 0.8585, 0.9365, 0.9403, 0.8039, 1.1747, 0.7258,\n",
      "        0.8782, 0.9412, 1.2034, 1.1458, 0.9897, 1.3598, 1.3542, 0.8880, 2.1583,\n",
      "        1.2035, 1.4422, 1.1254, 0.5711, 0.4739, 0.5886, 0.8441, 0.4185, 0.6635,\n",
      "        0.5261, 1.0399, 0.7693, 0.7719, 0.9685, 1.1256, 0.2597, 0.3705, 0.2489,\n",
      "        1.2279, 0.2801, 1.0277, 0.6865, 0.6030, 1.1211, 0.9869, 0.7606, 1.4470,\n",
      "        1.7752, 1.2326, 0.4317, 0.2878, 1.1459, 1.5245, 1.9518, 1.0221, 1.5587,\n",
      "        1.2507, 0.6781, 0.6717, 1.0067, 1.7209, 0.8538, 1.0330, 1.1369, 0.1956,\n",
      "        1.6617, 0.9431, 0.1981, 0.8697, 0.2425, 0.9840, 1.6342, 0.5013, 1.0872,\n",
      "        1.3644, 1.3578, 1.0797, 0.7268, 0.4792, 0.5990, 0.3524, 1.1061, 1.4016,\n",
      "        0.8951, 1.5801, 0.9980, 0.4557, 0.8157, 0.8565, 0.5622, 0.8613, 0.8256,\n",
      "        0.5021, 1.0279, 0.6974, 0.2030, 0.0135, 0.4735, 2.2059, 1.2691, 1.1873,\n",
      "        1.0224, 1.5659, 1.0266, 0.8622, 0.0969, 1.1437], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.6607, 0.8840, 1.3581, 1.3916, 1.0093, 1.0120, 0.0915, 0.9161, 0.2144,\n",
      "        1.0107, 0.7156, 0.6200, 0.6002, 0.4311, 1.4389, 0.1081, 0.5615, 0.6523,\n",
      "        1.0204, 0.6003, 0.1503, 0.6521, 0.9074, 0.1434, 0.3596, 0.8912, 0.8118,\n",
      "        0.6655, 0.8219, 0.9984, 0.9811, 0.9235, 0.8764, 0.7282, 1.0426, 1.0534,\n",
      "        0.5337, 0.3358, 0.4647, 0.9790, 0.9350, 0.9822, 1.1517, 1.0113, 0.8707,\n",
      "        1.0233, 0.7953, 1.1945, 0.5620, 0.8422, 1.0590, 1.1657, 1.2184, 0.5546,\n",
      "        0.5556, 0.8106, 0.6601, 0.9754, 1.2657, 1.0599, 0.7837, 0.2424, 1.0773,\n",
      "        0.3656, 0.8242, 0.4797, 0.9389, 1.1088, 0.9368, 0.9797, 0.8828, 0.5210,\n",
      "        0.7193, 1.8462, 3.1332, 0.6376, 1.0209, 0.9424, 0.3032, 0.8378, 0.9449,\n",
      "        0.9069, 0.7361, 0.0034, 0.8861, 0.8240, 0.4635, 1.0303, 0.2571, 0.8882,\n",
      "        0.3572, 0.5740, 0.9118, 0.9617, 0.7983, 0.8978, 0.8699, 0.7315, 0.9616,\n",
      "        0.6561, 0.4709, 1.8445, 0.4255, 0.8407, 1.0526, 0.5366, 0.7885, 0.9439,\n",
      "        0.8051, 1.1643, 0.9646, 0.6750, 1.2888, 0.9948, 1.0063, 0.9574, 0.8405,\n",
      "        0.3271, 0.8528, 1.0013, 0.9447, 0.9043, 0.8079, 0.5862, 0.5909, 0.9068,\n",
      "        1.0244, 1.0279, 0.9778, 0.6848, 1.0680, 0.7155, 0.9608, 1.1173, 1.0001,\n",
      "        0.0938, 1.1148, 0.2802, 1.0693, 0.9330, 0.4438], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.7733, 0.9941, 0.6619, 1.2813, 0.9594, 1.0679, 1.0855, 0.7184, 1.3815,\n",
      "        1.1162, 0.9941, 1.1556, 0.6129, 1.1316, 0.2330, 1.1555, 0.9453, 0.8881,\n",
      "        0.5631, 0.6716, 0.7504, 0.7454, 1.0891, 0.8461, 1.0538, 0.9869, 0.5657,\n",
      "        0.6023, 0.5456, 1.0959, 1.0984, 0.7783, 0.8056, 0.8048, 0.9849, 1.0626,\n",
      "        0.9631, 0.5554, 1.0146, 0.4274, 0.1197, 0.7879, 0.9481, 1.1029, 0.9111,\n",
      "        0.9346, 0.9793, 0.7384, 1.1183, 1.1481, 0.1145, 0.0427, 1.7499, 1.2328,\n",
      "        0.7426, 1.2246, 1.1411, 0.4461, 0.7835, 0.6986, 0.6247, 0.7494, 0.4964,\n",
      "        1.0146, 0.9067, 1.3171, 0.1966, 1.0525, 1.5554, 0.3352, 0.3021, 0.0340,\n",
      "        1.5805, 0.1233, 1.2006, 0.9800, 0.5633, 0.9791, 0.9537, 1.0802, 0.6895,\n",
      "        1.5528, 0.6483, 1.6631, 0.0109, 0.4432, 0.6315, 1.0549, 1.0039, 0.8842,\n",
      "        0.8485, 1.0887, 1.1506, 0.9554, 0.7899, 0.7699, 1.0030, 1.1615, 0.3169,\n",
      "        0.0891, 0.8762, 0.6682, 0.0305, 1.1133, 0.6137, 0.7677, 0.4869, 0.9040,\n",
      "        0.9384, 0.1355, 0.2535, 0.9350, 0.9986, 1.0298, 1.0120, 1.1381, 0.8124,\n",
      "        0.5218, 0.5158, 0.6743, 1.0313, 1.0029, 0.6506, 0.9111, 0.3286, 0.8386,\n",
      "        0.3051, 0.9633, 1.0511, 1.3148, 1.4132, 0.2258, 0.6005, 1.1871, 1.3299,\n",
      "        0.9601, 1.3960, 1.0823, 0.8865, 0.3215, 0.1070], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.1761e+00, 1.0648e+00, 2.1390e-01, 7.7004e-01, 1.3016e+00, 9.4908e-01,\n",
      "        5.7031e-01, 9.5933e-01, 3.5930e-01, 6.0662e-01, 1.1342e+00, 3.3619e-01,\n",
      "        6.8733e-01, 1.1470e+00, 2.4651e+00, 7.6663e-01, 3.3170e-01, 1.0900e+00,\n",
      "        1.2661e+00, 9.8824e-01, 1.5027e+00, 6.9258e-01, 9.8214e-01, 7.8158e-01,\n",
      "        6.0616e-01, 7.6447e-01, 3.4436e-03, 4.0876e+00, 2.7396e+00, 7.3336e-01,\n",
      "        4.1204e-01, 1.0500e+00, 1.0492e+00, 1.3699e+00, 8.2113e-01, 9.7538e-01,\n",
      "        6.8729e-01, 9.4043e-01, 8.3084e-01, 4.9627e-01, 1.0948e+00, 3.7898e-01,\n",
      "        5.3418e-01, 1.0460e+00, 9.7736e-01, 1.7732e+00, 1.0018e+00, 5.9446e-01,\n",
      "        1.4373e+00, 2.0813e-01, 5.8056e-01, 1.6929e+00, 8.8812e-01, 1.3333e+00,\n",
      "        3.1662e-01, 7.3285e-01, 8.1950e-04, 6.9134e-01, 4.9469e-01, 1.0122e+00,\n",
      "        1.0688e+00, 4.6102e-01, 2.6399e+00, 1.9004e+00, 2.1972e+00, 5.5327e-01,\n",
      "        7.4015e-01, 4.9108e-02, 7.0698e-01, 1.0265e+00, 6.0022e-01, 4.6183e-01,\n",
      "        3.3543e-01, 1.1320e+00, 6.2293e-01, 7.0809e-01, 1.2090e+00, 1.0923e+00,\n",
      "        7.2630e-01, 7.2901e-02, 9.1619e-01, 1.7672e+00, 8.4450e-01, 1.6513e+00,\n",
      "        6.7643e-01, 1.6922e+00, 1.6357e-02, 1.0842e+00, 6.2266e-01, 1.0876e+00,\n",
      "        8.9744e-02, 5.5878e-02, 1.0691e+00, 1.4243e+00, 9.8888e-01, 1.5506e+00,\n",
      "        3.7014e-01, 9.1472e-01, 9.7397e-01, 5.4689e-01, 1.0207e+00, 2.0055e-02,\n",
      "        5.0638e-02, 1.0102e+00, 6.3074e-01, 7.0591e-01, 1.2427e+00, 6.6631e-01,\n",
      "        9.2000e-01, 1.1566e+00, 8.6237e-01, 1.1829e+00, 1.0283e+00, 1.1380e+00,\n",
      "        1.2070e+00, 9.4468e-01, 9.5612e-01, 1.1525e+00, 8.9956e-01, 2.1448e+00,\n",
      "        8.2627e-01, 1.0805e+00, 1.4453e-01, 3.4265e-01, 1.0514e+00, 4.9267e-01,\n",
      "        6.3945e-01, 4.2613e-01, 1.4112e+00, 5.9121e-01, 1.9722e+00, 1.5668e+00,\n",
      "        1.1445e+00, 1.1567e+00, 1.0852e+00, 1.0276e+00, 8.3571e-01, 8.6626e-01,\n",
      "        7.7430e-01, 7.1516e-01, 4.0411e-02], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.3777, 0.4786, 1.0084, 0.6366, 0.0708, 0.8627, 2.4064, 0.8981, 1.2722,\n",
      "        1.6767, 0.9272, 0.9209, 0.8011, 0.7433, 1.9220, 1.1988, 1.0394, 0.7243,\n",
      "        1.2593, 1.6844, 1.0233, 1.0576, 0.9551, 0.4703, 1.0995, 0.6572, 1.0925,\n",
      "        1.5091, 0.3558, 0.4639, 0.8629, 0.0320, 1.9763, 0.2728, 0.2169, 0.7117,\n",
      "        1.0840, 1.0839, 0.5459, 0.5325, 2.4075, 0.8125, 0.8922, 1.1903, 0.4334,\n",
      "        0.6249, 1.3722, 0.7092, 1.5473, 1.1172, 1.0268, 0.7528, 0.4899, 0.8473,\n",
      "        0.1713, 0.2527, 0.3220, 0.6768, 1.1975, 0.5263, 0.3495, 0.8911, 1.3015,\n",
      "        0.4285, 0.7281, 0.8120, 2.1625, 1.2895, 0.0855, 0.0607, 0.8267, 1.2631,\n",
      "        0.8749, 0.5191, 0.6363, 0.8238, 0.9756, 0.6956, 0.6913, 1.0224, 0.4121,\n",
      "        1.0621, 0.4677, 0.4370, 1.4216, 0.8203, 2.6734, 0.5510, 0.0071, 0.3870,\n",
      "        0.7733, 0.0317, 0.6351, 0.6410, 1.5345, 0.5739, 0.6849, 1.5980, 0.8937,\n",
      "        0.9067, 0.8837, 0.6104, 1.1955, 0.4649, 0.5436, 0.2567, 0.4810, 0.8569,\n",
      "        0.9438, 0.8291, 0.8011, 0.6923, 0.4270, 1.7406, 0.0999, 0.3910, 0.7432,\n",
      "        0.0864, 0.5088, 0.7178], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.5210, 1.8742, 4.2279, 0.5227, 0.1074, 0.0661, 0.6012, 0.9297, 2.4224,\n",
      "        0.2182, 0.2485, 0.0691, 0.9048, 2.1626, 1.7335, 1.0043, 0.5792, 1.6134,\n",
      "        1.2565, 1.0625, 2.4485, 0.0626, 0.7977, 1.2297, 0.8861, 0.9424, 0.6460,\n",
      "        3.3922, 0.1388, 2.1564, 5.1252, 0.3396, 1.1952, 0.9980, 1.3724, 0.5055,\n",
      "        0.9504, 1.2375, 1.7923, 0.4763, 0.3512, 1.1267, 1.1269, 0.5367, 0.6775,\n",
      "        0.9884, 3.7984, 5.2261, 0.5085, 0.7500, 0.9516, 0.6933, 0.6938, 0.3162,\n",
      "        0.8984, 0.5094, 0.4143, 1.0432, 1.0879, 0.4679, 1.4483, 1.5287, 7.3698,\n",
      "        0.7878, 1.8940, 0.6229, 0.7088, 0.8378, 2.0761, 0.5101, 1.4933, 1.9562,\n",
      "        0.9811, 1.4003, 0.8004, 0.0086, 0.4015, 0.0237, 0.7983, 0.8660, 0.2343,\n",
      "        0.6921, 1.4968, 0.8119, 1.3895, 0.7449, 0.7064, 0.2770, 1.6180, 1.1546,\n",
      "        0.9375, 0.3992, 0.9152, 0.6805, 0.6797, 0.1381, 0.5902, 0.9885, 0.8875,\n",
      "        1.1606, 1.1532, 0.1662, 1.4612, 1.8344, 0.4122, 1.1147, 2.1204, 1.7604,\n",
      "        1.1185, 0.7689, 0.4013, 0.7916, 1.1936, 1.5261, 1.4154, 0.9164, 0.7485,\n",
      "        0.4602, 1.2594, 1.3046], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([2.4505, 0.4394, 2.3612, 1.0872, 0.5075, 0.3939, 5.2443, 3.6818, 0.3545,\n",
      "        0.9955, 1.4461, 0.6065, 0.7097, 0.1213, 0.1276, 0.6011, 0.3579, 0.0215,\n",
      "        1.6493, 0.4261, 1.4240, 1.2069, 1.6268, 0.7651, 0.1047, 0.1374, 0.9936,\n",
      "        0.9709, 1.7796, 1.2210, 1.6629, 1.0999, 3.0554, 1.2448, 0.9452, 0.8821,\n",
      "        1.7038, 1.1702, 0.7000, 0.3850, 2.7276, 0.1036, 0.6611, 0.4171, 0.9062,\n",
      "        3.9555, 5.5815, 1.0050, 1.0873, 1.8454, 0.7610, 2.4526, 0.1442, 2.2754,\n",
      "        0.8763, 0.8842, 1.3540, 0.8434, 1.0190, 0.4321, 0.9778, 0.8999, 0.4265,\n",
      "        0.2631, 1.3008, 0.1903, 1.3038, 1.0174, 1.7054, 1.9070, 0.9217, 1.1522,\n",
      "        0.6079, 0.7820, 1.0134, 3.3945, 1.3077, 0.2915, 0.7575, 0.7953, 0.0918,\n",
      "        0.7082, 1.0164, 0.7633, 0.1885, 1.0824, 1.5225, 2.3170, 2.4164, 0.0096,\n",
      "        0.6659, 1.2504, 1.9812, 2.5864, 0.4635, 2.8978, 0.1215, 0.0625, 1.4546,\n",
      "        0.8178, 1.0727, 0.0345, 1.3254, 0.5249, 1.5183, 1.7029, 0.7145, 0.0058,\n",
      "        0.6437, 1.5578, 1.6599, 1.3287, 0.8835, 1.2602, 0.9828, 0.6794, 1.8905,\n",
      "        0.4840, 1.5544], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.7574e+00, 4.8488e-01, 1.5091e+00, 5.9722e-01, 1.1759e+00, 8.4040e-01,\n",
      "        2.1069e-01, 9.3215e-01, 3.2852e-01, 6.6599e-01, 2.8554e-01, 1.7878e+00,\n",
      "        9.2641e-01, 1.8464e+00, 7.6795e-01, 2.0778e+00, 9.7652e-01, 1.0367e-02,\n",
      "        1.7438e-01, 8.7859e-01, 3.4252e-01, 3.1040e+00, 7.6884e-01, 1.0286e+00,\n",
      "        9.7667e-01, 4.9471e-01, 9.3656e-01, 8.2137e-01, 8.8404e-01, 9.2643e-01,\n",
      "        7.7835e-01, 6.4777e-01, 5.2821e-01, 8.0868e-01, 5.3082e-01, 1.8667e+00,\n",
      "        7.1549e-01, 8.5095e-01, 7.3826e-01, 1.6082e-01, 1.1163e+00, 1.1966e+00,\n",
      "        6.1306e-01, 3.9378e-01, 9.4890e-01, 3.1715e+01, 1.3696e+00, 1.1780e+01,\n",
      "        1.0211e+00, 5.3499e+00, 1.1814e-01, 1.1139e+00, 3.1959e-01, 7.8657e-01,\n",
      "        2.7057e-01, 3.5986e-01, 7.4220e-01, 7.3045e-01, 9.4271e-01, 6.4148e-01,\n",
      "        9.4163e-01, 5.4394e-01, 1.6704e+00, 1.6189e-01, 1.7078e-01, 3.7078e-01,\n",
      "        6.3146e-01, 1.0462e+00, 5.7899e-01, 4.0879e-01, 9.5087e-01, 4.5569e-02,\n",
      "        1.9328e-01, 7.8027e-01, 8.6774e-01, 2.2152e+00, 2.8634e+00, 2.9214e-01,\n",
      "        1.1480e+00, 1.6451e+00, 1.1562e+00, 8.1420e-01, 1.1532e+00, 6.4528e-01,\n",
      "        1.3410e+00, 5.4106e-02, 1.5448e+00, 1.2777e+00, 1.1116e+00, 1.5967e+00,\n",
      "        1.3496e+00, 4.7542e-01, 1.6832e-01, 2.3820e+00, 9.7510e-01, 9.8066e-01,\n",
      "        6.6823e-01, 9.8318e-01, 4.5758e-01, 9.7230e-01, 7.0799e-01, 1.1888e+00,\n",
      "        2.0241e+00, 8.2878e-01, 1.4557e+00, 2.2453e-02, 1.2494e+00, 1.0263e+00,\n",
      "        7.7763e-03, 6.2706e-01, 5.3605e-01, 7.7700e-01, 6.6425e-01, 3.7410e-01,\n",
      "        2.2985e-01, 6.0225e-01, 9.7811e-01, 7.4450e-01, 9.4582e-01, 9.0726e-01],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.2126, 1.0311, 1.0263, 1.1083, 0.3186, 0.1211, 0.4339, 0.5591, 0.8492,\n",
      "        0.6179, 0.7250, 0.8686, 0.7362, 1.5657, 1.1379, 0.3290, 1.0885, 0.8030,\n",
      "        0.8244, 0.8845, 0.2711, 0.2772, 0.8614, 0.0145, 0.9923, 0.1842, 0.9696,\n",
      "        0.4955, 0.4819, 0.1404, 0.4451, 0.5127, 0.4162, 0.0233, 0.9034, 1.0244,\n",
      "        0.7949, 0.6484, 1.0070, 1.0350, 1.0802, 0.6720, 0.6707, 0.6236, 0.6914,\n",
      "        0.9244, 1.3514, 1.2587, 0.2604, 1.4003, 0.1994, 0.7928, 0.4233, 1.2459,\n",
      "        0.2712, 0.5627, 0.5167, 1.0787, 0.6734, 0.3640, 0.5989, 0.7358, 0.6557,\n",
      "        0.8444, 0.8519, 0.6424, 2.0582, 1.1600, 0.3662, 0.9129, 0.8567, 0.7832,\n",
      "        0.9428, 0.6696, 0.7154, 0.3992, 0.3086, 1.0512, 1.0173, 0.5462, 0.8500,\n",
      "        0.9890, 1.0882, 1.0726, 1.1140, 0.0267, 0.8256, 0.9955, 0.6220, 0.7090,\n",
      "        0.7768, 1.0251, 0.8944, 0.8804, 0.0981, 0.4947, 0.7873, 0.8709, 0.8986,\n",
      "        0.3136, 0.1244, 0.8626, 0.0355, 1.1138, 1.2840, 1.0210, 1.0005, 0.1380,\n",
      "        0.9667, 1.0139, 0.7701, 0.3505, 1.1020, 0.3750, 0.5105, 0.1668, 0.5594,\n",
      "        0.7689, 0.6618, 0.6609], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([7.7906e-01, 2.6349e-01, 1.1272e+00, 3.8022e-01, 1.5318e-01, 3.4669e-01,\n",
      "        5.7803e-01, 4.5969e-01, 1.2136e+00, 1.4160e+00, 6.1223e-01, 8.3388e-02,\n",
      "        5.4539e-01, 8.3017e-01, 1.1903e+00, 9.7719e-01, 1.0219e+00, 1.0282e+00,\n",
      "        4.7442e-01, 3.8771e-01, 3.1114e-01, 4.4075e-01, 7.5654e-01, 3.5222e-01,\n",
      "        9.6656e-01, 7.4938e-01, 8.3398e-01, 6.0010e-01, 8.0076e-01, 1.3789e-03,\n",
      "        7.6082e-01, 7.4776e-01, 7.0792e-01, 5.2600e-01, 2.8976e-01, 7.6940e-01,\n",
      "        4.3198e-01, 2.8349e-01, 6.5144e-01, 7.5605e-01, 9.8434e-01, 4.0013e-01,\n",
      "        5.1705e-01, 1.2300e+00, 1.6906e-01, 7.3332e-01, 8.0640e-01, 1.3264e+00,\n",
      "        6.6599e-01, 1.3593e+00, 1.7302e+00, 1.0106e+00, 2.2455e-01, 9.9848e-01,\n",
      "        4.5946e-01, 2.2890e-01, 3.8836e-02, 4.5432e-01, 8.5887e-01, 1.0704e-01,\n",
      "        1.2736e+00, 6.8355e-01, 3.7964e-02, 8.1053e-01, 1.1338e+00, 9.9840e-01,\n",
      "        8.5714e-01, 1.0747e-01, 8.6267e-01, 5.5879e-01, 9.1618e-02, 1.1184e+00,\n",
      "        1.0805e+00, 8.9522e-01, 9.0837e-01, 1.5646e+00, 2.5683e+00, 2.1768e-01,\n",
      "        7.3321e-01, 1.1562e+00, 1.3502e+00, 2.2585e-01, 9.0087e-01, 5.1988e-01,\n",
      "        4.0025e-01, 9.0602e-01, 5.3249e-01, 4.9192e-01, 6.9757e-01, 1.5483e+00,\n",
      "        3.1505e-01, 1.0926e+00, 1.0193e+00, 8.8519e-01, 5.5958e-03, 6.9187e-01,\n",
      "        9.1152e-01, 1.0011e+00, 1.0152e+00, 1.0779e+00, 1.1242e+00, 1.4681e+00,\n",
      "        1.3221e+00, 1.8654e+00, 9.4328e-01, 1.0922e-01, 1.3819e+00, 9.8966e-01,\n",
      "        5.7653e-01, 7.4891e-01, 4.7077e-01, 9.1757e-01, 8.6836e-01, 7.9569e-01,\n",
      "        8.4936e-01, 1.0279e+00, 8.6718e-01, 9.8668e-01, 1.1622e+00, 2.0997e+00],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([6.4660e-01, 1.2118e+00, 1.7866e+00, 2.0497e-01, 1.0481e-01, 5.2255e-01,\n",
      "        9.2169e-01, 3.2426e-01, 1.6994e+00, 2.3048e+00, 3.5723e-01, 2.4328e-01,\n",
      "        9.3527e-01, 9.5312e-02, 8.7539e-01, 6.1172e-01, 9.3090e-01, 6.7154e-01,\n",
      "        2.4471e-01, 6.8315e-01, 3.0528e+00, 8.8997e-01, 6.8471e-01, 8.8808e-01,\n",
      "        5.8430e-02, 1.5376e-01, 5.9745e-01, 3.8679e-01, 8.6994e-01, 1.1154e+00,\n",
      "        6.6677e-02, 1.8274e+00, 4.9769e-01, 1.8023e+00, 6.2209e-01, 8.6443e-01,\n",
      "        8.4775e-01, 1.0714e+00, 2.7412e+00, 1.1856e+00, 5.7933e-01, 6.1180e-01,\n",
      "        5.5370e-01, 1.7347e-01, 1.8933e+00, 1.6602e+00, 5.8101e-01, 1.2367e-01,\n",
      "        1.5224e-03, 1.8812e+00, 1.0403e+00, 1.3386e+00, 1.9041e+00, 1.9135e+00,\n",
      "        1.7351e+00, 9.0806e-02, 6.5432e-01, 5.8506e-01, 1.0104e+00, 7.9939e-01,\n",
      "        5.3535e+00, 3.9653e+00, 6.6557e-01, 6.7246e-01, 1.3775e+00, 9.6608e-01,\n",
      "        4.3405e-01, 5.7210e+00, 3.7496e+00, 2.1478e+00, 7.6762e-01, 1.3219e+00,\n",
      "        3.5386e-01, 6.6570e-01, 7.4999e-01, 3.9481e-02, 1.7570e+00, 8.0850e-01],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.7111e+00, 2.8117e+00, 6.5329e-01, 1.2074e-03, 1.5839e+00, 3.6623e+00,\n",
      "        1.3663e+00, 5.4771e-01, 9.1590e-01, 3.7042e-01, 1.0528e+00, 1.3897e+00,\n",
      "        1.0116e+00, 8.1050e-01, 3.1120e-01, 1.6669e+00, 1.5948e+00, 3.6656e+00,\n",
      "        3.4069e+00, 6.0172e-01, 2.0489e+01, 3.1644e-01, 6.1942e-01, 1.2630e+00,\n",
      "        8.9493e-01, 1.0656e-01, 2.8975e+00, 5.9440e-02, 1.3138e+00, 4.3173e-01,\n",
      "        1.7354e+00, 1.6065e+00, 1.8864e-01, 5.9940e-01, 1.2644e+00, 2.0989e+00,\n",
      "        1.2210e+00, 2.2831e+00, 1.5400e-01, 1.6748e+00, 1.1676e-01, 1.6105e+00,\n",
      "        2.1988e+00, 9.5941e-01, 9.9408e-01, 1.3083e+00, 1.5344e+00, 2.5173e+00,\n",
      "        1.2454e+00, 1.8277e-01, 2.7132e+00, 5.9423e-01, 7.2660e-01, 2.6648e+00,\n",
      "        1.9756e-01, 7.4603e-01, 7.1996e-01, 3.3739e+00, 2.2017e+00, 9.9137e-01,\n",
      "        9.6584e-01, 1.0569e+00, 3.6551e-01, 6.1272e+00, 7.8474e-01, 2.7698e+00,\n",
      "        7.1919e-01, 8.6857e-01, 4.5386e+00, 4.6677e-01, 8.4365e-01, 2.1127e+00,\n",
      "        1.8537e+00, 5.0126e-01, 8.5602e-01, 5.9775e-01, 2.9359e-01, 1.0725e+00],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.0841, 1.2449, 2.1279, 0.8499, 1.6661, 1.2553, 1.8041, 0.7583, 1.2526,\n",
      "        0.3814, 1.5505, 0.5723, 0.7828, 0.3125, 1.7076, 0.1348, 1.0020, 1.9117,\n",
      "        0.8549, 0.7265, 0.5399, 0.0586, 0.9541, 0.0826, 0.2433, 0.5579, 0.8320,\n",
      "        0.4140, 0.4530, 0.9950, 0.2577, 0.6538, 0.8359, 0.0879, 0.9054, 0.2690,\n",
      "        1.5516, 0.1696, 0.5064, 1.8207, 1.1114, 1.7847, 0.5281, 1.0199, 1.4497,\n",
      "        0.9910, 0.0362, 0.9471, 2.1717, 0.7726, 1.0483, 0.7177, 0.1196, 0.5335,\n",
      "        2.4249, 0.9859, 1.1442, 0.7547, 0.4213, 0.5191, 1.9983, 1.0468, 4.6213,\n",
      "        1.0829, 2.2744, 1.4355, 1.2340, 0.7944, 0.9740, 0.5028, 0.3590, 1.0983,\n",
      "        0.7499, 1.1654, 0.3396, 0.9292, 0.9548, 0.5309], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([2.2862e-01, 7.6856e-01, 2.3178e+00, 1.1497e+00, 2.7901e+00, 9.3754e-01,\n",
      "        1.6365e+00, 1.2911e+00, 1.0392e+00, 9.7922e-01, 1.0492e+00, 1.7106e+00,\n",
      "        7.5339e-01, 3.5609e-01, 1.0900e-01, 5.1379e-01, 1.4188e+00, 8.7190e-01,\n",
      "        2.5570e+00, 4.0336e+00, 4.9922e-01, 5.7523e-01, 5.5524e-01, 8.7583e-01,\n",
      "        3.6819e-01, 4.7589e-01, 1.0520e+00, 1.3096e+00, 6.6400e-01, 1.2016e+00,\n",
      "        9.2438e-01, 1.4636e+00, 1.3324e-01, 9.2756e-03, 3.0228e-01, 1.0249e-03,\n",
      "        1.2585e+00, 3.3167e-02, 9.6924e-01, 1.5278e+00, 4.3388e-01, 5.6815e-01,\n",
      "        1.3113e+00, 2.0644e+00, 5.6540e-01, 7.8146e-01, 9.3523e-01, 8.2305e-02,\n",
      "        6.6790e-01, 1.4075e+00, 1.5777e+00, 6.5171e-01, 1.0010e+00, 3.5847e-01,\n",
      "        2.9000e-01, 1.0776e+00, 1.3173e+00, 4.7004e-01, 8.9807e-01, 3.4067e-01,\n",
      "        6.8176e-01, 6.0424e-01, 1.0367e+00, 4.3383e-01, 6.5562e-01, 7.0175e-01,\n",
      "        2.0864e+00, 1.6371e+00, 4.3171e+00, 1.2372e-01, 6.1729e-01, 9.5494e-02,\n",
      "        7.1513e-01, 3.9918e-01, 3.5623e-01, 6.1198e-01, 5.2550e-02, 6.1645e-01],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.4317, 1.1351, 0.5030, 0.8593, 1.2837, 0.9013, 0.4855, 0.6839, 1.1520,\n",
      "        1.1334, 0.2780, 0.4677, 0.2447, 0.5998, 0.8518, 0.9109, 0.3566, 0.6744,\n",
      "        0.7767, 0.2289, 0.7652, 1.4063, 1.9333, 0.6144, 0.5205, 0.4373, 0.5981,\n",
      "        0.0161, 0.0936, 0.6617, 0.6160, 0.4993, 0.2919, 0.0477, 1.0438, 0.8080,\n",
      "        0.3761, 0.7039, 2.5134, 0.3781, 0.9621, 1.0573, 1.0106, 0.7405, 0.2582,\n",
      "        1.0078, 2.5108, 0.4336, 1.2368, 1.0409, 1.5194, 0.8894, 1.1881, 0.9571,\n",
      "        2.2525, 0.7696, 0.7015, 0.3713, 0.4382, 0.9909, 0.6631, 0.3877, 0.3214,\n",
      "        0.7816, 0.2693, 2.3778, 0.4617, 0.6136, 0.7744, 0.6261, 1.0835, 0.6087,\n",
      "        1.3590, 0.6714, 0.9774, 0.5880, 0.8734, 0.8907], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9720, 1.3563, 0.8575, 2.7178, 1.8036, 0.1623, 1.1988, 0.6025, 0.9023,\n",
      "        2.4271, 0.0916, 1.5986, 0.6096, 0.6229, 0.8052, 1.0011, 1.5954, 1.2346,\n",
      "        0.4669, 1.5292, 0.8284, 0.4885, 1.0737, 0.2309, 0.5164, 0.9107, 0.5930,\n",
      "        1.5404, 1.2120, 0.9472, 0.6388, 1.4531, 0.0795, 0.4648, 0.9554, 1.4365,\n",
      "        0.8738, 0.7904, 1.1493, 1.6488, 0.6206, 0.5659, 0.9892, 0.6497, 0.8715,\n",
      "        0.8980, 1.3240, 1.5245, 0.0329, 1.3305, 0.4410, 0.9172, 0.7401, 1.1162,\n",
      "        0.9009, 0.0382, 1.0162, 0.1012, 0.6400, 0.7829, 0.9779, 1.3225, 0.3049,\n",
      "        1.4849, 0.6336, 0.2437, 0.3056, 0.2000, 0.9894, 0.0979, 1.0366, 1.3145,\n",
      "        1.0417, 1.3893, 0.3039, 0.3667, 0.8585, 0.7493], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.4356, 0.3044, 2.8469, 0.7401, 0.6178, 1.1955, 0.0539, 1.1972, 1.9384,\n",
      "        0.1353, 0.5794, 0.5712, 1.2044, 0.2636, 0.6318, 0.8837, 1.5026, 1.7912,\n",
      "        4.8417, 3.6996, 1.4486, 0.7993, 0.9653, 1.0219, 1.5812, 0.3570, 0.6887,\n",
      "        0.3994, 0.4382, 1.0627, 1.8225, 0.2329, 0.8125, 1.4873, 0.8366, 0.6057,\n",
      "        0.8359, 0.9449, 0.4858, 3.9508, 2.0718, 1.5369, 1.4095, 1.1841, 2.1279,\n",
      "        0.5382, 1.6090, 0.9858, 1.2180, 0.1123, 1.7298, 0.8847, 1.2359, 2.0600,\n",
      "        0.5247, 0.3966, 1.1626, 1.0846, 1.1626, 1.2773, 0.9454, 0.6450, 0.4172,\n",
      "        1.2383, 0.6064, 2.6129, 1.9480, 0.5699, 0.9742, 1.1503, 1.4501, 2.6006,\n",
      "        0.6597, 0.4035, 1.0873, 1.1891, 0.8873, 0.7298, 0.9554, 0.7602, 0.6493,\n",
      "        0.5011, 0.9373, 1.2559, 0.3420, 1.3074, 1.9858, 2.0311, 0.1831, 0.1729,\n",
      "        0.4204, 0.6696, 0.9944, 0.7168, 0.9096, 0.6847, 0.9234, 0.2815, 1.3405,\n",
      "        2.7335, 1.6804, 0.7801, 1.1584, 0.6058, 0.5721, 0.3467, 0.0370, 1.0769,\n",
      "        0.2270, 0.9163, 0.7257, 0.8438, 0.6625, 0.3001, 1.2144, 0.1710, 1.3077,\n",
      "        0.7783, 0.8296, 0.4612], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([8.5535e-01, 6.1491e-01, 4.9985e-01, 3.3824e+00, 1.0035e+00, 2.2450e+00,\n",
      "        2.0814e-01, 1.2918e+00, 1.8478e+00, 8.2915e-01, 3.4384e-01, 6.2598e-01,\n",
      "        4.6910e+00, 2.0986e+00, 1.0820e+00, 1.5238e+00, 5.4616e-01, 1.2549e+00,\n",
      "        5.3135e-01, 1.5556e+00, 1.1971e+00, 7.7687e+00, 4.7018e+00, 1.0679e+00,\n",
      "        7.8758e-02, 8.5902e-01, 9.4368e-01, 4.1018e-01, 6.7411e-01, 1.2746e-02,\n",
      "        9.1607e-01, 1.0984e+00, 9.3222e-04, 9.6110e-01, 7.4542e-01, 2.9410e-01,\n",
      "        1.0231e-01, 1.0289e+00, 3.2975e-01, 1.0137e+00, 1.0240e+00, 1.3282e+00,\n",
      "        9.2550e-01, 6.3012e-01, 4.0052e+00, 3.8735e-01, 4.6247e+00, 2.7997e+00,\n",
      "        1.7188e+00, 7.6510e-01, 4.3897e-01, 6.4175e-01, 1.8310e-01, 1.0790e+00,\n",
      "        9.6159e-01, 8.0910e-01, 1.2447e+00, 6.3971e-01, 1.0548e+00, 7.7590e-01,\n",
      "        1.8622e+00, 3.3262e-01, 5.3122e-01, 1.3566e+00, 8.0778e-01, 1.0677e+00,\n",
      "        1.0947e+00, 6.8614e-01, 6.0125e-01, 1.0026e+00, 2.0638e+00, 1.8101e+00,\n",
      "        5.7003e-01, 8.9222e-01, 8.3290e-03, 6.6128e-01, 2.2250e+00, 4.5694e-01,\n",
      "        2.7109e-01, 9.0232e-01, 1.0263e+00, 2.1763e+00, 1.5619e+00, 1.1469e+00,\n",
      "        3.6879e-02, 3.0963e-01, 3.5882e-01, 3.6854e+00, 2.6757e-01, 1.6145e+00,\n",
      "        1.2302e+00, 2.1096e+00, 3.0290e+00, 1.6340e+00, 2.2453e+00, 9.5940e-01,\n",
      "        1.1493e+00, 7.1152e-01, 2.1811e+00, 4.3799e-02, 9.3831e-01, 1.8309e+00,\n",
      "        9.3897e-01, 2.2175e+00, 1.2540e+00, 1.0847e+00, 4.4708e-01, 5.0781e-01,\n",
      "        3.8646e+00, 6.5110e+00, 2.1972e-01, 8.5516e-01, 2.5259e-01, 3.5285e-01,\n",
      "        8.2351e-02, 1.0238e+00, 2.4095e-01, 2.7802e-01, 1.7540e+00, 7.6254e-01],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.1103, 0.3725, 0.1108, 0.7438, 0.9126, 0.2623, 3.9649, 1.4307, 1.6025,\n",
      "        1.2395, 1.9396, 1.0144, 0.8129, 1.4490, 1.9104, 0.2401, 0.6358, 0.6214,\n",
      "        0.5793, 0.7397, 0.4982, 1.3195, 0.5894, 0.3243, 1.0851, 0.6811, 0.4641,\n",
      "        0.3013, 1.2012, 1.3378, 0.4724, 0.6442, 1.0261, 0.9392, 0.1493, 1.6348,\n",
      "        0.8384, 0.5523, 1.2360, 0.9923, 1.6062, 0.8969, 0.0778, 0.6982, 1.1762,\n",
      "        3.8792, 3.5354, 1.1807, 1.1203, 0.7335, 0.9727, 1.1926, 1.4535, 0.5533,\n",
      "        0.9655, 0.8891, 0.5948, 0.1927, 3.2048, 0.4782, 1.5334, 0.2930, 1.2464,\n",
      "        0.7993, 0.7233, 0.7719, 0.7997, 1.4404, 0.8740, 1.6164, 1.0049, 0.4530,\n",
      "        0.8912, 1.0776, 1.0353, 0.5638, 0.4841, 0.6440, 0.7235, 1.2148, 0.6482,\n",
      "        3.6020, 0.9785, 1.2379, 0.9873, 0.9550, 0.5886, 0.9823, 1.1291, 0.8586,\n",
      "        0.9330, 0.9232, 1.5336, 0.4648, 0.0794, 0.2013, 1.1778, 1.1880, 0.6721,\n",
      "        0.8767, 0.6923, 0.7555, 0.4790, 0.7910, 1.1166, 0.4719, 2.5298, 0.7032,\n",
      "        0.9292, 0.1534, 0.7281, 0.5776, 0.0490, 1.6360, 0.2599, 0.9156, 0.6375,\n",
      "        1.1057, 1.1199, 0.5651], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([7.2044e-01, 3.1285e-01, 8.2336e-01, 3.4695e-01, 8.7336e-01, 5.3187e-01,\n",
      "        7.7350e-01, 8.1192e-01, 1.2901e+00, 9.1921e-01, 6.7098e-01, 8.6720e-01,\n",
      "        7.1903e-01, 4.2226e-01, 1.1772e+00, 7.8581e-01, 7.3736e-01, 9.2763e-01,\n",
      "        8.8822e-01, 1.2708e+00, 2.8090e-01, 1.9392e-01, 1.0437e+00, 7.7290e-01,\n",
      "        9.0049e-01, 6.4328e-02, 8.2703e-01, 6.6783e-01, 4.0662e-01, 1.0447e+00,\n",
      "        7.6995e-02, 1.6757e-01, 1.0107e+00, 1.2942e-02, 1.0509e+00, 1.0429e+00,\n",
      "        7.8359e-01, 2.8325e-01, 2.5684e+00, 6.5860e-01, 1.1792e-01, 3.5080e-01,\n",
      "        2.2550e+00, 7.7645e-01, 2.6204e-01, 6.1433e-01, 1.2796e+00, 2.3261e+00,\n",
      "        2.7132e-01, 7.7009e-01, 1.0393e+00, 1.8333e+00, 1.3655e+00, 3.6427e-01,\n",
      "        8.3660e-01, 3.7909e-04, 3.5407e-01, 9.3875e-01, 1.1393e+00, 1.6847e+00,\n",
      "        8.9999e-01, 6.4365e-01, 1.2686e+00, 8.2632e-01, 1.4680e+00, 1.0636e+00,\n",
      "        1.1065e+00, 8.7365e-01, 1.4308e-01, 6.9251e-01, 2.0234e+00, 1.5863e+00,\n",
      "        1.1153e+00, 7.8668e-01, 8.8758e-01, 7.6076e-01, 1.0890e+00, 9.6698e-01,\n",
      "        7.1109e-01, 9.3676e-01, 8.9791e-03, 2.7820e+00, 1.0514e-01, 1.4648e+00,\n",
      "        8.8514e-01, 3.6737e-01, 9.9115e-01, 1.3328e+00, 2.5978e+00, 5.3882e-01,\n",
      "        6.2934e-01, 1.0392e+00, 6.1437e-01, 8.9945e-01, 1.3680e+00, 2.5974e-01,\n",
      "        2.1201e+00, 1.1453e+00, 1.3108e+00, 2.1367e-02, 1.9167e-01, 7.1305e-01,\n",
      "        7.3221e-01, 3.1121e-01, 4.0013e-01, 1.3186e+00, 1.4844e+00, 1.0665e+00,\n",
      "        9.6587e-01, 2.2187e-01, 3.2300e-01, 7.3388e-01, 1.0027e+00, 8.3574e-01,\n",
      "        1.0702e+00, 1.6720e+00, 2.3889e-01, 5.7615e-02, 9.8090e-01, 6.4398e-01],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([5.7383e-01, 5.0069e-01, 3.3994e-01, 3.3878e-01, 7.5752e-01, 8.0889e-01,\n",
      "        1.0074e+00, 1.0340e+00, 3.3655e-01, 6.5652e-01, 3.5241e-01, 4.8821e-01,\n",
      "        2.6462e+00, 1.1717e+00, 5.2795e-01, 7.5615e-01, 7.0974e-01, 3.2005e-01,\n",
      "        5.8413e-01, 1.0502e+00, 7.7467e-01, 5.5832e-01, 6.7903e-01, 7.9302e-01,\n",
      "        8.1552e-01, 1.7484e-01, 7.0428e-01, 1.6468e+00, 1.7010e+00, 8.6731e-02,\n",
      "        6.5420e-01, 3.3149e-01, 9.7671e-01, 2.1033e+00, 8.4221e-01, 2.0783e+00,\n",
      "        6.9810e-01, 1.8021e+00, 5.0154e-01, 3.3304e+00, 1.5302e+00, 4.2021e-01,\n",
      "        2.4196e-02, 2.6712e+00, 2.0715e+00, 6.8764e-01, 2.0778e-01, 2.9376e-01,\n",
      "        1.9226e-01, 7.4558e-01, 9.4362e-01, 1.0409e+00, 9.5347e-01, 1.0887e+00,\n",
      "        8.9307e-01, 7.3735e-02, 6.4814e-01, 4.9807e-01, 1.5144e+00, 2.3761e-01,\n",
      "        6.7164e-01, 2.5170e-01, 8.0931e-01, 3.2481e-01, 1.0592e+00, 3.5028e-03,\n",
      "        7.8045e-01, 1.1073e+00, 1.6419e-01, 4.4192e-01, 4.2682e-01, 2.6818e+00,\n",
      "        1.6918e+00, 1.0604e+00, 2.5456e-01, 9.6789e-01, 5.2548e-02, 6.5021e-01,\n",
      "        8.7250e-01, 8.8139e-02, 1.2703e+00, 3.7196e-01, 4.5719e-01, 4.5428e-01,\n",
      "        1.0077e+00, 2.4485e+00, 1.2505e+00, 9.6114e-01, 2.4402e+00, 2.8820e+00,\n",
      "        1.2902e+00, 6.6133e-01, 2.7472e-01, 9.5614e-01, 9.3364e-01, 1.0081e+00,\n",
      "        1.5071e+00, 7.0930e-01, 2.3774e-01, 2.7564e+00, 1.2274e-01, 6.5450e-01,\n",
      "        2.9036e-01, 6.3780e-01, 5.7161e-01, 1.0354e+00, 8.3730e-01, 6.8957e-01,\n",
      "        8.0473e-01, 1.1538e+00, 1.1850e+00, 1.8335e-01, 5.5988e-01, 1.5024e+00,\n",
      "        7.3493e-01, 6.0804e-01, 3.1383e-01, 6.5028e-01, 3.7249e-01, 1.4077e-03],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.1628, 0.4858, 0.2904, 1.7596, 1.1905, 0.8487, 0.2300, 1.0417, 0.0351,\n",
      "        0.1743, 0.7390, 1.6315, 3.3750, 1.7693, 1.5096, 0.3362, 1.1742, 1.3336,\n",
      "        0.9799, 1.8232, 0.2286, 0.7445, 1.9057, 1.8068, 1.7425, 0.6388, 1.2267,\n",
      "        0.9714, 1.2371, 0.4404, 0.6504, 0.5936, 0.7081, 0.4903, 0.4629, 1.0726,\n",
      "        0.9148, 0.1805, 1.3222, 0.9430, 1.2687, 1.0204, 0.8490, 1.4795, 0.9803,\n",
      "        6.2507, 3.9505, 0.3614, 0.4574, 2.1346, 1.8470, 0.7567, 0.4861, 0.9982,\n",
      "        2.3135, 1.1419, 0.5563, 3.2440, 2.7637, 0.8785, 1.0904, 0.8679, 1.9396,\n",
      "        0.9647, 0.2621, 0.2260, 0.6736, 0.4980, 0.5566, 2.1980, 1.4291, 2.5527,\n",
      "        1.6273, 0.1636, 2.0483, 2.2856, 1.8997, 0.3760, 1.2635, 1.6751, 0.5007,\n",
      "        0.7834, 0.7063, 0.0401, 0.4787, 2.4126, 1.2534, 1.1131, 1.8702, 0.0491,\n",
      "        1.7476, 2.1032, 3.1835, 1.1799, 1.1276, 0.1855, 0.2584, 1.1237, 1.0567,\n",
      "        0.8753, 0.7752, 1.7174, 4.4683, 1.8277, 0.4971, 0.5902, 0.7943, 0.0323,\n",
      "        0.9504, 0.2265, 1.1883, 0.3873, 0.9893, 2.2048, 0.5117, 0.7897, 2.5836,\n",
      "        2.9929, 0.5814, 3.6661], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([8.1529e-01, 1.1786e+00, 3.2705e-01, 8.1305e-01, 1.5787e+00, 1.1207e+00,\n",
      "        7.5661e-01, 8.1066e-01, 1.8694e+00, 7.5995e-01, 1.3663e+00, 6.0181e-02,\n",
      "        2.6870e+00, 9.3229e-02, 1.7167e+00, 3.6173e+00, 1.4082e+00, 3.5133e+00,\n",
      "        9.9112e-01, 1.2866e+00, 2.9402e-01, 2.5123e+00, 7.1941e-01, 1.2297e+00,\n",
      "        2.9635e-01, 4.9571e-01, 8.9650e-01, 8.6951e-01, 6.7105e-01, 1.3024e-01,\n",
      "        6.9211e-01, 1.3098e-01, 9.0079e-01, 1.2550e+00, 3.4483e-01, 8.8165e-01,\n",
      "        1.9621e+00, 3.1853e+00, 1.7625e+00, 2.9826e+00, 1.6025e+00, 7.5663e-01,\n",
      "        1.6484e+00, 1.0021e+00, 4.9831e-01, 2.6115e+00, 5.2720e+00, 6.8374e-01,\n",
      "        9.4204e-01, 7.4242e-01, 1.5675e+00, 2.6687e+00, 1.8764e+00, 7.5986e-01,\n",
      "        5.5303e-01, 7.5317e-01, 3.6616e-01, 1.4549e+00, 2.5915e+00, 1.6623e-01,\n",
      "        1.6378e+00, 5.4416e+00, 7.3765e+00, 7.4394e-01, 7.4702e-01, 2.1956e-01,\n",
      "        3.2996e-01, 5.3697e-01, 6.1699e-01, 7.8089e-01, 4.2575e+00, 1.1521e+00,\n",
      "        7.4597e-01, 1.7755e+00, 1.1005e+00, 1.7520e+00, 5.8306e-01, 1.1542e+00,\n",
      "        9.9681e-01, 1.4657e-01, 1.4727e+00, 1.0246e+00, 2.4582e+00, 2.4528e+00,\n",
      "        1.4071e+00, 2.3230e-01, 4.5826e-01, 1.7022e-01, 2.5884e+00, 5.5093e-01,\n",
      "        1.9943e+00, 4.5511e-01, 6.5003e-01, 8.7259e-01, 8.5617e-01, 5.0130e-01,\n",
      "        7.5075e-02, 1.7634e+00, 1.6855e+00, 1.8121e+00, 6.6484e-01, 1.5705e-01,\n",
      "        1.3550e+00, 3.8044e-01, 2.3311e-01, 3.6587e-01, 5.5456e-01, 3.3313e-01,\n",
      "        9.0534e-01, 6.1298e-01, 3.9233e-03, 2.3413e+00, 5.1374e-02, 2.2054e+00,\n",
      "        1.2637e-01, 1.5716e+00, 1.2482e+00, 5.0602e-01, 1.7337e-01, 5.8347e-01,\n",
      "        3.5392e-01, 1.4487e-01, 3.2057e-01], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.9874e+00, 3.0818e-01, 1.8975e-01, 3.9246e-01, 7.2060e-01, 2.8327e-01,\n",
      "        1.0715e+00, 1.5601e+00, 8.9073e-01, 8.4578e-01, 1.7935e+00, 1.0228e+00,\n",
      "        3.0539e-01, 1.7856e+00, 1.1596e+00, 4.5262e-01, 9.0703e-01, 3.8994e-03,\n",
      "        7.7465e-01, 7.6107e-01, 2.1472e+00, 9.0128e-01, 7.6087e-01, 1.4147e+00,\n",
      "        2.0705e+00, 2.3745e+00, 1.1421e+00, 7.0547e-01, 2.8626e-01, 5.8501e-01,\n",
      "        3.7383e-01, 3.9903e-01, 4.0383e-01, 3.6375e-01, 5.2997e+00, 3.2519e+00,\n",
      "        1.9847e+00, 9.6568e-01, 1.6884e+00, 8.0576e-01, 1.0562e+00, 1.1782e+00,\n",
      "        5.5569e-01, 8.1295e-01, 7.3248e-01, 8.1657e-01, 5.3439e-01, 1.3456e+00,\n",
      "        1.5832e+00, 8.9057e-01, 6.9476e-01, 3.6293e-01, 3.6787e+00, 5.5039e-02,\n",
      "        3.0465e+00, 2.1490e+00, 2.6420e-01, 1.3758e-01, 9.6995e-01, 4.4795e-02,\n",
      "        2.2891e-02, 4.8104e-01, 1.0066e+00, 6.6188e-01, 1.2559e+00, 2.2994e-01,\n",
      "        6.9523e-01, 7.6675e-01, 8.6303e-02, 2.1416e+00, 1.8108e+00, 4.7019e-02,\n",
      "        7.3102e-01, 2.2387e+00, 7.1742e-01, 2.1027e+00, 1.4211e+00, 1.5053e+00,\n",
      "        1.3564e+00, 6.9629e-01, 1.1673e+00, 1.0375e+00, 3.1857e-01, 5.9394e-01,\n",
      "        9.9539e-01, 7.8449e-03, 2.1908e-01, 1.0044e+00, 7.0337e-01, 1.2952e-01,\n",
      "        1.5193e+00, 1.1651e+00, 1.5814e+00, 4.2591e-01, 3.0229e-01, 1.3329e+00,\n",
      "        2.3519e+00, 1.5384e+00, 1.3326e+00, 1.4091e+00, 1.2900e+00, 6.4012e-01,\n",
      "        8.4433e-01, 7.5026e-01, 5.1288e-01, 3.7694e-02, 3.4598e-01, 2.0101e+00,\n",
      "        1.2138e+00, 4.1196e-01, 2.3822e-01, 9.0933e-01, 1.1909e+00, 1.9654e-01,\n",
      "        6.4598e-01, 1.5107e+00, 8.0156e-01, 4.8347e-01, 1.1588e+00, 1.3048e+00,\n",
      "        3.6930e-01, 7.2885e-01, 3.7559e-01], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.5796, 1.0324, 0.2091, 1.3787, 1.0701, 0.7512, 1.1550, 0.7538, 0.4553,\n",
      "        0.3144, 0.6149, 0.5954, 0.9646, 0.8667, 2.0305, 0.8909, 0.4022, 0.9413,\n",
      "        0.5199, 0.0448, 0.7145, 0.7240, 0.4016, 0.7575, 0.8216, 0.7277, 0.3783,\n",
      "        0.5787, 0.4131, 0.1775, 1.7416, 1.5866, 1.1106, 3.4125, 1.6639, 0.1547,\n",
      "        0.7045, 0.6028, 0.6430, 1.0452, 0.4371, 0.8245, 0.4929, 0.3381, 1.1352,\n",
      "        0.6550, 0.2465, 0.6979, 0.7899, 0.6890, 0.8948, 0.5078, 0.7526, 1.2564,\n",
      "        0.0773, 0.3936, 1.0172, 1.1500, 0.9346, 0.7320, 0.9548, 0.9910, 0.9154,\n",
      "        0.2406, 0.8416, 0.7395, 1.1139, 0.8952, 0.1830, 1.4414, 0.6635, 1.1353,\n",
      "        0.5516, 0.8890, 0.5394, 0.3730, 0.7508, 0.6619, 0.2357, 0.1456, 1.2570,\n",
      "        0.5924, 0.3362, 0.3791, 0.7717, 0.9598, 0.1049, 0.9348, 0.7376, 0.8258,\n",
      "        1.3766, 0.8019, 0.5564, 1.0769, 0.8118, 1.2178, 1.3353, 0.5975, 0.7607,\n",
      "        0.9500, 0.1490, 1.4114, 0.6008, 0.7405, 0.7576, 0.5804, 0.3392, 1.2074,\n",
      "        0.6301, 0.9458, 0.2401, 0.1173, 0.8327, 0.2153, 0.4826, 0.5737, 0.2429,\n",
      "        0.4354, 2.5586, 1.7366, 0.6807, 2.2136, 0.1830], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.2431, 0.5607, 0.3277, 0.8531, 0.8705, 0.5434, 1.0977, 0.2055, 0.0944,\n",
      "        0.7606, 0.6984, 0.2244, 0.4030, 0.1352, 0.5838, 1.3885, 0.8664, 0.1461,\n",
      "        0.9251, 0.9797, 1.5444, 0.1879, 1.0528, 0.3272, 0.8332, 0.7304, 0.3929,\n",
      "        0.0617, 0.1841, 0.5637, 1.2948, 0.1521, 1.5356, 1.0838, 0.6762, 0.7687,\n",
      "        0.7473, 1.3482, 1.0583, 0.7787, 0.5176, 0.3325, 0.5923, 0.8431, 1.0053,\n",
      "        0.8585, 0.3772, 1.0468, 0.1328, 1.1580, 0.9582, 0.9257, 1.5070, 1.3008,\n",
      "        1.1726, 0.1921, 0.7214, 0.8849, 0.9653, 0.7894, 0.7168, 0.7169, 0.8554,\n",
      "        0.9064, 0.5289, 0.3461, 1.1929, 0.0645, 1.3462, 0.5067, 1.2765, 1.8658,\n",
      "        1.3119, 1.2847, 0.6079, 0.5238, 0.8592, 0.8399, 0.8525, 1.0252, 0.8087,\n",
      "        1.2325, 0.1624, 1.0467, 1.2297, 1.6844, 0.9729, 0.7118, 0.2281, 0.0127,\n",
      "        0.9202, 0.2758, 1.0714, 1.6936, 2.3484, 0.4222, 1.2620, 1.1479, 1.4803,\n",
      "        0.3178, 0.4768, 0.8962, 1.3520, 1.2962, 0.7062, 0.8440, 1.0356, 1.0905,\n",
      "        1.4474, 0.2937, 0.2707, 0.7763, 0.0196, 1.3894, 0.4072, 0.5427, 0.8574,\n",
      "        0.8641, 1.0407, 0.1388, 0.9927, 0.9483, 0.8633], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([3.2915e-01, 2.7330e-01, 8.5090e-01, 1.8883e-01, 2.7389e-01, 1.0535e+00,\n",
      "        3.2416e-01, 1.6273e+00, 2.0712e+00, 4.8891e-02, 1.7482e+00, 9.5414e-01,\n",
      "        1.6379e+00, 1.1027e+00, 3.2619e-01, 1.7750e+00, 1.3689e+00, 8.3114e-01,\n",
      "        2.5482e-01, 9.4432e-01, 1.0771e+00, 9.4810e-01, 1.3102e+00, 6.7760e-01,\n",
      "        3.4470e-01, 1.0610e+00, 1.8504e-01, 1.1841e-02, 7.6508e-01, 1.2310e+00,\n",
      "        9.0700e-04, 4.8422e-01, 1.0854e+00, 1.0267e+00, 1.0535e+00, 4.5719e-01,\n",
      "        1.0805e+00, 1.1467e+00, 6.5654e-01, 1.8890e+00, 1.9450e+00, 1.7264e+00,\n",
      "        2.7319e-01, 1.9371e-01, 5.1872e-01, 2.2689e+00, 1.6703e+01, 3.1870e+01,\n",
      "        1.0876e+00, 4.0139e+00, 1.4861e+00, 8.6556e-01, 2.1296e+00, 8.3042e-01,\n",
      "        6.8136e-01, 1.1610e+00, 3.7742e+00, 5.5466e-02, 9.9406e-01, 1.8489e-01,\n",
      "        5.1878e-01, 5.4306e-01, 3.9623e-01, 8.9873e-01, 9.7123e-01, 6.4470e-02,\n",
      "        3.2220e-01, 3.3940e+00, 2.6711e+00, 1.1990e+00, 6.2765e-01, 4.7174e+00,\n",
      "        6.6543e-01, 1.4648e-01, 3.7366e-01, 3.0571e+00, 7.5683e-01, 2.1844e+00,\n",
      "        9.9319e-01, 1.2114e+00, 1.0780e+00, 1.0074e+00, 1.1084e+00, 2.7203e+00,\n",
      "        2.9661e+00, 8.0009e-01, 1.7683e-01, 7.9414e-01, 9.0365e-01, 7.9729e-01,\n",
      "        9.4513e-01, 6.5213e-01, 2.9862e+00, 5.1578e-02, 4.4803e-01, 5.7740e-01,\n",
      "        4.5024e-01, 1.0364e+00, 6.6137e-01, 6.1428e+00, 1.7430e-01, 2.2537e+00,\n",
      "        1.2716e+00, 1.3171e+00, 1.0217e+00, 1.9479e+00, 2.0751e+00, 1.4739e+00,\n",
      "        7.0010e-01, 1.3675e+00, 3.1592e-01, 9.3340e-01, 3.9172e-01, 1.1172e+00,\n",
      "        3.0407e-01, 1.5255e-01, 5.6918e-02, 6.2259e-01, 1.3064e+00, 2.2408e+00,\n",
      "        2.3282e+00, 6.0471e-01, 7.0696e-01], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([4.0443e-01, 8.9803e-01, 9.3161e-01, 1.5105e+00, 1.1763e+00, 1.4842e+00,\n",
      "        3.0907e-01, 7.7553e-01, 6.1651e-01, 1.2069e-01, 1.4576e+00, 2.1117e+00,\n",
      "        1.3189e-01, 1.8918e-01, 1.7045e-01, 1.3925e+00, 1.0964e+00, 1.1287e+00,\n",
      "        8.6166e-01, 7.5952e-01, 2.1211e+00, 1.8582e+00, 1.6446e+00, 8.9599e-01,\n",
      "        3.6574e-01, 3.3050e-01, 6.8510e-01, 5.4928e-01, 3.2246e-01, 4.1602e-01,\n",
      "        3.3274e-01, 9.1584e-01, 9.9632e-01, 6.7710e-02, 3.1092e+00, 1.3143e+00,\n",
      "        1.0408e+00, 4.3603e-01, 8.3502e-01, 4.6219e-01, 8.2666e-01, 4.1368e-01,\n",
      "        1.9756e+00, 5.0120e-01, 2.4904e+00, 5.2150e-01, 1.0063e-01, 3.5725e-01,\n",
      "        8.3111e-01, 1.0029e+00, 4.8529e-01, 3.6085e-01, 8.0561e-01, 1.1666e+00,\n",
      "        5.2533e-01, 1.2502e+00, 2.4446e-01, 1.6168e-01, 1.2555e+00, 4.0330e-01,\n",
      "        1.6422e+00, 1.0508e+00, 1.1327e+00, 7.5985e-01, 8.4553e-02, 1.2806e+00,\n",
      "        4.3190e-03, 2.1958e-01, 6.0670e-01, 1.0843e+00, 2.4098e-02, 4.9545e-01,\n",
      "        2.2275e-01, 9.6188e-01, 7.5336e-01, 1.2494e+00, 1.0218e+00, 4.9282e-01,\n",
      "        2.0642e+00, 1.5068e+00, 9.3300e-02, 1.6065e+00, 2.1094e+00, 1.3338e-01,\n",
      "        7.0826e-01, 1.4840e+00, 2.7204e-04, 6.0060e-01, 5.1492e-01, 1.1483e+00,\n",
      "        8.7072e-01, 3.7736e-01, 1.1230e+00, 3.7987e-01, 1.0117e+00, 4.0038e-01,\n",
      "        7.5123e-01, 3.9399e-01, 6.2666e-01, 2.2947e+00, 2.6097e+00, 8.5053e-01,\n",
      "        3.3185e-01, 1.0291e+00, 8.9625e-02, 9.7492e-01, 5.7045e-02, 4.2486e+00,\n",
      "        8.5495e-01, 7.5491e-01, 1.5177e-01, 2.4502e+00, 9.3972e-01, 1.8592e+00,\n",
      "        5.3288e-01, 8.9499e-02, 7.5101e-01, 1.8947e-01, 1.3438e+00, 7.4953e-01,\n",
      "        2.4615e-01, 1.1162e+00, 1.8236e+00], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([6.2019e-01, 1.6320e-04, 8.4926e-01, 5.3753e-01, 7.8149e-02, 9.4891e-01,\n",
      "        4.0967e-01, 1.9251e+00, 2.1941e-01, 7.4532e-02, 3.4012e-01, 4.5176e-01,\n",
      "        1.2055e+00, 4.5275e-01, 1.4861e+00, 9.1608e-01, 1.7526e-01, 1.1478e+00,\n",
      "        4.7614e-01, 4.0847e-01, 1.4038e-02, 6.8634e-01, 1.0007e+00, 1.1002e+00,\n",
      "        3.5163e+00, 9.4161e-01, 1.7224e+00, 3.5892e-01, 1.9012e+00, 6.6096e-01,\n",
      "        1.2044e+00, 4.1662e-01, 4.6924e-01, 4.7611e-01, 6.4348e-01, 1.8120e+00,\n",
      "        1.2801e-01, 1.3189e+00, 4.8668e-01, 1.2258e+00, 2.5552e-01, 5.3985e-01,\n",
      "        1.8228e-01, 1.5541e-01, 1.0426e+00, 3.2523e-01, 1.0834e+00, 1.7669e+00,\n",
      "        8.4988e-01, 5.1950e-01, 1.8295e-02, 8.7787e-01, 6.1700e-01, 1.4447e+00,\n",
      "        5.2635e-01, 2.2534e+00, 1.6843e-02, 8.4486e-01, 8.9669e-01, 8.3678e-01,\n",
      "        2.1717e-01, 4.9828e-02, 1.9904e+00, 2.6224e+00, 1.1739e-01, 1.7365e-01,\n",
      "        5.8133e-01, 4.3715e-01, 1.0581e+00, 5.0251e-01, 1.7234e+00, 1.2756e-01,\n",
      "        5.0953e-01, 1.5427e-01, 2.9612e-01, 5.8205e-01, 1.2690e+00, 1.0913e+00,\n",
      "        2.5126e-01, 4.4242e-01, 1.0492e+00, 9.8286e-01, 4.3354e-01, 6.4750e-01,\n",
      "        5.1808e-01, 3.5595e-01, 3.4267e-01, 1.0523e+00, 7.7918e-01, 3.7752e-01,\n",
      "        1.8145e-01, 6.5362e-01, 1.0234e+00, 8.6596e-01, 5.2741e-01, 5.8301e-01,\n",
      "        2.5944e-01, 9.9873e-01], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.7112, 0.5768, 0.7817, 0.7272, 0.6606, 0.5530, 3.1210, 0.4375, 0.8173,\n",
      "        0.0414, 1.2275, 0.2741, 1.7781, 1.6815, 1.2255, 1.1761, 0.8770, 1.2878,\n",
      "        3.0279, 2.1217, 0.8950, 0.8649, 2.3251, 2.1691, 1.2818, 1.8137, 0.6402,\n",
      "        1.5005, 1.8385, 1.8165, 1.4547, 0.7357, 0.0283, 0.7713, 0.8812, 0.1289,\n",
      "        0.6735, 1.5732, 1.3644, 0.6849, 0.7196, 0.1877, 1.3092, 0.2492, 0.5299,\n",
      "        1.6320, 1.5910, 0.8695, 2.2458, 2.1541, 0.6566, 0.2843, 0.0520, 0.3279,\n",
      "        0.5000, 0.4828, 0.2875, 1.7021, 1.5104, 0.5152, 1.6356, 0.0881, 0.9977,\n",
      "        2.2894, 2.7390, 4.8231, 0.7434, 1.1562, 0.5042, 0.1338, 0.7491, 1.1475,\n",
      "        1.5005, 1.0611, 0.3328, 0.5356, 2.1111, 0.7495, 1.2595, 0.2351, 1.1412,\n",
      "        1.1390, 1.1165, 1.0983, 1.1075, 1.5236, 1.0146, 1.2830, 0.3260, 0.8945,\n",
      "        2.0260, 0.5309, 1.2942, 1.8043, 0.9333, 0.6217, 0.3260, 0.6732, 1.1502],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0031, 0.4625, 0.2208, 0.7182, 0.3857, 1.0969, 0.4517, 1.9133, 0.7880,\n",
      "        0.2111, 0.6597, 1.0516, 0.5904, 1.1368, 1.1059, 1.2169, 0.1229, 0.5378,\n",
      "        0.9120, 0.9854, 0.5123, 1.7592, 0.5079, 1.6274, 2.2376, 0.7422, 0.9858,\n",
      "        2.0790, 2.9232, 0.4317, 2.0094, 2.2464, 1.3401, 2.2907, 2.6604, 1.3367,\n",
      "        2.7552, 2.8626, 0.1586, 0.3012, 1.2453, 0.5965, 0.1686, 0.2741, 0.4346,\n",
      "        2.3166, 1.4587, 0.2958, 0.3721, 0.9317, 1.0982, 0.4318, 1.2343, 0.2202,\n",
      "        1.0659, 0.0159, 0.4926, 0.5173, 0.2540, 0.8946, 0.5554, 0.0881, 0.5929,\n",
      "        1.5823, 0.9386, 1.2374, 0.1319, 0.0541, 0.7087, 0.3262, 0.3992, 0.5979,\n",
      "        1.9915, 0.9289, 0.9749, 1.0135, 1.5392, 1.4394, 1.9493, 1.7408, 1.4423,\n",
      "        2.6204, 2.6218, 0.1460, 2.8397, 1.5392, 0.3215, 4.2864, 2.5919, 0.4582,\n",
      "        4.1750, 0.9647, 4.3137, 0.0045, 0.4760, 0.9950, 0.3597, 0.4465, 2.0928],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([3.6927e-02, 9.7072e-01, 4.0158e-01, 4.5168e-01, 9.9028e-01, 5.5841e-02,\n",
      "        1.5874e-01, 6.8552e-01, 1.1422e+00, 4.2866e-01, 9.9941e-01, 1.3450e+00,\n",
      "        3.6523e-01, 1.2792e-01, 1.4821e+00, 6.9912e-01, 1.5895e+00, 9.3033e-01,\n",
      "        9.2267e-01, 1.1302e+00, 1.5482e+00, 1.4655e+00, 1.3694e+00, 2.8510e-01,\n",
      "        1.5401e-01, 3.5050e+00, 2.5939e+00, 2.7445e-01, 7.1601e-01, 8.8392e-01,\n",
      "        9.1248e-01, 1.2638e-02, 1.0547e+00, 6.2368e-01, 1.1722e+00, 2.9865e-01,\n",
      "        5.4596e-02, 9.5169e-01, 1.4905e+00, 1.7234e+00, 2.3991e+00, 8.4340e-01,\n",
      "        8.5984e-02, 2.8625e-01, 6.8739e-01, 7.7518e-01, 1.2163e+00, 8.3622e-01,\n",
      "        9.8237e-01, 2.8185e+00, 1.9171e+00, 3.5321e-01, 5.4428e-02, 1.3199e-01,\n",
      "        9.9856e-01, 2.9659e-01, 1.1935e+00, 8.2806e-01, 1.4175e+00, 8.7786e-01,\n",
      "        8.6485e-01, 1.8372e-01, 6.2923e-01, 6.1337e-01, 6.7709e-01, 1.1049e+00,\n",
      "        6.4920e-01, 1.7966e-03, 4.4828e-01, 8.8887e-01, 1.2835e+00, 3.2308e+00,\n",
      "        3.9234e-01, 9.1592e-01, 4.3813e-01, 6.9386e-01, 3.5143e-02, 4.9024e-01,\n",
      "        1.2239e+00, 1.9027e-01, 5.0113e-01, 3.1214e-01, 2.0943e-01, 5.6751e-01,\n",
      "        2.2314e-01, 8.6463e-01, 4.5931e-01, 1.4537e+00, 6.2815e-01, 1.5315e+00,\n",
      "        1.3721e+00, 4.4553e-01, 5.9395e-01, 1.1061e+00, 9.9634e-01, 1.0237e+00,\n",
      "        6.9271e-01, 4.7625e-01, 3.0555e-02], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.2831, 0.3856, 0.9336, 0.2372, 1.0741, 0.8646, 2.2828, 1.9566, 1.0265,\n",
      "        1.7118, 0.9018, 1.9205, 1.0126, 2.4050, 3.6295, 1.8700, 0.1890, 1.4258,\n",
      "        0.0765, 0.7147, 3.4235, 0.6918, 1.2688, 1.0036, 0.8708, 0.3813, 0.0412,\n",
      "        0.6811, 1.6993, 0.3473, 0.0122, 1.0475, 0.3251, 0.5265, 0.6908, 1.7685,\n",
      "        2.9254, 0.0088, 1.9118, 1.8178, 1.6738, 3.7261, 0.7021, 0.1506, 0.4513,\n",
      "        0.8836, 1.1724, 1.1668, 4.7998, 1.1828, 1.7598, 0.0540, 0.9530, 0.3097,\n",
      "        1.9861, 0.1631, 0.4934, 1.6009, 0.9602, 0.4743, 1.2613, 0.7686, 0.4806,\n",
      "        0.3506, 2.1890, 2.5499, 0.2461, 2.2273, 1.5414, 0.1959, 1.1615, 0.8221,\n",
      "        1.1216, 2.0974, 1.8443, 0.7652, 0.1993, 4.9542, 0.6692, 1.4647, 0.9665,\n",
      "        1.5158, 0.4257, 0.6457, 0.2703, 1.3409, 0.7859, 0.8676, 0.4616, 0.0632,\n",
      "        0.6227, 0.8957, 0.5354, 0.0488, 0.0176, 0.3001, 1.0507, 2.8067, 0.4710],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.1461, 0.9363, 0.6811, 0.4797, 0.6918, 0.7969, 1.2695, 0.6911, 0.7728,\n",
      "        1.8272, 0.1152, 0.2920, 7.6050, 1.7542, 9.5250, 1.3861, 0.4504, 0.9018,\n",
      "        1.4385, 1.3430, 4.3231, 0.2725, 0.1807, 2.1769, 2.0856, 1.7304, 2.1981,\n",
      "        0.3478, 0.6085, 0.3309, 0.9030, 0.6069, 1.7445, 0.2096, 0.5433, 0.0294,\n",
      "        2.1658, 1.8348, 1.0914, 0.3674, 4.2953, 0.8369, 1.1343, 0.4399, 0.0968,\n",
      "        1.3740, 1.7774, 0.3466, 0.2811, 0.2928, 1.2127, 0.9937, 0.5592, 0.0147,\n",
      "        1.0438, 1.3765, 1.0292, 0.0153, 0.1502, 0.2658, 0.5893, 0.6870, 0.7938,\n",
      "        0.7101, 1.5935, 1.0438, 1.1793, 1.1165, 0.6124, 1.0554, 0.8624, 0.8223,\n",
      "        0.7639, 0.4399, 0.8713, 0.0749, 0.7319, 0.6543, 0.0334, 0.9446, 0.5256,\n",
      "        0.0969, 0.5935, 0.6036, 0.3979, 0.2140, 0.2946, 0.2181, 0.2895, 0.3688,\n",
      "        1.4121, 0.8556, 1.1400, 0.2148, 0.7281, 0.5715, 0.4420, 0.4930, 0.2211],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0642, 1.2670, 1.3294, 0.1047, 0.9314, 2.1174, 0.8012, 0.2306, 0.3061,\n",
      "        0.8588, 0.3009, 0.0418, 1.8716, 3.2769, 0.0219, 1.9950, 2.4609, 0.3982,\n",
      "        0.0791, 0.2008, 1.1606, 2.3081, 1.5421, 2.2610, 0.9911, 1.1426, 1.0316,\n",
      "        1.0667, 0.4862, 0.3240, 0.5475, 0.7759, 0.2607, 1.8088, 0.6816, 0.3517,\n",
      "        1.8159, 0.1766, 0.0731, 0.3376, 0.4586], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.6312, 0.6622, 0.6082, 0.2572, 0.3844, 1.6715, 0.0800, 1.9318, 1.5965,\n",
      "        0.9910, 0.5166, 0.3701, 0.4651, 1.0238, 0.7303, 0.8489, 2.1461, 0.5693,\n",
      "        1.1784, 0.8337, 0.1093, 0.8875, 0.4764, 0.1234, 1.7176, 0.9297, 0.7676,\n",
      "        0.3970, 0.3133, 0.4231, 3.5432, 1.9749, 0.1138, 0.5886, 0.8222, 0.7965,\n",
      "        0.6921, 0.7310, 0.3035, 3.5062], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0436, 0.3821, 1.0467, 1.1652, 1.0077, 0.2361, 0.3442, 1.2926, 0.0281,\n",
      "        2.4255, 7.4072, 2.3083, 0.0883, 0.4304, 0.1817, 3.7973, 0.2396, 1.8804,\n",
      "        0.0194, 0.5512, 0.4381, 6.9467, 2.1061, 8.9417, 0.0218, 0.5488, 0.6533,\n",
      "        0.1375, 0.6451, 0.3129, 0.0715, 1.0090, 0.4710, 2.0286, 1.5694, 0.6509,\n",
      "        0.3760, 0.1635, 1.4377, 1.2253], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.6162, 0.6184, 0.0132, 0.7572, 0.4944, 0.0940, 1.3563, 1.7040, 1.1271,\n",
      "        0.6019, 0.6859, 0.6676, 1.7432, 1.4237, 0.3829, 1.2736, 0.2140, 0.4089,\n",
      "        0.6735, 1.5080, 0.6187, 0.0805, 0.3901, 0.5517, 0.3538, 1.3018, 2.4241,\n",
      "        1.6686, 0.2132, 0.3354, 1.4199, 1.3490, 0.5842, 0.2371, 0.1044, 0.5374,\n",
      "        1.7969, 0.1034, 0.8660], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([9.9439e-01, 6.6090e-01, 1.0872e+00, 4.9726e-01, 4.1891e-01, 8.2524e-01,\n",
      "        1.0986e+00, 9.5094e-01, 1.0180e+00, 2.1125e+00, 1.4464e+00, 9.0015e-01,\n",
      "        6.9037e-01, 1.0436e+00, 1.1640e+00, 1.0052e+00, 8.0824e-01, 3.5976e-01,\n",
      "        2.0879e+00, 9.7562e-01, 8.6961e-01, 7.6795e-01, 5.2932e-01, 1.2846e+00,\n",
      "        3.4876e-01, 7.6463e-01, 1.2706e-02, 6.1615e-01, 1.0947e+00, 7.8860e-01,\n",
      "        1.2313e+00, 2.6805e-01, 1.1739e+00, 1.1047e+00, 7.8244e-01, 1.0824e+00,\n",
      "        6.8135e-01, 2.8423e+00, 1.5859e-01, 1.1229e-02, 1.8400e-03],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.5456, 0.2459, 1.0561, 2.3039, 1.1809, 0.4097, 0.1044, 0.8989, 1.2926,\n",
      "        1.7080, 0.6247, 1.4464, 0.4943, 0.9404, 0.8647, 0.6308, 0.2226, 0.4656,\n",
      "        0.1632, 0.5242, 2.2554, 1.2137, 0.9199, 0.8533, 1.0118, 0.4420, 0.1096,\n",
      "        0.5679, 0.4489, 0.3909, 1.2564, 0.3219, 1.4628, 0.9045, 1.3331, 1.2732,\n",
      "        0.7043, 2.0947, 2.8576, 0.0943, 0.2357, 0.0430], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([2.2819e+00, 6.9889e-01, 2.2626e+00, 4.5767e-01, 5.2923e-01, 7.0136e-01,\n",
      "        2.7818e-01, 2.3433e+00, 1.0313e+00, 1.2360e-01, 3.3062e-01, 6.8653e-01,\n",
      "        2.3767e+00, 1.5403e+00, 4.8223e-01, 2.7885e+00, 3.1001e-01, 6.8611e-01,\n",
      "        3.2187e+00, 2.8528e-01, 1.7155e+00, 2.3027e+00, 1.0763e+00, 2.3363e+00,\n",
      "        4.4262e-01, 9.6721e-01, 2.4626e-01, 3.7098e-01, 1.5763e+00, 9.5484e-01,\n",
      "        9.9960e-01, 7.9652e-01, 1.4712e+00, 1.6114e+00, 6.1097e-01, 4.2574e+00,\n",
      "        1.2527e+00, 5.6328e+00, 8.8329e+00, 1.0766e+00, 5.2223e+00, 6.3003e-01,\n",
      "        8.3654e-01, 1.1562e+00, 4.8548e-01, 3.5323e+00, 3.2173e-01, 1.5542e+00,\n",
      "        7.6457e-01, 7.5115e-01, 6.2465e-02, 9.3297e-01, 8.0415e-01, 4.8958e-01,\n",
      "        8.2469e-04, 4.0483e+00, 2.0131e+00, 6.2855e-01, 1.5258e+00, 1.2958e+00,\n",
      "        9.6486e-01, 3.6717e-01, 2.7154e+00, 1.2069e+00, 8.7380e-01, 1.7103e+00,\n",
      "        7.6558e+00, 4.5876e+00, 2.3056e+00, 1.1027e+00, 3.1732e+00, 4.5490e+00,\n",
      "        3.6431e+00, 1.1442e+00, 8.1062e-01, 5.5282e-01, 1.1051e+00, 2.2664e+00,\n",
      "        1.5153e+00, 2.5408e-01, 8.1569e-01, 1.5618e+00, 9.9123e-01, 7.3492e-01,\n",
      "        7.5191e-01, 1.4058e+00, 4.0326e-01, 5.0439e-01, 7.6225e-01, 3.1574e+00,\n",
      "        1.7940e+00, 2.3670e-02, 2.1609e+00, 2.2455e+00, 4.4502e-01, 2.4744e+00,\n",
      "        9.4693e-01, 3.9288e+00, 1.2326e-01, 1.0263e-01, 6.1779e-01, 6.4975e-01,\n",
      "        2.0822e+00, 3.4301e+00, 6.9541e-01, 9.4042e-01, 2.8013e-01, 7.7763e-01,\n",
      "        9.1067e-01, 1.0219e+00, 1.1190e+00, 2.8643e-01, 3.2106e+00, 1.5039e+00,\n",
      "        3.7209e+00, 3.8039e-01, 1.8370e-01, 6.7297e-01, 1.1925e+00, 1.1751e+00,\n",
      "        6.0396e-01, 3.6888e+00, 3.5600e+00, 1.1307e+00, 2.3177e+00, 8.2276e-01],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.3991, 0.2424, 0.3857, 0.7608, 1.6943, 0.9834, 3.3917, 0.9032, 0.8029,\n",
      "        1.1975, 1.1995, 0.6908, 0.2900, 1.7751, 1.3940, 0.5603, 0.9177, 0.5036,\n",
      "        1.4574, 1.1319, 0.4569, 0.4213, 0.4501, 0.7080, 2.1794, 1.7198, 0.3095,\n",
      "        0.7561, 0.5792, 0.8346, 0.9944, 2.0127, 3.1120, 1.5942, 0.9254, 1.8149,\n",
      "        4.8109, 0.9607, 1.6158, 0.8508, 0.3690, 0.8566, 0.7044, 0.7420, 0.9413,\n",
      "        0.9340, 0.5947, 0.2872, 1.6699, 0.3570, 0.1583, 1.1587, 1.4117, 1.1126,\n",
      "        1.1943, 0.0690, 1.5543, 1.0959, 0.6924, 0.5886, 0.5217, 0.6471, 0.6410,\n",
      "        0.6901, 1.9092, 1.1501, 3.0177, 0.1268, 2.7260, 0.0716, 3.6085, 1.1957,\n",
      "        0.4147, 1.1185, 1.0746, 0.5683, 0.3451, 0.7597, 1.1590, 2.0498, 1.7294,\n",
      "        1.1045, 1.2946, 0.9899, 1.0812, 0.2292, 0.9776, 1.7599, 3.4083, 0.6538,\n",
      "        3.2241, 2.4450, 0.5956, 0.5910, 1.0710, 0.5231, 1.5664, 4.2080, 0.3734,\n",
      "        0.2249, 3.2679, 0.0114, 0.9899, 1.3247, 0.8585, 0.9598, 0.4101, 0.7906,\n",
      "        1.1246, 1.4105, 0.7010, 1.4591, 1.0333, 1.0561, 0.2534, 1.0403, 0.1018,\n",
      "        0.9561, 1.2390, 0.6102, 0.1931, 0.4711, 1.8307, 0.7145, 0.9267, 3.3802],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.5248, 1.1710, 1.3930, 0.7426, 0.5015, 1.1270, 0.1187, 1.2209, 1.0726,\n",
      "        1.7139, 0.4551, 0.6003, 0.9321, 0.7642, 1.1595, 0.9122, 1.3081, 0.3134,\n",
      "        0.2469, 0.3306, 0.2238, 0.4408, 0.8153, 1.3727, 8.4801, 5.7705, 0.1923,\n",
      "        1.0837, 0.7522, 1.1093, 0.3763, 0.4723, 0.2033, 1.0557, 0.8186, 0.4539,\n",
      "        0.2511, 0.7584, 0.4395, 0.1696, 0.5893, 0.3626, 0.8884, 0.6116, 0.3942,\n",
      "        0.5852, 0.0238, 0.2955, 1.1549, 0.9696, 0.7635, 1.9193, 0.7337, 1.0336,\n",
      "        1.2095, 0.6461, 1.0361, 0.9667, 0.3152, 0.6967, 0.3643, 1.2434, 0.1902,\n",
      "        0.4671, 1.2913, 0.9510, 0.4654, 0.9495, 0.7662, 1.3443, 0.7128, 0.4695,\n",
      "        0.8682, 0.0442, 1.2058, 0.6854, 0.7594, 0.5893, 0.3375, 0.2691, 0.0944,\n",
      "        0.3910, 0.2055, 0.4530, 1.0774, 1.0254, 1.5342, 0.4701, 3.0801, 0.9171,\n",
      "        1.2384, 1.4752, 2.6433, 0.6724, 2.4416, 1.1941, 0.0627, 1.1678, 0.7974,\n",
      "        1.2826, 0.9834, 0.7371, 0.8847, 0.4780, 0.2681, 1.0693, 0.0810, 0.5016,\n",
      "        1.0645, 1.0169, 0.4603, 0.8596, 1.1032, 0.1614, 0.9656, 0.6035, 1.1858,\n",
      "        2.2785, 1.3569, 0.5969, 0.8427, 1.0649, 0.5391, 0.5340, 0.2571, 0.4105],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.6478, 0.7071, 0.7286, 1.4281, 0.0848, 0.2097, 0.7319, 0.7604, 1.0592,\n",
      "        0.6079, 1.2785, 1.2068, 1.4308, 1.0705, 1.5015, 0.5461, 0.5636, 1.0459,\n",
      "        1.3596, 0.1270, 0.9108, 0.8123, 0.7286, 0.8377, 1.0355, 0.8326, 0.9194,\n",
      "        0.7934, 0.0105, 0.9396, 0.9224, 0.6934, 1.0878, 1.0259, 0.2242, 0.3755,\n",
      "        0.8288, 0.8080, 0.7694, 0.6677, 0.6308, 1.0798, 1.2228, 1.0783, 1.3833,\n",
      "        0.7842, 0.9645, 1.0272, 0.7258, 1.0940, 1.0057, 0.7004, 0.8066, 0.9215,\n",
      "        2.0929, 1.5619, 0.6761, 0.9801, 0.9196, 0.4975, 0.4267, 1.0167, 0.5229,\n",
      "        0.2790, 0.9582, 0.6987, 1.3572, 0.9900, 1.4760, 0.3047, 0.8747, 0.2191,\n",
      "        0.9973, 1.0055, 1.4432, 0.4559, 0.8073, 0.9804, 0.6636, 0.0103, 0.4109,\n",
      "        0.9122, 0.9580, 0.5711, 0.6599, 0.9041, 1.0943, 0.9192, 1.2726, 1.0090,\n",
      "        2.4546, 2.4822, 0.7594, 0.9464, 0.7926, 0.9576, 0.3862, 0.9779, 0.4474,\n",
      "        0.6511, 1.0061, 0.8442, 0.7539, 0.6781, 1.8174, 1.0401, 0.3172, 0.9050,\n",
      "        1.1201, 0.0860, 0.8790, 0.9281, 0.5879, 0.2184, 1.1066, 0.9981, 0.7468,\n",
      "        0.9881, 0.5905, 1.2862, 1.4775, 0.7809, 0.2539, 0.7410, 0.7222, 1.1726],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.2130, 0.6032, 1.1073, 0.9071, 0.6813, 1.1368, 0.9770, 0.8860, 0.4190,\n",
      "        0.8680, 0.5295, 1.3093, 0.2292, 1.3171, 0.1255, 1.0140, 1.1543, 0.9018,\n",
      "        1.0210, 1.9089, 2.9256, 0.2395, 0.7735, 0.8408, 1.1458, 0.4354, 1.8595,\n",
      "        0.4831, 1.1673, 1.4644, 0.5399, 0.7025, 0.5620, 0.5555, 1.1503, 1.0962,\n",
      "        0.7269, 0.5492, 0.5318, 0.9347, 0.8304, 0.9789, 0.0121, 0.7952, 0.6704,\n",
      "        1.0874, 0.9649, 0.4858, 0.0702, 0.8189, 0.9753, 0.5425, 0.5983, 0.9088,\n",
      "        0.8245, 1.4643, 1.4075, 0.3623, 0.5784, 1.0300, 1.1616, 0.9865, 0.6025,\n",
      "        0.2012, 1.0986, 0.7319, 0.6060, 1.5771, 0.7788, 0.4138, 0.7623, 0.8040,\n",
      "        1.3464, 0.1720, 0.6684, 0.7023, 1.9380, 1.1988, 0.0856, 0.9301, 1.3048,\n",
      "        0.0237, 0.8934, 0.4005, 1.0346, 2.2713, 1.7967, 0.9029, 1.1473, 1.2567,\n",
      "        1.2839, 1.2974, 0.7041, 1.4201, 0.4772, 1.5441, 0.1825, 1.8566, 1.0283,\n",
      "        0.6822, 0.5677, 0.7031, 0.1491, 0.0431, 0.2721, 0.8709, 0.8183, 0.0764,\n",
      "        0.0953, 1.2821, 0.9819, 0.3849, 0.6135, 0.5565, 0.1955, 1.1938, 0.2441,\n",
      "        1.1549, 0.7474, 0.8974, 0.8279, 1.3460, 1.1602, 0.3146, 0.3327, 0.3853],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.0243, 0.9534, 1.0468, 0.0394, 0.3834, 0.6644, 2.5675, 1.3891, 1.3711,\n",
      "        1.0527, 0.7659, 0.1429, 0.7969, 1.2197, 0.6488, 0.4233, 0.3812, 1.7358,\n",
      "        1.1426, 0.0423, 0.8500, 1.0140, 0.8981, 0.9159, 1.2876, 0.3975, 0.5599,\n",
      "        1.0624, 0.9241, 0.9336, 1.4099, 0.2632, 0.1106, 0.4766, 0.9070, 0.8162,\n",
      "        0.7293, 0.9307, 0.8016, 0.9489, 1.4733, 0.5926, 0.2381, 2.2594, 0.8484,\n",
      "        0.5511, 0.4363, 0.2262, 0.8433, 2.0789, 0.0705, 0.9454, 0.0340, 0.5788,\n",
      "        1.2277, 0.9779, 1.6401, 0.6534, 0.3703, 0.3063, 0.0356, 0.4322, 0.6700,\n",
      "        0.8461, 1.3742, 0.4813, 0.4915, 1.1900, 1.4159, 2.5769, 0.8202, 1.4456,\n",
      "        0.7768, 1.2509, 1.1579, 1.1464, 0.8893, 0.9711, 0.0746, 0.6268, 0.5887,\n",
      "        0.4588, 0.6035, 0.6900, 0.2456, 1.3043, 0.8560, 0.6028, 0.1734, 1.0235,\n",
      "        0.9486, 0.4334, 0.7745, 0.1982, 2.0181, 1.1446, 0.5270, 0.3539, 0.7492,\n",
      "        0.5575, 1.0845, 0.6854, 0.7093, 1.0155, 0.1778, 0.4732, 0.5394, 0.1494,\n",
      "        2.2168, 1.3045, 0.6397, 1.2007, 1.1116, 0.9328, 0.2621, 0.5686, 0.2220,\n",
      "        0.7006, 0.2086, 0.8507, 0.8517, 0.3881, 0.8412, 1.3097, 0.4677, 1.1407],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.2317, 5.6545, 4.6034, 0.4942, 0.5344, 0.6218, 0.2618, 0.5099, 1.0900,\n",
      "        0.8289, 1.9037, 0.3092, 0.9901, 0.8874, 1.1083, 0.8567, 1.5868, 1.1810,\n",
      "        2.1679, 0.1483, 1.2197, 0.3299, 2.1586, 1.0069, 0.3088, 0.4968, 0.2908,\n",
      "        0.5023, 2.5725, 2.7401, 1.5142, 0.5340, 0.6974, 0.2362, 2.8483, 0.6184,\n",
      "        1.6088, 0.7553, 0.2316, 1.1462, 1.2136, 0.7420, 0.0822, 1.2234, 0.0582,\n",
      "        1.9216, 0.4748, 1.5644, 0.5083, 1.5557, 0.9635, 1.0320, 1.2479, 1.0883,\n",
      "        0.5000, 0.7915, 2.5112, 0.9908, 1.8458, 0.7965, 0.6265, 1.1057, 0.3611,\n",
      "        0.6966, 1.4557, 3.6223, 0.5648, 2.3585, 0.6874], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([ 0.8420,  3.9278,  2.2287,  0.5287,  4.8153,  2.1460,  0.5370,  1.6268,\n",
      "         0.5479,  0.7591,  2.0633,  2.2424,  3.3369,  1.2684,  1.9364,  0.7718,\n",
      "         0.6492,  1.3306,  0.4520,  3.8026,  4.4240,  0.0571,  7.5289,  5.9130,\n",
      "         1.4778,  0.4767,  1.5740,  0.7077,  0.8037,  0.8967,  0.3586,  8.9657,\n",
      "         7.6720,  0.8166,  0.0811,  3.3076,  0.4482,  0.6340,  1.1707,  4.0666,\n",
      "         7.7831,  0.3985,  0.2576,  0.3443,  0.1275,  0.8190,  1.8053,  0.8778,\n",
      "         0.1592,  1.7018,  8.9536,  0.8139,  0.2896,  0.2407,  1.0180,  1.4091,\n",
      "         1.6105,  1.0114,  0.5235,  1.5932,  3.0329,  1.8530,  1.7430,  0.1903,\n",
      "         8.4607, 13.4524,  3.5811,  8.8292,  2.3574], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0202, 0.1282, 0.5028, 1.1228, 1.2122, 0.9516, 0.5020, 0.9211, 0.2697,\n",
      "        0.4014, 1.0124, 1.0766, 0.6409, 1.0338, 0.9992, 1.0223, 1.6952, 1.8360,\n",
      "        1.0897, 0.2749, 0.3935, 1.1035, 0.0175, 0.2504, 0.3095, 0.6203, 1.1251,\n",
      "        0.8755, 0.8482, 0.8241, 0.1508, 1.7193, 0.8684, 0.8453, 0.9305, 0.9801,\n",
      "        0.7787, 0.8145, 0.3741, 0.9196, 0.7696, 1.0354, 0.7433, 0.5571, 0.1796,\n",
      "        0.9431, 0.5086, 1.4031, 1.2723, 0.1841, 0.8367, 1.2165, 0.9592, 0.2759,\n",
      "        0.6334, 0.5402, 1.0422, 1.0077, 1.7187, 1.9510, 0.9901, 1.1538, 0.3013,\n",
      "        0.9923, 1.6060, 1.3446, 0.9263, 0.7929, 1.5231], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.5511, 1.1700, 1.2271, 0.7858, 0.8722, 0.7948, 0.9118, 0.9749, 0.9262,\n",
      "        0.9500, 1.0545, 1.0665, 0.9731, 0.9670, 0.9530, 1.0217, 0.9419, 1.0077,\n",
      "        0.9991, 0.7480, 0.8733, 0.6257, 1.3443, 1.0219, 0.9501, 0.9790, 0.9620,\n",
      "        0.6636, 0.9360, 0.8447, 0.3268, 0.7546, 0.1629, 1.0217, 0.7465, 0.8888,\n",
      "        1.0307, 0.8550, 1.0173, 1.0041, 1.0411, 0.9037, 0.7964, 0.9261, 1.0302,\n",
      "        0.9136, 0.8558, 0.8078, 0.4719, 0.9875, 0.9025, 1.1042, 1.0865, 1.0088,\n",
      "        1.1174, 0.8860, 1.0074, 0.7615, 1.0026, 0.9938, 0.7763, 1.0188, 0.9272,\n",
      "        0.8303, 1.0096, 0.9721, 0.7107, 0.2610, 0.8295], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0042, 0.9612, 0.9996, 1.0018, 0.9799, 0.9715, 0.9822, 0.9585, 1.0261,\n",
      "        1.0283, 0.9447, 0.9651, 0.8242, 1.0825, 1.1369, 0.7625, 0.8612, 0.6869,\n",
      "        0.4090, 0.9964, 0.9117, 0.9826, 0.9751, 0.8686, 0.9253, 0.9987, 1.0611,\n",
      "        0.6896, 0.9776, 0.9373, 0.8110, 0.7343, 0.6331, 0.9428, 0.8995, 1.0103,\n",
      "        0.6291, 1.0092, 1.0126, 0.9358, 0.4880, 0.9837, 0.9735, 0.9647, 0.9162,\n",
      "        0.9992, 1.1970, 1.0988, 1.0466, 1.0063, 0.3237, 1.0778, 1.0002, 1.0130,\n",
      "        0.9633, 0.9445, 0.8777, 0.8883, 0.9054, 0.9092, 0.9508, 0.9238, 0.9846,\n",
      "        0.9522, 0.9879, 1.0343, 1.0134, 0.8924, 1.0404], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0261, 1.0552, 0.8683, 0.8970, 0.9847, 0.9298, 0.9540, 0.7546, 0.8514,\n",
      "        0.9729, 1.0051, 0.9604, 0.9915, 1.0179, 0.9862, 1.0799, 0.9873, 0.9929,\n",
      "        0.2220, 0.9084, 0.9738, 1.0082, 0.9931, 1.0093, 0.9923, 0.9447, 0.9393,\n",
      "        0.6082, 0.7709, 0.9513, 0.6826, 0.8622, 0.9801, 0.9970, 1.0390, 0.9195,\n",
      "        0.9946, 1.0013, 0.9917, 1.0553, 0.9992, 0.9293, 1.0201, 0.8614, 1.0191,\n",
      "        0.6431, 1.1550, 1.0067, 0.7698, 0.6983, 0.9622, 0.9732, 0.8925, 0.9786,\n",
      "        0.9491, 1.0056, 0.9737, 1.0016, 1.0115, 0.8857, 1.0352, 0.8991, 0.7991,\n",
      "        1.0683, 1.0423, 0.9099, 0.9742, 0.8078, 0.8850], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0848, 0.9331, 0.8498, 0.9891, 0.9315, 0.9947, 0.9807, 0.7935, 0.9584,\n",
      "        0.8548, 0.9788, 0.8843, 0.8618, 1.0233, 0.7412, 0.9622, 0.9898, 1.0435,\n",
      "        1.0159, 0.8815, 1.0226, 0.9522, 0.8909, 0.9581, 0.9176, 0.8876, 0.6715,\n",
      "        1.0542, 1.1174, 0.8683, 0.9943, 1.0345, 1.0691, 0.5978, 0.7496, 0.6127,\n",
      "        0.9452, 0.9364, 0.9929, 0.9380, 0.9514, 1.0693, 0.9880, 1.0084, 1.0001,\n",
      "        0.6651, 0.5099, 0.8056, 0.7212, 0.9350, 0.2702], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.0084, 0.5631, 0.7383, 0.4720, 0.7780, 0.9679, 0.0393, 0.3523, 0.3693,\n",
      "        0.7535, 0.9458, 0.9793, 0.9900, 0.9679, 1.0659, 0.8813, 0.9879, 1.0905,\n",
      "        0.9815, 0.9557, 0.8090, 0.6607, 0.6149, 0.8519, 1.0778, 1.0096, 0.8922,\n",
      "        0.9861, 0.9801, 0.6979, 0.9072, 0.9842, 0.7722, 0.9327, 1.1677, 0.9739,\n",
      "        0.9629, 1.1189, 0.9955, 1.1098, 1.0444, 0.8330, 0.7971, 0.8498, 0.8596,\n",
      "        0.8354, 0.9519, 0.3078, 0.9647, 0.6074, 0.8172], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.8808, 0.9489, 0.7798, 0.6930, 0.9358, 0.8224, 0.8565, 0.7644, 0.3710,\n",
      "        0.9383, 1.0006, 0.7962, 1.0410, 1.1932, 1.0366, 0.6324, 0.9659, 1.0665,\n",
      "        0.8837, 0.7983, 0.7701, 0.9324, 0.4344, 0.4295, 0.9507, 1.0100, 0.6855,\n",
      "        0.7397, 0.8274, 1.0099, 1.4411, 0.9497, 0.7590, 1.1189, 1.0283, 1.0069,\n",
      "        1.0094, 0.6723, 0.9556, 0.9986, 1.0690, 1.0137, 0.9099, 0.4242, 0.7306,\n",
      "        0.4186, 0.9279, 1.0255, 0.8486, 0.9917, 1.0530], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9518, 0.8315, 0.3709, 0.9856, 0.9965, 0.9141, 0.9052, 0.8702, 0.9042,\n",
      "        0.3797, 0.3331, 0.9041, 0.9036, 0.8032, 1.0268, 0.4911, 1.0136, 1.0498,\n",
      "        0.6538, 0.2783, 0.3287, 0.2441, 0.6085, 0.6827, 1.0265, 0.2136, 0.3606,\n",
      "        0.6876, 0.6849, 0.9902, 0.9039, 0.8148, 1.1705, 0.9854, 0.9136, 1.0122,\n",
      "        1.0743, 1.0898, 0.1070, 0.9697, 1.0197, 0.8974, 0.1775, 0.1588, 0.4821,\n",
      "        0.9046, 0.2918, 0.5534, 0.2853, 1.0136, 0.8936], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.5848, 0.7211, 0.1393, 0.9516, 0.5686, 1.1202, 0.2654, 1.1069, 0.2139,\n",
      "        1.1385, 0.8218, 1.0877, 0.4044, 1.3570, 1.4536, 0.9089, 0.9428, 0.9969,\n",
      "        1.1560, 1.3578, 0.9324, 0.0892, 0.2906, 0.8552, 1.5171, 1.0770, 0.7558,\n",
      "        0.4837, 0.7446, 1.1174, 0.8671, 1.6394, 2.7167, 0.4961, 0.8158, 0.5515,\n",
      "        0.5699, 1.5834, 0.5125, 1.2087, 0.7609, 1.6654, 1.1115, 0.8172, 1.0115,\n",
      "        0.8556, 0.5322, 0.0184, 1.1088, 0.1720, 0.0766], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.9587, 0.7191, 1.9305, 0.8327, 1.1500, 0.7990, 0.2988, 0.6826, 1.4600,\n",
      "        1.0605, 0.8431, 0.7292, 0.7189, 0.9861, 0.8186, 0.6562, 2.3899, 0.2497,\n",
      "        1.0181, 0.0586, 0.4853, 0.6093, 1.5705, 0.6060, 1.1527, 1.1488, 0.2717,\n",
      "        3.5903, 0.1956, 3.5249, 1.7640, 0.1789, 0.7112, 2.0715, 0.8927, 0.5600,\n",
      "        1.3999, 1.2320, 2.3065, 1.6021, 0.2821, 1.5850, 0.9500, 1.0031, 0.4761,\n",
      "        0.6936, 0.8326, 0.3228, 1.0183, 0.8321, 0.9286], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([1.2479e-01, 7.4738e-01, 3.5649e-01, 1.4554e-01, 3.3307e-01, 5.5658e-01,\n",
      "        2.5518e-01, 4.2098e-01, 3.4503e-01, 1.2848e+00, 1.4496e-02, 9.7667e-01,\n",
      "        7.7684e-01, 1.1440e+00, 1.6673e+00, 8.3145e-01, 8.1883e-01, 2.4486e-01,\n",
      "        6.8610e-01, 8.2502e-02, 1.9919e-01, 1.6240e+00, 5.2214e-01, 1.2688e+00,\n",
      "        8.6335e-01, 8.3010e-01, 1.0543e-02, 9.3519e-01, 2.0287e+00, 8.7588e-02,\n",
      "        1.0722e+00, 4.6102e-01, 1.2208e+00, 1.9351e+00, 7.2558e-01, 5.5198e-01,\n",
      "        1.0503e+00, 5.6148e-02, 6.4923e-01, 4.7012e-01, 7.9580e-01, 1.0995e+00,\n",
      "        4.5527e-01, 7.1287e-01, 7.7709e-01, 1.1645e+00, 1.1179e+00, 1.9950e+00,\n",
      "        8.5118e-01, 7.6025e-01, 4.0004e-01, 9.7084e-01, 8.7175e-01, 6.7005e-01,\n",
      "        1.8565e+00, 1.6404e+00, 2.3713e-01, 8.9908e-01, 2.0206e+00, 2.8922e-01,\n",
      "        9.7518e-01, 5.3980e-01, 4.9864e-01, 1.8433e-01, 3.4229e-01, 2.9897e-01,\n",
      "        9.7547e-02, 1.0874e+00, 1.0558e+00, 6.9353e-01, 7.1484e-01, 1.5709e+00,\n",
      "        4.7812e+00, 6.3676e-01, 1.3876e+00, 8.5609e-01, 1.0907e+00, 1.3446e-01,\n",
      "        1.1138e+00, 2.1559e-01, 7.5727e-01, 1.7469e+00, 8.0070e-01, 1.6367e+00,\n",
      "        1.8711e+00, 3.4385e-01, 1.9711e+00, 9.2281e-01, 7.7569e-01, 5.4936e-01,\n",
      "        7.7521e-01, 4.8888e-01, 3.9763e-01, 6.1686e-01, 8.9983e-01, 7.2881e-01,\n",
      "        7.8009e-01, 1.2055e+00, 5.1372e-01, 1.0782e+00, 2.5090e-01, 3.8349e-01,\n",
      "        8.7324e-01, 7.6268e-01, 7.3517e-01, 2.6320e+00, 6.1108e-01, 1.2926e+00,\n",
      "        8.4673e-01, 1.5316e-01, 9.3979e-01, 3.8606e+00, 1.0467e+00, 9.5100e-01,\n",
      "        7.8593e-01, 9.2036e-01, 9.8753e-01, 3.7608e-03, 2.6295e-01, 9.2319e-01,\n",
      "        6.6594e-01, 4.2338e-01, 9.2217e-01, 3.5397e+00, 1.8662e-01, 6.4394e-01,\n",
      "        7.6222e-01, 9.7985e-01, 9.0039e-01, 4.5881e-01, 1.2567e+00, 2.7640e-01,\n",
      "        1.1926e+00, 4.2529e-01, 6.5375e-01, 1.9069e+00, 1.1272e+00, 4.7751e-01,\n",
      "        9.4564e-01, 7.3941e-01, 9.6694e-01, 2.9299e-01, 6.0618e-01, 1.0398e+00,\n",
      "        1.4514e+00, 1.2512e+00, 1.0512e+00, 4.1410e-01, 5.0768e-01, 1.6201e+00,\n",
      "        2.4387e-01, 9.9404e-02, 3.7870e-01, 4.7801e-01, 4.5236e-01, 1.0716e+00,\n",
      "        3.9826e-01, 1.0161e+00, 9.9299e-01, 6.9152e-01, 9.1820e-01, 6.5537e-02,\n",
      "        2.0521e+00, 6.8451e-01, 5.6399e-01], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9930, 0.3378, 0.7812, 5.7474, 3.6394, 1.0100, 1.6001, 0.8740, 0.2991,\n",
      "        0.0123, 0.8944, 0.2231, 1.6758, 1.6035, 1.0427, 0.2278, 7.9135, 7.0979,\n",
      "        0.5708, 0.2793, 0.6620, 0.6024, 0.7315, 0.9141, 1.0820, 0.9652, 2.0816,\n",
      "        1.5334, 1.7776, 1.6127, 0.9361, 0.1607, 1.8977, 1.2281, 1.4295, 3.3282,\n",
      "        0.8493, 0.5261, 0.3268, 6.8592, 1.7441, 4.3238, 0.9817, 1.1583, 0.0389,\n",
      "        0.0140, 1.9396, 0.9783, 0.2957, 3.3621, 3.7537, 0.2847, 0.4218, 0.7493,\n",
      "        0.4286, 0.3519, 0.7447, 1.4538, 0.4812, 0.4757, 0.7906, 0.4090, 2.0279,\n",
      "        0.8320, 0.6658, 1.3672, 1.4112, 0.3162, 0.0145, 1.0259, 1.7812, 1.4210,\n",
      "        0.3452, 0.4610, 0.1847, 2.1806, 0.2485, 0.6266, 1.4932, 0.5358, 1.6359,\n",
      "        1.6117, 0.2468, 1.4644, 1.6273, 3.9958, 9.7452, 0.6216, 0.9164, 3.1641,\n",
      "        0.4632, 0.5858, 1.2577, 1.1039, 0.3644, 1.0332, 0.6956, 1.8998, 0.9342,\n",
      "        0.7898, 0.6934, 0.4216, 0.2174, 0.3103, 0.6960, 1.6326, 4.6699, 0.3249,\n",
      "        0.9601, 0.1127, 0.4235, 0.8423, 1.0236, 0.9849, 3.1135, 1.2861, 0.0952,\n",
      "        0.0688, 1.0993, 1.1316, 1.0134, 0.2249, 2.2894, 2.8313, 0.4087, 0.8154,\n",
      "        0.1639, 1.1735, 2.5629, 0.6834, 0.5519, 2.1766, 1.1464, 0.5094, 0.5265,\n",
      "        0.0580, 0.3076, 1.9260, 0.0859, 0.6031, 2.0698, 1.4264, 0.3248, 8.2700,\n",
      "        0.6624, 1.5848, 0.2380, 0.1784, 0.5343, 1.1632, 1.3615, 0.9372, 0.6445,\n",
      "        0.9752, 0.7219, 0.0391, 1.7662, 1.0314, 0.8602, 1.6750, 0.6683, 0.4615,\n",
      "        0.5366, 1.4567, 1.7710], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.7077, 1.0506, 1.4868, 0.4135, 0.9375, 0.8290, 0.0327, 0.7943, 0.9589,\n",
      "        0.0824, 0.9429, 0.7218, 0.4410, 0.7315, 1.2447, 2.1480, 1.3619, 0.8392,\n",
      "        0.9574, 0.1915, 1.1471, 0.8876, 2.2020, 0.4868, 0.0714, 0.1999, 0.6401,\n",
      "        2.0238, 0.5467, 1.5361, 0.6174, 1.1147, 1.4011, 0.1228, 0.2778, 0.5585,\n",
      "        3.9672, 0.0687, 0.7172, 1.1687, 0.5634, 0.8175, 1.0042, 2.0045, 1.5486,\n",
      "        1.2227, 0.1538, 4.3407, 0.8741, 0.3292, 0.3514, 0.1506, 0.4862, 0.8305,\n",
      "        0.2535, 0.1841, 0.6922, 1.0390, 0.9993, 0.5369, 0.0091, 1.3792, 1.2745,\n",
      "        0.9002, 0.9250, 0.2418, 0.6569, 0.9255, 0.2684, 0.4753, 0.0088, 0.9073,\n",
      "        0.9464, 0.9479, 0.9888, 1.6175, 0.5869, 0.6672, 0.9874, 0.3447, 0.7005,\n",
      "        2.4179, 1.4913, 0.6474, 2.5658, 0.3120, 2.5662, 0.2136, 0.8969, 1.4067,\n",
      "        0.4786, 1.0065, 0.3496, 0.1814, 1.0450, 0.7052, 2.7852, 1.1657, 0.7377,\n",
      "        0.4891, 0.3592, 0.9211, 0.1948, 0.6258, 0.2268, 0.1130, 0.3818, 1.8336,\n",
      "        0.7218, 1.1709, 1.1442, 1.5949, 1.9715, 0.4382, 0.3921, 0.4697, 0.2758,\n",
      "        0.4418, 0.7733, 1.3077, 4.4913, 2.6380, 0.5960, 1.5716, 1.3295, 0.5780,\n",
      "        1.2496, 0.4052, 0.6034, 0.6645, 0.0086, 0.0354, 0.5453, 0.3849, 0.9373,\n",
      "        2.0227, 1.1333, 0.1741, 2.2490, 0.9128, 0.1326, 0.0547, 1.5730, 0.3744,\n",
      "        0.5166, 2.8542, 1.6622, 0.8390, 0.2037, 0.3760, 0.8288, 1.1134, 1.1752,\n",
      "        1.7035, 1.0794, 0.0479, 0.2780, 1.1693, 1.3797, 2.3912, 0.3270, 2.3398,\n",
      "        0.5422, 0.7471, 0.3489], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([0.4708, 0.6901, 0.2785, 1.2676, 1.2297, 0.1683, 1.6413, 0.0122, 0.0834,\n",
      "        0.3869, 0.8397, 2.0412, 0.6568, 0.5410, 0.9316, 0.6099, 0.7286, 1.6962,\n",
      "        2.6300, 2.3942, 0.9052, 1.2737, 1.0164, 0.1382, 0.4365, 0.6629, 0.0150,\n",
      "        1.2224, 1.2256, 0.6982, 0.7015, 0.2172, 0.3964, 0.6248, 1.4868, 3.4885,\n",
      "        0.0883, 1.1555, 1.1323, 0.0495, 0.9333, 0.4503, 1.0002, 0.9991, 0.9524,\n",
      "        1.0105, 0.0441, 0.0517, 0.8575, 0.9755, 0.1106, 0.8049, 0.8826, 1.0466,\n",
      "        1.1984, 1.4243, 0.9907, 0.3284, 1.6590, 1.6110, 1.3195, 2.6423, 0.4097,\n",
      "        0.6519, 0.5539, 1.0728, 1.0004, 0.0436, 1.0752, 1.1736, 0.7745, 0.2202,\n",
      "        0.9976, 1.0107, 0.7467, 1.0088, 0.9537, 0.3709, 0.6267, 0.0689, 0.3620,\n",
      "        0.1916, 0.2768, 0.4245, 0.4088, 0.8932, 1.1879, 0.8625, 1.2459, 0.7477,\n",
      "        0.6427, 0.4828, 0.9963, 0.2130, 0.9144, 0.2528, 0.2617, 0.2156, 0.0937,\n",
      "        0.5545, 0.8760, 1.3112, 0.2801, 1.9382, 0.6796, 0.5338, 1.3616, 1.4057,\n",
      "        1.1168, 0.6091, 1.1542, 1.3268, 0.8497, 0.7392, 0.4015, 0.5419, 0.6804,\n",
      "        0.3527, 0.9870, 0.9991, 0.1865, 0.2086, 0.9965, 0.2172, 0.4341, 0.5996,\n",
      "        0.4869, 3.2029, 2.8452, 1.0691, 0.8694, 0.6573, 0.4617, 0.4605, 0.4572,\n",
      "        0.5651, 0.3603, 0.7324, 1.1769, 0.4480, 0.7348, 2.0764, 2.9752, 0.8053,\n",
      "        0.7510, 0.9955, 0.9206, 0.7260, 0.9665, 0.6150, 0.3760, 0.6866, 0.2001,\n",
      "        3.3833, 1.5126, 0.8255, 0.8230, 0.0389, 0.1580, 0.0177, 0.9232, 0.8101,\n",
      "        0.3795, 0.0691, 0.2995], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([2.2788e-01, 4.9356e-01, 2.3421e-01, 7.9508e-01, 1.0404e+00, 8.8414e-01,\n",
      "        4.2042e-01, 5.6129e-01, 1.4241e+00, 1.4678e+00, 8.1817e-01, 6.9589e-01,\n",
      "        2.4305e-02, 1.8044e-01, 3.5893e-01, 9.9992e-01, 1.0382e+00, 8.6232e-01,\n",
      "        6.9302e-01, 3.4520e-01, 8.7570e-01, 3.6301e-01, 1.4773e+00, 7.7369e-01,\n",
      "        1.8789e+00, 7.0272e-01, 9.4829e-01, 8.9403e-01, 5.9812e-01, 7.6076e-01,\n",
      "        6.8686e-01, 4.7058e-01, 7.8253e-01, 2.1170e-01, 1.9709e+00, 8.1080e-01,\n",
      "        4.5095e-01, 2.6641e-01, 5.2501e-01, 1.4847e+00, 1.1840e-01, 6.7793e-01,\n",
      "        5.9104e-01, 1.9750e-01, 1.9143e-01, 7.5895e-01, 9.6330e-01, 8.3662e-01,\n",
      "        8.0546e-01, 9.0143e-01, 3.7255e-01, 1.4437e+00, 2.2294e-01, 1.0468e+00,\n",
      "        1.2795e+00, 4.3878e-01, 6.3640e-01, 2.4480e-01, 1.1153e+00, 5.0687e-01,\n",
      "        7.7081e-02, 9.3516e-01, 2.9874e-01, 3.4623e+00, 8.7410e-01, 2.1402e+00,\n",
      "        1.2204e+00, 1.4671e+00, 1.4406e+00, 5.9087e-01, 1.0246e+00, 2.3584e-01,\n",
      "        9.6532e-01, 1.7196e+00, 3.2781e+00, 1.3935e+00, 4.7814e-01, 9.3709e-01,\n",
      "        1.0944e+00, 7.1053e-01, 1.6834e-01, 4.0702e-01, 2.8346e-01, 3.3817e-01,\n",
      "        3.5915e-03, 1.9486e+00, 1.8153e+00, 4.6089e-01, 1.5062e+00, 8.3593e-01,\n",
      "        8.6451e-01, 1.6878e-01, 1.0355e+00, 9.5514e-01, 4.3819e-01, 3.5542e-01,\n",
      "        2.7568e-01, 9.3155e-01, 9.6263e-01, 5.2075e-01, 3.5354e-01, 1.0310e+00,\n",
      "        4.3525e-01, 1.0214e+00, 8.8063e-01, 9.1316e-01, 5.3327e-02, 7.8637e-01,\n",
      "        1.0987e+00, 1.0110e+00, 4.4546e-01, 3.4953e-01, 8.5688e-01, 2.4258e-01,\n",
      "        6.6145e-01, 4.8656e-01, 7.0225e-01, 9.4152e-01, 6.1333e-01, 4.6685e-02,\n",
      "        1.4130e+00, 1.4923e+00, 6.2492e-01, 2.6242e+00, 1.6595e+00, 1.4026e+00,\n",
      "        9.3967e-01, 7.3366e-01, 9.1615e-01, 7.8920e-01, 9.6809e-01, 3.5662e-01,\n",
      "        1.4847e-01, 9.0384e-01, 3.6582e-01, 9.0213e-01, 7.9850e-01, 1.3530e+00,\n",
      "        1.8287e+00, 4.2818e-01, 5.5502e+00, 2.4832e-01, 3.7669e-01, 1.8017e-01,\n",
      "        4.1396e-01, 4.1522e-01, 6.3604e-01, 1.2783e-01, 1.5610e-01, 8.9625e-01,\n",
      "        7.1890e-01, 9.1021e-01, 8.1062e-01, 2.1302e+00, 5.5828e-01, 3.3174e+00,\n",
      "        6.8002e-02, 6.5935e-01, 1.4601e+00, 7.6244e+00, 1.1255e+00, 7.4901e-01,\n",
      "        2.6599e-01, 8.9309e-01, 9.4583e-01], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([5.5021e-02, 1.8524e-02, 1.0035e+00, 2.3643e+00, 8.4833e-01, 9.1551e-01,\n",
      "        3.9402e-01, 1.0974e+00, 2.3410e-01, 1.7397e+00, 7.8095e-01, 6.8429e-01,\n",
      "        1.6913e-01, 8.6262e-01, 1.1407e+00, 1.1036e+00, 6.3410e-01, 5.7294e-01,\n",
      "        5.9890e-01, 1.4642e-01, 6.3147e-01, 1.0055e+00, 4.3422e-01, 8.3844e-01,\n",
      "        1.3130e+00, 7.0586e-02, 1.6464e+00, 4.3867e-01, 2.6770e+00, 8.0146e-01,\n",
      "        4.3255e-01, 4.3016e-01, 1.8764e+00, 3.2963e+00, 4.7590e-01, 1.2854e+00,\n",
      "        9.6994e-01, 3.9072e-01, 4.9830e-01, 7.2641e-01, 3.5917e-01, 9.8106e-01,\n",
      "        1.3373e+00, 1.7375e-01, 1.0265e+00, 4.2117e+00, 8.1714e-01, 8.6162e-01,\n",
      "        3.3922e-01, 3.5568e-01, 4.0582e-01, 4.5367e-01, 2.5485e-01, 4.4341e-01,\n",
      "        1.0019e+00, 1.0027e+00, 1.0397e+00, 9.1150e-01, 9.9435e-01, 2.2099e-01,\n",
      "        8.6755e-01, 2.9886e-01, 1.9011e+00, 7.0621e-01, 1.3529e+00, 1.0008e+00,\n",
      "        5.9602e-01, 9.9971e-01, 6.0275e-01, 5.1600e-01, 9.2114e-01, 9.9668e-01,\n",
      "        2.4151e-01, 6.2768e-01, 9.7182e-01, 1.3426e+00, 1.8413e+00, 3.3732e-01,\n",
      "        2.2587e-01, 4.4707e-01, 1.8980e+00, 1.0493e+00, 8.1932e-01, 1.1732e+00,\n",
      "        8.0646e-01, 3.8302e-01, 5.8447e-01, 2.9686e-01, 4.1010e-02, 7.4351e-01,\n",
      "        7.2869e-01, 6.7180e-01, 1.4426e+00, 1.3124e+00, 9.8635e-01, 1.0480e+00,\n",
      "        8.5822e-01, 1.5586e+00, 8.7137e-01, 1.0761e+00, 1.1218e+00, 1.5478e-01,\n",
      "        4.7807e-01, 2.4316e-01, 9.0839e-01, 6.8340e-01, 6.1026e-01, 2.8847e-01,\n",
      "        9.4665e-01, 6.7055e-01, 1.5462e+00, 1.0990e+00, 1.8944e-03, 7.2641e-01,\n",
      "        5.8951e-02, 7.7399e-01, 1.3197e+00, 8.3813e-01, 9.9950e-01, 1.8011e+00,\n",
      "        1.2534e+00, 1.1443e-01, 5.3352e-01, 8.4359e-03, 1.0527e+00, 1.2302e+00,\n",
      "        2.2711e-02, 1.0612e+00, 1.9274e-01, 9.1494e-01, 1.4609e-01, 3.4131e-01,\n",
      "        3.4932e-01, 4.2347e-01, 9.9504e-01, 9.3328e-01, 1.3085e+00, 9.4375e-01,\n",
      "        5.8497e-01, 6.0859e-01, 3.7615e-01, 7.3157e-02, 5.1856e-01, 9.9544e-01,\n",
      "        1.4160e+00, 6.0235e-01, 7.5214e-01, 2.4071e-01, 7.0408e-01, 2.1104e-02,\n",
      "        1.0903e+00, 1.2986e+00, 1.2397e+00, 7.7611e-01, 6.9318e-01, 2.3144e-01,\n",
      "        4.4191e-01, 8.2123e-02, 5.8627e-01, 3.6044e-01, 7.3585e-01, 5.7550e-01,\n",
      "        4.6543e-01, 8.4955e-01], device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [04:33<18:00, 135.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 02/10 LOSS: 1.0119 tensor([ 79.9771,   6.9032,  15.0976,  17.1235,  28.2978,  98.8012,   8.5610,\n",
      "        108.1576,   1.7469,  19.5355,   2.8446,  35.4882,  44.4491,  10.1770,\n",
      "         45.7215,  10.5877,   1.1044,   7.5530,  35.4151,   9.8341,  47.6233,\n",
      "         63.6645,  47.3286,  71.3572, 159.3850,  70.3525,   9.1882,   0.5386,\n",
      "         76.7852,  78.9236,  88.2306, 262.2958,  86.8061, 231.2738,  35.9536,\n",
      "        187.3986,  80.5420,  27.8371,  48.8189, 153.7679, 310.9901, 147.9766,\n",
      "        408.3677, 111.2057,   1.3133,  18.5587,  22.6203,   8.8069,   4.5712,\n",
      "         15.8250,  25.1122,  56.9905,   2.9567], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.9540, 0.9239, 0.9820, 0.9988, 0.9046, 0.8506, 0.6857, 1.0341, 1.0095,\n",
      "        1.0239, 1.0163, 0.9981, 0.9886, 1.0049, 1.0079, 1.0762, 0.9074, 0.9771,\n",
      "        1.0727, 0.9429, 1.0053, 0.9739, 1.0303, 1.0016, 0.9965, 1.0127, 1.0059,\n",
      "        0.9361, 0.9600, 0.9102, 0.9653, 1.1052, 1.0554, 0.9389, 1.0040, 0.9779,\n",
      "        0.9932, 0.8961, 0.9519, 1.2286, 0.9073, 0.5175, 0.9540, 1.0789, 1.0128,\n",
      "        0.9895, 0.9397, 0.9918, 0.8715, 0.9279, 0.9941, 0.9949, 0.9815, 0.8335,\n",
      "        0.9911, 1.0000, 1.0038, 1.1030, 1.0547, 0.9654], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([0.6835, 4.3592, 0.9985, 0.5052, 0.8044, 0.8266, 0.9077, 0.6194, 1.2781,\n",
      "        0.7791, 1.1226, 2.5468, 0.8366, 1.5456, 1.4644, 0.2724, 1.3025, 1.4993,\n",
      "        0.0347, 0.7347, 0.0695, 0.7752, 1.1352, 1.1333, 0.1403, 1.0598, 1.0137,\n",
      "        0.9677, 0.1336, 0.5569, 0.6019, 0.9204, 0.1639, 0.2607, 0.9386, 0.5781,\n",
      "        1.8202, 0.1787, 1.4663, 0.5971, 0.6256, 0.3795, 0.0958, 2.4269, 1.6257,\n",
      "        1.3784, 0.8005, 1.3830, 1.5789, 1.2024, 1.0467, 0.8029, 0.6400, 0.8731,\n",
      "        7.1042, 1.4000, 0.3184, 1.1122, 1.4672, 0.6154], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([ 3.0959,  1.1115,  1.5837,  1.0411,  1.0543,  4.5827,  1.2655,  0.3048,\n",
      "         1.4107,  0.0889,  0.5417,  0.4568,  1.0616,  3.2476,  7.3807,  8.9781,\n",
      "         0.0782,  1.1278,  1.4195,  1.4643,  3.1640,  1.1500,  0.7848,  4.6969,\n",
      "         7.6672,  9.2966,  2.2860,  2.5207,  1.5725,  3.2142,  1.6917,  0.4186,\n",
      "         2.0524,  1.2836,  1.2734,  1.1901,  5.7433,  2.5217,  1.1342,  0.8060,\n",
      "         2.3454,  0.7080,  5.5187,  1.8043,  1.2213,  1.5469,  0.9100,  1.4374,\n",
      "         0.6044,  0.5588,  0.3464,  1.6434,  1.3339,  0.9031,  0.5092,  0.8612,\n",
      "         1.5376, 10.7103,  3.3399], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([1.8463e+00, 1.5327e+01, 5.5005e+01, 1.5348e+02, 4.6795e+00, 8.7682e+01,\n",
      "        6.4177e+00, 2.7034e+00, 9.7624e-01, 1.5339e+01, 5.3623e+00, 2.9205e+00,\n",
      "        1.4244e+00, 3.8181e+01, 3.8386e+01, 1.2139e+02, 7.2714e+00, 4.0611e+01,\n",
      "        5.8850e-01, 1.8457e+01, 3.6871e+01, 1.1106e+02, 1.8404e+00, 1.5671e+01,\n",
      "        1.0297e+01, 1.6032e+01, 2.7192e+01, 2.2575e+00, 3.2914e+01, 1.1069e+00,\n",
      "        1.5380e+00, 1.8729e+00, 1.2977e+01, 4.8048e+01, 2.3609e+02, 1.2955e+01,\n",
      "        1.5128e+01, 7.7680e+00, 9.0784e+01, 4.8561e+01, 1.9125e+01, 4.2947e+01,\n",
      "        5.9387e-01, 2.7667e+00, 1.6771e-02, 4.5047e+01, 8.7504e+01, 4.1629e+00,\n",
      "        3.6532e+01, 7.0620e+00, 3.0859e+01, 3.6368e+00, 2.6761e+01, 2.6627e+01,\n",
      "        9.4855e+00, 1.1598e+02, 1.2957e+02, 1.6298e+01, 1.6872e+01],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([7.1439e+02, 1.5154e+02, 1.7183e+01, 1.6708e+02, 6.2089e+01, 1.2822e+02,\n",
      "        1.6577e+02, 5.4868e+02, 1.0055e+02, 3.1567e+01, 8.0860e+03, 9.6710e+03,\n",
      "        2.3383e+02, 1.8000e+00, 3.4017e+02, 1.5287e+02, 1.2925e+02, 1.3314e+02,\n",
      "        1.9400e+01, 4.1803e+02, 1.0213e+02, 1.2924e+01, 2.2179e+02, 9.7106e+02,\n",
      "        1.3825e+02, 6.5791e+02, 3.7440e+02, 1.2128e+01, 1.3526e+02, 1.4982e+03,\n",
      "        2.2133e+03, 2.2958e+02, 5.3601e+01, 2.2148e+01, 2.5169e+01, 9.2208e+01,\n",
      "        1.5274e+02, 4.1535e+02, 1.5195e+02, 1.0051e+02, 6.0790e+02, 1.4140e+01,\n",
      "        3.7064e+00, 5.5606e+01, 2.8177e+03, 1.1789e+03, 1.6531e+03, 6.9506e+02,\n",
      "        3.0350e+02, 1.0678e+05, 7.2100e+04, 3.8854e+01, 9.4908e+02, 7.5354e+02,\n",
      "        9.9279e+03, 2.9233e+04, 2.3594e+02], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n",
      "tensor([8.0908e+21, 2.6535e+21, 3.5998e+22, 6.1185e+23, 8.8004e+23, 1.9951e+22,\n",
      "        3.8941e+22, 6.2675e+22, 9.1753e+19, 3.9970e+23, 5.2602e+23, 9.0651e+23,\n",
      "        6.2842e+22, 1.1711e+24, 2.0700e+22, 1.2069e+21, 4.8187e+21, 1.7065e+23,\n",
      "        2.8838e+21, 2.5042e+23, 2.8794e+23, 2.9349e+23, 3.1196e+23, 1.2177e+23,\n",
      "        2.5759e+22, 2.4337e+22, 2.4550e+21, 9.4773e+23, 8.3675e+23, 1.4443e+22,\n",
      "        1.4217e+24, 3.2729e+23, 8.6811e+23, 4.1367e+22, 1.6946e+24, 2.5485e+23,\n",
      "        3.8605e+22, 3.7132e+23, 9.7287e+23, 1.4649e+23, 7.5259e+19, 7.5696e+22,\n",
      "        1.1398e+23, 8.3981e+21, 6.3666e+22, 1.5250e+23, 8.2901e+21, 4.2660e+23,\n",
      "        1.7676e+23, 1.8934e+22, 4.0511e+22, 2.3703e+22, 5.6302e+22, 9.1156e+21,\n",
      "        4.6080e+23, 5.7820e+22, 1.5020e+23, 2.1742e+22, 3.1728e+22, 1.1283e+24,\n",
      "        1.7306e+24, 7.0583e+22, 2.4396e+22, 3.0304e+23, 6.7661e+22, 1.3804e+23,\n",
      "        1.4301e+23, 2.1976e+21, 2.6660e+23, 4.0605e+22, 2.8414e+23, 8.9194e+22,\n",
      "        9.4132e+22, 1.1786e+23, 6.0018e+23, 5.0119e+23, 3.1810e+21, 3.1964e+21,\n",
      "        4.3133e+23, 2.7416e+23], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([nan], device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [05:56<23:47, 178.48s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-15-60de3835e7c4>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[1;31m# start training\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 31\u001B[1;33m \u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_trainer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-14-aa7d0667a7f9>\u001B[0m in \u001B[0;36mrun_trainer\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     44\u001B[0m                     \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# one backward pass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     45\u001B[0m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 46\u001B[1;33m                     \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     47\u001B[0m                     \u001B[0minput\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     48\u001B[0m                     \u001B[0mtarget\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "\n",
    "# model\n",
    "embedding_net = EmbeddingNet()\n",
    "model = embedding_net.to(device)\n",
    "\n",
    "\n",
    "# margin value\n",
    "margin=1\n",
    "\n",
    "# criterion\n",
    "criterion = TripletLoss(margin,  Informative_Negative_TripletSelector(margin))\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(model=model,\n",
    "                  device=device,\n",
    "                  criterion=criterion,\n",
    "                  optimizer=optimizer,\n",
    "                  training_dict=train_loader_dict,\n",
    "                  validation_DataLoader=train_loader_dict,\n",
    "                  epochs=10)\n",
    "\n",
    "# start training\n",
    "trainer.run_trainer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "name = 'test_scnn2'\n",
    "state = {'net': model.state_dict(),'loss': 1.0}\n",
    "if not os.path.isdir('checkpoint'):\n",
    "    os.mkdir('checkpoint')\n",
    "torch.save(state, './checkpoint/%s.t7'%(name))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['annotated_images', 'annotated_images_labels', 'unseen_images', 'unseen_images_labels'])\n"
     ]
    }
   ],
   "source": [
    "# load the test data:\n",
    "\n",
    "data_dict_test = load_data('test_data_task1.pkl')\n",
    "# keys are 'annotated_images', 'annotated_images_labels', 'unseen_images', 'unseen_images_labels'.\n",
    "# These keys correspond to the annotated images with known labels for each test alphabet (the sets A);\n",
    "# labels of the images with known labels for each test alphabet;\n",
    "# to-be-labeled unseen images for each test alphabet (sets U);\n",
    "# and labels of the to-be-labeled unseen images for each alphabet, respectively.\n",
    "# For each alphabet, the labels of the unseen images should be predicted by the model.\n",
    "# The true labels of the unseen images can only be used to calculate evaluation metrics.\n",
    "print(data_dict_test.keys())\n",
    "\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f82021775a0a6fbf",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Old_Church_Slavonic_(Cyrillic) annotated images: torch.Size([45, 1, 105, 105])\n",
      "Number of Old_Church_Slavonic_(Cyrillic) annotated labels: 45\n",
      "Shape of Old_Church_Slavonic_(Cyrillic) unseen images: torch.Size([855, 1, 105, 105])\n",
      "Number of Old_Church_Slavonic_(Cyrillic) unseen labels: 855. Use the unseen labels only for evaluating your model!\n"
     ]
    }
   ],
   "source": [
    "# example: let's get some annotated images and their labels for an alphabet in the test data:\n",
    "\n",
    "alphabets_test = list(data_dict_test['annotated_images'].keys())\n",
    "alphabet_id = np.random.randint(0, len(alphabets_test))\n",
    "alphabet = alphabets_test[alphabet_id]\n",
    "\n",
    "alphabet_annotated = data_dict_test['annotated_images'][alphabet]  # a tensor of shape (num_images, 1, height, width)\n",
    "print(f'Shape of {alphabet} annotated images:', alphabet_annotated.shape)\n",
    "\n",
    "alphabet_annotated_labels = data_dict_test['annotated_images_labels'][alphabet]  # a list of length num_images\n",
    "print(f'Number of {alphabet} annotated labels:', len(alphabet_annotated_labels))  # equals num_images\n",
    "\n",
    "alphabet_unseen = data_dict_test['unseen_images'][alphabet]  # a tensor of shape (num_images, 1, height, width)\n",
    "print(f'Shape of {alphabet} unseen images:', alphabet_unseen.shape)\n",
    "\n",
    "alphabet_unseen_labels = data_dict_test['unseen_images_labels'][alphabet]  # a list of length num_images\n",
    "print(f'Number of {alphabet} unseen labels: {len(alphabet_unseen_labels)}. Use the unseen labels only for evaluating your model!')  # equals num_images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eedf16c955d94af7",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# evaluation of the model:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1966916fdd423fe",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1.t7 LOSS:\t 1.0\n"
     ]
    }
   ],
   "source": [
    "# device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "def load_net(name,architecture, path = \"checkpoint/\"):\n",
    "    checkpoint = torch.load(path+name,map_location='cpu')\n",
    "    architecture.load_state_dict(checkpoint['net'])\n",
    "    architecture.eval()\n",
    "    print(name+' LOSS:\\t',checkpoint['loss'])\n",
    "    return architecture\n",
    "model = EmbeddingNet()\n",
    "model = load_net('test1.t7', model).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "char_dict = {f\"character{i:02d}\": i - 1 for i in range(1, 100)}\n",
    "annotated_loader_dict = {}\n",
    "annotated_images_dict = data_dict_test['annotated_images']\n",
    "annotated_targets_dict = data_dict_test['annotated_images_labels']\n",
    "# Iterate over the dictionary items (label: images_list)\n",
    "for alphabet in alphabets_test:\n",
    "    images = annotated_images_dict[alphabet]\n",
    "    targets = annotated_targets_dict[alphabet]\n",
    "    targets = [char_dict[key] for key in targets]\n",
    "    annotated_loader = torch.utils.data.DataLoader(list(zip(images, targets)), batch_size=200)\n",
    "    annotated_loader_dict[alphabet] = annotated_loader\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "char_dict = {f\"character{i:02d}\": i - 1 for i in range(1, 100)}\n",
    "test_loader_dict = {}\n",
    "test_images_dict = data_dict_test['unseen_images']\n",
    "test_targets_dict = data_dict_test['unseen_images_labels']\n",
    "# Iterate over the dictionary items (label: images_list)\n",
    "for alphabet in alphabets_test:\n",
    "    images = test_images_dict[alphabet]\n",
    "    targets = test_targets_dict[alphabet]\n",
    "    targets = [char_dict[key] for key in targets]\n",
    "    test_loader = torch.utils.data.DataLoader(list(zip(images, targets)), batch_size=200)\n",
    "    test_loader_dict[alphabet] = test_loader\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "200\n",
      "Targets (labels):\n",
      "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "         8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10])\n",
      "Batch 1:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "200\n",
      "Targets (labels):\n",
      "tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15,\n",
      "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17,\n",
      "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18,\n",
      "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19,\n",
      "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "        20, 21])\n",
      "Batch 2:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "94\n",
      "Targets (labels):\n",
      "tensor([21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
      "        22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n",
      "        24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "        25, 25, 25, 25])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#print(len(annotated_loader_dict['Atemayar_Qelisayer']))\n",
    "i=0\n",
    "for batch_idx, (inputs, targets) in enumerate(test_loader_dict['Atemayar_Qelisayer']):\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(\"Inputs (features):\")\n",
    "    print(type(inputs))\n",
    "    print(len(targets))  # Print input data (features)\n",
    "    print(\"Targets (labels):\")\n",
    "    print(targets)\n",
    "    i+=1\n",
    "print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "10"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_layer = list(model.children())[-1]\n",
    "last_layer.out_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def extract_embeddings(dataloader, model, out_features):\n",
    "    cuda = torch.cuda.is_available()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        embeddings = np.zeros((len(dataloader.dataset), out_features))\n",
    "        labels = np.zeros(len(dataloader.dataset))\n",
    "        k = 0\n",
    "        for images, target in dataloader:\n",
    "            if cuda:\n",
    "                images = images.cuda()\n",
    "            embeddings[k:k+len(images)] = model.get_embedding(images).data.cpu().numpy()\n",
    "            labels[k:k+len(images)] = target.numpy()\n",
    "            k += len(images)\n",
    "    return embeddings, labels\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e832c436112fef2",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 256, 380, 0.6736842105263158)\n",
      "('Atemayar_Qelisayer', 536, 874, 0.6132723112128147)\n",
      "('Atlantean', 763, 1368, 0.5577485380116959)\n",
      "('Aurek-Besh', 1136, 1862, 0.6100966702470462)\n",
      "('Avesta', 1400, 2356, 0.5942275042444821)\n",
      "('Ge_ez', 1646, 2850, 0.5775438596491228)\n",
      "('Glagolitic', 2010, 3705, 0.5425101214574899)\n",
      "('Gurmukhi', 2342, 4560, 0.5135964912280702)\n",
      "('Kannada', 2590, 5339, 0.4851095710807267)\n",
      "('Keble', 2944, 5833, 0.5047145551174352)\n",
      "('Malayalam', 3344, 6726, 0.4971751412429379)\n",
      "('Manipuri', 3618, 7486, 0.48330216403954046)\n",
      "('Mongolian', 3887, 8056, 0.48249751737835156)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 4429, 8911, 0.49702614745819773)\n",
      "('Oriya', 4650, 9785, 0.4752171691364333)\n",
      "('Sylheti', 4838, 10317, 0.4689347678588737)\n",
      "('Syriac_(Serto)', 5030, 10754, 0.46773293658173704)\n",
      "('Tengwar', 5248, 11229, 0.46736129664262177)\n",
      "('Tibetan', 5617, 12027, 0.46703251018541614)\n",
      "('ULOG', 5924, 12521, 0.4731251497484226)\n",
      "0.4731251497484226\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.4731251497484226"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_results(model, annotated_loader_dict, test_loader_dict, k):\n",
    "    correct=0\n",
    "    total_images = 0\n",
    "    last_layer = list(model.children())[-1]\n",
    "    out_features = last_layer.out_features\n",
    "    for alphabet in annotated_loader_dict.keys():\n",
    "        annotated_embeddings, annotated_targets = extract_embeddings(annotated_loader_dict[alphabet], model, out_features)\n",
    "        test_embeddings, test_targets = extract_embeddings(test_loader_dict[alphabet], model, out_features)\n",
    "        distances=cdist(annotated_embeddings,test_embeddings)\n",
    "        all_image_distances=[]\n",
    "        for i in range(len(test_targets)):\n",
    "            image_distances= []\n",
    "            for j in range(len(distances)):\n",
    "                image_distances.append((distances[j][i], j))\n",
    "            all_image_distances.append(sorted(image_distances))\n",
    "\n",
    "        k_classification = []\n",
    "        for i in range(len(all_image_distances)):\n",
    "            k_classification.append([score[1] for score in all_image_distances[i]][:k])\n",
    "        #print(all_image_distances)\n",
    "        for i in range(len(k_classification)):\n",
    "\n",
    "            if test_targets[i] in k_classification[i]:\n",
    "                correct+=1\n",
    "        total_images+=len(test_targets)\n",
    "        print((alphabet, correct, total_images, correct/total_images))\n",
    "\n",
    "    top_k_accuracy = correct/total_images\n",
    "    print(top_k_accuracy)\n",
    "    return top_k_accuracy\n",
    "get_results(model, annotated_loader_dict, test_loader_dict, 1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e87003112448465",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 336, 380, 0.8842105263157894)\n",
      "('Atemayar_Qelisayer', 693, 874, 0.7929061784897025)\n",
      "('Atlantean', 980, 1368, 0.716374269005848)\n",
      "('Aurek-Besh', 1405, 1862, 0.7545649838882922)\n",
      "('Avesta', 1769, 2356, 0.7508488964346349)\n",
      "('Ge_ez', 2100, 2850, 0.7368421052631579)\n",
      "('Glagolitic', 2563, 3705, 0.6917678812415654)\n",
      "('Gurmukhi', 3054, 4560, 0.6697368421052632)\n",
      "('Kannada', 3438, 5339, 0.6439408128863083)\n",
      "('Keble', 3839, 5833, 0.6581518943939654)\n",
      "('Malayalam', 4381, 6726, 0.651352958667856)\n",
      "('Manipuri', 4772, 7486, 0.6374565856265028)\n",
      "('Mongolian', 5134, 8056, 0.6372889771598809)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 5820, 8911, 0.6531253506901582)\n",
      "('Oriya', 6163, 9785, 0.6298415942769545)\n",
      "('Sylheti', 6448, 10317, 0.624987884074828)\n",
      "('Syriac_(Serto)', 6698, 10754, 0.622838013762321)\n",
      "('Tengwar', 6995, 11229, 0.6229406002315433)\n",
      "('Tibetan', 7516, 12027, 0.6249272470275214)\n",
      "('ULOG', 7893, 12521, 0.6303809599872214)\n",
      "0.6303809599872214\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.6303809599872214"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results(model, annotated_loader_dict, test_loader_dict, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 360, 380, 0.9473684210526315)\n",
      "('Atemayar_Qelisayer', 785, 874, 0.8981693363844394)\n",
      "('Atlantean', 1150, 1368, 0.8406432748538012)\n",
      "('Aurek-Besh', 1593, 1862, 0.855531686358754)\n",
      "('Avesta', 2028, 2356, 0.8607809847198642)\n",
      "('Ge_ez', 2428, 2850, 0.8519298245614035)\n",
      "('Glagolitic', 3023, 3705, 0.8159244264507423)\n",
      "('Gurmukhi', 3687, 4560, 0.8085526315789474)\n",
      "('Kannada', 4188, 5339, 0.7844165574077543)\n",
      "('Keble', 4634, 5833, 0.7944453968798217)\n",
      "('Malayalam', 5322, 6726, 0.7912578055307761)\n",
      "('Manipuri', 5830, 7486, 0.7787870691958322)\n",
      "('Mongolian', 6292, 8056, 0.7810327706057597)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 7058, 8911, 0.7920547637751094)\n",
      "('Oriya', 7554, 9785, 0.7719979560551865)\n",
      "('Sylheti', 7951, 10317, 0.7706697683435108)\n",
      "('Syriac_(Serto)', 8284, 10754, 0.7703180212014135)\n",
      "('Tengwar', 8660, 11229, 0.7712173835604239)\n",
      "('Tibetan', 9335, 12027, 0.7761702835287271)\n",
      "('ULOG', 9757, 12521, 0.7792508585576232)\n",
      "0.7792508585576232\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7792508585576232"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results(model, annotated_loader_dict, test_loader_dict, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 373, 380, 0.9815789473684211)\n",
      "('Atemayar_Qelisayer', 849, 874, 0.971395881006865)\n",
      "('Atlantean', 1283, 1368, 0.9378654970760234)\n",
      "('Aurek-Besh', 1752, 1862, 0.9409237379162191)\n",
      "('Avesta', 2226, 2356, 0.9448217317487266)\n",
      "('Ge_ez', 2672, 2850, 0.9375438596491228)\n",
      "('Glagolitic', 3378, 3705, 0.9117408906882591)\n",
      "('Gurmukhi', 4154, 4560, 0.9109649122807018)\n",
      "('Kannada', 4779, 5339, 0.8951114440906537)\n",
      "('Keble', 5259, 5833, 0.9015943768215327)\n",
      "('Malayalam', 6059, 6726, 0.9008325899494499)\n",
      "('Manipuri', 6676, 7486, 0.8917980229762222)\n",
      "('Mongolian', 7214, 8056, 0.8954816285998014)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 8033, 8911, 0.9014700931433061)\n",
      "('Oriya', 8689, 9785, 0.8879918242207461)\n",
      "('Sylheti', 9162, 10317, 0.8880488514102937)\n",
      "('Syriac_(Serto)', 9556, 10754, 0.8885995908499164)\n",
      "('Tengwar', 9981, 11229, 0.8888592038471814)\n",
      "('Tibetan', 10734, 12027, 0.8924918932402095)\n",
      "('ULOG', 11194, 12521, 0.8940180496765434)\n",
      "0.8940180496765434\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.8940180496765434"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results(model, annotated_loader_dict, test_loader_dict, 8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 2: rotation problem"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f49a6fcc9bcd5994"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load the test data for task 2:\n",
    "# the structure of the test data of task 2 is exactly the same as for task 1,\n",
    "# but now the images are rotated by an unknown angle between 0 and 360 degrees.\n",
    "data_dict_test_task2 = load_data('test_data_task2.pkl')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "800d9fa43d711ae0",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['annotated_images', 'annotated_images_labels', 'unseen_images', 'unseen_images_labels'])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict_test_task2.keys()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfd690817a188882",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# solution and evaluation of task 2:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab7aa34500088f66",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "71298802fa5d6fb8",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4e6e3e82ce917c0f",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e701b2a68bd4d32a",
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 3: Domain knowledge injection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfdbe34799376c36"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['unseen_images_labels', 'annotated_images_labels', 'unseen_images', 'annotated_images', 'unseen_images_preceding_types', 'character_to_type_mapping', 'type_following_probs'])\n"
     ]
    }
   ],
   "source": [
    "# load the test data for task 3:\n",
    "# the structure of the data of task 3 is exactly the same as for task 1, but now our the loaded dictionary contains some additional keys.\n",
    "# These additional keys will be explained in the cells below:\n",
    "\n",
    "data_dict_test_task3 = load_data('test_data_task3.pkl')\n",
    "print(data_dict_test_task3.keys())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa248dbece85da5c",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# The keys 'annotated_images', 'annotated_images_labels', 'unseen_images', 'unseen_images_labels' are the same as for task 1, and the structure of the data is exactly the same. \n",
    "\n",
    "# The key 'unseen_images_preceding_types' maps to the type of the preceding character in the sequence where the unseen image was observed, for each alphabet.\n",
    "# The key 'character_to_type_mapping' maps to the mapping of each character to its type, for each alphabet.\n",
    "# The key 'type_following_probs' maps to the probabilities of each character type being followed by another character type, for each alphabet."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fb6a6237a187493",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphabet: Gurmukhi\n",
      "Some character types that preceded unseen images from the Gurmukhi alphabet: ['I' 'II' 'II' 'I' 'II']\n",
      "There are 855 preceding character types in the Gurmukhi alphabet, and 855 unseen images.\n",
      "Type of character10 from the Gurmukhi alphabet: I\n",
      "Probability of a character of type I following a character of type I in the Gurmukhi alphabet: 0.8962472406181016\n"
     ]
    }
   ],
   "source": [
    "# examples:\n",
    "\n",
    "alphabet = np.random.choice(list(data_dict_test_task3['unseen_images_preceding_types'].keys()))\n",
    "print(f'Alphabet: {alphabet}')\n",
    "\n",
    "\n",
    "preceding_character_types_alphabet = data_dict_test_task3[\"unseen_images_preceding_types\"][alphabet]  # a list\n",
    "print(f'Some character types that preceded unseen images from the {alphabet} alphabet: {np.random.choice(preceding_character_types_alphabet, size=5)}')\n",
    "print(f'There are {len(preceding_character_types_alphabet)} preceding character types in the {alphabet} alphabet, and {len(data_dict_test_task3[\"unseen_images\"][alphabet])} unseen images.')\n",
    "\n",
    "\n",
    "character_to_type_mapping_alphabet = data_dict_test_task3[\"character_to_type_mapping\"][alphabet]  \n",
    "# this is a dict, with as keys the characters and as values the types\n",
    "random_character = np.random.choice(list(character_to_type_mapping_alphabet.keys()))\n",
    "print(f'Type of {random_character} from the {alphabet} alphabet: {character_to_type_mapping_alphabet[random_character]}')\n",
    "\n",
    "\n",
    "\n",
    "type_following_probs_alphabet = data_dict_test_task3[\"type_following_probs\"][alphabet]  # a dict of dicts\n",
    "preceding_type = np.random.choice(list(type_following_probs_alphabet.keys()))\n",
    "following_type = np.random.choice(list(type_following_probs_alphabet[preceding_type].keys()))\n",
    "print(f'Probability of a character of type {following_type} following a character of type {preceding_type} in the {alphabet} alphabet: {type_following_probs_alphabet[preceding_type][following_type]}')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef9bcef5572f0a78",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'Angelic': ['II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II'],\n 'Atemayar_Qelisayer': ['II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I'],\n 'Atlantean': ['I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II'],\n 'Aurek-Besh': ['II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II'],\n 'Avesta': ['I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II'],\n 'Ge_ez': ['II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I'],\n 'Glagolitic': ['II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II'],\n 'Gurmukhi': ['II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II'],\n 'Kannada': ['II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I'],\n 'Keble': ['I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II'],\n 'Malayalam': ['II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I'],\n 'Manipuri': ['I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II'],\n 'Mongolian': ['I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II'],\n 'Old_Church_Slavonic_(Cyrillic)': ['II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II'],\n 'Oriya': ['I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II'],\n 'Sylheti': ['I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II'],\n 'Syriac_(Serto)': ['I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II'],\n 'Tengwar': ['II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I'],\n 'Tibetan': ['II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II'],\n 'ULOG': ['I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'II',\n  'I',\n  'II',\n  'I',\n  'I',\n  'II',\n  'II',\n  'I',\n  'I',\n  'II',\n  'I',\n  'II',\n  'I',\n  'II']}"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict_test_task3['unseen_images_preceding_types']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbaa137b41e610ce",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380\n",
      "494\n",
      "494\n",
      "494\n",
      "494\n",
      "494\n",
      "855\n",
      "855\n",
      "779\n",
      "494\n",
      "893\n",
      "760\n",
      "570\n",
      "855\n",
      "874\n",
      "532\n",
      "437\n",
      "475\n",
      "798\n",
      "494\n"
     ]
    }
   ],
   "source": [
    "char_dict = {f\"character{i:02d}\": i - 1 for i in range(1, 100)}\n",
    "char_dict_rev = {i-1:f\"character{i:02d}\" for i in range(1, 100)}\n",
    "annotated_loader_dict_task3 = {}\n",
    "annotated_images_dict_task3 = data_dict_test_task3['annotated_images']\n",
    "annotated_targets_dict_task3 = data_dict_test_task3['annotated_images_labels']\n",
    "# Iterate over the dictionary items (label: images_list)\n",
    "for alphabet in alphabets_test:\n",
    "    images = annotated_images_dict_task3[alphabet]\n",
    "    targets = annotated_targets_dict_task3[alphabet]\n",
    "    targets = [char_dict[key] for key in targets]\n",
    "    annotated_loader = torch.utils.data.DataLoader(list(zip(images, targets, targets)), batch_size=200)\n",
    "    annotated_loader_dict_task3[alphabet] = annotated_loader\n",
    "\n",
    "\n",
    "test_loader_dict_task3 = {}\n",
    "test_images_dict_task3 = data_dict_test_task3['unseen_images']\n",
    "test_targets_dict_task3 = data_dict_test_task3['unseen_images_labels']\n",
    "preceding_type_dict = data_dict_test_task3['unseen_images_preceding_types']\n",
    "mapping_type_dict = data_dict_test_task3['character_to_type_mapping']\n",
    "# Iterate over the dictionary items (label: images_list)\n",
    "for alphabet in alphabets_test:\n",
    "    images = test_images_dict[alphabet]\n",
    "    targets = test_targets_dict[alphabet]\n",
    "    targets = [char_dict[key] for key in targets]\n",
    "    preceding_type = preceding_type_dict[alphabet]\n",
    "    print(len(preceding_type))\n",
    "    #mapping_type = [mapping_type_dict[alphabet][char_dict_rev[target]] for target in targets]\n",
    "    test_loader = torch.utils.data.DataLoader(list(zip(images, targets, preceding_type)), batch_size=200)\n",
    "    test_loader_dict_task3[alphabet] = test_loader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "700c29e735fd10c5",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('II', 'II', 'II', 'II', 'II', 'II', 'I', 'I', 'II', 'I', 'II', 'II', 'II', 'I', 'II', 'I', 'II', 'II', 'II', 'I', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'II', 'II', 'I', 'II', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'I', 'II', 'I', 'II', 'II', 'I', 'II', 'I', 'II', 'I', 'I', 'II', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'II', 'I', 'II', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'I', 'II', 'II', 'II', 'II', 'I', 'II', 'II', 'I', 'I', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'II', 'I', 'II', 'I', 'II', 'II', 'II', 'I', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'I', 'I', 'I', 'II', 'II', 'II', 'I', 'I', 'II', 'I', 'II', 'II', 'II', 'II', 'I', 'II', 'II', 'I', 'I', 'II', 'II', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'I', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'I', 'I', 'I', 'I', 'II', 'I', 'II', 'I')\n",
      "200\n",
      "Batch 0:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "200\n",
      "Targets (labels):\n",
      "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "         8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10])\n",
      "('I', 'II', 'I', 'II', 'II', 'I', 'I', 'II', 'II', 'II', 'II', 'I', 'II', 'I', 'I', 'II', 'I', 'I', 'I', 'I', 'I', 'II', 'II', 'II', 'II', 'II', 'I', 'II', 'I', 'II', 'I', 'II', 'II', 'II', 'II', 'I', 'II', 'II', 'I', 'II', 'II', 'I', 'I', 'I', 'II', 'II', 'I', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'I', 'I', 'I', 'I', 'II', 'I', 'I', 'I', 'II', 'I', 'I', 'II', 'II', 'I', 'I', 'I', 'II', 'II', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'II', 'I', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'II', 'I', 'II', 'II', 'I', 'II', 'I', 'I', 'I', 'II', 'II', 'II', 'II', 'II', 'II', 'I', 'II', 'II', 'II', 'I', 'II', 'I', 'II', 'I', 'I', 'I', 'II', 'II', 'II', 'I', 'II', 'II', 'I', 'I', 'II', 'II', 'II', 'I', 'I', 'I', 'II', 'II', 'I', 'II', 'II', 'I', 'II', 'I', 'I', 'I', 'I', 'I', 'II', 'II')\n",
      "180\n",
      "Batch 1:\n",
      "Inputs (features):\n",
      "<class 'torch.Tensor'>\n",
      "180\n",
      "Targets (labels):\n",
      "tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15,\n",
      "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17,\n",
      "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18,\n",
      "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19,\n",
      "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#print(len(annotated_loader_dict['Atemayar_Qelisayer']))\n",
    "i=0\n",
    "for batch_idx, (inputs, targets, p) in enumerate(test_loader_dict_task3['Angelic']):\n",
    "    print(p)\n",
    "    print(len(p))\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(\"Inputs (features):\")\n",
    "    print(type(inputs))\n",
    "    print(len(targets))  # Print input data (features)\n",
    "    print(\"Targets (labels):\")\n",
    "    print(targets)\n",
    "    i+=1\n",
    "print(i)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb7d09f31839b40",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 'character01',\n 1: 'character02',\n 2: 'character03',\n 3: 'character04',\n 4: 'character05',\n 5: 'character06',\n 6: 'character07',\n 7: 'character08',\n 8: 'character09',\n 9: 'character10',\n 10: 'character11',\n 11: 'character12',\n 12: 'character13',\n 13: 'character14',\n 14: 'character15',\n 15: 'character16',\n 16: 'character17',\n 17: 'character18',\n 18: 'character19',\n 19: 'character20',\n 20: 'character21',\n 21: 'character22',\n 22: 'character23',\n 23: 'character24',\n 24: 'character25',\n 25: 'character26',\n 26: 'character27',\n 27: 'character28',\n 28: 'character29',\n 29: 'character30',\n 30: 'character31',\n 31: 'character32',\n 32: 'character33',\n 33: 'character34',\n 34: 'character35',\n 35: 'character36',\n 36: 'character37',\n 37: 'character38',\n 38: 'character39',\n 39: 'character40',\n 40: 'character41',\n 41: 'character42',\n 42: 'character43',\n 43: 'character44',\n 44: 'character45',\n 45: 'character46',\n 46: 'character47',\n 47: 'character48',\n 48: 'character49',\n 49: 'character50',\n 50: 'character51',\n 51: 'character52',\n 52: 'character53',\n 53: 'character54',\n 54: 'character55',\n 55: 'character56',\n 56: 'character57',\n 57: 'character58',\n 58: 'character59',\n 59: 'character60',\n 60: 'character61',\n 61: 'character62',\n 62: 'character63',\n 63: 'character64',\n 64: 'character65',\n 65: 'character66',\n 66: 'character67',\n 67: 'character68',\n 68: 'character69',\n 69: 'character70',\n 70: 'character71',\n 71: 'character72',\n 72: 'character73',\n 73: 'character74',\n 74: 'character75',\n 75: 'character76',\n 76: 'character77',\n 77: 'character78',\n 78: 'character79',\n 79: 'character80',\n 80: 'character81',\n 81: 'character82',\n 82: 'character83',\n 83: 'character84',\n 84: 'character85',\n 85: 'character86',\n 86: 'character87',\n 87: 'character88',\n 88: 'character89',\n 89: 'character90',\n 90: 'character91',\n 91: 'character92',\n 92: 'character93',\n 93: 'character94',\n 94: 'character95',\n 95: 'character96',\n 96: 'character97',\n 97: 'character98',\n 98: 'character99'}"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dict_rev"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Angelic': {'I': {'I': 0.2867647058823529, 'II': 0.7132352941176471},\n  'II': {'I': 0.5409836065573771, 'II': 0.45901639344262296}},\n 'Atemayar_Qelisayer': {'I': {'I': 0.0, 'II': 1.0},\n  'II': {'I': 0.8735632183908046, 'II': 0.12643678160919541}},\n 'Atlantean': {'I': {'I': 0.8113207547169812, 'II': 0.18867924528301888},\n  'II': {'I': 0.06382978723404255, 'II': 0.9361702127659575}},\n 'Aurek-Besh': {'I': {'I': 0.12096774193548387, 'II': 0.8790322580645161},\n  'II': {'I': 0.9351351351351351, 'II': 0.06486486486486487}},\n 'Avesta': {'I': {'I': 0.4, 'II': 0.6},\n  'II': {'I': 0.7990867579908676, 'II': 0.2009132420091324}},\n 'Ge_ez': {'I': {'I': 0.5808383233532934, 'II': 0.41916167664670656},\n  'II': {'I': 0.3425076452599388, 'II': 0.6574923547400612}},\n 'Glagolitic': {'I': {'I': 0.057692307692307696, 'II': 0.9423076923076923},\n  'II': {'I': 0.7311608961303462, 'II': 0.26883910386965376}},\n 'Gurmukhi': {'I': {'I': 0.8962472406181016, 'II': 0.10375275938189846},\n  'II': {'I': 0.17164179104477612, 'II': 0.8283582089552238}},\n 'Kannada': {'I': {'I': 0.7773851590106007, 'II': 0.2226148409893993},\n  'II': {'I': 0.1643192488262911, 'II': 0.8356807511737089}},\n 'Keble': {'I': {'I': 0.6237623762376238, 'II': 0.37623762376237624},\n  'II': {'I': 1.0, 'II': 0.0}},\n 'Malayalam': {'I': {'I': 0.3764172335600907, 'II': 0.6235827664399093},\n  'II': {'I': 0.5995575221238938, 'II': 0.4004424778761062}},\n 'Manipuri': {'I': {'I': 0.7532258064516129, 'II': 0.2467741935483871},\n  'II': {'I': 0.8714285714285714, 'II': 0.12857142857142856}},\n 'Mongolian': {'I': {'I': 0.0, 'II': 1.0},\n  'II': {'I': 0.5679347826086957, 'II': 0.4320652173913043}},\n 'Old_Church_Slavonic_(Cyrillic)': {'I': {'I': 0.1588447653429603,\n   'II': 0.8411552346570397},\n  'II': {'I': 0.6799307958477508, 'II': 0.32006920415224915}},\n 'Oriya': {'I': {'I': 0.6217105263157895, 'II': 0.3782894736842105},\n  'II': {'I': 0.793233082706767, 'II': 0.20676691729323307}},\n 'Sylheti': {'I': {'I': 0.7608695652173914, 'II': 0.2391304347826087},\n  'II': {'I': 0.36423841059602646, 'II': 0.6357615894039735}},\n 'Syriac_(Serto)': {'I': {'I': 0.7770700636942676, 'II': 0.2229299363057325},\n  'II': {'I': 0.9512195121951219, 'II': 0.04878048780487805}},\n 'Tengwar': {'I': {'I': 0.5041666666666667, 'II': 0.49583333333333335},\n  'II': {'I': 0.5361702127659574, 'II': 0.46382978723404256}},\n 'Tibetan': {'I': {'I': 0.9932885906040269, 'II': 0.006711409395973154},\n  'II': {'I': 0.016, 'II': 0.984}},\n 'ULOG': {'I': {'I': 0.4, 'II': 0.6},\n  'II': {'I': 0.5836431226765799, 'II': 0.4163568773234201}}}"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict_test_task3['type_following_probs']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 257, 380, 0.6763157894736842)\n",
      "('Atemayar_Qelisayer', 572, 874, 0.6544622425629291)\n",
      "('Atlantean', 828, 1368, 0.6052631578947368)\n",
      "('Aurek-Besh', 1203, 1862, 0.6460794844253491)\n",
      "('Avesta', 1478, 2356, 0.6273344651952462)\n",
      "('Ge_ez', 1725, 2850, 0.6052631578947368)\n",
      "('Glagolitic', 2128, 3705, 0.5743589743589743)\n",
      "('Gurmukhi', 2517, 4560, 0.5519736842105263)\n",
      "('Kannada', 2794, 5339, 0.52331897359056)\n",
      "('Keble', 3146, 5833, 0.5393451054345962)\n",
      "('Malayalam', 3542, 6726, 0.5266131430270592)\n",
      "('Manipuri', 3802, 7486, 0.5078813785733369)\n",
      "('Mongolian', 4097, 8056, 0.5085650446871897)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 4663, 8911, 0.523285826506565)\n",
      "('Oriya', 4883, 9785, 0.49902912621359224)\n",
      "('Sylheti', 5066, 10317, 0.4910342153726859)\n",
      "('Syriac_(Serto)', 5247, 10754, 0.4879114748000744)\n",
      "('Tengwar', 5466, 11229, 0.48677531391931605)\n",
      "('Tibetan', 5964, 12027, 0.49588426041406836)\n",
      "('ULOG', 6266, 12521, 0.5004392620397732)\n",
      "0.5004392620397732\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.5004392620397732"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_embeddings_task3(dataloader, model, out_features, test=False):\n",
    "    type_dict = {'I':0, 'II':1}\n",
    "    cuda = torch.cuda.is_available()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        embeddings = np.zeros((len(dataloader.dataset), out_features))\n",
    "        labels = np.zeros(len(dataloader.dataset))\n",
    "        preceding_types_list = np.zeros(len(dataloader.dataset))\n",
    "        k = 0\n",
    "        for images, target, preceding_type in dataloader:\n",
    "            if cuda:\n",
    "                images = images.cuda()\n",
    "            embeddings[k:k+len(images)] = model.get_embedding(images).data.cpu().numpy()\n",
    "            labels[k:k+len(images)] = target.numpy()\n",
    "            if test==True:\n",
    "                preceding_type = [type_dict[i] for i in preceding_type]\n",
    "                preceding_types_list[k:k+len(images)] = preceding_type\n",
    "            k += len(images)\n",
    "    return embeddings, labels, preceding_types_list\n",
    "\n",
    "def get_results_task3(model, annotated_loader_dict, test_loader_dict, data_dict, k):\n",
    "    char_dict_rev = {i-1:f\"character{i:02d}\" for i in range(1, 100)}\n",
    "    type_dict = {0:'I', 1:'II'}\n",
    "    correct=0\n",
    "    total_images = 0\n",
    "    last_layer = list(model.children())[-1]\n",
    "    out_features = last_layer.out_features\n",
    "    for alphabet in annotated_loader_dict.keys():\n",
    "        annotated_embeddings, annotated_targets, n = extract_embeddings_task3(annotated_loader_dict[alphabet], model, out_features)\n",
    "        test_embeddings, test_targets, preceding_types = extract_embeddings_task3(test_loader_dict[alphabet], model, out_features, test=True)\n",
    "        distances=cdist(annotated_embeddings,test_embeddings)\n",
    "        all_image_distances=[]\n",
    "        # print(len(preceding_types))\n",
    "        # print(preceding_types)\n",
    "        # print(len(test_targets))\n",
    "        for i in range(len(test_targets)):\n",
    "            #print(i)\n",
    "            image_distances= []\n",
    "            for j in range(len(distances)):\n",
    "                character_type = data_dict['character_to_type_mapping'][alphabet][char_dict_rev[j]]\n",
    "                probability = data_dict['type_following_probs'][alphabet][type_dict[preceding_types[i]]][character_type]\n",
    "                if probability==0:\n",
    "                    probability=0.0000001\n",
    "                image_distances.append((distances[j][i] - probability, j))\n",
    "            all_image_distances.append(sorted(image_distances))\n",
    "        #print(all_image_distances)\n",
    "        k_classification = []\n",
    "        for i in range(len(all_image_distances)):\n",
    "            k_classification.append([score[1] for score in all_image_distances[i]][:k])\n",
    "        #print(all_image_distances)\n",
    "        for i in range(len(k_classification)):\n",
    "\n",
    "            if test_targets[i] in k_classification[i]:\n",
    "                correct+=1\n",
    "        total_images+=len(test_targets)\n",
    "        print((alphabet, correct, total_images, correct/total_images))\n",
    "\n",
    "    top_k_accuracy = correct/total_images\n",
    "    print(top_k_accuracy)\n",
    "    return top_k_accuracy\n",
    "get_results_task3(model, annotated_loader_dict_task3, test_loader_dict_task3, data_dict_test_task3, 1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "596ab2a615cb44e9",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 332, 380, 0.8736842105263158)\n",
      "('Atemayar_Qelisayer', 730, 874, 0.8352402745995423)\n",
      "('Atlantean', 1062, 1368, 0.7763157894736842)\n",
      "('Aurek-Besh', 1491, 1862, 0.8007518796992481)\n",
      "('Avesta', 1858, 2356, 0.7886247877758913)\n",
      "('Ge_ez', 2193, 2850, 0.7694736842105263)\n",
      "('Glagolitic', 2719, 3705, 0.7338731443994602)\n",
      "('Gurmukhi', 3283, 4560, 0.7199561403508772)\n",
      "('Kannada', 3692, 5339, 0.6915152650309047)\n",
      "('Keble', 4094, 5833, 0.7018686782101834)\n",
      "('Malayalam', 4646, 6726, 0.6907523044900387)\n",
      "('Manipuri', 5016, 7486, 0.6700507614213198)\n",
      "('Mongolian', 5404, 8056, 0.6708043694141013)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 6099, 8911, 0.6844349680170576)\n",
      "('Oriya', 6444, 9785, 0.6585590189064895)\n",
      "('Sylheti', 6741, 10317, 0.6533876126781041)\n",
      "('Syriac_(Serto)', 6989, 10754, 0.6498977124790776)\n",
      "('Tengwar', 7289, 11229, 0.6491228070175439)\n",
      "('Tibetan', 7915, 12027, 0.6581026024777584)\n",
      "('ULOG', 8291, 12521, 0.6621675585017172)\n",
      "0.6621675585017172\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.6621675585017172"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results_task3(model, annotated_loader_dict_task3, test_loader_dict_task3, data_dict_test_task3, 2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2656ede1e4adbe8",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 359, 380, 0.9447368421052632)\n",
      "('Atemayar_Qelisayer', 812, 874, 0.9290617848970252)\n",
      "('Atlantean', 1200, 1368, 0.8771929824561403)\n",
      "('Aurek-Besh', 1652, 1862, 0.8872180451127819)\n",
      "('Avesta', 2092, 2356, 0.8879456706281834)\n",
      "('Ge_ez', 2501, 2850, 0.8775438596491228)\n",
      "('Glagolitic', 3145, 3705, 0.8488529014844804)\n",
      "('Gurmukhi', 3837, 4560, 0.8414473684210526)\n",
      "('Kannada', 4366, 5339, 0.8177561341075108)\n",
      "('Keble', 4811, 5833, 0.8247899879993142)\n",
      "('Malayalam', 5493, 6726, 0.8166815343443354)\n",
      "('Manipuri', 5985, 7486, 0.799492385786802)\n",
      "('Mongolian', 6463, 8056, 0.8022591857000994)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 7238, 8911, 0.812254516889238)\n",
      "('Oriya', 7716, 9785, 0.7885539090444558)\n",
      "('Sylheti', 8113, 10317, 0.7863720073664825)\n",
      "('Syriac_(Serto)', 8444, 10754, 0.7851962060628603)\n",
      "('Tengwar', 8818, 11229, 0.7852880933297711)\n",
      "('Tibetan', 9541, 12027, 0.7932984119065436)\n",
      "('ULOG', 9960, 12521, 0.7954636211165242)\n",
      "0.7954636211165242\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7954636211165242"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results_task3(model, annotated_loader_dict_task3, test_loader_dict_task3, data_dict_test_task3, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angelic', 374, 380, 0.9842105263157894)\n",
      "('Atemayar_Qelisayer', 858, 874, 0.9816933638443935)\n",
      "('Atlantean', 1311, 1368, 0.9583333333333334)\n",
      "('Aurek-Besh', 1795, 1862, 0.9640171858216972)\n",
      "('Avesta', 2271, 2356, 0.9639219015280136)\n",
      "('Ge_ez', 2714, 2850, 0.952280701754386)\n",
      "('Glagolitic', 3451, 3705, 0.9314439946018893)\n",
      "('Gurmukhi', 4248, 4560, 0.9315789473684211)\n",
      "('Kannada', 4893, 5339, 0.9164637572579135)\n",
      "('Keble', 5370, 5833, 0.9206240356591805)\n",
      "('Malayalam', 6168, 6726, 0.9170383586083853)\n",
      "('Manipuri', 6787, 7486, 0.9066257013091104)\n",
      "('Mongolian', 7327, 8056, 0.9095084409136047)\n",
      "('Old_Church_Slavonic_(Cyrillic)', 8150, 8911, 0.9145999326674896)\n",
      "('Oriya', 8792, 9785, 0.8985181400102197)\n",
      "('Sylheti', 9274, 10317, 0.898904720364447)\n",
      "('Syriac_(Serto)', 9671, 10754, 0.8992932862190812)\n",
      "('Tengwar', 10096, 11229, 0.8991005432362632)\n",
      "('Tibetan', 10871, 12027, 0.9038829300740001)\n",
      "('ULOG', 11332, 12521, 0.9050395335835796)\n",
      "0.9050395335835796\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9050395335835796"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results_task3(model, annotated_loader_dict_task3, test_loader_dict_task3, data_dict_test_task3, 8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "42d46e71207afe47"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}